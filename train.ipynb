{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# restart notebook when retrain model as some initial problem\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from cifar10 import cifar10_train\n",
    "from cifar10.cifar10_args import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "/home/ipython/cnn-cifar10/tb_log/vgg1/train\n",
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "(256,)\n",
      "INFO:tensorflow:Summary name vgg1-conv0/weight_loss (raw) is illegal; using vgg1-conv0/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg1-conv1/weight_loss (raw) is illegal; using vgg1-conv1/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local3/weight_loss (raw) is illegal; using local3/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local4/weight_loss (raw) is illegal; using local4/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name softmax_linear/weight_loss (raw) is illegal; using softmax_linear/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name cross_entropy (raw) is illegal; using cross_entropy__raw_ instead.\n",
      "INFO:tensorflow:Summary name total_loss (raw) is illegal; using total_loss__raw_ instead.\n",
      "10000000\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /home/ipython/cnn-cifar10/tb_log/vgg1/train/model.ckpt.\n",
      "2017-05-26 10:21:03.409285: step 0, loss = 11.25 (214.8 examples/sec; 1.192 sec/batch)\n",
      "2017-05-26 10:21:04.760165: step 10, loss = 7.77 (1895.1 examples/sec; 0.135 sec/batch)\n",
      "2017-05-26 10:21:06.336740: step 20, loss = 5.45 (1623.8 examples/sec; 0.158 sec/batch)\n",
      "2017-05-26 10:21:09.542961: step 40, loss = 3.06 (1620.7 examples/sec; 0.158 sec/batch)\n",
      "2017-05-26 10:21:11.130423: step 50, loss = 2.64 (1612.6 examples/sec; 0.159 sec/batch)\n",
      "2017-05-26 10:21:12.707888: step 60, loss = 2.35 (1622.9 examples/sec; 0.158 sec/batch)\n",
      "2017-05-26 10:21:14.285680: step 70, loss = 1.98 (1622.5 examples/sec; 0.158 sec/batch)\n",
      "2017-05-26 10:21:15.881065: step 80, loss = 2.03 (1604.6 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:21:17.446983: step 90, loss = 1.86 (1634.8 examples/sec; 0.157 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 6.16981\n",
      "2017-05-26 10:21:19.431650: step 100, loss = 1.88 (1289.9 examples/sec; 0.198 sec/batch)\n",
      "2017-05-26 10:21:20.876802: step 110, loss = 1.92 (1771.4 examples/sec; 0.145 sec/batch)\n",
      "2017-05-26 10:21:22.471864: step 120, loss = 1.88 (1605.0 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:21:24.051468: step 130, loss = 1.87 (1620.7 examples/sec; 0.158 sec/batch)\n",
      "2017-05-26 10:21:25.627413: step 140, loss = 1.88 (1624.4 examples/sec; 0.158 sec/batch)\n",
      "2017-05-26 10:21:27.225031: step 150, loss = 1.84 (1602.4 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:21:28.834485: step 160, loss = 1.79 (1590.6 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:21:30.403471: step 170, loss = 1.73 (1631.6 examples/sec; 0.157 sec/batch)\n",
      "2017-05-26 10:21:32.007933: step 180, loss = 1.83 (1595.6 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:21:33.611688: step 190, loss = 1.80 (1596.3 examples/sec; 0.160 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 6.19411\n",
      "2017-05-26 10:21:35.573495: step 200, loss = 1.75 (1304.9 examples/sec; 0.196 sec/batch)\n",
      "2017-05-26 10:21:37.051742: step 210, loss = 1.62 (1731.8 examples/sec; 0.148 sec/batch)\n",
      "2017-05-26 10:21:40.213189: step 230, loss = 1.54 (1629.9 examples/sec; 0.157 sec/batch)\n",
      "2017-05-26 10:21:41.794432: step 240, loss = 1.48 (1619.0 examples/sec; 0.158 sec/batch)\n",
      "2017-05-26 10:21:43.397756: step 250, loss = 1.61 (1596.7 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:21:44.981128: step 260, loss = 1.54 (1616.8 examples/sec; 0.158 sec/batch)\n",
      "2017-05-26 10:21:46.609619: step 270, loss = 1.65 (1572.0 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:21:48.202523: step 280, loss = 1.62 (1607.1 examples/sec; 0.159 sec/batch)\n",
      "2017-05-26 10:21:49.818300: step 290, loss = 1.60 (1584.4 examples/sec; 0.162 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 6.14635\n",
      "2017-05-26 10:21:51.843582: step 300, loss = 1.50 (1264.0 examples/sec; 0.203 sec/batch)\n",
      "2017-05-26 10:21:53.278188: step 310, loss = 1.64 (1784.5 examples/sec; 0.143 sec/batch)\n",
      "2017-05-26 10:21:54.854199: step 320, loss = 1.51 (1624.4 examples/sec; 0.158 sec/batch)\n",
      "2017-05-26 10:21:56.443332: step 330, loss = 1.59 (1610.9 examples/sec; 0.159 sec/batch)\n",
      "2017-05-26 10:21:58.060267: step 340, loss = 1.45 (1583.2 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:21:59.640048: step 350, loss = 1.45 (1620.5 examples/sec; 0.158 sec/batch)\n",
      "2017-05-26 10:22:01.313119: step 360, loss = 1.61 (1530.1 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:22:02.891510: step 370, loss = 1.44 (1621.9 examples/sec; 0.158 sec/batch)\n",
      "2017-05-26 10:22:04.502157: step 380, loss = 1.41 (1589.4 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:22:06.076173: step 390, loss = 1.44 (1626.4 examples/sec; 0.157 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 6.08521\n",
      "2017-05-26 10:22:08.277098: step 400, loss = 1.51 (1163.2 examples/sec; 0.220 sec/batch)\n",
      "2017-05-26 10:22:09.558586: step 410, loss = 1.44 (1997.7 examples/sec; 0.128 sec/batch)\n",
      "2017-05-26 10:22:12.817356: step 430, loss = 1.54 (1575.6 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:22:14.411281: step 440, loss = 1.49 (1606.1 examples/sec; 0.159 sec/batch)\n",
      "2017-05-26 10:22:16.017240: step 450, loss = 1.53 (1594.1 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:22:17.625463: step 460, loss = 1.56 (1591.8 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:22:19.279423: step 470, loss = 1.38 (1547.8 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:22:20.846347: step 480, loss = 1.47 (1633.8 examples/sec; 0.157 sec/batch)\n",
      "2017-05-26 10:22:22.428745: step 490, loss = 1.47 (1617.8 examples/sec; 0.158 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 6.22194\n",
      "2017-05-26 10:22:24.350354: step 500, loss = 1.42 (1332.2 examples/sec; 0.192 sec/batch)\n",
      "2017-05-26 10:22:25.868025: step 510, loss = 1.48 (1686.8 examples/sec; 0.152 sec/batch)\n",
      "2017-05-26 10:22:27.507110: step 520, loss = 1.35 (1561.8 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:22:29.504510: step 530, loss = 1.51 (1281.7 examples/sec; 0.200 sec/batch)\n",
      "2017-05-26 10:22:31.635038: step 540, loss = 1.57 (1201.6 examples/sec; 0.213 sec/batch)\n",
      "2017-05-26 10:22:33.481822: step 550, loss = 1.32 (1386.2 examples/sec; 0.185 sec/batch)\n",
      "2017-05-26 10:22:35.244619: step 560, loss = 1.28 (1452.2 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:22:36.928847: step 570, loss = 1.39 (1520.0 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:22:38.582878: step 580, loss = 1.35 (1547.7 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:22:40.192199: step 590, loss = 1.49 (1590.7 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:22:45.215277: step 620, loss = 1.24 (1602.1 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:22:46.844337: step 630, loss = 1.45 (1571.5 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:22:48.648973: step 640, loss = 1.40 (1418.6 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:22:50.728190: step 650, loss = 1.40 (1231.2 examples/sec; 0.208 sec/batch)\n",
      "2017-05-26 10:22:52.704941: step 660, loss = 1.43 (1295.1 examples/sec; 0.198 sec/batch)\n",
      "2017-05-26 10:22:54.502918: step 670, loss = 1.55 (1423.8 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:22:56.257200: step 680, loss = 1.30 (1459.3 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:22:57.934248: step 690, loss = 1.23 (1526.5 examples/sec; 0.168 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.62178\n",
      "2017-05-26 10:22:59.924862: step 700, loss = 1.41 (1286.0 examples/sec; 0.199 sec/batch)\n",
      "2017-05-26 10:23:01.563399: step 710, loss = 1.39 (1562.4 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:23:03.375058: step 720, loss = 1.38 (1413.1 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:23:05.069958: step 730, loss = 1.31 (1510.4 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:23:06.708113: step 740, loss = 1.31 (1562.7 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:23:08.365817: step 750, loss = 1.37 (1544.3 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:23:10.139786: step 760, loss = 1.26 (1443.1 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:23:11.946287: step 770, loss = 1.37 (1417.1 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:23:13.582898: step 780, loss = 1.24 (1564.2 examples/sec; 0.164 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.70773\n",
      "2017-05-26 10:23:17.447071: step 800, loss = 1.35 (1143.3 examples/sec; 0.224 sec/batch)\n",
      "2017-05-26 10:23:18.997668: step 810, loss = 1.31 (1651.0 examples/sec; 0.155 sec/batch)\n",
      "2017-05-26 10:23:20.694895: step 820, loss = 1.38 (1508.3 examples/sec; 0.170 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-26 10:23:22.294503: step 830, loss = 1.29 (1600.4 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:23:23.954461: step 840, loss = 1.38 (1542.2 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:23:25.750680: step 850, loss = 1.33 (1425.2 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:23:27.521342: step 860, loss = 1.36 (1445.8 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:23:29.278958: step 870, loss = 1.23 (1456.5 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:23:30.936200: step 880, loss = 1.32 (1544.7 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:23:32.599708: step 890, loss = 1.33 (1538.9 examples/sec; 0.166 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.74777\n",
      "2017-05-26 10:23:34.845155: step 900, loss = 1.41 (1140.1 examples/sec; 0.225 sec/batch)\n",
      "2017-05-26 10:23:36.414404: step 910, loss = 1.34 (1631.4 examples/sec; 0.157 sec/batch)\n",
      "2017-05-26 10:23:38.063171: step 920, loss = 1.33 (1552.7 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:23:39.688037: step 930, loss = 1.35 (1575.5 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:23:41.427125: step 940, loss = 1.37 (1472.0 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:23:43.186524: step 950, loss = 1.31 (1455.0 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:23:44.885099: step 960, loss = 1.28 (1507.1 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:23:49.943389: step 990, loss = 1.45 (1447.9 examples/sec; 0.177 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.7408\n",
      "2017-05-26 10:23:52.263529: step 1000, loss = 1.18 (1103.4 examples/sec; 0.232 sec/batch)\n",
      "2017-05-26 10:23:54.600392: step 1010, loss = 1.26 (1095.5 examples/sec; 0.234 sec/batch)\n",
      "2017-05-26 10:23:56.975826: step 1020, loss = 1.39 (1077.7 examples/sec; 0.238 sec/batch)\n",
      "2017-05-26 10:23:59.103681: step 1030, loss = 1.39 (1203.1 examples/sec; 0.213 sec/batch)\n",
      "2017-05-26 10:24:01.035237: step 1040, loss = 1.34 (1325.4 examples/sec; 0.193 sec/batch)\n",
      "2017-05-26 10:24:02.819020: step 1050, loss = 1.33 (1435.2 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:24:04.557195: step 1060, loss = 1.43 (1472.8 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:24:06.189683: step 1070, loss = 1.23 (1568.2 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:24:07.877888: step 1080, loss = 1.31 (1516.4 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:24:09.478448: step 1090, loss = 1.23 (1599.4 examples/sec; 0.160 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.22257\n",
      "2017-05-26 10:24:11.410301: step 1100, loss = 1.21 (1325.2 examples/sec; 0.193 sec/batch)\n",
      "2017-05-26 10:24:12.897634: step 1110, loss = 1.32 (1721.2 examples/sec; 0.149 sec/batch)\n",
      "2017-05-26 10:24:14.543390: step 1120, loss = 1.18 (1555.5 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:24:16.239538: step 1130, loss = 1.27 (1509.3 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:24:20.469110: step 1150, loss = 1.27 (1253.7 examples/sec; 0.204 sec/batch)\n",
      "2017-05-26 10:24:22.283963: step 1160, loss = 1.30 (1410.6 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:24:24.059435: step 1170, loss = 1.36 (1441.9 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:24:25.692636: step 1180, loss = 1.25 (1567.5 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:24:27.323087: step 1190, loss = 1.32 (1570.1 examples/sec; 0.163 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.52731\n",
      "2017-05-26 10:24:29.501786: step 1200, loss = 1.26 (1175.0 examples/sec; 0.218 sec/batch)\n",
      "2017-05-26 10:24:31.104500: step 1210, loss = 1.19 (1597.3 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:24:32.845123: step 1220, loss = 1.22 (1470.7 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:24:34.475308: step 1230, loss = 1.19 (1570.4 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:24:36.127838: step 1240, loss = 1.16 (1549.1 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:24:38.106060: step 1250, loss = 1.29 (1294.1 examples/sec; 0.198 sec/batch)\n",
      "2017-05-26 10:24:40.039517: step 1260, loss = 1.18 (1324.1 examples/sec; 0.193 sec/batch)\n",
      "2017-05-26 10:24:41.668504: step 1270, loss = 1.21 (1571.5 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:24:43.307152: step 1280, loss = 1.33 (1562.3 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:24:45.021996: step 1290, loss = 1.20 (1492.8 examples/sec; 0.171 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.65065\n",
      "2017-05-26 10:24:47.199112: step 1300, loss = 1.26 (1175.9 examples/sec; 0.218 sec/batch)\n",
      "2017-05-26 10:24:48.814135: step 1310, loss = 1.26 (1585.1 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:24:53.979144: step 1340, loss = 1.24 (1397.0 examples/sec; 0.183 sec/batch)\n",
      "2017-05-26 10:24:55.759343: step 1350, loss = 1.17 (1438.0 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:24:57.420469: step 1360, loss = 1.23 (1541.1 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:24:59.086416: step 1370, loss = 1.22 (1536.7 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:25:00.778439: step 1380, loss = 1.29 (1513.0 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:25:02.553734: step 1390, loss = 1.30 (1442.0 examples/sec; 0.178 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.7042\n",
      "2017-05-26 10:25:04.730175: step 1400, loss = 1.20 (1176.2 examples/sec; 0.218 sec/batch)\n",
      "2017-05-26 10:25:06.214983: step 1410, loss = 1.19 (1724.1 examples/sec; 0.148 sec/batch)\n",
      "2017-05-26 10:25:07.868511: step 1420, loss = 1.07 (1548.2 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:25:09.662123: step 1430, loss = 1.20 (1427.3 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:25:11.479368: step 1440, loss = 1.22 (1408.7 examples/sec; 0.182 sec/batch)\n",
      "2017-05-26 10:25:13.165558: step 1450, loss = 1.14 (1518.2 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:25:14.775199: step 1460, loss = 1.36 (1590.4 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:25:16.445304: step 1470, loss = 1.17 (1532.8 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:25:18.247204: step 1480, loss = 1.29 (1420.7 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:25:19.992637: step 1490, loss = 1.31 (1466.7 examples/sec; 0.175 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.73625\n",
      "2017-05-26 10:25:25.213282: step 1520, loss = 1.29 (1500.8 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:25:26.993827: step 1530, loss = 1.23 (1437.8 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:25:28.723912: step 1540, loss = 1.19 (1479.7 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:25:30.338670: step 1550, loss = 1.21 (1585.4 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:25:31.978198: step 1560, loss = 1.24 (1561.4 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:25:33.775627: step 1570, loss = 1.24 (1424.3 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:25:35.562418: step 1580, loss = 1.14 (1432.7 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:25:37.231017: step 1590, loss = 1.23 (1534.2 examples/sec; 0.167 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.85475\n",
      "2017-05-26 10:25:39.244389: step 1600, loss = 1.23 (1271.5 examples/sec; 0.201 sec/batch)\n",
      "2017-05-26 10:25:40.799907: step 1610, loss = 1.19 (1645.8 examples/sec; 0.156 sec/batch)\n",
      "2017-05-26 10:25:42.577706: step 1620, loss = 1.19 (1440.0 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:25:44.358994: step 1630, loss = 1.25 (1437.2 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:25:45.984503: step 1640, loss = 1.21 (1574.9 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:25:47.621049: step 1650, loss = 1.11 (1564.3 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:25:49.377629: step 1660, loss = 1.06 (1457.4 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:25:51.189072: step 1670, loss = 1.19 (1413.2 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:25:52.896236: step 1680, loss = 1.09 (1499.6 examples/sec; 0.171 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.76809\n",
      "2017-05-26 10:25:56.580187: step 1700, loss = 1.21 (1248.8 examples/sec; 0.205 sec/batch)\n",
      "2017-05-26 10:25:58.250790: step 1710, loss = 1.22 (1532.4 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:26:00.116284: step 1720, loss = 1.23 (1372.3 examples/sec; 0.187 sec/batch)\n",
      "2017-05-26 10:26:02.583514: step 1730, loss = 1.15 (1037.6 examples/sec; 0.247 sec/batch)\n",
      "2017-05-26 10:26:04.896279: step 1740, loss = 1.23 (1106.9 examples/sec; 0.231 sec/batch)\n",
      "2017-05-26 10:26:07.009357: step 1750, loss = 1.11 (1211.5 examples/sec; 0.211 sec/batch)\n",
      "2017-05-26 10:26:08.991960: step 1760, loss = 1.14 (1291.2 examples/sec; 0.198 sec/batch)\n",
      "2017-05-26 10:26:10.779379: step 1770, loss = 1.16 (1432.2 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:26:12.518546: step 1780, loss = 1.17 (1472.0 examples/sec; 0.174 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-26 10:26:14.146393: step 1790, loss = 1.20 (1572.6 examples/sec; 0.163 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.05488\n",
      "2017-05-26 10:26:16.362726: step 1800, loss = 1.25 (1155.1 examples/sec; 0.222 sec/batch)\n",
      "2017-05-26 10:26:17.789483: step 1810, loss = 1.23 (1794.3 examples/sec; 0.143 sec/batch)\n",
      "2017-05-26 10:26:19.584947: step 1820, loss = 1.20 (1425.8 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:26:21.255253: step 1830, loss = 1.21 (1532.7 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:26:22.877015: step 1840, loss = 1.13 (1578.5 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:26:24.552299: step 1850, loss = 1.22 (1528.1 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:26:28.166586: step 1870, loss = 1.16 (1409.9 examples/sec; 0.182 sec/batch)\n",
      "2017-05-26 10:26:29.835493: step 1880, loss = 1.12 (1533.9 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:26:31.471666: step 1890, loss = 1.19 (1564.6 examples/sec; 0.164 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.80603\n",
      "2017-05-26 10:26:33.586663: step 1900, loss = 1.14 (1210.4 examples/sec; 0.211 sec/batch)\n",
      "2017-05-26 10:26:35.265661: step 1910, loss = 1.20 (1524.7 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:26:36.967304: step 1920, loss = 1.09 (1504.4 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:26:38.588017: step 1930, loss = 1.10 (1579.6 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:26:40.209055: step 1940, loss = 1.18 (1579.2 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:26:41.969345: step 1950, loss = 1.22 (1454.3 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:26:43.723759: step 1960, loss = 1.14 (1459.2 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:26:45.379886: step 1970, loss = 1.09 (1545.8 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:26:47.013175: step 1980, loss = 1.16 (1567.4 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:26:48.696237: step 1990, loss = 1.11 (1521.0 examples/sec; 0.168 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.75133\n",
      "2017-05-26 10:26:50.973709: step 2000, loss = 1.05 (1124.1 examples/sec; 0.228 sec/batch)\n",
      "2017-05-26 10:26:52.670619: step 2010, loss = 1.16 (1508.6 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:26:55.127530: step 2020, loss = 1.25 (1042.0 examples/sec; 0.246 sec/batch)\n",
      "2017-05-26 10:26:57.414206: step 2030, loss = 1.32 (1119.5 examples/sec; 0.229 sec/batch)\n",
      "2017-05-26 10:27:01.446523: step 2050, loss = 1.29 (1361.5 examples/sec; 0.188 sec/batch)\n",
      "2017-05-26 10:27:03.270833: step 2060, loss = 1.03 (1403.3 examples/sec; 0.182 sec/batch)\n",
      "2017-05-26 10:27:04.985303: step 2070, loss = 1.09 (1493.2 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:27:06.600954: step 2080, loss = 1.16 (1584.5 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:27:08.240871: step 2090, loss = 1.14 (1561.1 examples/sec; 0.164 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.12945\n",
      "2017-05-26 10:27:10.468691: step 2100, loss = 1.14 (1149.1 examples/sec; 0.223 sec/batch)\n",
      "2017-05-26 10:27:12.095609: step 2110, loss = 1.10 (1573.5 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:27:13.741845: step 2120, loss = 1.19 (1555.1 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:27:15.377149: step 2130, loss = 1.20 (1565.5 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:27:17.090450: step 2140, loss = 1.15 (1494.2 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:27:18.907116: step 2150, loss = 1.13 (1409.2 examples/sec; 0.182 sec/batch)\n",
      "2017-05-26 10:27:20.658808: step 2160, loss = 1.12 (1461.4 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:27:22.268586: step 2170, loss = 1.10 (1590.3 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:27:23.888625: step 2180, loss = 1.20 (1580.2 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:27:25.658025: step 2190, loss = 1.00 (1446.8 examples/sec; 0.177 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.75285\n",
      "2017-05-26 10:27:27.853210: step 2200, loss = 1.15 (1166.2 examples/sec; 0.220 sec/batch)\n",
      "2017-05-26 10:27:29.409731: step 2210, loss = 1.13 (1644.7 examples/sec; 0.156 sec/batch)\n",
      "2017-05-26 10:27:34.598809: step 2240, loss = 1.17 (1357.4 examples/sec; 0.189 sec/batch)\n",
      "2017-05-26 10:27:36.379524: step 2250, loss = 1.14 (1437.6 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:27:38.037757: step 2260, loss = 1.10 (1543.8 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:27:39.678934: step 2270, loss = 1.06 (1559.9 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:27:41.401890: step 2280, loss = 1.18 (1485.8 examples/sec; 0.172 sec/batch)\n",
      "2017-05-26 10:27:43.159679: step 2290, loss = 1.11 (1456.4 examples/sec; 0.176 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.73996\n",
      "2017-05-26 10:27:45.273034: step 2300, loss = 1.14 (1211.3 examples/sec; 0.211 sec/batch)\n",
      "2017-05-26 10:27:46.782719: step 2310, loss = 1.15 (1695.7 examples/sec; 0.151 sec/batch)\n",
      "2017-05-26 10:27:48.454526: step 2320, loss = 1.15 (1531.3 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:27:50.238994: step 2330, loss = 1.19 (1434.6 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:27:52.032098: step 2340, loss = 1.07 (1427.7 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:27:54.456535: step 2350, loss = 1.10 (1055.9 examples/sec; 0.242 sec/batch)\n",
      "2017-05-26 10:27:56.829761: step 2360, loss = 1.04 (1078.7 examples/sec; 0.237 sec/batch)\n",
      "2017-05-26 10:27:58.979937: step 2370, loss = 1.00 (1190.6 examples/sec; 0.215 sec/batch)\n",
      "2017-05-26 10:28:00.975374: step 2380, loss = 1.16 (1282.9 examples/sec; 0.200 sec/batch)\n",
      "2017-05-26 10:28:02.752674: step 2390, loss = 1.09 (1440.4 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:28:06.437633: step 2410, loss = 1.05 (1684.1 examples/sec; 0.152 sec/batch)\n",
      "2017-05-26 10:28:08.091694: step 2420, loss = 1.02 (1547.7 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:28:09.878230: step 2430, loss = 1.12 (1432.9 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:28:11.658384: step 2440, loss = 1.09 (1438.1 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:28:13.345034: step 2450, loss = 1.18 (1517.8 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:28:14.963839: step 2460, loss = 1.15 (1581.4 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:28:16.635205: step 2470, loss = 1.15 (1531.7 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:28:18.436455: step 2480, loss = 1.12 (1421.2 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:28:20.254685: step 2490, loss = 1.24 (1408.0 examples/sec; 0.182 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.77559\n",
      "2017-05-26 10:28:22.231973: step 2500, loss = 1.21 (1294.7 examples/sec; 0.198 sec/batch)\n",
      "2017-05-26 10:28:23.753087: step 2510, loss = 1.07 (1683.0 examples/sec; 0.152 sec/batch)\n",
      "2017-05-26 10:28:25.518905: step 2520, loss = 1.11 (1449.8 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:28:27.291822: step 2530, loss = 1.00 (1443.9 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:28:29.030623: step 2540, loss = 1.14 (1472.3 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:28:30.682323: step 2550, loss = 1.12 (1549.9 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:28:32.338347: step 2560, loss = 1.10 (1545.9 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:28:34.104047: step 2570, loss = 1.16 (1449.9 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:28:35.888865: step 2580, loss = 1.04 (1434.3 examples/sec; 0.178 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.78005\n",
      "2017-05-26 10:28:39.533146: step 2600, loss = 1.14 (1294.6 examples/sec; 0.198 sec/batch)\n",
      "2017-05-26 10:28:41.130737: step 2610, loss = 1.13 (1602.4 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:28:42.915177: step 2620, loss = 1.07 (1434.6 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:28:44.687496: step 2630, loss = 1.19 (1444.4 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:28:46.328961: step 2640, loss = 1.10 (1559.6 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:28:47.970537: step 2650, loss = 1.11 (1559.5 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:28:49.721768: step 2660, loss = 1.11 (1461.8 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:28:51.506497: step 2670, loss = 1.04 (1434.4 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:28:53.212584: step 2680, loss = 1.08 (1500.5 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:28:54.843239: step 2690, loss = 1.04 (1569.9 examples/sec; 0.163 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.77375\n",
      "2017-05-26 10:28:56.853721: step 2700, loss = 1.10 (1273.3 examples/sec; 0.201 sec/batch)\n",
      "2017-05-26 10:28:58.572749: step 2710, loss = 0.93 (1489.2 examples/sec; 0.172 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-26 10:29:00.371419: step 2720, loss = 1.16 (1423.3 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:29:02.037541: step 2730, loss = 1.19 (1536.5 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:29:03.686297: step 2740, loss = 1.10 (1552.7 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:29:05.442812: step 2750, loss = 1.08 (1457.4 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:29:07.228822: step 2760, loss = 1.07 (1433.4 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:29:10.611929: step 2780, loss = 1.01 (1556.9 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:29:12.237740: step 2790, loss = 1.16 (1574.6 examples/sec; 0.163 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.68032\n",
      "2017-05-26 10:29:14.459730: step 2800, loss = 1.20 (1152.1 examples/sec; 0.222 sec/batch)\n",
      "2017-05-26 10:29:16.073423: step 2810, loss = 1.05 (1586.4 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:29:17.724443: step 2820, loss = 1.13 (1550.6 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:29:19.376142: step 2830, loss = 1.14 (1549.9 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:29:21.044105: step 2840, loss = 0.96 (1534.8 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:29:22.845115: step 2850, loss = 1.04 (1421.4 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:29:24.595629: step 2860, loss = 0.99 (1462.4 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:29:26.241072: step 2870, loss = 1.09 (1555.8 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:29:27.911712: step 2880, loss = 1.03 (1532.3 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:29:29.688969: step 2890, loss = 1.07 (1440.4 examples/sec; 0.178 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.74566\n",
      "2017-05-26 10:29:31.864062: step 2900, loss = 1.10 (1177.0 examples/sec; 0.218 sec/batch)\n",
      "2017-05-26 10:29:33.972437: step 2910, loss = 1.15 (1214.2 examples/sec; 0.211 sec/batch)\n",
      "2017-05-26 10:29:36.423414: step 2920, loss = 1.16 (1044.5 examples/sec; 0.245 sec/batch)\n",
      "2017-05-26 10:29:38.570445: step 2930, loss = 1.03 (1192.3 examples/sec; 0.215 sec/batch)\n",
      "2017-05-26 10:29:42.405573: step 2950, loss = 1.03 (1438.4 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:29:44.205345: step 2960, loss = 1.19 (1422.4 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:29:45.863717: step 2970, loss = 0.98 (1543.7 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:29:47.496552: step 2980, loss = 1.01 (1567.8 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:29:49.211485: step 2990, loss = 1.21 (1492.8 examples/sec; 0.171 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.07849\n",
      "2017-05-26 10:29:51.552630: step 3000, loss = 1.08 (1093.5 examples/sec; 0.234 sec/batch)\n",
      "2017-05-26 10:29:52.975004: step 3010, loss = 1.05 (1799.8 examples/sec; 0.142 sec/batch)\n",
      "2017-05-26 10:29:54.607356: step 3020, loss = 1.12 (1568.3 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:29:56.213427: step 3030, loss = 1.10 (1594.0 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:29:57.996309: step 3040, loss = 1.07 (1435.9 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:29:59.783162: step 3050, loss = 1.21 (1432.7 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:30:01.461578: step 3060, loss = 1.10 (1525.2 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:30:03.095849: step 3070, loss = 0.95 (1566.4 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:30:04.768209: step 3080, loss = 1.04 (1530.8 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:30:06.628361: step 3090, loss = 1.06 (1376.2 examples/sec; 0.186 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.80805\n",
      "2017-05-26 10:30:08.771833: step 3100, loss = 1.09 (1194.3 examples/sec; 0.214 sec/batch)\n",
      "2017-05-26 10:30:10.277162: step 3110, loss = 1.05 (1700.6 examples/sec; 0.151 sec/batch)\n",
      "2017-05-26 10:30:13.670678: step 3130, loss = 1.15 (1460.1 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:30:15.453696: step 3140, loss = 1.09 (1435.8 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:30:17.586304: step 3150, loss = 1.16 (1200.4 examples/sec; 0.213 sec/batch)\n",
      "2017-05-26 10:30:20.061931: step 3160, loss = 1.10 (1034.1 examples/sec; 0.248 sec/batch)\n",
      "2017-05-26 10:30:22.217454: step 3170, loss = 1.11 (1187.6 examples/sec; 0.216 sec/batch)\n",
      "2017-05-26 10:30:24.411786: step 3180, loss = 1.12 (1166.6 examples/sec; 0.219 sec/batch)\n",
      "2017-05-26 10:30:26.260667: step 3190, loss = 1.07 (1384.6 examples/sec; 0.185 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.08781\n",
      "2017-05-26 10:30:28.426309: step 3200, loss = 1.04 (1182.1 examples/sec; 0.217 sec/batch)\n",
      "2017-05-26 10:30:29.956744: step 3210, loss = 1.05 (1672.7 examples/sec; 0.153 sec/batch)\n",
      "2017-05-26 10:30:31.599889: step 3220, loss = 1.00 (1558.0 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:30:33.329558: step 3230, loss = 1.06 (1480.1 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:30:35.101946: step 3240, loss = 1.06 (1444.4 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:30:36.842122: step 3250, loss = 1.19 (1471.1 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:30:38.493477: step 3260, loss = 1.16 (1550.2 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:30:40.123704: step 3270, loss = 1.29 (1570.3 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:30:41.876105: step 3280, loss = 1.12 (1460.9 examples/sec; 0.175 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.73301\n",
      "2017-05-26 10:30:45.867559: step 3300, loss = 0.93 (1162.6 examples/sec; 0.220 sec/batch)\n",
      "2017-05-26 10:30:47.196074: step 3310, loss = 0.95 (1927.0 examples/sec; 0.133 sec/batch)\n",
      "2017-05-26 10:30:48.868522: step 3320, loss = 1.13 (1530.7 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:30:50.668592: step 3330, loss = 1.06 (1422.2 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:30:52.456791: step 3340, loss = 1.28 (1431.6 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:30:54.088692: step 3350, loss = 1.01 (1568.7 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:30:55.731829: step 3360, loss = 0.99 (1558.0 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:30:57.441764: step 3370, loss = 1.10 (1497.1 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:30:59.249898: step 3380, loss = 1.06 (1415.8 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:31:00.960248: step 3390, loss = 1.05 (1496.8 examples/sec; 0.171 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.85928\n",
      "2017-05-26 10:31:02.934520: step 3400, loss = 1.00 (1296.7 examples/sec; 0.197 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 3404 into /home/ipython/cnn-cifar10/tb_log/vgg1/train/model.ckpt.\n",
      "2017-05-26 10:31:04.519083: step 3410, loss = 1.07 (1615.6 examples/sec; 0.158 sec/batch)\n",
      "2017-05-26 10:31:06.318635: step 3420, loss = 1.23 (1422.6 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:31:08.116527: step 3430, loss = 1.13 (1423.9 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:31:09.763973: step 3440, loss = 0.98 (1553.9 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:31:11.482241: step 3450, loss = 1.09 (1489.9 examples/sec; 0.172 sec/batch)\n",
      "2017-05-26 10:31:13.148419: step 3460, loss = 1.02 (1536.5 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:31:18.365822: step 3490, loss = 1.06 (1540.5 examples/sec; 0.166 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.74091\n",
      "2017-05-26 10:31:20.354885: step 3500, loss = 1.20 (1287.0 examples/sec; 0.199 sec/batch)\n",
      "2017-05-26 10:31:21.995901: step 3510, loss = 1.12 (1560.0 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:31:23.772918: step 3520, loss = 1.00 (1440.6 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:31:25.990008: step 3530, loss = 1.00 (1154.7 examples/sec; 0.222 sec/batch)\n",
      "2017-05-26 10:31:28.488835: step 3540, loss = 1.06 (1024.5 examples/sec; 0.250 sec/batch)\n",
      "2017-05-26 10:31:30.627461: step 3550, loss = 0.99 (1197.0 examples/sec; 0.214 sec/batch)\n",
      "2017-05-26 10:31:32.697595: step 3560, loss = 1.12 (1236.6 examples/sec; 0.207 sec/batch)\n",
      "2017-05-26 10:31:34.529409: step 3570, loss = 1.06 (1397.5 examples/sec; 0.183 sec/batch)\n",
      "2017-05-26 10:31:36.312423: step 3580, loss = 1.09 (1435.8 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:31:37.964097: step 3590, loss = 1.14 (1549.9 examples/sec; 0.165 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.09849\n",
      "2017-05-26 10:31:39.967221: step 3600, loss = 1.12 (1278.0 examples/sec; 0.200 sec/batch)\n",
      "2017-05-26 10:31:41.644545: step 3610, loss = 1.02 (1526.2 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:31:43.448544: step 3620, loss = 0.99 (1419.1 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:31:45.142021: step 3630, loss = 1.08 (1511.7 examples/sec; 0.169 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-26 10:31:46.808330: step 3640, loss = 1.10 (1536.3 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:31:50.275632: step 3660, loss = 1.08 (1422.7 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:31:52.046699: step 3670, loss = 1.01 (1445.5 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:31:53.719369: step 3680, loss = 1.07 (1530.5 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:31:55.326546: step 3690, loss = 1.02 (1592.9 examples/sec; 0.161 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.74605\n",
      "2017-05-26 10:31:57.372011: step 3700, loss = 0.94 (1251.5 examples/sec; 0.205 sec/batch)\n",
      "2017-05-26 10:31:59.117074: step 3710, loss = 1.06 (1467.0 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:32:00.846117: step 3720, loss = 1.06 (1480.6 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:32:02.489580: step 3730, loss = 1.02 (1557.7 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:32:04.110477: step 3740, loss = 0.97 (1579.4 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:32:05.853727: step 3750, loss = 1.07 (1468.5 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:32:07.721656: step 3760, loss = 1.08 (1370.5 examples/sec; 0.187 sec/batch)\n",
      "2017-05-26 10:32:09.452411: step 3770, loss = 1.01 (1479.1 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:32:11.068387: step 3780, loss = 1.10 (1584.2 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:32:12.739023: step 3790, loss = 1.06 (1532.4 examples/sec; 0.167 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.68566\n",
      "2017-05-26 10:32:14.958767: step 3800, loss = 1.09 (1153.3 examples/sec; 0.222 sec/batch)\n",
      "2017-05-26 10:32:16.702064: step 3810, loss = 0.97 (1468.5 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:32:21.514647: step 3830, loss = 1.00 (1102.0 examples/sec; 0.232 sec/batch)\n",
      "2017-05-26 10:32:23.674668: step 3840, loss = 1.05 (1185.2 examples/sec; 0.216 sec/batch)\n",
      "2017-05-26 10:32:25.620409: step 3850, loss = 1.10 (1315.7 examples/sec; 0.195 sec/batch)\n",
      "2017-05-26 10:32:27.434406: step 3860, loss = 1.07 (1411.2 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:32:29.157608: step 3870, loss = 1.03 (1485.6 examples/sec; 0.172 sec/batch)\n",
      "2017-05-26 10:32:30.768625: step 3880, loss = 0.92 (1589.1 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:32:32.395199: step 3890, loss = 1.03 (1573.9 examples/sec; 0.163 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.11364\n",
      "2017-05-26 10:32:34.515759: step 3900, loss = 1.01 (1207.2 examples/sec; 0.212 sec/batch)\n",
      "2017-05-26 10:32:36.176516: step 3910, loss = 1.01 (1541.5 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:32:37.863015: step 3920, loss = 1.00 (1517.9 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:32:39.506543: step 3930, loss = 1.04 (1557.6 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:32:41.195399: step 3940, loss = 1.10 (1515.8 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:32:42.989503: step 3950, loss = 1.09 (1426.9 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:32:44.761450: step 3960, loss = 1.03 (1444.7 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:32:46.379687: step 3970, loss = 1.02 (1582.0 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:32:48.024353: step 3980, loss = 1.00 (1556.6 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:32:49.765070: step 3990, loss = 1.14 (1470.7 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:32:53.529637: step 4010, loss = 1.05 (1592.9 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:32:55.169846: step 4020, loss = 1.09 (1560.8 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:32:56.844639: step 4030, loss = 0.98 (1528.5 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:32:58.678428: step 4040, loss = 0.97 (1396.0 examples/sec; 0.183 sec/batch)\n",
      "2017-05-26 10:33:00.535714: step 4050, loss = 1.21 (1378.4 examples/sec; 0.186 sec/batch)\n",
      "2017-05-26 10:33:02.146107: step 4060, loss = 1.02 (1589.7 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:33:03.777808: step 4070, loss = 1.05 (1568.9 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:33:05.532502: step 4080, loss = 1.01 (1458.9 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:33:07.308115: step 4090, loss = 1.09 (1441.8 examples/sec; 0.178 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.70671\n",
      "2017-05-26 10:33:09.445507: step 4100, loss = 1.03 (1197.7 examples/sec; 0.214 sec/batch)\n",
      "2017-05-26 10:33:10.912719: step 4110, loss = 1.02 (1744.8 examples/sec; 0.147 sec/batch)\n",
      "2017-05-26 10:33:12.539448: step 4120, loss = 1.02 (1573.7 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:33:14.330201: step 4130, loss = 1.01 (1429.6 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:33:16.129310: step 4140, loss = 1.02 (1422.9 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:33:18.479800: step 4150, loss = 1.02 (1089.1 examples/sec; 0.235 sec/batch)\n",
      "2017-05-26 10:33:20.872197: step 4160, loss = 1.00 (1070.1 examples/sec; 0.239 sec/batch)\n",
      "2017-05-26 10:33:25.004234: step 4180, loss = 1.07 (1265.8 examples/sec; 0.202 sec/batch)\n",
      "2017-05-26 10:33:26.802556: step 4190, loss = 1.11 (1423.6 examples/sec; 0.180 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.13786\n",
      "2017-05-26 10:33:28.910773: step 4200, loss = 1.07 (1214.3 examples/sec; 0.211 sec/batch)\n",
      "2017-05-26 10:33:30.515251: step 4210, loss = 1.04 (1595.5 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:33:32.137099: step 4220, loss = 1.11 (1578.4 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:33:33.863700: step 4230, loss = 1.03 (1482.7 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:33:35.668114: step 4240, loss = 1.12 (1418.7 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:33:37.368784: step 4250, loss = 1.09 (1505.3 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:33:39.016170: step 4260, loss = 1.03 (1554.0 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:33:40.700343: step 4270, loss = 1.03 (1520.0 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:33:42.485431: step 4280, loss = 1.04 (1434.1 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:33:44.283495: step 4290, loss = 0.97 (1423.8 examples/sec; 0.180 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.76608\n",
      "2017-05-26 10:33:46.251565: step 4300, loss = 1.01 (1300.8 examples/sec; 0.197 sec/batch)\n",
      "2017-05-26 10:33:47.778477: step 4310, loss = 0.99 (1676.6 examples/sec; 0.153 sec/batch)\n",
      "2017-05-26 10:33:49.532213: step 4320, loss = 1.08 (1459.7 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:33:51.311426: step 4330, loss = 1.06 (1438.8 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:33:53.078855: step 4340, loss = 1.06 (1448.4 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:33:54.721917: step 4350, loss = 1.06 (1558.1 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:33:58.115948: step 4370, loss = 0.99 (1433.4 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:33:59.946011: step 4380, loss = 1.08 (1398.9 examples/sec; 0.183 sec/batch)\n",
      "2017-05-26 10:34:01.617012: step 4390, loss = 1.15 (1532.0 examples/sec; 0.167 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.71167\n",
      "2017-05-26 10:34:03.759648: step 4400, loss = 1.13 (1194.8 examples/sec; 0.214 sec/batch)\n",
      "2017-05-26 10:34:05.433233: step 4410, loss = 0.95 (1529.7 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:34:07.201195: step 4420, loss = 1.06 (1448.0 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:34:09.154443: step 4430, loss = 1.07 (1310.6 examples/sec; 0.195 sec/batch)\n",
      "2017-05-26 10:34:11.737314: step 4440, loss = 1.02 (991.1 examples/sec; 0.258 sec/batch)\n",
      "2017-05-26 10:34:13.966724: step 4450, loss = 1.02 (1148.3 examples/sec; 0.223 sec/batch)\n",
      "2017-05-26 10:34:16.082119: step 4460, loss = 0.95 (1210.2 examples/sec; 0.212 sec/batch)\n",
      "2017-05-26 10:34:17.974086: step 4470, loss = 0.92 (1353.1 examples/sec; 0.189 sec/batch)\n",
      "2017-05-26 10:34:19.772342: step 4480, loss = 1.04 (1423.6 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:34:21.490090: step 4490, loss = 1.04 (1490.3 examples/sec; 0.172 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.06715\n",
      "2017-05-26 10:34:23.494481: step 4500, loss = 1.02 (1277.2 examples/sec; 0.200 sec/batch)\n",
      "2017-05-26 10:34:25.019720: step 4510, loss = 0.96 (1678.4 examples/sec; 0.153 sec/batch)\n",
      "2017-05-26 10:34:26.825826: step 4520, loss = 1.07 (1417.4 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:34:30.309884: step 4540, loss = 1.08 (1546.4 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:34:31.943330: step 4550, loss = 1.03 (1567.2 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:34:33.693842: step 4560, loss = 1.05 (1462.4 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:34:35.447721: step 4570, loss = 1.03 (1459.6 examples/sec; 0.175 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-26 10:34:37.158862: step 4580, loss = 1.04 (1496.1 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:34:38.837272: step 4590, loss = 1.09 (1525.3 examples/sec; 0.168 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.78319\n",
      "2017-05-26 10:34:40.786418: step 4600, loss = 0.99 (1313.4 examples/sec; 0.195 sec/batch)\n",
      "2017-05-26 10:34:42.500537: step 4610, loss = 1.20 (1493.5 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:34:44.293200: step 4620, loss = 1.02 (1428.0 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:34:45.959110: step 4630, loss = 1.12 (1536.7 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:34:47.595985: step 4640, loss = 1.02 (1564.0 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:34:49.391382: step 4650, loss = 1.00 (1425.9 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:34:51.182422: step 4660, loss = 1.09 (1429.3 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:34:52.919273: step 4670, loss = 1.14 (1473.9 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:34:54.569499: step 4680, loss = 1.02 (1551.3 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:34:56.209321: step 4690, loss = 0.88 (1561.1 examples/sec; 0.164 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.67877\n",
      "2017-05-26 10:34:58.396608: step 4700, loss = 0.86 (1170.4 examples/sec; 0.219 sec/batch)\n",
      "2017-05-26 10:35:01.677415: step 4720, loss = 0.95 (1515.8 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:35:03.319077: step 4730, loss = 1.09 (1559.4 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:35:05.005536: step 4740, loss = 0.87 (1518.0 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:35:06.787337: step 4750, loss = 0.99 (1436.7 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:35:08.582517: step 4760, loss = 0.95 (1426.0 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:35:11.052523: step 4770, loss = 0.97 (1036.4 examples/sec; 0.247 sec/batch)\n",
      "2017-05-26 10:35:13.370879: step 4780, loss = 1.00 (1104.2 examples/sec; 0.232 sec/batch)\n",
      "2017-05-26 10:35:15.486783: step 4790, loss = 0.97 (1209.9 examples/sec; 0.212 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.09658\n",
      "2017-05-26 10:35:18.018560: step 4800, loss = 1.17 (1011.1 examples/sec; 0.253 sec/batch)\n",
      "2017-05-26 10:35:19.481558: step 4810, loss = 1.07 (1749.8 examples/sec; 0.146 sec/batch)\n",
      "2017-05-26 10:35:21.213737: step 4820, loss = 1.05 (1477.9 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:35:22.852121: step 4830, loss = 0.96 (1562.5 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:35:24.473185: step 4840, loss = 1.07 (1579.2 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:35:26.261229: step 4850, loss = 1.08 (1431.7 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:35:28.049239: step 4860, loss = 1.00 (1431.8 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:35:29.728831: step 4870, loss = 1.18 (1524.2 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:35:33.058984: step 4890, loss = 1.00 (1522.9 examples/sec; 0.168 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.78433\n",
      "2017-05-26 10:35:35.305228: step 4900, loss = 0.99 (1139.7 examples/sec; 0.225 sec/batch)\n",
      "2017-05-26 10:35:36.850449: step 4910, loss = 0.94 (1656.7 examples/sec; 0.155 sec/batch)\n",
      "2017-05-26 10:35:38.531193: step 4920, loss = 1.14 (1523.1 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:35:40.154343: step 4930, loss = 0.96 (1577.2 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:35:41.924208: step 4940, loss = 1.02 (1446.4 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:35:43.713127: step 4950, loss = 1.03 (1431.0 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:35:45.419991: step 4960, loss = 0.98 (1499.8 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:35:47.060895: step 4970, loss = 1.06 (1560.1 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:35:48.697713: step 4980, loss = 1.06 (1564.0 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:35:50.481769: step 4990, loss = 0.90 (1434.9 examples/sec; 0.178 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.72859\n",
      "2017-05-26 10:35:52.761832: step 5000, loss = 1.03 (1122.8 examples/sec; 0.228 sec/batch)\n",
      "2017-05-26 10:35:54.920302: step 5010, loss = 1.03 (1186.0 examples/sec; 0.216 sec/batch)\n",
      "2017-05-26 10:35:57.280100: step 5020, loss = 1.09 (1084.8 examples/sec; 0.236 sec/batch)\n",
      "2017-05-26 10:35:59.428484: step 5030, loss = 0.98 (1191.6 examples/sec; 0.215 sec/batch)\n",
      "2017-05-26 10:36:01.405815: step 5040, loss = 1.05 (1294.7 examples/sec; 0.198 sec/batch)\n",
      "2017-05-26 10:36:04.939783: step 5060, loss = 1.09 (1451.7 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:36:06.580730: step 5070, loss = 1.00 (1560.1 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:36:08.239743: step 5080, loss = 1.00 (1543.1 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:36:09.990489: step 5090, loss = 1.02 (1462.2 examples/sec; 0.175 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.16237\n",
      "2017-05-26 10:36:12.132060: step 5100, loss = 0.95 (1195.4 examples/sec; 0.214 sec/batch)\n",
      "2017-05-26 10:36:13.721577: step 5110, loss = 1.20 (1610.6 examples/sec; 0.159 sec/batch)\n",
      "2017-05-26 10:36:15.395918: step 5120, loss = 0.98 (1529.0 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:36:17.049971: step 5130, loss = 1.00 (1547.7 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:36:18.867989: step 5140, loss = 1.10 (1408.1 examples/sec; 0.182 sec/batch)\n",
      "2017-05-26 10:36:20.666190: step 5150, loss = 0.99 (1423.6 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:36:22.308247: step 5160, loss = 0.99 (1559.0 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:36:23.920921: step 5170, loss = 1.05 (1587.4 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:36:25.627596: step 5180, loss = 1.02 (1500.0 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:36:27.398426: step 5190, loss = 1.06 (1445.6 examples/sec; 0.177 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.65528\n",
      "2017-05-26 10:36:29.814399: step 5200, loss = 1.02 (1059.6 examples/sec; 0.242 sec/batch)\n",
      "2017-05-26 10:36:31.061724: step 5210, loss = 0.96 (2052.4 examples/sec; 0.125 sec/batch)\n",
      "2017-05-26 10:36:32.709484: step 5220, loss = 0.96 (1553.6 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:36:34.486022: step 5230, loss = 0.98 (1441.0 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:36:37.981636: step 5250, loss = 0.93 (1495.0 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:36:39.627122: step 5260, loss = 1.03 (1555.8 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:36:41.325954: step 5270, loss = 0.97 (1506.9 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:36:43.106520: step 5280, loss = 1.05 (1437.7 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:36:44.956474: step 5290, loss = 1.08 (1383.8 examples/sec; 0.185 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.48556\n",
      "2017-05-26 10:36:48.045407: step 5300, loss = 0.99 (828.8 examples/sec; 0.309 sec/batch)\n",
      "2017-05-26 10:36:50.061191: step 5310, loss = 0.95 (1270.0 examples/sec; 0.202 sec/batch)\n",
      "2017-05-26 10:36:52.184272: step 5320, loss = 0.98 (1205.8 examples/sec; 0.212 sec/batch)\n",
      "2017-05-26 10:36:54.058329: step 5330, loss = 0.93 (1366.0 examples/sec; 0.187 sec/batch)\n",
      "2017-05-26 10:36:55.865738: step 5340, loss = 0.97 (1416.4 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:36:57.558105: step 5350, loss = 1.13 (1512.7 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:36:59.202509: step 5360, loss = 1.00 (1556.8 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:37:00.889818: step 5370, loss = 1.11 (1517.2 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:37:02.728022: step 5380, loss = 1.06 (1392.7 examples/sec; 0.184 sec/batch)\n",
      "2017-05-26 10:37:04.511489: step 5390, loss = 0.94 (1435.4 examples/sec; 0.178 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.33266\n",
      "2017-05-26 10:37:06.797369: step 5400, loss = 1.00 (1119.9 examples/sec; 0.229 sec/batch)\n",
      "2017-05-26 10:37:09.831787: step 5420, loss = 1.10 (1470.2 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:37:11.614529: step 5430, loss = 0.99 (1436.0 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:37:13.364646: step 5440, loss = 1.00 (1462.8 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:37:15.004486: step 5450, loss = 1.16 (1561.1 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:37:16.652004: step 5460, loss = 1.04 (1553.9 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:37:18.451220: step 5470, loss = 1.00 (1422.8 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:37:20.231840: step 5480, loss = 0.97 (1437.7 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:37:21.905146: step 5490, loss = 1.01 (1529.9 examples/sec; 0.167 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 5.87146\n",
      "2017-05-26 10:37:23.829220: step 5500, loss = 1.00 (1331.2 examples/sec; 0.192 sec/batch)\n",
      "2017-05-26 10:37:25.447634: step 5510, loss = 0.98 (1580.8 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:37:27.237388: step 5520, loss = 0.96 (1430.4 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:37:28.990946: step 5530, loss = 0.93 (1459.9 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:37:30.636087: step 5540, loss = 1.10 (1556.1 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:37:32.288565: step 5550, loss = 1.12 (1549.2 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:37:34.049314: step 5560, loss = 1.05 (1453.9 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:37:35.893531: step 5570, loss = 0.94 (1388.1 examples/sec; 0.184 sec/batch)\n",
      "2017-05-26 10:37:37.609398: step 5580, loss = 1.11 (1492.0 examples/sec; 0.172 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.7407\n",
      "2017-05-26 10:37:41.247839: step 5600, loss = 0.94 (1279.7 examples/sec; 0.200 sec/batch)\n",
      "2017-05-26 10:37:42.917638: step 5610, loss = 1.14 (1533.1 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:37:44.702735: step 5620, loss = 1.01 (1434.1 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:37:46.338216: step 5630, loss = 1.01 (1565.3 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:37:47.989907: step 5640, loss = 0.91 (1549.9 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:37:49.715933: step 5650, loss = 1.13 (1483.2 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:37:51.490684: step 5660, loss = 1.00 (1442.5 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:37:53.450668: step 5670, loss = 0.99 (1306.1 examples/sec; 0.196 sec/batch)\n",
      "2017-05-26 10:37:55.937489: step 5680, loss = 0.94 (1029.4 examples/sec; 0.249 sec/batch)\n",
      "2017-05-26 10:37:58.203768: step 5690, loss = 1.00 (1129.6 examples/sec; 0.227 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.12962\n",
      "2017-05-26 10:38:00.742343: step 5700, loss = 1.00 (1008.4 examples/sec; 0.254 sec/batch)\n",
      "2017-05-26 10:38:02.431957: step 5710, loss = 1.12 (1515.1 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:38:04.222814: step 5720, loss = 0.98 (1429.5 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:38:05.891728: step 5730, loss = 1.06 (1533.9 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:38:07.556874: step 5740, loss = 0.87 (1537.4 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:38:09.241704: step 5750, loss = 0.99 (1519.4 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:38:12.845157: step 5770, loss = 0.92 (1416.0 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:38:14.480827: step 5780, loss = 0.99 (1565.1 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:38:16.120727: step 5790, loss = 0.98 (1561.1 examples/sec; 0.164 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.71886\n",
      "2017-05-26 10:38:18.228751: step 5800, loss = 0.92 (1214.4 examples/sec; 0.211 sec/batch)\n",
      "2017-05-26 10:38:19.924066: step 5810, loss = 0.95 (1510.0 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:38:21.623427: step 5820, loss = 1.09 (1506.4 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:38:23.290587: step 5830, loss = 1.06 (1535.5 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:38:24.920265: step 5840, loss = 0.93 (1570.9 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:38:26.730358: step 5850, loss = 0.94 (1414.3 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:38:28.535813: step 5860, loss = 1.00 (1417.9 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:38:30.176629: step 5870, loss = 0.99 (1560.2 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:38:31.852613: step 5880, loss = 1.01 (1527.5 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:38:33.522556: step 5890, loss = 1.04 (1533.0 examples/sec; 0.167 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.74351\n",
      "2017-05-26 10:38:35.641301: step 5900, loss = 0.81 (1208.3 examples/sec; 0.212 sec/batch)\n",
      "2017-05-26 10:38:37.570818: step 5910, loss = 1.00 (1326.8 examples/sec; 0.193 sec/batch)\n",
      "2017-05-26 10:38:40.027651: step 5920, loss = 1.01 (1042.0 examples/sec; 0.246 sec/batch)\n",
      "2017-05-26 10:38:42.361307: step 5930, loss = 0.93 (1097.0 examples/sec; 0.233 sec/batch)\n",
      "2017-05-26 10:38:44.507467: step 5940, loss = 0.90 (1192.8 examples/sec; 0.215 sec/batch)\n",
      "2017-05-26 10:38:46.348485: step 5950, loss = 1.07 (1390.5 examples/sec; 0.184 sec/batch)\n",
      "2017-05-26 10:38:48.149806: step 5960, loss = 1.06 (1421.2 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:38:49.833835: step 5970, loss = 1.02 (1520.2 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:38:51.452815: step 5980, loss = 0.99 (1581.2 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:38:53.114019: step 5990, loss = 0.93 (1541.0 examples/sec; 0.166 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.08426\n",
      "2017-05-26 10:38:55.308107: step 6000, loss = 1.06 (1166.8 examples/sec; 0.219 sec/batch)\n",
      "2017-05-26 10:38:56.893805: step 6010, loss = 1.04 (1614.4 examples/sec; 0.159 sec/batch)\n",
      "2017-05-26 10:38:58.555586: step 6020, loss = 1.06 (1540.5 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:39:00.178316: step 6030, loss = 0.92 (1577.6 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:39:01.911190: step 6040, loss = 0.89 (1477.3 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:39:03.760786: step 6050, loss = 0.89 (1384.1 examples/sec; 0.185 sec/batch)\n",
      "2017-05-26 10:39:05.500709: step 6060, loss = 0.96 (1471.3 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:39:07.117801: step 6070, loss = 0.87 (1583.1 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:39:08.767589: step 6080, loss = 0.93 (1551.7 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:39:10.558378: step 6090, loss = 0.94 (1429.5 examples/sec; 0.179 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.75834\n",
      "2017-05-26 10:39:12.674150: step 6100, loss = 0.91 (1210.0 examples/sec; 0.212 sec/batch)\n",
      "2017-05-26 10:39:17.567118: step 6130, loss = 0.97 (1501.8 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:39:19.362458: step 6140, loss = 0.97 (1425.9 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:39:21.265974: step 6150, loss = 0.92 (1344.9 examples/sec; 0.190 sec/batch)\n",
      "2017-05-26 10:39:23.728792: step 6160, loss = 0.99 (1039.5 examples/sec; 0.246 sec/batch)\n",
      "2017-05-26 10:39:26.004483: step 6170, loss = 1.01 (1124.9 examples/sec; 0.228 sec/batch)\n",
      "2017-05-26 10:39:28.140153: step 6180, loss = 0.99 (1198.7 examples/sec; 0.214 sec/batch)\n",
      "2017-05-26 10:39:30.047335: step 6190, loss = 1.05 (1342.3 examples/sec; 0.191 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.10181\n",
      "2017-05-26 10:39:32.275736: step 6200, loss = 1.02 (1148.8 examples/sec; 0.223 sec/batch)\n",
      "2017-05-26 10:39:33.765773: step 6210, loss = 1.02 (1718.1 examples/sec; 0.149 sec/batch)\n",
      "2017-05-26 10:39:35.408199: step 6220, loss = 0.96 (1558.7 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:39:37.027118: step 6230, loss = 1.04 (1581.3 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:39:38.804329: step 6240, loss = 0.90 (1440.5 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:39:40.574167: step 6250, loss = 0.99 (1446.5 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:39:42.205562: step 6260, loss = 0.98 (1569.2 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:39:43.845146: step 6270, loss = 0.97 (1561.4 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:39:45.560254: step 6280, loss = 1.12 (1492.6 examples/sec; 0.172 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.84511\n",
      "2017-05-26 10:39:49.382918: step 6300, loss = 0.92 (1248.2 examples/sec; 0.205 sec/batch)\n",
      "2017-05-26 10:39:50.979323: step 6310, loss = 0.93 (1603.6 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:39:52.595753: step 6320, loss = 0.97 (1583.7 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:39:54.378558: step 6330, loss = 1.05 (1435.9 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:39:56.172685: step 6340, loss = 0.98 (1426.9 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:39:57.868297: step 6350, loss = 1.18 (1509.8 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:39:59.524786: step 6360, loss = 1.06 (1545.4 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:40:01.156982: step 6370, loss = 0.90 (1568.4 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:40:02.927654: step 6380, loss = 1.01 (1445.8 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:40:04.711409: step 6390, loss = 0.93 (1435.2 examples/sec; 0.178 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.74673\n",
      "2017-05-26 10:40:06.784230: step 6400, loss = 1.06 (1235.0 examples/sec; 0.207 sec/batch)\n",
      "2017-05-26 10:40:08.202523: step 6410, loss = 0.88 (1805.0 examples/sec; 0.142 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-26 10:40:09.925097: step 6420, loss = 0.99 (1486.1 examples/sec; 0.172 sec/batch)\n",
      "2017-05-26 10:40:11.722185: step 6430, loss = 1.00 (1424.5 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:40:13.734596: step 6440, loss = 1.06 (1272.1 examples/sec; 0.201 sec/batch)\n",
      "2017-05-26 10:40:16.192895: step 6450, loss = 0.85 (1041.4 examples/sec; 0.246 sec/batch)\n",
      "2017-05-26 10:40:18.430744: step 6460, loss = 1.04 (1144.0 examples/sec; 0.224 sec/batch)\n",
      "2017-05-26 10:40:22.502148: step 6480, loss = 1.02 (1327.7 examples/sec; 0.193 sec/batch)\n",
      "2017-05-26 10:40:24.291476: step 6490, loss = 0.99 (1430.7 examples/sec; 0.179 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.11573\n",
      "2017-05-26 10:40:26.331941: step 6500, loss = 0.74 (1254.6 examples/sec; 0.204 sec/batch)\n",
      "2017-05-26 10:40:27.814975: step 6510, loss = 0.99 (1726.2 examples/sec; 0.148 sec/batch)\n",
      "2017-05-26 10:40:29.496418: step 6520, loss = 0.99 (1522.5 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:40:31.299487: step 6530, loss = 0.94 (1419.8 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:40:33.068022: step 6540, loss = 1.02 (1447.5 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:40:34.715543: step 6550, loss = 1.01 (1553.8 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:40:36.364420: step 6560, loss = 0.84 (1552.6 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:40:38.095208: step 6570, loss = 0.94 (1479.1 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:40:39.868294: step 6580, loss = 1.08 (1443.8 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:40:41.599241: step 6590, loss = 1.00 (1479.0 examples/sec; 0.173 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.80517\n",
      "2017-05-26 10:40:43.557639: step 6600, loss = 1.00 (1307.2 examples/sec; 0.196 sec/batch)\n",
      "2017-05-26 10:40:45.087530: step 6610, loss = 0.96 (1673.3 examples/sec; 0.153 sec/batch)\n",
      "2017-05-26 10:40:46.885431: step 6620, loss = 1.03 (1423.9 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:40:48.694250: step 6630, loss = 0.91 (1415.3 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:40:50.342151: step 6640, loss = 0.98 (1553.5 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:40:53.685958: step 6660, loss = 0.91 (1508.9 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:40:55.478508: step 6670, loss = 0.98 (1428.1 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:40:57.254293: step 6680, loss = 0.88 (1441.6 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:40:58.880654: step 6690, loss = 0.97 (1574.1 examples/sec; 0.163 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.78763\n",
      "2017-05-26 10:41:00.837749: step 6700, loss = 1.00 (1308.1 examples/sec; 0.196 sec/batch)\n",
      "2017-05-26 10:41:02.431534: step 6710, loss = 0.95 (1606.2 examples/sec; 0.159 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 6716 into /home/ipython/cnn-cifar10/tb_log/vgg1/train/model.ckpt.\n",
      "2017-05-26 10:41:04.383129: step 6720, loss = 1.17 (1311.7 examples/sec; 0.195 sec/batch)\n",
      "2017-05-26 10:41:06.070129: step 6730, loss = 0.93 (1517.5 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:41:07.703617: step 6740, loss = 0.98 (1567.2 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:41:09.369807: step 6750, loss = 1.07 (1536.4 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:41:11.160450: step 6760, loss = 1.03 (1429.7 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:41:12.959233: step 6770, loss = 1.10 (1423.2 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:41:14.590552: step 6780, loss = 1.10 (1569.3 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:41:16.203643: step 6790, loss = 0.96 (1587.0 examples/sec; 0.161 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.72071\n",
      "2017-05-26 10:41:18.318153: step 6800, loss = 0.96 (1210.7 examples/sec; 0.211 sec/batch)\n",
      "2017-05-26 10:41:19.986985: step 6810, loss = 1.04 (1534.0 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:41:22.131038: step 6820, loss = 0.84 (1194.0 examples/sec; 0.214 sec/batch)\n",
      "2017-05-26 10:41:26.783939: step 6840, loss = 0.95 (1165.4 examples/sec; 0.220 sec/batch)\n",
      "2017-05-26 10:41:28.928492: step 6850, loss = 1.05 (1193.7 examples/sec; 0.214 sec/batch)\n",
      "2017-05-26 10:41:30.732999: step 6860, loss = 0.90 (1418.7 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:41:32.543328: step 6870, loss = 0.95 (1414.1 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:41:34.195480: step 6880, loss = 0.88 (1549.5 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:41:35.850440: step 6890, loss = 0.91 (1546.9 examples/sec; 0.165 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.11442\n",
      "2017-05-26 10:41:37.868990: step 6900, loss = 1.06 (1268.2 examples/sec; 0.202 sec/batch)\n",
      "2017-05-26 10:41:39.553821: step 6910, loss = 0.94 (1519.4 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:41:41.292586: step 6920, loss = 1.05 (1472.3 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:41:42.980755: step 6930, loss = 0.94 (1516.4 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:41:44.607177: step 6940, loss = 1.08 (1574.0 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:41:46.376636: step 6950, loss = 1.05 (1446.8 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:41:48.191038: step 6960, loss = 0.96 (1410.9 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:41:49.893639: step 6970, loss = 0.95 (1503.6 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:41:51.532920: step 6980, loss = 0.95 (1561.7 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:41:53.189792: step 6990, loss = 0.92 (1545.1 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:41:58.570914: step 7020, loss = 0.96 (1589.1 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:42:00.191363: step 7030, loss = 1.00 (1579.8 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:42:01.911928: step 7040, loss = 0.97 (1487.9 examples/sec; 0.172 sec/batch)\n",
      "2017-05-26 10:42:03.708033: step 7050, loss = 1.08 (1425.3 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:42:05.426009: step 7060, loss = 1.02 (1490.1 examples/sec; 0.172 sec/batch)\n",
      "2017-05-26 10:42:07.074490: step 7070, loss = 1.00 (1552.9 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:42:08.704410: step 7080, loss = 0.97 (1570.6 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:42:10.500316: step 7090, loss = 0.90 (1425.5 examples/sec; 0.180 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.81521\n",
      "2017-05-26 10:42:12.633802: step 7100, loss = 0.94 (1199.9 examples/sec; 0.213 sec/batch)\n",
      "2017-05-26 10:42:14.211335: step 7110, loss = 0.98 (1622.8 examples/sec; 0.158 sec/batch)\n",
      "2017-05-26 10:42:15.847521: step 7120, loss = 0.98 (1564.6 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:42:17.553703: step 7130, loss = 0.95 (1500.4 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:42:19.372986: step 7140, loss = 0.90 (1407.1 examples/sec; 0.182 sec/batch)\n",
      "2017-05-26 10:42:21.153526: step 7150, loss = 1.04 (1437.8 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:42:22.794631: step 7160, loss = 1.01 (1559.9 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:42:24.484620: step 7170, loss = 0.90 (1514.8 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:42:26.246539: step 7180, loss = 1.04 (1453.0 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:42:30.062737: step 7200, loss = 1.01 (1273.3 examples/sec; 0.201 sec/batch)\n",
      "2017-05-26 10:42:31.587558: step 7210, loss = 0.98 (1678.9 examples/sec; 0.152 sec/batch)\n",
      "2017-05-26 10:42:33.241949: step 7220, loss = 0.95 (1547.4 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:42:35.013041: step 7230, loss = 0.96 (1445.4 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:42:36.800652: step 7240, loss = 0.97 (1432.1 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:42:38.452703: step 7250, loss = 0.99 (1549.6 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:42:40.081283: step 7260, loss = 0.94 (1571.9 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:42:41.781783: step 7270, loss = 0.98 (1505.4 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:42:43.576740: step 7280, loss = 1.04 (1426.2 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:42:45.319740: step 7290, loss = 1.00 (1468.7 examples/sec; 0.174 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.78301\n",
      "2017-05-26 10:42:47.354826: step 7300, loss = 0.90 (1257.9 examples/sec; 0.204 sec/batch)\n",
      "2017-05-26 10:42:48.811056: step 7310, loss = 1.10 (1758.0 examples/sec; 0.146 sec/batch)\n",
      "2017-05-26 10:42:50.590067: step 7320, loss = 0.94 (1439.0 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:42:52.349022: step 7330, loss = 0.94 (1455.4 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:42:54.550558: step 7340, loss = 0.93 (1162.8 examples/sec; 0.220 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-26 10:42:57.020425: step 7350, loss = 1.00 (1036.5 examples/sec; 0.247 sec/batch)\n",
      "2017-05-26 10:42:59.232659: step 7360, loss = 0.96 (1157.2 examples/sec; 0.221 sec/batch)\n",
      "2017-05-26 10:43:03.096667: step 7380, loss = 0.91 (1425.6 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:43:04.892878: step 7390, loss = 0.93 (1425.2 examples/sec; 0.180 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.03294\n",
      "2017-05-26 10:43:07.223836: step 7400, loss = 1.08 (1098.3 examples/sec; 0.233 sec/batch)\n",
      "2017-05-26 10:43:08.496616: step 7410, loss = 0.97 (2011.3 examples/sec; 0.127 sec/batch)\n",
      "2017-05-26 10:43:10.235030: step 7420, loss = 0.89 (1472.6 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:43:12.004025: step 7430, loss = 1.02 (1447.2 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:43:13.715790: step 7440, loss = 0.88 (1495.5 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:43:15.355706: step 7450, loss = 0.99 (1561.1 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:43:16.989423: step 7460, loss = 0.82 (1567.0 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:43:18.803829: step 7470, loss = 1.01 (1410.9 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:43:20.617339: step 7480, loss = 0.93 (1411.6 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:43:22.287429: step 7490, loss = 0.86 (1532.9 examples/sec; 0.167 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.86807\n",
      "2017-05-26 10:43:24.265398: step 7500, loss = 1.07 (1294.3 examples/sec; 0.198 sec/batch)\n",
      "2017-05-26 10:43:25.767134: step 7510, loss = 0.84 (1704.7 examples/sec; 0.150 sec/batch)\n",
      "2017-05-26 10:43:27.551614: step 7520, loss = 0.91 (1434.6 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:43:29.447345: step 7530, loss = 0.87 (1350.4 examples/sec; 0.190 sec/batch)\n",
      "2017-05-26 10:43:34.230077: step 7550, loss = 1.00 (1099.5 examples/sec; 0.233 sec/batch)\n",
      "2017-05-26 10:43:36.343415: step 7560, loss = 1.00 (1211.4 examples/sec; 0.211 sec/batch)\n",
      "2017-05-26 10:43:38.256572: step 7570, loss = 1.00 (1338.1 examples/sec; 0.191 sec/batch)\n",
      "2017-05-26 10:43:40.043823: step 7580, loss = 0.99 (1432.4 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:43:41.733368: step 7590, loss = 0.98 (1515.2 examples/sec; 0.169 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.15919\n",
      "2017-05-26 10:43:43.648527: step 7600, loss = 1.10 (1336.7 examples/sec; 0.192 sec/batch)\n",
      "2017-05-26 10:43:45.191145: step 7610, loss = 0.90 (1659.5 examples/sec; 0.154 sec/batch)\n",
      "2017-05-26 10:43:46.978679: step 7620, loss = 0.92 (1432.1 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:43:48.786721: step 7630, loss = 0.87 (1415.9 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:43:50.452094: step 7640, loss = 0.97 (1537.2 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:43:52.083267: step 7650, loss = 1.01 (1569.4 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:43:53.835418: step 7660, loss = 0.93 (1461.1 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:43:55.661370: step 7670, loss = 0.91 (1402.0 examples/sec; 0.183 sec/batch)\n",
      "2017-05-26 10:43:57.401551: step 7680, loss = 1.00 (1471.1 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:43:59.048316: step 7690, loss = 0.98 (1554.6 examples/sec; 0.165 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.64938\n",
      "2017-05-26 10:44:01.349982: step 7700, loss = 0.97 (1112.2 examples/sec; 0.230 sec/batch)\n",
      "2017-05-26 10:44:02.767709: step 7710, loss = 1.03 (1805.7 examples/sec; 0.142 sec/batch)\n",
      "2017-05-26 10:44:06.251642: step 7730, loss = 0.99 (1507.2 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:44:07.864882: step 7740, loss = 0.87 (1586.9 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:44:09.592256: step 7750, loss = 0.94 (1482.0 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:44:11.363434: step 7760, loss = 0.88 (1445.4 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:44:13.129637: step 7770, loss = 0.89 (1449.4 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:44:14.773570: step 7780, loss = 0.91 (1557.2 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:44:16.399530: step 7790, loss = 0.91 (1574.5 examples/sec; 0.163 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.82295\n",
      "2017-05-26 10:44:18.524385: step 7800, loss = 0.97 (1204.8 examples/sec; 0.212 sec/batch)\n",
      "2017-05-26 10:44:20.149727: step 7810, loss = 1.03 (1575.1 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:44:21.838889: step 7820, loss = 0.98 (1515.5 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:44:23.481008: step 7830, loss = 0.93 (1559.0 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:44:25.102297: step 7840, loss = 0.86 (1579.0 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:44:26.899552: step 7850, loss = 0.90 (1424.4 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:44:28.749695: step 7860, loss = 0.96 (1383.7 examples/sec; 0.185 sec/batch)\n",
      "2017-05-26 10:44:31.106696: step 7870, loss = 0.93 (1086.1 examples/sec; 0.236 sec/batch)\n",
      "2017-05-26 10:44:33.477672: step 7880, loss = 1.04 (1079.7 examples/sec; 0.237 sec/batch)\n",
      "2017-05-26 10:44:35.612281: step 7890, loss = 1.01 (1199.3 examples/sec; 0.213 sec/batch)\n",
      "2017-05-26 10:44:37.996143: step 7900, loss = 1.00 (1073.9 examples/sec; 0.238 sec/batch)\n",
      "2017-05-26 10:44:39.691743: step 7910, loss = 1.06 (1509.8 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:44:41.494400: step 7920, loss = 0.87 (1420.1 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:44:43.146098: step 7930, loss = 1.01 (1549.9 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:44:44.758872: step 7940, loss = 0.88 (1587.3 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:44:46.498945: step 7950, loss = 0.93 (1471.2 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:44:48.292524: step 7960, loss = 0.91 (1427.3 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:44:49.967047: step 7970, loss = 1.00 (1528.8 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:44:51.584912: step 7980, loss = 0.92 (1582.3 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:44:53.247186: step 7990, loss = 0.96 (1540.1 examples/sec; 0.166 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.73128\n",
      "2017-05-26 10:44:55.446043: step 8000, loss = 0.93 (1164.2 examples/sec; 0.220 sec/batch)\n",
      "2017-05-26 10:44:57.055036: step 8010, loss = 0.99 (1591.1 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:44:58.954895: step 8020, loss = 0.98 (1347.5 examples/sec; 0.190 sec/batch)\n",
      "2017-05-26 10:45:00.612529: step 8030, loss = 0.99 (1544.4 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:45:02.375740: step 8040, loss = 0.89 (1451.9 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:45:04.162175: step 8050, loss = 1.03 (1433.0 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:45:05.875604: step 8060, loss = 0.85 (1494.1 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:45:07.493805: step 8070, loss = 1.06 (1582.0 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:45:10.952113: step 8090, loss = 0.89 (1422.7 examples/sec; 0.180 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.67741\n",
      "2017-05-26 10:45:13.057478: step 8100, loss = 0.99 (1215.9 examples/sec; 0.211 sec/batch)\n",
      "2017-05-26 10:45:14.592181: step 8110, loss = 0.98 (1668.1 examples/sec; 0.153 sec/batch)\n",
      "2017-05-26 10:45:16.226049: step 8120, loss = 0.94 (1566.8 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:45:17.931151: step 8130, loss = 0.97 (1501.4 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:45:19.691557: step 8140, loss = 1.02 (1454.2 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:45:21.629237: step 8150, loss = 1.05 (1321.2 examples/sec; 0.194 sec/batch)\n",
      "2017-05-26 10:45:24.120212: step 8160, loss = 0.97 (1027.7 examples/sec; 0.249 sec/batch)\n",
      "2017-05-26 10:45:26.368859: step 8170, loss = 0.94 (1138.5 examples/sec; 0.225 sec/batch)\n",
      "2017-05-26 10:45:28.549464: step 8180, loss = 0.84 (1174.0 examples/sec; 0.218 sec/batch)\n",
      "2017-05-26 10:45:30.451487: step 8190, loss = 1.05 (1345.9 examples/sec; 0.190 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.12879\n",
      "2017-05-26 10:45:32.555602: step 8200, loss = 1.04 (1216.7 examples/sec; 0.210 sec/batch)\n",
      "2017-05-26 10:45:34.199086: step 8210, loss = 1.02 (1557.7 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:45:35.828972: step 8220, loss = 0.96 (1570.7 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:45:37.537379: step 8230, loss = 1.01 (1498.5 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:45:39.345446: step 8240, loss = 0.98 (1415.9 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:45:44.453817: step 8270, loss = 0.94 (1577.6 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:45:46.184514: step 8280, loss = 0.93 (1479.2 examples/sec; 0.173 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-26 10:45:47.999098: step 8290, loss = 0.84 (1410.8 examples/sec; 0.181 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.70578\n",
      "2017-05-26 10:45:50.081336: step 8300, loss = 0.81 (1229.4 examples/sec; 0.208 sec/batch)\n",
      "2017-05-26 10:45:51.612051: step 8310, loss = 0.88 (1672.4 examples/sec; 0.153 sec/batch)\n",
      "2017-05-26 10:45:53.252009: step 8320, loss = 0.95 (1561.0 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:45:55.063668: step 8330, loss = 0.94 (1413.1 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:45:56.839376: step 8340, loss = 0.88 (1441.7 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:45:58.517909: step 8350, loss = 0.87 (1525.1 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:46:00.173165: step 8360, loss = 0.98 (1546.6 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:46:01.900339: step 8370, loss = 0.96 (1482.2 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:46:03.673519: step 8380, loss = 0.91 (1443.7 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:46:05.425298: step 8390, loss = 1.00 (1461.4 examples/sec; 0.175 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.7863\n",
      "2017-05-26 10:46:07.364122: step 8400, loss = 0.92 (1320.4 examples/sec; 0.194 sec/batch)\n",
      "2017-05-26 10:46:08.926241: step 8410, loss = 0.97 (1638.8 examples/sec; 0.156 sec/batch)\n",
      "2017-05-26 10:46:10.669092: step 8420, loss = 0.93 (1468.9 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:46:12.482351: step 8430, loss = 0.94 (1411.8 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:46:15.810046: step 8450, loss = 1.08 (1585.5 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:46:17.468461: step 8460, loss = 0.98 (1543.6 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:46:19.294127: step 8470, loss = 1.13 (1402.2 examples/sec; 0.183 sec/batch)\n",
      "2017-05-26 10:46:21.080905: step 8480, loss = 1.03 (1432.7 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:46:23.527797: step 8490, loss = 0.89 (1046.2 examples/sec; 0.245 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.28406\n",
      "2017-05-26 10:46:26.289228: step 8500, loss = 0.96 (927.1 examples/sec; 0.276 sec/batch)\n",
      "2017-05-26 10:46:28.318270: step 8510, loss = 1.04 (1261.7 examples/sec; 0.203 sec/batch)\n",
      "2017-05-26 10:46:30.234065: step 8520, loss = 0.90 (1336.3 examples/sec; 0.192 sec/batch)\n",
      "2017-05-26 10:46:32.080669: step 8530, loss = 0.95 (1386.3 examples/sec; 0.185 sec/batch)\n",
      "2017-05-26 10:46:33.809889: step 8540, loss = 1.10 (1480.4 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:46:35.439394: step 8550, loss = 0.89 (1571.0 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:46:37.067243: step 8560, loss = 0.99 (1572.6 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:46:38.838622: step 8570, loss = 0.95 (1445.2 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:46:40.621241: step 8580, loss = 1.03 (1436.1 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:46:42.322309: step 8590, loss = 0.92 (1504.9 examples/sec; 0.170 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.56572\n",
      "2017-05-26 10:46:44.255636: step 8600, loss = 0.96 (1324.1 examples/sec; 0.193 sec/batch)\n",
      "2017-05-26 10:46:47.596270: step 8620, loss = 0.99 (1449.6 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:46:49.398004: step 8630, loss = 0.93 (1420.9 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:46:51.032845: step 8640, loss = 0.88 (1565.9 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:46:52.646438: step 8650, loss = 1.07 (1586.5 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:46:54.363731: step 8660, loss = 0.97 (1490.7 examples/sec; 0.172 sec/batch)\n",
      "2017-05-26 10:46:56.165788: step 8670, loss = 1.01 (1420.6 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:46:57.885543: step 8680, loss = 1.01 (1488.6 examples/sec; 0.172 sec/batch)\n",
      "2017-05-26 10:46:59.525582: step 8690, loss = 0.93 (1560.9 examples/sec; 0.164 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.80765\n",
      "2017-05-26 10:47:01.474344: step 8700, loss = 1.04 (1313.7 examples/sec; 0.195 sec/batch)\n",
      "2017-05-26 10:47:03.160782: step 8710, loss = 0.89 (1518.0 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:47:04.917326: step 8720, loss = 0.96 (1457.4 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:47:06.584055: step 8730, loss = 0.87 (1535.9 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:47:08.193579: step 8740, loss = 0.88 (1590.5 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:47:09.904324: step 8750, loss = 0.99 (1496.4 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:47:11.702270: step 8760, loss = 0.99 (1423.8 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:47:13.483203: step 8770, loss = 0.93 (1437.4 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:47:15.128060: step 8780, loss = 0.93 (1556.4 examples/sec; 0.164 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.74185\n",
      "2017-05-26 10:47:18.890222: step 8800, loss = 0.89 (1211.0 examples/sec; 0.211 sec/batch)\n",
      "2017-05-26 10:47:20.597039: step 8810, loss = 1.00 (1499.9 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:47:22.809977: step 8820, loss = 0.99 (1156.8 examples/sec; 0.221 sec/batch)\n",
      "2017-05-26 10:47:25.254831: step 8830, loss = 0.82 (1047.1 examples/sec; 0.244 sec/batch)\n",
      "2017-05-26 10:47:27.348264: step 8840, loss = 1.00 (1222.9 examples/sec; 0.209 sec/batch)\n",
      "2017-05-26 10:47:29.441388: step 8850, loss = 0.95 (1223.1 examples/sec; 0.209 sec/batch)\n",
      "2017-05-26 10:47:31.263029: step 8860, loss = 0.91 (1405.3 examples/sec; 0.182 sec/batch)\n",
      "2017-05-26 10:47:33.048825: step 8870, loss = 0.98 (1433.5 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:47:34.763733: step 8880, loss = 1.09 (1492.8 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:47:36.412513: step 8890, loss = 0.98 (1552.7 examples/sec; 0.165 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.10776\n",
      "2017-05-26 10:47:38.468718: step 8900, loss = 0.86 (1245.0 examples/sec; 0.206 sec/batch)\n",
      "2017-05-26 10:47:40.199048: step 8910, loss = 0.96 (1479.5 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:47:41.925247: step 8920, loss = 0.89 (1483.0 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:47:43.550668: step 8930, loss = 0.89 (1575.0 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:47:45.196727: step 8940, loss = 0.89 (1555.2 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:47:46.968499: step 8950, loss = 0.92 (1444.9 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:47:50.465512: step 8970, loss = 0.96 (1495.8 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:47:52.096679: step 8980, loss = 0.85 (1569.4 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:47:53.777765: step 8990, loss = 0.97 (1522.8 examples/sec; 0.168 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.7519\n",
      "2017-05-26 10:47:55.855511: step 9000, loss = 0.97 (1232.1 examples/sec; 0.208 sec/batch)\n",
      "2017-05-26 10:47:57.511777: step 9010, loss = 0.87 (1545.6 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:47:59.154399: step 9020, loss = 0.87 (1558.5 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:48:00.793809: step 9030, loss = 0.93 (1561.5 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:48:02.529163: step 9040, loss = 0.97 (1475.2 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:48:04.306007: step 9050, loss = 0.92 (1440.8 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:48:06.037472: step 9060, loss = 1.01 (1478.5 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:48:07.664052: step 9070, loss = 0.92 (1573.9 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:48:09.371773: step 9080, loss = 0.97 (1499.1 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:48:11.120600: step 9090, loss = 0.96 (1463.8 examples/sec; 0.175 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.75031\n",
      "2017-05-26 10:48:13.247872: step 9100, loss = 0.93 (1203.4 examples/sec; 0.213 sec/batch)\n",
      "2017-05-26 10:48:15.512768: step 9110, loss = 0.93 (1130.3 examples/sec; 0.226 sec/batch)\n",
      "2017-05-26 10:48:17.828933: step 9120, loss = 0.89 (1105.3 examples/sec; 0.232 sec/batch)\n",
      "2017-05-26 10:48:21.916837: step 9140, loss = 1.01 (1299.2 examples/sec; 0.197 sec/batch)\n",
      "2017-05-26 10:48:23.682197: step 9150, loss = 0.90 (1450.1 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:48:25.407325: step 9160, loss = 0.83 (1483.9 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:48:27.029923: step 9170, loss = 0.90 (1577.7 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:48:28.663393: step 9180, loss = 1.01 (1567.2 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:48:30.374141: step 9190, loss = 0.91 (1496.4 examples/sec; 0.171 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.17407\n",
      "2017-05-26 10:48:32.571615: step 9200, loss = 1.02 (1165.0 examples/sec; 0.220 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-26 10:48:34.174006: step 9210, loss = 0.93 (1597.6 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:48:35.804227: step 9220, loss = 1.04 (1570.3 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:48:37.438478: step 9230, loss = 0.95 (1566.5 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:48:39.237156: step 9240, loss = 0.91 (1423.3 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 10:48:40.986705: step 9250, loss = 0.94 (1463.2 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:48:42.621867: step 9260, loss = 1.00 (1565.6 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:48:44.238058: step 9270, loss = 0.91 (1584.0 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:48:45.904237: step 9280, loss = 0.99 (1536.5 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:48:47.671996: step 9290, loss = 1.00 (1448.2 examples/sec; 0.177 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.836\n",
      "2017-05-26 10:48:49.708115: step 9300, loss = 0.92 (1257.3 examples/sec; 0.204 sec/batch)\n",
      "2017-05-26 10:48:51.297150: step 9310, loss = 1.02 (1611.0 examples/sec; 0.159 sec/batch)\n",
      "2017-05-26 10:48:54.666398: step 9330, loss = 0.93 (1467.5 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:48:56.446373: step 9340, loss = 1.02 (1438.2 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:48:58.588998: step 9350, loss = 0.90 (1194.8 examples/sec; 0.214 sec/batch)\n",
      "2017-05-26 10:49:01.064753: step 9360, loss = 0.99 (1034.0 examples/sec; 0.248 sec/batch)\n",
      "2017-05-26 10:49:03.311982: step 9370, loss = 0.79 (1139.2 examples/sec; 0.225 sec/batch)\n",
      "2017-05-26 10:49:05.396757: step 9380, loss = 0.91 (1227.9 examples/sec; 0.208 sec/batch)\n",
      "2017-05-26 10:49:07.142310: step 9390, loss = 0.96 (1466.6 examples/sec; 0.175 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.10601\n",
      "2017-05-26 10:49:09.291075: step 9400, loss = 0.89 (1191.4 examples/sec; 0.215 sec/batch)\n",
      "2017-05-26 10:49:10.841618: step 9410, loss = 0.97 (1651.0 examples/sec; 0.155 sec/batch)\n",
      "2017-05-26 10:49:12.458682: step 9420, loss = 1.05 (1583.1 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:49:14.146049: step 9430, loss = 0.92 (1517.2 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:49:15.885896: step 9440, loss = 0.99 (1471.4 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:49:17.692509: step 9450, loss = 0.91 (1417.0 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:49:19.307177: step 9460, loss = 0.88 (1585.5 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:49:20.919345: step 9470, loss = 0.86 (1587.9 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:49:22.671615: step 9480, loss = 0.96 (1461.0 examples/sec; 0.175 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.78787\n",
      "2017-05-26 10:49:26.569741: step 9500, loss = 0.90 (1209.6 examples/sec; 0.212 sec/batch)\n",
      "2017-05-26 10:49:28.012727: step 9510, loss = 0.97 (1774.1 examples/sec; 0.144 sec/batch)\n",
      "2017-05-26 10:49:29.629301: step 9520, loss = 0.95 (1583.6 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:49:31.422384: step 9530, loss = 0.91 (1427.7 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:49:33.183756: step 9540, loss = 0.99 (1453.4 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:49:34.796748: step 9550, loss = 0.99 (1587.1 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:49:36.426136: step 9560, loss = 0.96 (1571.1 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:49:38.141822: step 9570, loss = 0.82 (1492.1 examples/sec; 0.172 sec/batch)\n",
      "2017-05-26 10:49:39.919344: step 9580, loss = 1.02 (1440.2 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:49:41.823968: step 9590, loss = 1.11 (1344.1 examples/sec; 0.190 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.49332\n",
      "2017-05-26 10:49:44.774539: step 9600, loss = 0.83 (867.6 examples/sec; 0.295 sec/batch)\n",
      "2017-05-26 10:49:46.837183: step 9610, loss = 0.99 (1241.1 examples/sec; 0.206 sec/batch)\n",
      "2017-05-26 10:49:48.994610: step 9620, loss = 1.02 (1186.6 examples/sec; 0.216 sec/batch)\n",
      "2017-05-26 10:49:50.836698: step 9630, loss = 1.18 (1389.7 examples/sec; 0.184 sec/batch)\n",
      "2017-05-26 10:49:52.607261: step 9640, loss = 0.91 (1445.9 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:49:54.318994: step 9650, loss = 0.99 (1495.6 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:49:59.387361: step 9680, loss = 1.05 (1406.8 examples/sec; 0.182 sec/batch)\n",
      "2017-05-26 10:50:01.143380: step 9690, loss = 1.06 (1457.8 examples/sec; 0.176 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.47596\n",
      "2017-05-26 10:50:03.034159: step 9700, loss = 0.90 (1353.9 examples/sec; 0.189 sec/batch)\n",
      "2017-05-26 10:50:04.540689: step 9710, loss = 1.01 (1699.3 examples/sec; 0.151 sec/batch)\n",
      "2017-05-26 10:50:06.224768: step 9720, loss = 1.01 (1520.1 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:50:07.996203: step 9730, loss = 0.88 (1445.2 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:50:09.721488: step 9740, loss = 0.90 (1483.8 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:50:11.357803: step 9750, loss = 0.94 (1564.5 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:50:12.977836: step 9760, loss = 1.02 (1580.2 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:50:14.709241: step 9770, loss = 1.05 (1478.6 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:50:16.493929: step 9780, loss = 0.96 (1434.4 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:50:18.590310: step 9790, loss = 0.94 (1221.2 examples/sec; 0.210 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.38806\n",
      "2017-05-26 10:50:21.594502: step 9800, loss = 0.87 (852.1 examples/sec; 0.300 sec/batch)\n",
      "2017-05-26 10:50:23.462930: step 9810, loss = 0.96 (1370.1 examples/sec; 0.187 sec/batch)\n",
      "2017-05-26 10:50:25.541443: step 9820, loss = 0.92 (1231.6 examples/sec; 0.208 sec/batch)\n",
      "2017-05-26 10:50:27.334240: step 9830, loss = 0.93 (1427.9 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:50:30.746668: step 9850, loss = 0.91 (1570.9 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:50:32.359469: step 9860, loss = 0.93 (1587.3 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:50:34.011259: step 9870, loss = 0.88 (1549.8 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:50:35.760046: step 9880, loss = 0.97 (1463.9 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:50:37.588217: step 9890, loss = 0.95 (1400.3 examples/sec; 0.183 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.56371\n",
      "2017-05-26 10:50:39.567191: step 9900, loss = 0.91 (1293.6 examples/sec; 0.198 sec/batch)\n",
      "2017-05-26 10:50:41.004549: step 9910, loss = 0.90 (1781.0 examples/sec; 0.144 sec/batch)\n",
      "2017-05-26 10:50:42.776475: step 9920, loss = 1.02 (1444.8 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:50:44.543582: step 9930, loss = 0.89 (1448.7 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:50:46.226987: step 9940, loss = 0.91 (1520.7 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:50:47.834791: step 9950, loss = 0.91 (1592.2 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:50:49.462597: step 9960, loss = 1.01 (1572.7 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:50:51.255813: step 9970, loss = 0.91 (1427.6 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:50:53.040365: step 9980, loss = 0.89 (1434.5 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:50:54.707758: step 9990, loss = 0.75 (1535.3 examples/sec; 0.167 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.87491\n",
      "2017-05-26 10:50:56.588712: step 10000, loss = 0.86 (1361.0 examples/sec; 0.188 sec/batch)\n",
      "2017-05-26 10:50:58.229502: step 10010, loss = 0.96 (1560.2 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:51:03.332559: step 10040, loss = 0.93 (1578.3 examples/sec; 0.162 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 10042 into /home/ipython/cnn-cifar10/tb_log/vgg1/train/model.ckpt.\n",
      "2017-05-26 10:51:05.027973: step 10050, loss = 0.80 (1510.0 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:51:06.759517: step 10060, loss = 0.91 (1478.4 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:51:08.550465: step 10070, loss = 0.84 (1429.4 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:51:10.235494: step 10080, loss = 0.88 (1519.3 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:51:11.868314: step 10090, loss = 1.00 (1567.8 examples/sec; 0.163 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.81778\n",
      "2017-05-26 10:51:13.777631: step 10100, loss = 1.00 (1340.8 examples/sec; 0.191 sec/batch)\n",
      "2017-05-26 10:51:15.471930: step 10110, loss = 0.98 (1510.9 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:51:17.236809: step 10120, loss = 0.98 (1450.5 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:51:18.876858: step 10130, loss = 1.03 (1560.9 examples/sec; 0.164 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-26 10:51:20.497139: step 10140, loss = 1.02 (1580.0 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:51:22.185522: step 10150, loss = 0.85 (1516.2 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:51:23.937746: step 10160, loss = 0.89 (1461.0 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:51:25.669368: step 10170, loss = 0.92 (1478.4 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:51:27.316012: step 10180, loss = 0.80 (1554.7 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:51:28.984861: step 10190, loss = 1.01 (1534.0 examples/sec; 0.167 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.79381\n",
      "2017-05-26 10:51:31.037689: step 10200, loss = 0.91 (1247.1 examples/sec; 0.205 sec/batch)\n",
      "2017-05-26 10:51:34.874017: step 10220, loss = 1.00 (1183.9 examples/sec; 0.216 sec/batch)\n",
      "2017-05-26 10:51:37.328987: step 10230, loss = 0.92 (1042.8 examples/sec; 0.245 sec/batch)\n",
      "2017-05-26 10:51:39.469695: step 10240, loss = 1.01 (1195.9 examples/sec; 0.214 sec/batch)\n",
      "2017-05-26 10:51:41.543823: step 10250, loss = 0.85 (1234.3 examples/sec; 0.207 sec/batch)\n",
      "2017-05-26 10:51:43.308865: step 10260, loss = 0.90 (1450.4 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:51:45.074243: step 10270, loss = 0.92 (1450.1 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:51:46.700446: step 10280, loss = 0.84 (1574.2 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:51:48.313381: step 10290, loss = 0.83 (1587.2 examples/sec; 0.161 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.1922\n",
      "2017-05-26 10:51:50.299156: step 10300, loss = 0.91 (1289.2 examples/sec; 0.199 sec/batch)\n",
      "2017-05-26 10:51:51.972838: step 10310, loss = 0.97 (1529.6 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:51:53.699815: step 10320, loss = 0.85 (1482.4 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:51:55.335812: step 10330, loss = 0.91 (1564.8 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:51:56.938509: step 10340, loss = 0.96 (1597.3 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:51:58.665763: step 10350, loss = 0.86 (1482.1 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:52:00.450711: step 10360, loss = 0.91 (1434.2 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:52:02.606733: step 10370, loss = 0.94 (1187.4 examples/sec; 0.216 sec/batch)\n",
      "2017-05-26 10:52:07.208664: step 10390, loss = 0.95 (1173.5 examples/sec; 0.218 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.15014\n",
      "2017-05-26 10:52:09.713916: step 10400, loss = 1.00 (1021.9 examples/sec; 0.251 sec/batch)\n",
      "2017-05-26 10:52:11.418176: step 10410, loss = 1.04 (1502.1 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:52:13.174365: step 10420, loss = 0.92 (1457.7 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:52:14.829940: step 10430, loss = 0.90 (1546.3 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:52:16.446030: step 10440, loss = 0.93 (1584.1 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:52:18.173553: step 10450, loss = 0.88 (1481.9 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:52:19.927814: step 10460, loss = 0.84 (1459.3 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:52:21.661263: step 10470, loss = 0.95 (1476.8 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:52:23.278745: step 10480, loss = 0.91 (1582.7 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:52:24.892676: step 10490, loss = 0.96 (1586.2 examples/sec; 0.161 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.82509\n",
      "2017-05-26 10:52:26.883985: step 10500, loss = 0.98 (1285.6 examples/sec; 0.199 sec/batch)\n",
      "2017-05-26 10:52:28.549740: step 10510, loss = 0.90 (1536.8 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:52:30.245165: step 10520, loss = 0.92 (1509.9 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:52:31.851426: step 10530, loss = 0.90 (1593.8 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:52:33.429159: step 10540, loss = 0.87 (1622.6 examples/sec; 0.158 sec/batch)\n",
      "2017-05-26 10:52:35.159945: step 10550, loss = 0.98 (1479.1 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:52:38.628956: step 10570, loss = 0.81 (1537.3 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:52:40.246069: step 10580, loss = 0.79 (1583.1 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:52:41.962016: step 10590, loss = 0.85 (1491.9 examples/sec; 0.172 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.81386\n",
      "2017-05-26 10:52:44.083212: step 10600, loss = 0.84 (1206.9 examples/sec; 0.212 sec/batch)\n",
      "2017-05-26 10:52:45.769795: step 10610, loss = 0.92 (1517.9 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:52:48.224087: step 10620, loss = 0.93 (1043.1 examples/sec; 0.245 sec/batch)\n",
      "2017-05-26 10:52:50.481490: step 10630, loss = 1.04 (1134.0 examples/sec; 0.226 sec/batch)\n",
      "2017-05-26 10:52:52.610341: step 10640, loss = 0.99 (1202.5 examples/sec; 0.213 sec/batch)\n",
      "2017-05-26 10:52:54.496967: step 10650, loss = 0.91 (1356.9 examples/sec; 0.189 sec/batch)\n",
      "2017-05-26 10:52:56.230722: step 10660, loss = 0.97 (1476.6 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:52:57.982279: step 10670, loss = 1.05 (1461.6 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:52:59.571604: step 10680, loss = 0.91 (1610.7 examples/sec; 0.159 sec/batch)\n",
      "2017-05-26 10:53:01.242337: step 10690, loss = 0.93 (1532.3 examples/sec; 0.167 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.17637\n",
      "2017-05-26 10:53:03.400217: step 10700, loss = 0.89 (1186.3 examples/sec; 0.216 sec/batch)\n",
      "2017-05-26 10:53:04.980475: step 10710, loss = 0.90 (1620.0 examples/sec; 0.158 sec/batch)\n",
      "2017-05-26 10:53:06.641295: step 10720, loss = 1.01 (1541.4 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:53:09.939557: step 10740, loss = 0.97 (1563.1 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:53:11.701209: step 10750, loss = 1.06 (1453.2 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:53:13.444866: step 10760, loss = 0.99 (1468.2 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:53:15.090746: step 10770, loss = 0.93 (1555.4 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:53:16.686670: step 10780, loss = 0.91 (1604.1 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:53:18.395781: step 10790, loss = 0.89 (1497.9 examples/sec; 0.171 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.85021\n",
      "2017-05-26 10:53:20.495011: step 10800, loss = 1.00 (1219.5 examples/sec; 0.210 sec/batch)\n",
      "2017-05-26 10:53:22.084524: step 10810, loss = 1.00 (1610.6 examples/sec; 0.159 sec/batch)\n",
      "2017-05-26 10:53:23.682359: step 10820, loss = 0.98 (1602.2 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:53:25.313416: step 10830, loss = 0.89 (1569.5 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:53:27.071864: step 10840, loss = 1.02 (1455.8 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:53:28.880966: step 10850, loss = 0.95 (1415.1 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:53:30.569896: step 10860, loss = 0.93 (1515.8 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:53:32.203838: step 10870, loss = 0.95 (1566.8 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:53:33.860771: step 10880, loss = 0.86 (1545.0 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:53:35.627662: step 10890, loss = 0.78 (1448.9 examples/sec; 0.177 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.77142\n",
      "2017-05-26 10:53:37.823912: step 10900, loss = 0.86 (1165.6 examples/sec; 0.220 sec/batch)\n",
      "2017-05-26 10:53:42.476139: step 10920, loss = 0.92 (1110.5 examples/sec; 0.231 sec/batch)\n",
      "2017-05-26 10:53:44.591452: step 10930, loss = 0.98 (1210.2 examples/sec; 0.212 sec/batch)\n",
      "2017-05-26 10:53:46.512432: step 10940, loss = 1.00 (1332.7 examples/sec; 0.192 sec/batch)\n",
      "2017-05-26 10:53:48.328249: step 10950, loss = 0.91 (1409.8 examples/sec; 0.182 sec/batch)\n",
      "2017-05-26 10:53:50.039339: step 10960, loss = 0.93 (1496.1 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:53:51.638280: step 10970, loss = 0.85 (1601.1 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:53:53.265142: step 10980, loss = 0.91 (1573.6 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:53:55.027327: step 10990, loss = 0.85 (1452.7 examples/sec; 0.176 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.17349\n",
      "2017-05-26 10:53:57.151080: step 11000, loss = 0.85 (1205.4 examples/sec; 0.212 sec/batch)\n",
      "2017-05-26 10:53:58.720801: step 11010, loss = 0.90 (1630.9 examples/sec; 0.157 sec/batch)\n",
      "2017-05-26 10:54:00.340757: step 11020, loss = 0.96 (1580.3 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:54:02.020161: step 11030, loss = 0.86 (1524.4 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:54:03.789092: step 11040, loss = 0.81 (1447.2 examples/sec; 0.177 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-26 10:54:05.551617: step 11050, loss = 0.86 (1452.5 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:54:07.262333: step 11060, loss = 0.99 (1496.4 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:54:09.017348: step 11070, loss = 0.91 (1458.7 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:54:10.723575: step 11080, loss = 1.03 (1500.4 examples/sec; 0.171 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.64701\n",
      "2017-05-26 10:54:14.857697: step 11100, loss = 0.81 (1086.3 examples/sec; 0.236 sec/batch)\n",
      "2017-05-26 10:54:16.098164: step 11110, loss = 0.95 (2063.7 examples/sec; 0.124 sec/batch)\n",
      "2017-05-26 10:54:17.709619: step 11120, loss = 0.94 (1588.6 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:54:19.537839: step 11130, loss = 1.07 (1400.3 examples/sec; 0.183 sec/batch)\n",
      "2017-05-26 10:54:21.298462: step 11140, loss = 1.03 (1454.0 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:54:22.935857: step 11150, loss = 0.94 (1563.5 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:54:24.568379: step 11160, loss = 0.92 (1568.1 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:54:26.241566: step 11170, loss = 0.95 (1530.0 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:54:28.004396: step 11180, loss = 1.02 (1452.2 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:54:29.802507: step 11190, loss = 0.89 (1423.7 examples/sec; 0.180 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.92291\n",
      "2017-05-26 10:54:31.741290: step 11200, loss = 0.86 (1320.4 examples/sec; 0.194 sec/batch)\n",
      "2017-05-26 10:54:33.264078: step 11210, loss = 0.81 (1681.1 examples/sec; 0.152 sec/batch)\n",
      "2017-05-26 10:54:34.995086: step 11220, loss = 1.05 (1478.9 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:54:36.749854: step 11230, loss = 0.81 (1458.9 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:54:38.454737: step 11240, loss = 0.94 (1501.6 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:54:40.066734: step 11250, loss = 0.93 (1588.1 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:54:41.704476: step 11260, loss = 0.86 (1563.1 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:54:43.453533: step 11270, loss = 0.97 (1463.6 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:54:46.910835: step 11290, loss = 0.91 (1554.3 examples/sec; 0.165 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.85742\n",
      "2017-05-26 10:54:48.813797: step 11300, loss = 0.99 (1345.3 examples/sec; 0.190 sec/batch)\n",
      "2017-05-26 10:54:50.413802: step 11310, loss = 0.85 (1600.0 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:54:52.159240: step 11320, loss = 0.99 (1466.7 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:54:54.090718: step 11330, loss = 0.84 (1325.4 examples/sec; 0.193 sec/batch)\n",
      "2017-05-26 10:54:56.546675: step 11340, loss = 0.96 (1042.4 examples/sec; 0.246 sec/batch)\n",
      "2017-05-26 10:54:58.835325: step 11350, loss = 0.93 (1118.6 examples/sec; 0.229 sec/batch)\n",
      "2017-05-26 10:55:00.914293: step 11360, loss = 0.98 (1231.4 examples/sec; 0.208 sec/batch)\n",
      "2017-05-26 10:55:02.794791: step 11370, loss = 0.92 (1361.3 examples/sec; 0.188 sec/batch)\n",
      "2017-05-26 10:55:04.565309: step 11380, loss = 0.81 (1445.9 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:55:06.246757: step 11390, loss = 0.89 (1522.5 examples/sec; 0.168 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.17565\n",
      "2017-05-26 10:55:08.135658: step 11400, loss = 0.94 (1355.3 examples/sec; 0.189 sec/batch)\n",
      "2017-05-26 10:55:09.679238: step 11410, loss = 0.86 (1658.5 examples/sec; 0.154 sec/batch)\n",
      "2017-05-26 10:55:11.450691: step 11420, loss = 0.96 (1445.1 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:55:13.229720: step 11430, loss = 0.89 (1439.0 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:55:14.867603: step 11440, loss = 0.85 (1563.0 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:55:18.152537: step 11460, loss = 0.93 (1546.1 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:55:19.908093: step 11470, loss = 0.96 (1458.2 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:55:21.672141: step 11480, loss = 0.88 (1451.2 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:55:23.297094: step 11490, loss = 0.95 (1575.4 examples/sec; 0.162 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.87151\n",
      "2017-05-26 10:55:25.167983: step 11500, loss = 0.93 (1368.3 examples/sec; 0.187 sec/batch)\n",
      "2017-05-26 10:55:26.841392: step 11510, loss = 0.85 (1529.8 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:55:28.635207: step 11520, loss = 0.82 (1427.1 examples/sec; 0.179 sec/batch)\n",
      "2017-05-26 10:55:30.351761: step 11530, loss = 0.86 (1491.4 examples/sec; 0.172 sec/batch)\n",
      "2017-05-26 10:55:32.039509: step 11540, loss = 0.85 (1516.8 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:55:33.643981: step 11550, loss = 0.89 (1595.5 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:55:35.418075: step 11560, loss = 0.96 (1443.0 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:55:37.164216: step 11570, loss = 0.88 (1466.1 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:55:38.829955: step 11580, loss = 0.98 (1536.9 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:55:40.474236: step 11590, loss = 0.82 (1556.9 examples/sec; 0.164 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.79132\n",
      "2017-05-26 10:55:42.434015: step 11600, loss = 0.94 (1306.3 examples/sec; 0.196 sec/batch)\n",
      "2017-05-26 10:55:44.078394: step 11610, loss = 1.07 (1556.8 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:55:45.816899: step 11620, loss = 0.83 (1472.5 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:55:47.468137: step 11630, loss = 0.81 (1550.4 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:55:50.777249: step 11650, loss = 0.93 (1493.5 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:55:52.542632: step 11660, loss = 0.95 (1450.1 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:55:54.242588: step 11670, loss = 0.99 (1505.9 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:55:55.851725: step 11680, loss = 0.87 (1590.9 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:55:57.492528: step 11690, loss = 0.91 (1560.2 examples/sec; 0.164 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.81034\n",
      "2017-05-26 10:55:59.644563: step 11700, loss = 0.85 (1189.6 examples/sec; 0.215 sec/batch)\n",
      "2017-05-26 10:56:01.336536: step 11710, loss = 0.95 (1513.0 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:56:02.971843: step 11720, loss = 0.80 (1565.5 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:56:04.566619: step 11730, loss = 0.98 (1605.2 examples/sec; 0.159 sec/batch)\n",
      "2017-05-26 10:56:06.231695: step 11740, loss = 0.95 (1537.5 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 10:56:08.040974: step 11750, loss = 1.06 (1414.9 examples/sec; 0.181 sec/batch)\n",
      "2017-05-26 10:56:09.804362: step 11760, loss = 0.86 (1451.8 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:56:11.405579: step 11770, loss = 0.93 (1598.8 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:56:12.992788: step 11780, loss = 0.90 (1612.9 examples/sec; 0.159 sec/batch)\n",
      "2017-05-26 10:56:14.692570: step 11790, loss = 1.06 (1506.1 examples/sec; 0.170 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.78901\n",
      "2017-05-26 10:56:16.918400: step 11800, loss = 0.90 (1150.1 examples/sec; 0.223 sec/batch)\n",
      "2017-05-26 10:56:18.698142: step 11810, loss = 0.88 (1438.4 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:56:23.315285: step 11830, loss = 0.92 (1170.0 examples/sec; 0.219 sec/batch)\n",
      "2017-05-26 10:56:25.403346: step 11840, loss = 0.84 (1226.0 examples/sec; 0.209 sec/batch)\n",
      "2017-05-26 10:56:27.262426: step 11850, loss = 0.98 (1377.0 examples/sec; 0.186 sec/batch)\n",
      "2017-05-26 10:56:29.012719: step 11860, loss = 0.88 (1462.6 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:56:30.676586: step 11870, loss = 0.94 (1538.6 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:56:32.291865: step 11880, loss = 0.86 (1584.9 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:56:33.955453: step 11890, loss = 1.05 (1538.8 examples/sec; 0.166 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.22192\n",
      "2017-05-26 10:56:36.070348: step 11900, loss = 0.92 (1210.5 examples/sec; 0.211 sec/batch)\n",
      "2017-05-26 10:56:37.706311: step 11910, loss = 1.00 (1564.8 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:56:39.321235: step 11920, loss = 0.91 (1585.2 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:56:40.926106: step 11930, loss = 0.86 (1595.1 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:56:42.615955: step 11940, loss = 0.85 (1514.9 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:56:44.379161: step 11950, loss = 0.84 (1451.9 examples/sec; 0.176 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-26 10:56:46.102732: step 11960, loss = 0.86 (1485.3 examples/sec; 0.172 sec/batch)\n",
      "2017-05-26 10:56:47.765360: step 11970, loss = 0.85 (1539.7 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:56:49.399654: step 11980, loss = 0.88 (1566.4 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:56:51.131632: step 11990, loss = 1.04 (1478.1 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:56:54.752706: step 12010, loss = 0.85 (1708.2 examples/sec; 0.150 sec/batch)\n",
      "2017-05-26 10:56:56.354714: step 12020, loss = 1.00 (1598.0 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:56:58.011990: step 12030, loss = 0.94 (1544.7 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:56:59.895593: step 12040, loss = 0.79 (1359.1 examples/sec; 0.188 sec/batch)\n",
      "2017-05-26 10:57:01.651374: step 12050, loss = 0.90 (1458.0 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:57:03.298065: step 12060, loss = 0.99 (1554.6 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:57:04.880113: step 12070, loss = 0.88 (1618.2 examples/sec; 0.158 sec/batch)\n",
      "2017-05-26 10:57:06.598497: step 12080, loss = 0.92 (1489.8 examples/sec; 0.172 sec/batch)\n",
      "2017-05-26 10:57:08.480598: step 12090, loss = 0.85 (1360.2 examples/sec; 0.188 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.66075\n",
      "2017-05-26 10:57:10.920687: step 12100, loss = 0.92 (1049.1 examples/sec; 0.244 sec/batch)\n",
      "2017-05-26 10:57:13.292053: step 12110, loss = 1.02 (1079.5 examples/sec; 0.237 sec/batch)\n",
      "2017-05-26 10:57:15.436865: step 12120, loss = 0.81 (1193.6 examples/sec; 0.214 sec/batch)\n",
      "2017-05-26 10:57:17.518566: step 12130, loss = 0.82 (1229.8 examples/sec; 0.208 sec/batch)\n",
      "2017-05-26 10:57:19.417830: step 12140, loss = 0.95 (1347.9 examples/sec; 0.190 sec/batch)\n",
      "2017-05-26 10:57:21.161050: step 12150, loss = 0.93 (1468.5 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:57:22.816196: step 12160, loss = 0.93 (1546.7 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:57:26.061552: step 12180, loss = 0.89 (1564.1 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:57:27.824443: step 12190, loss = 0.89 (1452.2 examples/sec; 0.176 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.20886\n",
      "2017-05-26 10:57:30.118810: step 12200, loss = 0.95 (1115.8 examples/sec; 0.229 sec/batch)\n",
      "2017-05-26 10:57:32.445858: step 12210, loss = 0.90 (1100.1 examples/sec; 0.233 sec/batch)\n",
      "2017-05-26 10:57:34.724011: step 12220, loss = 0.99 (1123.7 examples/sec; 0.228 sec/batch)\n",
      "2017-05-26 10:57:36.914144: step 12230, loss = 0.94 (1168.9 examples/sec; 0.219 sec/batch)\n",
      "2017-05-26 10:57:39.026359: step 12240, loss = 0.87 (1212.0 examples/sec; 0.211 sec/batch)\n",
      "2017-05-26 10:57:40.754604: step 12250, loss = 0.89 (1481.3 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:57:42.450644: step 12260, loss = 0.93 (1509.4 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:57:44.082632: step 12270, loss = 0.89 (1568.6 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:57:45.694002: step 12280, loss = 0.92 (1588.7 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:57:47.443399: step 12290, loss = 0.88 (1463.4 examples/sec; 0.175 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.07598\n",
      "2017-05-26 10:57:49.818053: step 12300, loss = 0.82 (1078.1 examples/sec; 0.237 sec/batch)\n",
      "2017-05-26 10:57:51.123389: step 12310, loss = 0.87 (1961.2 examples/sec; 0.131 sec/batch)\n",
      "2017-05-26 10:57:52.748654: step 12320, loss = 0.89 (1575.1 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:57:54.424205: step 12330, loss = 0.95 (1527.9 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:57:57.972952: step 12350, loss = 1.03 (1464.9 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:57:59.710966: step 12360, loss = 0.84 (1472.9 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:58:01.327960: step 12370, loss = 0.89 (1583.2 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:58:03.075514: step 12380, loss = 0.87 (1464.9 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:58:04.847305: step 12390, loss = 0.83 (1444.9 examples/sec; 0.177 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.87182\n",
      "2017-05-26 10:58:06.848559: step 12400, loss = 0.90 (1279.2 examples/sec; 0.200 sec/batch)\n",
      "2017-05-26 10:58:08.367302: step 12410, loss = 1.01 (1685.6 examples/sec; 0.152 sec/batch)\n",
      "2017-05-26 10:58:10.118334: step 12420, loss = 0.93 (1462.0 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:58:11.849277: step 12430, loss = 0.87 (1479.0 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:58:13.591673: step 12440, loss = 0.85 (1469.2 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:58:15.203105: step 12450, loss = 0.91 (1588.6 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:58:16.802706: step 12460, loss = 0.82 (1600.4 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:58:18.481916: step 12470, loss = 0.85 (1524.5 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:58:20.264321: step 12480, loss = 0.89 (1436.3 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:58:22.009716: step 12490, loss = 0.87 (1466.7 examples/sec; 0.175 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.84727\n",
      "2017-05-26 10:58:23.950293: step 12500, loss = 0.87 (1319.2 examples/sec; 0.194 sec/batch)\n",
      "2017-05-26 10:58:25.446803: step 12510, loss = 0.89 (1710.6 examples/sec; 0.150 sec/batch)\n",
      "2017-05-26 10:58:27.178618: step 12520, loss = 0.93 (1478.2 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:58:30.643674: step 12540, loss = 0.82 (1525.1 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:58:32.246357: step 12550, loss = 0.96 (1597.3 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:58:33.897442: step 12560, loss = 0.95 (1550.5 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:58:35.643343: step 12570, loss = 0.97 (1466.3 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:58:37.404721: step 12580, loss = 0.92 (1453.4 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 10:58:39.063395: step 12590, loss = 0.89 (1543.4 examples/sec; 0.166 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.872\n",
      "2017-05-26 10:58:40.982084: step 12600, loss = 0.97 (1334.2 examples/sec; 0.192 sec/batch)\n",
      "2017-05-26 10:58:42.537420: step 12610, loss = 0.81 (1645.9 examples/sec; 0.156 sec/batch)\n",
      "2017-05-26 10:58:44.286923: step 12620, loss = 0.81 (1463.3 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:58:46.013676: step 12630, loss = 0.98 (1482.6 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:58:47.642656: step 12640, loss = 0.88 (1571.5 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 10:58:49.280350: step 12650, loss = 0.93 (1563.2 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 10:58:51.058426: step 12660, loss = 0.87 (1439.8 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:58:52.840589: step 12670, loss = 0.97 (1436.5 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:58:54.896600: step 12680, loss = 0.91 (1245.1 examples/sec; 0.206 sec/batch)\n",
      "2017-05-26 10:58:57.344339: step 12690, loss = 1.05 (1045.9 examples/sec; 0.245 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.27782\n",
      "2017-05-26 10:59:01.916244: step 12710, loss = 0.92 (1289.4 examples/sec; 0.199 sec/batch)\n",
      "2017-05-26 10:59:03.698660: step 12720, loss = 1.02 (1436.3 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:59:05.434601: step 12730, loss = 0.92 (1474.7 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 10:59:07.128883: step 12740, loss = 0.90 (1511.0 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 10:59:08.804681: step 12750, loss = 0.90 (1527.6 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 10:59:10.458891: step 12760, loss = 1.03 (1547.6 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 10:59:12.229571: step 12770, loss = 0.90 (1445.8 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:59:13.979784: step 12780, loss = 0.91 (1462.7 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:59:15.612738: step 12790, loss = 0.86 (1567.7 examples/sec; 0.163 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.66751\n",
      "2017-05-26 10:59:17.572189: step 12800, loss = 0.82 (1306.5 examples/sec; 0.196 sec/batch)\n",
      "2017-05-26 10:59:19.227998: step 12810, loss = 0.98 (1546.1 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 10:59:20.980735: step 12820, loss = 0.93 (1460.6 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:59:22.695207: step 12830, loss = 0.93 (1493.2 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 10:59:24.307469: step 12840, loss = 0.99 (1587.8 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 10:59:25.911694: step 12850, loss = 0.98 (1595.8 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:59:27.677562: step 12860, loss = 0.95 (1449.7 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 10:59:29.477352: step 12870, loss = 0.87 (1422.4 examples/sec; 0.180 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-26 10:59:31.110826: step 12880, loss = 0.93 (1567.2 examples/sec; 0.163 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.77245\n",
      "2017-05-26 10:59:34.896403: step 12900, loss = 0.86 (1184.0 examples/sec; 0.216 sec/batch)\n",
      "2017-05-26 10:59:36.359666: step 12910, loss = 0.86 (1749.5 examples/sec; 0.146 sec/batch)\n",
      "2017-05-26 10:59:38.109873: step 12920, loss = 0.86 (1462.7 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 10:59:39.712399: step 12930, loss = 1.01 (1597.5 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 10:59:41.329675: step 12940, loss = 0.93 (1582.9 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 10:59:43.056367: step 12950, loss = 0.92 (1482.6 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 10:59:44.841156: step 12960, loss = 0.88 (1434.3 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:59:46.862647: step 12970, loss = 0.90 (1266.4 examples/sec; 0.202 sec/batch)\n",
      "2017-05-26 10:59:49.394052: step 12980, loss = 0.86 (1011.3 examples/sec; 0.253 sec/batch)\n",
      "2017-05-26 10:59:51.545423: step 12990, loss = 0.96 (1189.9 examples/sec; 0.215 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.22385\n",
      "2017-05-26 10:59:54.039424: step 13000, loss = 0.98 (1026.5 examples/sec; 0.249 sec/batch)\n",
      "2017-05-26 10:59:55.736156: step 13010, loss = 0.97 (1508.8 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 10:59:57.511623: step 13020, loss = 0.90 (1441.9 examples/sec; 0.178 sec/batch)\n",
      "2017-05-26 10:59:59.159183: step 13030, loss = 0.90 (1553.8 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 11:00:00.766036: step 13040, loss = 0.96 (1593.2 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 11:00:02.438551: step 13050, loss = 0.84 (1530.6 examples/sec; 0.167 sec/batch)\n",
      "2017-05-26 11:00:05.976039: step 13070, loss = 0.85 (1466.6 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 11:00:07.565109: step 13080, loss = 0.98 (1611.0 examples/sec; 0.159 sec/batch)\n",
      "2017-05-26 11:00:09.313235: step 13090, loss = 0.89 (1464.4 examples/sec; 0.175 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.7775\n",
      "2017-05-26 11:00:11.347251: step 13100, loss = 0.84 (1258.6 examples/sec; 0.203 sec/batch)\n",
      "2017-05-26 11:00:12.998777: step 13110, loss = 1.01 (1550.1 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 11:00:14.729871: step 13120, loss = 0.92 (1478.8 examples/sec; 0.173 sec/batch)\n",
      "2017-05-26 11:00:16.363851: step 13130, loss = 0.90 (1566.7 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 11:00:17.991785: step 13140, loss = 0.81 (1572.5 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 11:00:19.931865: step 13150, loss = 0.87 (1319.5 examples/sec; 0.194 sec/batch)\n",
      "2017-05-26 11:00:21.679996: step 13160, loss = 0.96 (1464.4 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 11:00:23.338561: step 13170, loss = 0.97 (1543.5 examples/sec; 0.166 sec/batch)\n",
      "2017-05-26 11:00:24.941412: step 13180, loss = 0.88 (1597.2 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 11:00:26.607910: step 13190, loss = 0.87 (1536.2 examples/sec; 0.167 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.75744\n",
      "2017-05-26 11:00:28.716078: step 13200, loss = 0.92 (1214.3 examples/sec; 0.211 sec/batch)\n",
      "2017-05-26 11:00:30.418600: step 13210, loss = 0.86 (1503.7 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 11:00:32.024933: step 13220, loss = 0.88 (1593.7 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 11:00:33.664255: step 13230, loss = 1.02 (1561.6 examples/sec; 0.164 sec/batch)\n",
      "2017-05-26 11:00:35.402919: step 13240, loss = 0.90 (1472.4 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 11:00:39.474964: step 13260, loss = 0.86 (1106.1 examples/sec; 0.231 sec/batch)\n",
      "2017-05-26 11:00:41.872869: step 13270, loss = 0.86 (1067.6 examples/sec; 0.240 sec/batch)\n",
      "2017-05-26 11:00:43.963107: step 13280, loss = 0.95 (1224.7 examples/sec; 0.209 sec/batch)\n",
      "2017-05-26 11:00:46.017042: step 13290, loss = 0.98 (1246.4 examples/sec; 0.205 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.13684\n",
      "2017-05-26 11:00:48.183794: step 13300, loss = 1.00 (1181.5 examples/sec; 0.217 sec/batch)\n",
      "2017-05-26 11:00:49.759206: step 13310, loss = 0.92 (1625.0 examples/sec; 0.158 sec/batch)\n",
      "2017-05-26 11:00:51.387189: step 13320, loss = 0.84 (1572.5 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 11:00:52.993108: step 13330, loss = 0.93 (1594.1 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 11:00:54.713462: step 13340, loss = 0.90 (1488.1 examples/sec; 0.172 sec/batch)\n",
      "2017-05-26 11:00:56.449749: step 13350, loss = 0.88 (1474.4 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 11:00:58.205380: step 13360, loss = 0.82 (1458.2 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 11:00:59.897632: step 13370, loss = 0.87 (1512.8 examples/sec; 0.169 sec/batch)\n",
      "2017-05-26 11:01:01.502479: step 13380, loss = 0.84 (1595.2 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 11:01:03.216662: step 13390, loss = 0.92 (1493.4 examples/sec; 0.171 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 13393 into /home/ipython/cnn-cifar10/tb_log/vgg1/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 5.79199\n",
      "2017-05-26 11:01:05.449168: step 13400, loss = 1.00 (1146.7 examples/sec; 0.223 sec/batch)\n",
      "2017-05-26 11:01:06.981863: step 13410, loss = 0.86 (1670.3 examples/sec; 0.153 sec/batch)\n",
      "2017-05-26 11:01:10.302068: step 13430, loss = 0.78 (1577.1 examples/sec; 0.162 sec/batch)\n",
      "2017-05-26 11:01:12.058967: step 13440, loss = 0.88 (1457.1 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 11:01:13.820385: step 13450, loss = 0.87 (1453.4 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 11:01:15.410168: step 13460, loss = 0.90 (1610.3 examples/sec; 0.159 sec/batch)\n",
      "2017-05-26 11:01:16.998148: step 13470, loss = 0.87 (1612.1 examples/sec; 0.159 sec/batch)\n",
      "2017-05-26 11:01:18.694410: step 13480, loss = 0.94 (1509.2 examples/sec; 0.170 sec/batch)\n",
      "2017-05-26 11:01:20.509857: step 13490, loss = 0.84 (1410.1 examples/sec; 0.182 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.84904\n",
      "2017-05-26 11:01:22.545209: step 13500, loss = 0.84 (1257.8 examples/sec; 0.204 sec/batch)\n",
      "2017-05-26 11:01:24.046036: step 13510, loss = 0.85 (1705.7 examples/sec; 0.150 sec/batch)\n",
      "2017-05-26 11:01:25.653689: step 13520, loss = 0.88 (1592.4 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 11:01:27.426424: step 13530, loss = 0.93 (1444.1 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 11:01:29.230194: step 13540, loss = 0.83 (1419.2 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 11:01:30.979476: step 13550, loss = 1.01 (1463.5 examples/sec; 0.175 sec/batch)\n",
      "2017-05-26 11:01:32.613074: step 13560, loss = 0.85 (1567.1 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 11:01:34.262694: step 13570, loss = 0.86 (1551.9 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 11:01:36.025831: step 13580, loss = 0.84 (1452.0 examples/sec; 0.176 sec/batch)\n",
      "2017-05-26 11:01:37.791711: step 13590, loss = 0.87 (1449.7 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 11:01:43.015387: step 13610, loss = 0.94 (1176.2 examples/sec; 0.218 sec/batch)\n",
      "2017-05-26 11:01:45.133943: step 13620, loss = 0.89 (1208.4 examples/sec; 0.212 sec/batch)\n",
      "2017-05-26 11:01:47.036438: step 13630, loss = 0.78 (1345.6 examples/sec; 0.190 sec/batch)\n",
      "2017-05-26 11:01:48.840058: step 13640, loss = 0.85 (1419.4 examples/sec; 0.180 sec/batch)\n",
      "2017-05-26 11:01:50.552017: step 13650, loss = 0.87 (1495.4 examples/sec; 0.171 sec/batch)\n",
      "2017-05-26 11:01:52.162479: step 13660, loss = 0.99 (1589.6 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 11:01:53.761817: step 13670, loss = 0.90 (1600.7 examples/sec; 0.160 sec/batch)\n",
      "2017-05-26 11:01:55.527117: step 13680, loss = 0.88 (1450.2 examples/sec; 0.177 sec/batch)\n",
      "2017-05-26 11:01:57.308602: step 13690, loss = 0.81 (1437.0 examples/sec; 0.178 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 5.43022\n",
      "2017-05-26 11:01:59.252776: step 13700, loss = 0.98 (1316.8 examples/sec; 0.194 sec/batch)\n",
      "2017-05-26 11:02:00.798530: step 13710, loss = 0.86 (1656.2 examples/sec; 0.155 sec/batch)\n",
      "2017-05-26 11:02:02.450103: step 13720, loss = 0.94 (1550.0 examples/sec; 0.165 sec/batch)\n",
      "2017-05-26 11:02:04.191057: step 13730, loss = 0.79 (1470.5 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 11:02:05.932088: step 13740, loss = 0.95 (1470.4 examples/sec; 0.174 sec/batch)\n",
      "2017-05-26 11:02:07.560744: step 13750, loss = 0.96 (1571.8 examples/sec; 0.163 sec/batch)\n",
      "2017-05-26 11:02:09.172746: step 13760, loss = 0.87 (1588.1 examples/sec; 0.161 sec/batch)\n",
      "2017-05-26 11:02:10.850802: step 13770, loss = 0.95 (1525.6 examples/sec; 0.168 sec/batch)\n",
      "2017-05-26 11:02:14.320666: step 13790, loss = 0.93 (1482.8 examples/sec; 0.173 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 5.9006\n",
      "2017-05-26 11:02:16.201874: step 13800, loss = 0.88 (1360.8 examples/sec; 0.188 sec/batch)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9d1711d24cbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mArguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcifar10_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ipython/cnn-cifar10/cifar10/cifar10_train.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m             log_device_placement=Arguments.log_device_placement)) as mon_sess:\n\u001b[1;32m    100\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    482\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    818\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    821\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    928\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m     \u001b[0mfetch_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \"\"\"\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    230\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m       \u001b[0;31m# Look for a handler in the registered expansions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     self._mappers = [_FetchMapper.for_fetch(fetch)\n\u001b[0;32m--> 370\u001b[0;31m                      for fetch in fetches.values()]\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    265\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 267\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    268\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2409\u001b[0m     \"\"\"\n\u001b[1;32m   2410\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2411\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2413\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2432\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allow_tensor and allow_operation can't both be False.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2434\u001b[0;31m     \u001b[0mtemp_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtemp_obj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2436\u001b[0m       \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_as_graph_element\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    136\u001b[0m   \"\"\"\n\u001b[1;32m    137\u001b[0m   \u001b[0mconv_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_as_graph_element\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mconv_fn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconv_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "Arguments.set_model_folder(\"vgg1\")\n",
    "print(Arguments.train_dir)\n",
    "\n",
    "cifar10_train.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
