{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# restart notebook when retrain model as some initial problem\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from cifar10 import cifar10_train\n",
    "from cifar10.cifar10_args import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "/home/ipython/cnn-cifar10/tb_log/vggE/train\n",
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "(256,)\n",
      "INFO:tensorflow:Summary name vgg1-conv0/weight_loss (raw) is illegal; using vgg1-conv0/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg1-conv1/weight_loss (raw) is illegal; using vgg1-conv1/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg2-conv0/weight_loss (raw) is illegal; using vgg2-conv0/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg2-conv1/weight_loss (raw) is illegal; using vgg2-conv1/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg3-conv0/weight_loss (raw) is illegal; using vgg3-conv0/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg3-conv1/weight_loss (raw) is illegal; using vgg3-conv1/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg3-conv2/weight_loss (raw) is illegal; using vgg3-conv2/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg3-conv3/weight_loss (raw) is illegal; using vgg3-conv3/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg4-conv0/weight_loss (raw) is illegal; using vgg4-conv0/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg4-conv1/weight_loss (raw) is illegal; using vgg4-conv1/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg4-conv2/weight_loss (raw) is illegal; using vgg4-conv2/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg4-conv3/weight_loss (raw) is illegal; using vgg4-conv3/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local3/weight_loss (raw) is illegal; using local3/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local4/weight_loss (raw) is illegal; using local4/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name softmax_linear/weight_loss (raw) is illegal; using softmax_linear/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name cross_entropy (raw) is illegal; using cross_entropy__raw_ instead.\n",
      "INFO:tensorflow:Summary name total_loss (raw) is illegal; using total_loss__raw_ instead.\n",
      "10000000\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /home/ipython/cnn-cifar10/tb_log/vggE/train/model.ckpt.\n",
      "2017-05-26 15:38:03.952549: step 0, loss = 33.26 (163.9 examples/sec; 1.562 sec/batch)\n",
      "2017-05-26 15:38:07.056242: step 10, loss = 21.35 (824.8 examples/sec; 0.310 sec/batch)\n",
      "2017-05-26 15:38:10.310503: step 20, loss = 13.51 (786.7 examples/sec; 0.325 sec/batch)\n",
      "2017-05-26 15:38:13.625037: step 30, loss = 8.70 (772.4 examples/sec; 0.331 sec/batch)\n",
      "2017-05-26 15:38:16.960733: step 40, loss = 5.85 (767.5 examples/sec; 0.334 sec/batch)\n",
      "2017-05-26 15:38:20.236458: step 50, loss = 4.22 (781.5 examples/sec; 0.328 sec/batch)\n",
      "2017-05-26 15:38:23.583562: step 60, loss = 3.31 (764.8 examples/sec; 0.335 sec/batch)\n",
      "2017-05-26 15:38:26.834423: step 70, loss = 2.82 (787.5 examples/sec; 0.325 sec/batch)\n",
      "2017-05-26 15:38:30.143320: step 80, loss = 2.51 (773.7 examples/sec; 0.331 sec/batch)\n",
      "2017-05-26 15:38:33.491253: step 90, loss = 2.42 (764.7 examples/sec; 0.335 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.82757\n",
      "2017-05-26 15:38:38.445576: step 100, loss = 2.30 (516.7 examples/sec; 0.495 sec/batch)\n",
      "2017-05-26 15:38:42.337329: step 110, loss = 2.17 (657.8 examples/sec; 0.389 sec/batch)\n",
      "2017-05-26 15:38:48.060105: step 120, loss = 2.16 (447.3 examples/sec; 0.572 sec/batch)\n",
      "2017-05-26 15:38:53.104066: step 130, loss = 2.11 (507.5 examples/sec; 0.504 sec/batch)\n",
      "2017-05-26 15:38:58.317106: step 140, loss = 2.16 (491.1 examples/sec; 0.521 sec/batch)\n",
      "2017-05-26 15:39:03.171322: step 150, loss = 2.09 (527.4 examples/sec; 0.485 sec/batch)\n",
      "2017-05-26 15:39:08.215241: step 160, loss = 2.13 (507.5 examples/sec; 0.504 sec/batch)\n",
      "2017-05-26 15:39:13.861184: step 170, loss = 2.13 (453.4 examples/sec; 0.565 sec/batch)\n",
      "2017-05-26 15:39:19.073391: step 180, loss = 2.10 (491.2 examples/sec; 0.521 sec/batch)\n",
      "2017-05-26 15:39:23.624518: step 190, loss = 2.09 (562.5 examples/sec; 0.455 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.8543\n",
      "2017-05-26 15:39:32.378646: step 200, loss = 2.05 (292.4 examples/sec; 0.875 sec/batch)\n",
      "2017-05-26 15:39:36.770595: step 210, loss = 2.08 (582.9 examples/sec; 0.439 sec/batch)\n",
      "2017-05-26 15:39:41.458753: step 220, loss = 2.11 (546.1 examples/sec; 0.469 sec/batch)\n",
      "2017-05-26 15:39:46.264211: step 230, loss = 2.10 (532.7 examples/sec; 0.481 sec/batch)\n",
      "2017-05-26 15:39:51.590809: step 240, loss = 2.06 (480.6 examples/sec; 0.533 sec/batch)\n",
      "2017-05-26 15:39:57.243899: step 250, loss = 2.10 (452.8 examples/sec; 0.565 sec/batch)\n",
      "2017-05-26 15:40:02.019317: step 260, loss = 2.12 (536.1 examples/sec; 0.478 sec/batch)\n",
      "2017-05-26 15:40:06.661126: step 270, loss = 2.11 (551.5 examples/sec; 0.464 sec/batch)\n",
      "2017-05-26 15:40:12.332001: step 280, loss = 2.08 (451.4 examples/sec; 0.567 sec/batch)\n",
      "2017-05-26 15:40:17.543143: step 290, loss = 2.07 (491.3 examples/sec; 0.521 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.90145\n",
      "2017-05-26 15:40:24.965375: step 300, loss = 2.05 (344.9 examples/sec; 0.742 sec/batch)\n",
      "2017-05-26 15:40:29.029599: step 310, loss = 2.09 (629.9 examples/sec; 0.406 sec/batch)\n",
      "2017-05-26 15:40:34.639289: step 320, loss = 2.09 (456.4 examples/sec; 0.561 sec/batch)\n",
      "2017-05-26 15:40:39.747830: step 330, loss = 2.07 (501.1 examples/sec; 0.511 sec/batch)\n",
      "2017-05-26 15:40:44.860497: step 340, loss = 1.98 (500.7 examples/sec; 0.511 sec/batch)\n",
      "2017-05-26 15:40:49.713687: step 350, loss = 2.06 (527.5 examples/sec; 0.485 sec/batch)\n",
      "2017-05-26 15:40:59.647772: step 370, loss = 1.99 (483.4 examples/sec; 0.530 sec/batch)\n",
      "2017-05-26 15:41:05.160690: step 380, loss = 2.01 (464.4 examples/sec; 0.551 sec/batch)\n",
      "2017-05-26 15:41:09.798479: step 390, loss = 2.03 (552.0 examples/sec; 0.464 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.88319\n",
      "2017-05-26 15:41:18.071694: step 400, loss = 2.04 (309.4 examples/sec; 0.827 sec/batch)\n",
      "2017-05-26 15:41:22.757461: step 410, loss = 2.03 (546.3 examples/sec; 0.469 sec/batch)\n",
      "2017-05-26 15:41:27.673083: step 420, loss = 2.04 (520.8 examples/sec; 0.492 sec/batch)\n",
      "2017-05-26 15:41:32.371028: step 430, loss = 2.08 (544.9 examples/sec; 0.470 sec/batch)\n",
      "2017-05-26 15:41:37.201748: step 440, loss = 2.03 (529.9 examples/sec; 0.483 sec/batch)\n",
      "2017-05-26 15:41:42.956213: step 450, loss = 1.99 (444.9 examples/sec; 0.575 sec/batch)\n",
      "2017-05-26 15:41:47.864104: step 460, loss = 2.02 (521.6 examples/sec; 0.491 sec/batch)\n",
      "2017-05-26 15:41:52.649367: step 470, loss = 2.00 (535.0 examples/sec; 0.479 sec/batch)\n",
      "2017-05-26 15:42:03.663501: step 490, loss = 2.04 (446.5 examples/sec; 0.573 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.89239\n",
      "2017-05-26 15:42:10.908685: step 500, loss = 2.03 (353.3 examples/sec; 0.725 sec/batch)\n",
      "2017-05-26 15:42:14.702377: step 510, loss = 2.02 (674.8 examples/sec; 0.379 sec/batch)\n",
      "2017-05-26 15:42:20.425330: step 520, loss = 2.00 (447.3 examples/sec; 0.572 sec/batch)\n",
      "2017-05-26 15:42:25.799037: step 530, loss = 2.01 (476.4 examples/sec; 0.537 sec/batch)\n",
      "2017-05-26 15:42:30.492937: step 540, loss = 2.00 (545.4 examples/sec; 0.469 sec/batch)\n",
      "2017-05-26 15:42:35.313764: step 550, loss = 2.01 (531.0 examples/sec; 0.482 sec/batch)\n",
      "2017-05-26 15:42:41.016389: step 560, loss = 2.02 (448.9 examples/sec; 0.570 sec/batch)\n",
      "2017-05-26 15:42:46.270765: step 570, loss = 1.99 (487.2 examples/sec; 0.525 sec/batch)\n",
      "2017-05-26 15:42:51.512375: step 580, loss = 1.95 (488.4 examples/sec; 0.524 sec/batch)\n",
      "2017-05-26 15:42:56.636084: step 590, loss = 2.00 (499.6 examples/sec; 0.512 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.89007\n",
      "2017-05-26 15:43:03.819203: step 600, loss = 1.93 (356.4 examples/sec; 0.718 sec/batch)\n",
      "2017-05-26 15:43:09.105420: step 610, loss = 2.11 (484.3 examples/sec; 0.529 sec/batch)\n",
      "2017-05-26 15:43:14.494768: step 620, loss = 1.95 (475.0 examples/sec; 0.539 sec/batch)\n",
      "2017-05-26 15:43:19.291776: step 630, loss = 1.95 (533.7 examples/sec; 0.480 sec/batch)\n",
      "2017-05-26 15:43:24.073913: step 640, loss = 1.89 (535.3 examples/sec; 0.478 sec/batch)\n",
      "2017-05-26 15:43:29.881271: step 650, loss = 2.01 (440.8 examples/sec; 0.581 sec/batch)\n",
      "2017-05-26 15:43:35.029196: step 660, loss = 1.97 (497.3 examples/sec; 0.515 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-26 15:43:39.625198: step 670, loss = 1.89 (557.0 examples/sec; 0.460 sec/batch)\n",
      "2017-05-26 15:43:44.406007: step 680, loss = 1.99 (535.5 examples/sec; 0.478 sec/batch)\n",
      "2017-05-26 15:43:50.247525: step 690, loss = 1.97 (438.2 examples/sec; 0.584 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.84819\n",
      "2017-05-26 15:43:57.925811: step 700, loss = 1.94 (333.4 examples/sec; 0.768 sec/batch)\n",
      "2017-05-26 15:44:02.150718: step 710, loss = 1.90 (605.9 examples/sec; 0.422 sec/batch)\n",
      "2017-05-26 15:44:06.808830: step 720, loss = 1.93 (549.6 examples/sec; 0.466 sec/batch)\n",
      "2017-05-26 15:44:10.676193: step 730, loss = 1.94 (661.9 examples/sec; 0.387 sec/batch)\n",
      "2017-05-26 15:44:14.255442: step 740, loss = 1.96 (715.2 examples/sec; 0.358 sec/batch)\n",
      "2017-05-26 15:44:17.618982: step 750, loss = 1.93 (761.1 examples/sec; 0.336 sec/batch)\n",
      "2017-05-26 15:44:20.897004: step 760, loss = 1.90 (781.0 examples/sec; 0.328 sec/batch)\n",
      "2017-05-26 15:44:24.306828: step 770, loss = 1.83 (750.8 examples/sec; 0.341 sec/batch)\n",
      "2017-05-26 15:44:27.689088: step 780, loss = 1.97 (756.9 examples/sec; 0.338 sec/batch)\n",
      "2017-05-26 15:44:31.150705: step 790, loss = 1.96 (739.5 examples/sec; 0.346 sec/batch)\n",
      "2017-05-26 15:44:40.227185: step 810, loss = 1.91 (803.7 examples/sec; 0.319 sec/batch)\n",
      "2017-05-26 15:44:43.740712: step 820, loss = 1.90 (728.6 examples/sec; 0.351 sec/batch)\n",
      "2017-05-26 15:44:47.018249: step 830, loss = 1.92 (781.1 examples/sec; 0.328 sec/batch)\n",
      "2017-05-26 15:44:50.394949: step 840, loss = 1.94 (758.1 examples/sec; 0.338 sec/batch)\n",
      "2017-05-26 15:44:53.830331: step 850, loss = 1.82 (745.2 examples/sec; 0.344 sec/batch)\n",
      "2017-05-26 15:44:57.109544: step 860, loss = 1.90 (780.7 examples/sec; 0.328 sec/batch)\n",
      "2017-05-26 15:45:00.547962: step 870, loss = 1.88 (744.5 examples/sec; 0.344 sec/batch)\n",
      "2017-05-26 15:45:03.818664: step 880, loss = 1.78 (782.7 examples/sec; 0.327 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.49766\n",
      "2017-05-26 15:45:17.079508: step 900, loss = 1.79 (295.6 examples/sec; 0.866 sec/batch)\n",
      "2017-05-26 15:45:21.616529: step 910, loss = 1.76 (564.2 examples/sec; 0.454 sec/batch)\n",
      "2017-05-26 15:45:26.929207: step 920, loss = 1.77 (481.9 examples/sec; 0.531 sec/batch)\n",
      "2017-05-26 15:45:32.313556: step 930, loss = 1.84 (475.5 examples/sec; 0.538 sec/batch)\n",
      "2017-05-26 15:45:37.163256: step 940, loss = 1.82 (527.9 examples/sec; 0.485 sec/batch)\n",
      "2017-05-26 15:45:42.296279: step 950, loss = 1.75 (498.7 examples/sec; 0.513 sec/batch)\n",
      "2017-05-26 15:45:47.452971: step 960, loss = 1.81 (496.4 examples/sec; 0.516 sec/batch)\n",
      "2017-05-26 15:45:52.689117: step 970, loss = 1.74 (488.9 examples/sec; 0.524 sec/batch)\n",
      "2017-05-26 15:45:57.994024: step 980, loss = 1.86 (482.6 examples/sec; 0.530 sec/batch)\n",
      "2017-05-26 15:46:03.229604: step 990, loss = 1.93 (489.0 examples/sec; 0.524 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.84355\n",
      "2017-05-26 15:46:11.325180: step 1000, loss = 1.77 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-26 15:46:15.518736: step 1010, loss = 1.82 (610.5 examples/sec; 0.419 sec/batch)\n",
      "2017-05-26 15:46:20.156781: step 1020, loss = 1.83 (552.0 examples/sec; 0.464 sec/batch)\n",
      "2017-05-26 15:46:25.025294: step 1030, loss = 1.71 (525.8 examples/sec; 0.487 sec/batch)\n",
      "2017-05-26 15:46:30.702122: step 1040, loss = 1.71 (451.0 examples/sec; 0.568 sec/batch)\n",
      "2017-05-26 15:46:35.794741: step 1050, loss = 1.67 (502.7 examples/sec; 0.509 sec/batch)\n",
      "2017-05-26 15:46:40.546379: step 1060, loss = 1.83 (538.8 examples/sec; 0.475 sec/batch)\n",
      "2017-05-26 15:46:45.654973: step 1070, loss = 1.61 (501.1 examples/sec; 0.511 sec/batch)\n",
      "2017-05-26 15:46:51.475472: step 1080, loss = 1.64 (439.8 examples/sec; 0.582 sec/batch)\n",
      "2017-05-26 15:46:56.513036: step 1090, loss = 1.65 (508.2 examples/sec; 0.504 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.92981\n",
      "2017-05-26 15:47:03.141248: step 1100, loss = 1.73 (386.2 examples/sec; 0.663 sec/batch)\n",
      "2017-05-26 15:47:08.537759: step 1110, loss = 1.76 (474.4 examples/sec; 0.540 sec/batch)\n",
      "2017-05-26 15:47:13.945151: step 1120, loss = 1.62 (473.4 examples/sec; 0.541 sec/batch)\n",
      "2017-05-26 15:47:18.570192: step 1130, loss = 1.67 (553.5 examples/sec; 0.463 sec/batch)\n",
      "2017-05-26 15:47:23.327520: step 1140, loss = 1.71 (538.1 examples/sec; 0.476 sec/batch)\n",
      "2017-05-26 15:47:28.671852: step 1150, loss = 1.66 (479.0 examples/sec; 0.534 sec/batch)\n",
      "2017-05-26 15:47:34.026916: step 1160, loss = 1.72 (478.1 examples/sec; 0.536 sec/batch)\n",
      "2017-05-26 15:47:38.749806: step 1170, loss = 1.73 (542.0 examples/sec; 0.472 sec/batch)\n",
      "2017-05-26 15:47:43.549352: step 1180, loss = 1.67 (533.4 examples/sec; 0.480 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.85977\n",
      "2017-05-26 15:47:56.911796: step 1200, loss = 1.60 (330.9 examples/sec; 0.774 sec/batch)\n",
      "2017-05-26 15:48:00.851678: step 1210, loss = 1.64 (649.8 examples/sec; 0.394 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 1216 into /home/ipython/cnn-cifar10/tb_log/vggE/train/model.ckpt.\n",
      "2017-05-26 15:48:06.049224: step 1220, loss = 1.57 (492.5 examples/sec; 0.520 sec/batch)\n",
      "2017-05-26 15:48:12.084172: step 1230, loss = 1.63 (424.2 examples/sec; 0.603 sec/batch)\n",
      "2017-05-26 15:48:16.932304: step 1240, loss = 1.65 (528.0 examples/sec; 0.485 sec/batch)\n",
      "2017-05-26 15:48:21.581291: step 1250, loss = 1.62 (550.7 examples/sec; 0.465 sec/batch)\n",
      "2017-05-26 15:48:26.738337: step 1260, loss = 1.72 (496.4 examples/sec; 0.516 sec/batch)\n",
      "2017-05-26 15:48:32.398937: step 1270, loss = 1.64 (452.2 examples/sec; 0.566 sec/batch)\n",
      "2017-05-26 15:48:37.442777: step 1280, loss = 1.70 (507.5 examples/sec; 0.504 sec/batch)\n",
      "2017-05-26 15:48:42.039691: step 1290, loss = 1.57 (556.9 examples/sec; 0.460 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.85022\n",
      "2017-05-26 15:48:50.961425: step 1300, loss = 1.65 (286.9 examples/sec; 0.892 sec/batch)\n",
      "2017-05-26 15:48:55.192942: step 1310, loss = 1.47 (605.0 examples/sec; 0.423 sec/batch)\n",
      "2017-05-26 15:49:00.288796: step 1320, loss = 1.61 (502.4 examples/sec; 0.510 sec/batch)\n",
      "2017-05-26 15:49:05.295483: step 1330, loss = 1.67 (511.3 examples/sec; 0.501 sec/batch)\n",
      "2017-05-26 15:49:09.894295: step 1340, loss = 1.55 (556.7 examples/sec; 0.460 sec/batch)\n",
      "2017-05-26 15:49:14.930505: step 1350, loss = 1.62 (508.3 examples/sec; 0.504 sec/batch)\n",
      "2017-05-26 15:49:20.632152: step 1360, loss = 1.56 (449.0 examples/sec; 0.570 sec/batch)\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "Arguments.set_model_folder(\"vggE\")\n",
    "print(Arguments.train_dir)\n",
    "\n",
    "cifar10_train.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
