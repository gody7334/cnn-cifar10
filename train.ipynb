{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# restart notebook when retrain model as some initial problem\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from cifar10 import cifar10_train\n",
    "from cifar10.cifar10_args import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "/home/ipython/cnn-cifar10/tb_log/vggA/train\n",
      "/home/ipython/cnn-cifar10/tb_log/vggA/eval\n",
      "/home/ipython/cnn-cifar10/tb_log/vggA/train\n",
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "INFO:tensorflow:Summary name vgg1-conv0/weight_loss (raw) is illegal; using vgg1-conv0/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg2-conv0/weight_loss (raw) is illegal; using vgg2-conv0/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg3-conv0/weight_loss (raw) is illegal; using vgg3-conv0/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg3-conv1/weight_loss (raw) is illegal; using vgg3-conv1/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg4-conv0/weight_loss (raw) is illegal; using vgg4-conv0/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg4-conv1/weight_loss (raw) is illegal; using vgg4-conv1/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg5-conv0/weight_loss (raw) is illegal; using vgg5-conv0/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name vgg5-conv1/weight_loss (raw) is illegal; using vgg5-conv1/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local3/weight_loss (raw) is illegal; using local3/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local4/weight_loss (raw) is illegal; using local4/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name softmax_linear/weight_loss (raw) is illegal; using softmax_linear/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name cross_entropy (raw) is illegal; using cross_entropy__raw_ instead.\n",
      "INFO:tensorflow:Summary name total_loss (raw) is illegal; using total_loss__raw_ instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "2017-05-30 08:40:20.953357: step 0, loss = 17.64 (115.6 examples/sec; 2.214 sec/batch)\n",
      "2017-05-30 08:40:23.188937: step 10, loss = 11.69 (1145.1 examples/sec; 0.224 sec/batch)\n",
      "2017-05-30 08:40:25.676178: step 20, loss = 7.74 (1029.3 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 08:40:28.139680: step 30, loss = 5.33 (1039.2 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 08:40:30.602421: step 40, loss = 3.88 (1039.5 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 08:40:33.063001: step 50, loss = 3.07 (1040.4 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 08:40:35.507947: step 60, loss = 2.67 (1047.1 examples/sec; 0.244 sec/batch)\n",
      "2017-05-30 08:40:37.958735: step 70, loss = 2.34 (1044.6 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 08:40:40.430263: step 80, loss = 2.25 (1035.8 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 08:40:42.913882: step 90, loss = 2.07 (1030.8 examples/sec; 0.248 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.66627\n",
      "2017-05-30 08:40:47.638562: step 100, loss = 2.20 (541.8 examples/sec; 0.472 sec/batch)\n",
      "2017-05-30 08:40:49.701745: step 110, loss = 1.98 (1240.8 examples/sec; 0.206 sec/batch)\n",
      "2017-05-30 08:40:54.651918: step 130, loss = 1.91 (1029.7 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 08:40:57.116476: step 140, loss = 1.92 (1038.7 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 08:40:59.598651: step 150, loss = 1.79 (1031.4 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 08:41:02.090480: step 160, loss = 1.73 (1027.4 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 08:41:04.562814: step 170, loss = 1.79 (1035.5 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 08:41:07.040645: step 180, loss = 1.82 (1033.2 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 08:41:09.496927: step 190, loss = 1.70 (1042.2 examples/sec; 0.246 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.80142\n",
      "2017-05-30 08:41:13.944821: step 200, loss = 1.59 (575.6 examples/sec; 0.445 sec/batch)\n",
      "2017-05-30 08:41:16.059862: step 210, loss = 1.62 (1210.4 examples/sec; 0.212 sec/batch)\n",
      "2017-05-30 08:41:18.844245: step 220, loss = 1.83 (919.4 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 08:41:21.344362: step 230, loss = 1.65 (1024.0 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 08:41:26.342052: step 250, loss = 1.57 (1041.0 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 08:41:28.780379: step 260, loss = 1.57 (1049.9 examples/sec; 0.244 sec/batch)\n",
      "2017-05-30 08:41:31.289164: step 270, loss = 1.58 (1020.4 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 08:41:33.836436: step 280, loss = 1.44 (1005.0 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 08:41:36.309795: step 290, loss = 1.61 (1035.0 examples/sec; 0.247 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.70696\n",
      "2017-05-30 08:41:40.924519: step 300, loss = 1.75 (554.7 examples/sec; 0.461 sec/batch)\n",
      "2017-05-30 08:41:43.424060: step 310, loss = 1.51 (1024.2 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 08:41:46.267069: step 320, loss = 1.49 (900.5 examples/sec; 0.284 sec/batch)\n",
      "2017-05-30 08:41:49.166372: step 330, loss = 1.55 (883.0 examples/sec; 0.290 sec/batch)\n",
      "2017-05-30 08:41:51.678013: step 340, loss = 1.44 (1019.3 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 08:41:54.141836: step 350, loss = 1.55 (1039.0 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 08:41:56.631148: step 360, loss = 1.48 (1028.4 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 08:41:59.154527: step 370, loss = 1.36 (1014.5 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 08:42:01.840875: step 380, loss = 1.39 (953.0 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 08:42:04.839603: step 390, loss = 1.45 (853.7 examples/sec; 0.300 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.49764\n",
      "2017-05-30 08:42:09.512317: step 400, loss = 1.31 (547.9 examples/sec; 0.467 sec/batch)\n",
      "2017-05-30 08:42:11.641602: step 410, loss = 1.41 (1202.3 examples/sec; 0.213 sec/batch)\n",
      "2017-05-30 08:42:14.132751: step 420, loss = 1.37 (1027.6 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 08:42:16.603510: step 430, loss = 1.34 (1036.1 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 08:42:19.175299: step 440, loss = 1.30 (995.4 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 08:42:22.009271: step 450, loss = 1.40 (903.3 examples/sec; 0.283 sec/batch)\n",
      "2017-05-30 08:42:24.947453: step 460, loss = 1.20 (871.3 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 08:42:30.123634: step 480, loss = 1.21 (1008.4 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 08:42:32.672693: step 490, loss = 1.23 (1004.3 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 08:42:37.029566: step 500, loss = 1.17 (587.6 examples/sec; 0.436 sec/batch)\n",
      "2017-05-30 08:42:39.057597: step 510, loss = 1.27 (1262.3 examples/sec; 0.203 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3268  Precision @ 1 train: 0.6383\n",
      "2017-05-30 08:42:41.716176: step 520, loss = 1.30 (962.9 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 08:42:44.875274: step 530, loss = 1.20 (810.4 examples/sec; 0.316 sec/batch)\n",
      "2017-05-30 08:42:47.517116: step 540, loss = 1.15 (969.0 examples/sec; 0.264 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3147  Precision @ 1 eval: 0.6146\n",
      "INFO:tensorflow:global_step/sec: 2.59893\n",
      "2017-05-30 08:42:50.100627: step 550, loss = 1.45 (990.9 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 08:42:52.865400: step 560, loss = 1.22 (925.9 examples/sec; 0.276 sec/batch)\n",
      "2017-05-30 08:42:55.484597: step 570, loss = 1.21 (977.4 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 08:42:58.085245: step 580, loss = 1.16 (984.4 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 08:43:00.675902: step 590, loss = 1.20 (988.2 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 08:43:03.303349: step 600, loss = 1.16 (974.3 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 08:43:05.857007: step 610, loss = 1.16 (1002.5 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 08:43:08.349083: step 620, loss = 1.16 (1027.3 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 08:43:11.006792: step 630, loss = 1.11 (963.2 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 08:43:13.648321: step 640, loss = 1.11 (969.1 examples/sec; 0.264 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.59286\n",
      "2017-05-30 08:43:17.578413: step 650, loss = 1.07 (651.4 examples/sec; 0.393 sec/batch)\n",
      "2017-05-30 08:43:20.222252: step 660, loss = 1.31 (968.3 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 08:43:23.127710: step 670, loss = 1.03 (881.1 examples/sec; 0.291 sec/batch)\n",
      "2017-05-30 08:43:25.667829: step 680, loss = 1.13 (1007.8 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 08:43:28.290649: step 690, loss = 1.17 (976.0 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 08:43:36.016433: step 720, loss = 1.05 (962.7 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 08:43:38.533575: step 730, loss = 1.14 (1017.0 examples/sec; 0.252 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 08:43:41.039149: step 740, loss = 1.13 (1021.7 examples/sec; 0.251 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.60803\n",
      "2017-05-30 08:43:45.322363: step 750, loss = 1.15 (597.7 examples/sec; 0.428 sec/batch)\n",
      "2017-05-30 08:43:47.890831: step 760, loss = 1.12 (996.7 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 08:43:50.498382: step 770, loss = 1.05 (981.8 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 08:43:53.590496: step 780, loss = 1.07 (827.9 examples/sec; 0.309 sec/batch)\n",
      "2017-05-30 08:43:56.902131: step 790, loss = 0.98 (773.0 examples/sec; 0.331 sec/batch)\n",
      "2017-05-30 08:43:59.868388: step 800, loss = 0.91 (863.0 examples/sec; 0.297 sec/batch)\n",
      "2017-05-30 08:44:02.765354: step 810, loss = 1.14 (883.7 examples/sec; 0.290 sec/batch)\n",
      "2017-05-30 08:44:07.918336: step 830, loss = 1.15 (1011.6 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 08:44:10.475044: step 840, loss = 0.98 (1001.3 examples/sec; 0.256 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.39831\n",
      "2017-05-30 08:44:14.700628: step 850, loss = 0.97 (605.8 examples/sec; 0.423 sec/batch)\n",
      "2017-05-30 08:44:17.207031: step 860, loss = 0.98 (1021.4 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 08:44:19.841365: step 870, loss = 1.03 (971.8 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 08:44:22.418591: step 880, loss = 0.97 (993.3 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 08:44:25.149472: step 890, loss = 1.01 (937.4 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 08:44:27.776739: step 900, loss = 1.00 (974.4 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 08:44:30.304256: step 910, loss = 1.07 (1012.9 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 08:44:32.792294: step 920, loss = 0.85 (1028.9 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 08:44:35.435670: step 930, loss = 0.96 (968.5 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 08:44:37.993563: step 940, loss = 1.06 (1000.8 examples/sec; 0.256 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.64452\n",
      "2017-05-30 08:44:42.249027: step 950, loss = 1.11 (601.6 examples/sec; 0.426 sec/batch)\n",
      "2017-05-30 08:44:44.886041: step 960, loss = 0.93 (970.8 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 08:44:47.366153: step 970, loss = 1.00 (1032.2 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 08:44:49.902655: step 980, loss = 0.91 (1009.3 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 08:44:52.566066: step 990, loss = 1.03 (961.2 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 08:44:55.260202: step 1000, loss = 1.00 (950.2 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 08:44:57.774384: step 1010, loss = 0.99 (1018.2 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 08:45:00.408224: step 1020, loss = 0.98 (972.0 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 08:45:03.041441: step 1030, loss = 0.99 (972.2 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 08:45:05.595137: step 1040, loss = 0.91 (1002.5 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 08:45:09.910197: step 1050, loss = 0.97 (593.3 examples/sec; 0.432 sec/batch)\n",
      "2017-05-30 08:45:12.461755: step 1060, loss = 0.98 (1003.3 examples/sec; 0.255 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3739  Precision @ 1 train: 0.7303\n",
      "2017-05-30 08:45:14.972027: step 1070, loss = 1.06 (1019.8 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 08:45:17.917237: step 1080, loss = 0.98 (869.2 examples/sec; 0.295 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3601  Precision @ 1 eval: 0.7033\n",
      "INFO:tensorflow:global_step/sec: 2.57529\n",
      "2017-05-30 08:45:21.171692: step 1090, loss = 0.98 (786.6 examples/sec; 0.325 sec/batch)\n",
      "2017-05-30 08:45:24.146356: step 1100, loss = 0.94 (860.6 examples/sec; 0.297 sec/batch)\n",
      "2017-05-30 08:45:27.116815: step 1110, loss = 0.89 (861.8 examples/sec; 0.297 sec/batch)\n",
      "2017-05-30 08:45:29.707834: step 1120, loss = 1.04 (988.0 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 08:45:32.194936: step 1130, loss = 0.96 (1029.3 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 08:45:34.757547: step 1140, loss = 0.77 (999.0 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 08:45:37.377400: step 1150, loss = 1.01 (977.2 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 08:45:42.509289: step 1170, loss = 1.16 (971.6 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 08:45:45.199944: step 1180, loss = 0.93 (951.4 examples/sec; 0.269 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.31565\n",
      "2017-05-30 08:45:50.816362: step 1190, loss = 1.00 (455.8 examples/sec; 0.562 sec/batch)\n",
      "2017-05-30 08:45:53.708621: step 1200, loss = 0.91 (885.1 examples/sec; 0.289 sec/batch)\n",
      "2017-05-30 08:45:56.603791: step 1210, loss = 0.88 (884.2 examples/sec; 0.290 sec/batch)\n",
      "2017-05-30 08:45:59.109667: step 1220, loss = 0.93 (1021.6 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 08:46:01.668537: step 1230, loss = 1.00 (1000.4 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 08:46:04.340248: step 1240, loss = 0.92 (958.2 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 08:46:06.858199: step 1250, loss = 0.88 (1016.7 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 08:46:09.369012: step 1260, loss = 0.89 (1019.6 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 08:46:14.575476: step 1280, loss = 0.83 (998.8 examples/sec; 0.256 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.5776\n",
      "2017-05-30 08:46:18.641063: step 1290, loss = 0.84 (629.7 examples/sec; 0.407 sec/batch)\n",
      "2017-05-30 08:46:21.310053: step 1300, loss = 0.80 (959.2 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 08:46:23.850113: step 1310, loss = 0.91 (1007.9 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 08:46:26.577702: step 1320, loss = 0.88 (938.6 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 08:46:29.303831: step 1330, loss = 0.80 (939.1 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 08:46:31.809483: step 1340, loss = 0.91 (1021.7 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 08:46:34.432570: step 1350, loss = 0.75 (975.9 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 08:46:37.066899: step 1360, loss = 0.80 (971.8 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 08:46:39.560987: step 1370, loss = 0.82 (1026.4 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 08:46:42.200008: step 1380, loss = 0.89 (970.1 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 08:46:46.754416: step 1390, loss = 0.87 (562.1 examples/sec; 0.455 sec/batch)\n",
      "2017-05-30 08:46:49.950083: step 1400, loss = 0.76 (801.1 examples/sec; 0.320 sec/batch)\n",
      "2017-05-30 08:46:52.955133: step 1410, loss = 0.83 (851.9 examples/sec; 0.301 sec/batch)\n",
      "2017-05-30 08:46:55.602603: step 1420, loss = 0.84 (967.0 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 08:46:58.374841: step 1430, loss = 0.74 (923.4 examples/sec; 0.277 sec/batch)\n",
      "2017-05-30 08:47:00.841609: step 1440, loss = 0.94 (1037.8 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 08:47:03.475458: step 1450, loss = 0.84 (972.0 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 08:47:06.048218: step 1460, loss = 0.83 (995.0 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 08:47:08.534120: step 1470, loss = 0.78 (1029.8 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 08:47:11.127087: step 1480, loss = 0.85 (987.3 examples/sec; 0.259 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.39068\n",
      "2017-05-30 08:47:19.274609: step 1500, loss = 0.77 (842.3 examples/sec; 0.304 sec/batch)\n",
      "2017-05-30 08:47:22.145317: step 1510, loss = 0.76 (891.8 examples/sec; 0.287 sec/batch)\n",
      "2017-05-30 08:47:24.800463: step 1520, loss = 0.73 (964.2 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 08:47:27.302844: step 1530, loss = 0.78 (1023.0 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 08:47:30.051085: step 1540, loss = 0.77 (931.5 examples/sec; 0.275 sec/batch)\n",
      "2017-05-30 08:47:32.765239: step 1550, loss = 0.76 (943.2 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 08:47:35.279245: step 1560, loss = 0.78 (1018.3 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 08:47:37.902377: step 1570, loss = 0.89 (975.9 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 08:47:40.527313: step 1580, loss = 0.87 (975.3 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 08:47:44.346161: step 1590, loss = 0.73 (670.4 examples/sec; 0.382 sec/batch)\n",
      "2017-05-30 08:47:47.077127: step 1600, loss = 0.79 (937.4 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 08:47:49.573256: step 1610, loss = 0.83 (1025.6 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 08:47:52.012721: step 1620, loss = 0.67 (1049.4 examples/sec; 0.244 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3913  Precision @ 1 eval: 0.7643\n",
      "INFO:tensorflow:global_step/sec: 2.58181\n",
      "2017-05-30 08:47:54.475464: step 1630, loss = 0.77 (1039.5 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 08:47:57.096827: step 1640, loss = 0.82 (976.6 examples/sec; 0.262 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 08:47:59.798290: step 1650, loss = 0.87 (947.6 examples/sec; 0.270 sec/batch)\n",
      "2017-05-30 08:48:02.444844: step 1660, loss = 0.82 (967.3 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 08:48:05.156316: step 1670, loss = 0.73 (944.1 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 08:48:08.566913: step 1680, loss = 0.71 (750.6 examples/sec; 0.341 sec/batch)\n",
      "2017-05-30 08:48:11.606041: step 1690, loss = 0.76 (842.3 examples/sec; 0.304 sec/batch)\n",
      "2017-05-30 08:48:14.389827: step 1700, loss = 0.91 (919.6 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 08:48:17.019047: step 1710, loss = 0.73 (973.7 examples/sec; 0.263 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.39607\n",
      "2017-05-30 08:48:23.647617: step 1730, loss = 0.71 (619.5 examples/sec; 0.413 sec/batch)\n",
      "2017-05-30 08:48:26.233805: step 1740, loss = 0.79 (989.9 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 08:48:28.789836: step 1750, loss = 0.72 (1001.6 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 08:48:31.629432: step 1760, loss = 0.87 (901.5 examples/sec; 0.284 sec/batch)\n",
      "2017-05-30 08:48:34.185475: step 1770, loss = 0.81 (1001.5 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 08:48:36.668493: step 1780, loss = 0.85 (1031.0 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 08:48:39.293559: step 1790, loss = 0.78 (975.2 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 08:48:41.904110: step 1800, loss = 0.77 (980.6 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 08:48:44.382453: step 1810, loss = 0.71 (1032.9 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 08:48:46.974203: step 1820, loss = 0.63 (987.7 examples/sec; 0.259 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.52781\n",
      "2017-05-30 08:48:55.204102: step 1840, loss = 0.74 (830.5 examples/sec; 0.308 sec/batch)\n",
      "2017-05-30 08:48:58.057319: step 1850, loss = 0.78 (897.2 examples/sec; 0.285 sec/batch)\n",
      "2017-05-30 08:49:00.890220: step 1860, loss = 0.86 (903.7 examples/sec; 0.283 sec/batch)\n",
      "2017-05-30 08:49:03.446646: step 1870, loss = 0.72 (1001.4 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 08:49:06.169002: step 1880, loss = 0.75 (940.4 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 08:49:08.903962: step 1890, loss = 0.75 (936.0 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 08:49:11.428296: step 1900, loss = 1.06 (1014.1 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 08:49:13.976442: step 1910, loss = 0.71 (1004.7 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 08:49:16.640239: step 1920, loss = 0.65 (961.0 examples/sec; 0.266 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.50854\n",
      "2017-05-30 08:49:20.581178: step 1930, loss = 0.66 (649.6 examples/sec; 0.394 sec/batch)\n",
      "2017-05-30 08:49:23.175455: step 1940, loss = 0.75 (986.8 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 08:49:25.781721: step 1950, loss = 0.87 (982.2 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 08:49:28.288743: step 1960, loss = 0.77 (1021.1 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 08:49:30.960783: step 1970, loss = 0.58 (958.1 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 08:49:33.702775: step 1980, loss = 0.80 (933.6 examples/sec; 0.274 sec/batch)\n",
      "2017-05-30 08:49:36.173692: step 1990, loss = 0.75 (1036.1 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 08:49:38.813927: step 2000, loss = 0.75 (969.6 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 08:49:41.474507: step 2010, loss = 0.75 (962.2 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 08:49:43.962977: step 2020, loss = 0.60 (1028.7 examples/sec; 0.249 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.61926\n",
      "2017-05-30 08:49:48.111212: step 2030, loss = 0.70 (617.1 examples/sec; 0.415 sec/batch)\n",
      "2017-05-30 08:49:50.654286: step 2040, loss = 0.67 (1006.7 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 08:49:53.155655: step 2050, loss = 0.72 (1023.4 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 08:49:58.734450: step 2070, loss = 0.80 (864.3 examples/sec; 0.296 sec/batch)\n",
      "2017-05-30 08:50:02.076974: step 2080, loss = 0.71 (765.9 examples/sec; 0.334 sec/batch)\n",
      "2017-05-30 08:50:05.232839: step 2090, loss = 0.83 (811.2 examples/sec; 0.316 sec/batch)\n",
      "2017-05-30 08:50:07.961547: step 2100, loss = 0.63 (938.2 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 08:50:10.491551: step 2110, loss = 0.79 (1011.9 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 08:50:13.047111: step 2120, loss = 0.76 (1001.7 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 08:50:17.122901: step 2130, loss = 0.66 (628.1 examples/sec; 0.408 sec/batch)\n",
      "2017-05-30 08:50:19.721866: step 2140, loss = 0.61 (985.0 examples/sec; 0.260 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /home/ipython/cnn-cifar10/tb_log/vggA/train/model.ckpt.\n",
      "  Num examples: 5120  Num correct: 4171  Precision @ 1 train: 0.8146\n",
      "2017-05-30 08:50:22.630004: step 2150, loss = 0.69 (880.3 examples/sec; 0.291 sec/batch)\n",
      "2017-05-30 08:50:25.279430: step 2160, loss = 0.73 (966.2 examples/sec; 0.265 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4055  Precision @ 1 eval: 0.7920\n",
      "INFO:tensorflow:global_step/sec: 2.5103\n",
      "2017-05-30 08:50:27.670839: step 2170, loss = 0.78 (1070.5 examples/sec; 0.239 sec/batch)\n",
      "2017-05-30 08:50:30.199993: step 2180, loss = 0.63 (1012.2 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 08:50:33.135415: step 2190, loss = 0.65 (872.1 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 08:50:35.694993: step 2200, loss = 0.53 (1000.2 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 08:50:38.268261: step 2210, loss = 0.57 (994.8 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 08:50:40.896215: step 2220, loss = 0.70 (974.1 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 08:50:43.397790: step 2230, loss = 0.77 (1023.4 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 08:50:45.915358: step 2240, loss = 0.60 (1016.9 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 08:50:48.517314: step 2250, loss = 0.69 (983.9 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 08:50:51.055915: step 2260, loss = 0.68 (1008.4 examples/sec; 0.254 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.61024\n",
      "2017-05-30 08:50:55.192682: step 2270, loss = 0.70 (618.8 examples/sec; 0.414 sec/batch)\n",
      "2017-05-30 08:50:57.764155: step 2280, loss = 0.58 (995.5 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 08:51:03.100564: step 2300, loss = 0.72 (897.2 examples/sec; 0.285 sec/batch)\n",
      "2017-05-30 08:51:05.894463: step 2310, loss = 0.66 (916.3 examples/sec; 0.279 sec/batch)\n",
      "2017-05-30 08:51:09.205294: step 2320, loss = 0.65 (773.2 examples/sec; 0.331 sec/batch)\n",
      "2017-05-30 08:51:12.210037: step 2330, loss = 0.65 (852.0 examples/sec; 0.300 sec/batch)\n",
      "2017-05-30 08:51:14.954214: step 2340, loss = 0.57 (932.9 examples/sec; 0.274 sec/batch)\n",
      "2017-05-30 08:51:17.543089: step 2350, loss = 0.70 (988.8 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 08:51:20.046797: step 2360, loss = 0.68 (1022.5 examples/sec; 0.250 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.44251\n",
      "2017-05-30 08:51:24.222737: step 2370, loss = 0.81 (613.0 examples/sec; 0.418 sec/batch)\n",
      "2017-05-30 08:51:26.753183: step 2380, loss = 0.68 (1011.7 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 08:51:29.228966: step 2390, loss = 0.76 (1034.0 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 08:51:34.679124: step 2410, loss = 0.61 (924.5 examples/sec; 0.277 sec/batch)\n",
      "2017-05-30 08:51:37.179745: step 2420, loss = 0.59 (1023.7 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 08:51:39.799558: step 2430, loss = 0.64 (977.2 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 08:51:42.376842: step 2440, loss = 0.54 (993.3 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 08:51:44.880422: step 2450, loss = 0.64 (1022.5 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 08:51:47.557021: step 2460, loss = 0.66 (956.4 examples/sec; 0.268 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.47554\n",
      "2017-05-30 08:51:53.027789: step 2470, loss = 0.72 (467.9 examples/sec; 0.547 sec/batch)\n",
      "2017-05-30 08:51:55.913635: step 2480, loss = 0.69 (887.1 examples/sec; 0.289 sec/batch)\n",
      "2017-05-30 08:51:58.696578: step 2490, loss = 0.66 (919.9 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 08:52:01.312361: step 2500, loss = 0.74 (978.7 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 08:52:06.690244: step 2520, loss = 0.71 (962.9 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 08:52:09.296672: step 2530, loss = 0.74 (982.2 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 08:52:11.780189: step 2540, loss = 0.72 (1030.8 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 08:52:14.315665: step 2550, loss = 0.58 (1009.7 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 08:52:16.947498: step 2560, loss = 0.76 (972.7 examples/sec; 0.263 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.59858\n",
      "2017-05-30 08:52:20.758679: step 2570, loss = 0.48 (671.7 examples/sec; 0.381 sec/batch)\n",
      "2017-05-30 08:52:23.487707: step 2580, loss = 0.73 (938.1 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 08:52:26.137143: step 2590, loss = 0.59 (966.2 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 08:52:28.616598: step 2600, loss = 0.57 (1032.5 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 08:52:31.219651: step 2610, loss = 0.65 (983.5 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 08:52:34.116688: step 2620, loss = 0.60 (883.7 examples/sec; 0.290 sec/batch)\n",
      "2017-05-30 08:52:37.636018: step 2630, loss = 0.71 (727.4 examples/sec; 0.352 sec/batch)\n",
      "2017-05-30 08:52:40.607793: step 2640, loss = 0.68 (861.4 examples/sec; 0.297 sec/batch)\n",
      "2017-05-30 08:52:43.374827: step 2650, loss = 0.63 (925.2 examples/sec; 0.277 sec/batch)\n",
      "2017-05-30 08:52:45.959125: step 2660, loss = 0.57 (990.6 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 08:52:49.718998: step 2670, loss = 0.61 (680.9 examples/sec; 0.376 sec/batch)\n",
      "2017-05-30 08:52:52.568741: step 2680, loss = 0.50 (898.3 examples/sec; 0.285 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4303  Precision @ 1 train: 0.8404\n",
      "2017-05-30 08:52:54.958584: step 2690, loss = 0.63 (1071.2 examples/sec; 0.239 sec/batch)\n",
      "2017-05-30 08:52:57.403490: step 2700, loss = 0.64 (1047.1 examples/sec; 0.244 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4176  Precision @ 1 eval: 0.8156\n",
      "INFO:tensorflow:global_step/sec: 2.53171\n",
      "2017-05-30 08:52:59.991182: step 2710, loss = 0.52 (989.3 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 08:53:02.605256: step 2720, loss = 0.56 (979.3 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 08:53:05.326157: step 2730, loss = 0.48 (940.9 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 08:53:10.614888: step 2750, loss = 0.69 (968.4 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 08:53:13.178057: step 2760, loss = 0.70 (998.8 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 08:53:15.802954: step 2770, loss = 0.50 (975.3 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 08:53:18.365542: step 2780, loss = 0.52 (999.0 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 08:53:20.833513: step 2790, loss = 0.63 (1037.3 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 08:53:23.487557: step 2800, loss = 0.55 (964.6 examples/sec; 0.265 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.41561\n",
      "2017-05-30 08:53:29.268759: step 2810, loss = 0.74 (442.8 examples/sec; 0.578 sec/batch)\n",
      "2017-05-30 08:53:31.872598: step 2820, loss = 0.65 (983.2 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 08:53:34.716724: step 2830, loss = 0.67 (900.1 examples/sec; 0.284 sec/batch)\n",
      "2017-05-30 08:53:37.520852: step 2840, loss = 0.61 (912.9 examples/sec; 0.280 sec/batch)\n",
      "2017-05-30 08:53:42.598599: step 2860, loss = 0.46 (988.9 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 08:53:45.260295: step 2870, loss = 0.64 (961.8 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 08:53:47.775326: step 2880, loss = 0.66 (1017.9 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 08:53:50.354176: step 2890, loss = 0.54 (992.7 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 08:53:52.992362: step 2900, loss = 0.51 (970.4 examples/sec; 0.264 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.56113\n",
      "2017-05-30 08:53:57.349138: step 2910, loss = 0.63 (587.6 examples/sec; 0.436 sec/batch)\n",
      "2017-05-30 08:53:59.675723: step 2920, loss = 0.58 (1100.3 examples/sec; 0.233 sec/batch)\n",
      "2017-05-30 08:54:02.250777: step 2930, loss = 0.65 (994.2 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 08:54:04.737816: step 2940, loss = 0.55 (1029.3 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 08:54:07.642393: step 2950, loss = 0.68 (881.4 examples/sec; 0.290 sec/batch)\n",
      "2017-05-30 08:54:10.214039: step 2960, loss = 0.55 (995.5 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 08:54:15.473152: step 2980, loss = 0.70 (980.7 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 08:54:18.332914: step 2990, loss = 0.54 (895.2 examples/sec; 0.286 sec/batch)\n",
      "2017-05-30 08:54:21.629118: step 3000, loss = 0.62 (776.7 examples/sec; 0.330 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.40994\n",
      "2017-05-30 08:54:26.675232: step 3010, loss = 0.66 (507.3 examples/sec; 0.505 sec/batch)\n",
      "2017-05-30 08:54:29.042328: step 3020, loss = 0.53 (1081.5 examples/sec; 0.237 sec/batch)\n",
      "2017-05-30 08:54:31.594255: step 3030, loss = 0.65 (1003.2 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 08:54:34.145330: step 3040, loss = 0.60 (1003.5 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 08:54:36.831919: step 3050, loss = 0.48 (952.9 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 08:54:40.332695: step 3060, loss = 0.61 (731.3 examples/sec; 0.350 sec/batch)\n",
      "2017-05-30 08:54:43.395816: step 3070, loss = 0.73 (835.7 examples/sec; 0.306 sec/batch)\n",
      "2017-05-30 08:54:46.223260: step 3080, loss = 0.54 (905.4 examples/sec; 0.283 sec/batch)\n",
      "2017-05-30 08:54:48.852794: step 3090, loss = 0.55 (973.6 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 08:54:51.392057: step 3100, loss = 0.64 (1008.2 examples/sec; 0.254 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.41276\n",
      "2017-05-30 08:54:55.977374: step 3110, loss = 0.63 (558.3 examples/sec; 0.459 sec/batch)\n",
      "2017-05-30 08:54:58.280080: step 3120, loss = 0.67 (1111.7 examples/sec; 0.230 sec/batch)\n",
      "2017-05-30 08:55:00.762165: step 3130, loss = 0.58 (1031.4 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 08:55:03.369692: step 3140, loss = 0.56 (981.8 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 08:55:05.992472: step 3150, loss = 0.72 (976.1 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 08:55:08.605453: step 3160, loss = 0.50 (979.7 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 08:55:11.242792: step 3170, loss = 0.52 (970.7 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 08:55:13.957625: step 3180, loss = 0.57 (943.0 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 08:55:19.053000: step 3200, loss = 0.49 (991.7 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 08:55:23.200573: step 3210, loss = 0.52 (617.2 examples/sec; 0.415 sec/batch)\n",
      "2017-05-30 08:55:25.414365: step 3220, loss = 0.59 (1156.4 examples/sec; 0.221 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4394  Precision @ 1 train: 0.8582\n",
      "2017-05-30 08:55:27.990100: step 3230, loss = 0.53 (993.9 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 08:55:30.495756: step 3240, loss = 0.54 (1021.7 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 08:55:32.897891: step 3250, loss = 0.57 (1065.7 examples/sec; 0.240 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4174  Precision @ 1 eval: 0.8152\n",
      "INFO:tensorflow:global_step/sec: 2.67778\n",
      "2017-05-30 08:55:35.436679: step 3260, loss = 0.59 (1008.4 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 08:55:38.119120: step 3270, loss = 0.72 (954.4 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 08:55:40.738939: step 3280, loss = 0.51 (977.2 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 08:55:43.345172: step 3290, loss = 0.69 (982.3 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 08:55:46.071356: step 3300, loss = 0.48 (939.0 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 08:55:52.355431: step 3320, loss = 0.60 (856.6 examples/sec; 0.299 sec/batch)\n",
      "2017-05-30 08:55:55.120809: step 3330, loss = 0.58 (925.7 examples/sec; 0.277 sec/batch)\n",
      "2017-05-30 08:55:57.732105: step 3340, loss = 0.55 (980.4 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 08:56:00.252012: step 3350, loss = 0.63 (1015.9 examples/sec; 0.252 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.42485\n",
      "2017-05-30 08:56:04.326270: step 3360, loss = 0.62 (628.3 examples/sec; 0.407 sec/batch)\n",
      "2017-05-30 08:56:06.887169: step 3370, loss = 0.61 (999.6 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 08:56:09.491623: step 3380, loss = 0.56 (982.9 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 08:56:12.255965: step 3390, loss = 0.62 (926.1 examples/sec; 0.276 sec/batch)\n",
      "2017-05-30 08:56:14.785642: step 3400, loss = 0.54 (1012.0 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 08:56:17.248619: step 3410, loss = 0.54 (1039.4 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 08:56:22.799406: step 3430, loss = 0.55 (878.6 examples/sec; 0.291 sec/batch)\n",
      "2017-05-30 08:56:26.088693: step 3440, loss = 0.50 (778.3 examples/sec; 0.329 sec/batch)\n",
      "2017-05-30 08:56:29.022019: step 3450, loss = 0.47 (872.7 examples/sec; 0.293 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.45769\n",
      "2017-05-30 08:56:33.226461: step 3460, loss = 0.60 (608.9 examples/sec; 0.420 sec/batch)\n",
      "2017-05-30 08:56:35.752010: step 3470, loss = 0.48 (1013.6 examples/sec; 0.253 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 08:56:38.259614: step 3480, loss = 0.56 (1020.9 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 08:56:41.207511: step 3490, loss = 0.64 (868.4 examples/sec; 0.295 sec/batch)\n",
      "2017-05-30 08:56:43.719990: step 3500, loss = 0.53 (1018.9 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 08:56:46.255562: step 3510, loss = 0.71 (1009.6 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 08:56:48.867655: step 3520, loss = 0.56 (980.1 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 08:56:51.409372: step 3530, loss = 0.63 (1007.2 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 08:56:53.908906: step 3540, loss = 0.64 (1024.2 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 08:56:56.507142: step 3550, loss = 0.46 (985.3 examples/sec; 0.260 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.53523\n",
      "2017-05-30 08:57:01.891375: step 3560, loss = 0.52 (475.5 examples/sec; 0.538 sec/batch)\n",
      "2017-05-30 08:57:04.827257: step 3570, loss = 0.50 (872.0 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 08:57:07.499017: step 3580, loss = 0.55 (958.2 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 08:57:10.188168: step 3590, loss = 0.54 (952.0 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 08:57:12.795315: step 3600, loss = 0.44 (981.9 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 08:57:15.362530: step 3610, loss = 0.52 (997.2 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 08:57:17.945390: step 3620, loss = 0.49 (991.1 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 08:57:20.416650: step 3630, loss = 0.57 (1035.9 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 08:57:23.011260: step 3640, loss = 0.45 (986.7 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 08:57:25.645695: step 3650, loss = 0.41 (971.7 examples/sec; 0.263 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.56862\n",
      "2017-05-30 08:57:29.459011: step 3660, loss = 0.49 (671.3 examples/sec; 0.381 sec/batch)\n",
      "2017-05-30 08:57:32.119629: step 3670, loss = 0.41 (962.2 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 08:57:34.661244: step 3680, loss = 0.54 (1007.2 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 08:57:37.099422: step 3690, loss = 0.48 (1050.0 examples/sec; 0.244 sec/batch)\n",
      "2017-05-30 08:57:39.785302: step 3700, loss = 0.60 (953.1 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 08:57:42.974394: step 3710, loss = 0.42 (802.7 examples/sec; 0.319 sec/batch)\n",
      "2017-05-30 08:57:46.158015: step 3720, loss = 0.54 (804.1 examples/sec; 0.318 sec/batch)\n",
      "2017-05-30 08:57:49.101485: step 3730, loss = 0.53 (869.7 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 08:57:51.782639: step 3740, loss = 0.49 (954.8 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 08:57:54.360126: step 3750, loss = 0.44 (993.2 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 08:57:58.139342: step 3760, loss = 0.49 (677.4 examples/sec; 0.378 sec/batch)\n",
      "2017-05-30 08:58:00.853327: step 3770, loss = 0.55 (943.3 examples/sec; 0.271 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4501  Precision @ 1 train: 0.8791\n",
      "2017-05-30 08:58:03.221298: step 3780, loss = 0.51 (1081.1 examples/sec; 0.237 sec/batch)\n",
      "2017-05-30 08:58:05.625738: step 3790, loss = 0.51 (1064.7 examples/sec; 0.240 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4264  Precision @ 1 eval: 0.8328\n",
      "INFO:tensorflow:global_step/sec: 2.57276\n",
      "2017-05-30 08:58:08.189611: step 3800, loss = 0.53 (998.5 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 08:58:10.787412: step 3810, loss = 0.51 (985.4 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 08:58:13.463006: step 3820, loss = 0.57 (956.8 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 08:58:16.099968: step 3830, loss = 0.66 (970.8 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 08:58:18.666449: step 3840, loss = 0.50 (997.5 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 08:58:21.165275: step 3850, loss = 0.47 (1024.5 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 08:58:23.781622: step 3860, loss = 0.54 (978.5 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 08:58:26.354620: step 3870, loss = 0.47 (994.9 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 08:58:31.432870: step 3890, loss = 0.45 (988.7 examples/sec; 0.259 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.56169\n",
      "2017-05-30 08:58:36.204193: step 3900, loss = 0.53 (536.5 examples/sec; 0.477 sec/batch)\n",
      "2017-05-30 08:58:39.291158: step 3910, loss = 0.50 (829.3 examples/sec; 0.309 sec/batch)\n",
      "2017-05-30 08:58:42.280924: step 3920, loss = 0.47 (856.3 examples/sec; 0.299 sec/batch)\n",
      "2017-05-30 08:58:45.106172: step 3930, loss = 0.49 (906.1 examples/sec; 0.283 sec/batch)\n",
      "2017-05-30 08:58:47.598542: step 3940, loss = 0.49 (1027.1 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 08:58:50.109920: step 3950, loss = 0.66 (1019.4 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 08:58:52.782498: step 3960, loss = 0.46 (957.9 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 08:58:55.284269: step 3970, loss = 0.46 (1023.3 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 08:58:57.786717: step 3980, loss = 0.49 (1023.0 examples/sec; 0.250 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.41358\n",
      "2017-05-30 08:59:05.623878: step 4000, loss = 0.48 (487.8 examples/sec; 0.525 sec/batch)\n",
      "2017-05-30 08:59:08.595684: step 4010, loss = 0.46 (861.4 examples/sec; 0.297 sec/batch)\n",
      "2017-05-30 08:59:11.309135: step 4020, loss = 0.62 (943.4 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 08:59:14.097265: step 4030, loss = 0.54 (918.2 examples/sec; 0.279 sec/batch)\n",
      "2017-05-30 08:59:16.887812: step 4040, loss = 0.57 (917.4 examples/sec; 0.279 sec/batch)\n",
      "2017-05-30 08:59:19.707847: step 4050, loss = 0.55 (907.8 examples/sec; 0.282 sec/batch)\n",
      "2017-05-30 08:59:22.300503: step 4060, loss = 0.42 (987.4 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 08:59:24.749433: step 4070, loss = 0.56 (1045.4 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 08:59:27.320894: step 4080, loss = 0.48 (995.5 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 08:59:29.930159: step 4090, loss = 0.49 (981.1 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 08:59:33.835476: step 4100, loss = 0.53 (655.5 examples/sec; 0.391 sec/batch)\n",
      "2017-05-30 08:59:36.454543: step 4110, loss = 0.57 (977.4 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 08:59:38.984701: step 4120, loss = 0.50 (1011.8 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 08:59:41.440860: step 4130, loss = 0.38 (1042.3 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 08:59:44.258193: step 4140, loss = 0.45 (908.7 examples/sec; 0.282 sec/batch)\n",
      "2017-05-30 08:59:46.923831: step 4150, loss = 0.41 (960.4 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 08:59:49.412592: step 4160, loss = 0.45 (1028.6 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 08:59:52.078303: step 4170, loss = 0.50 (960.3 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 08:59:54.704575: step 4180, loss = 0.56 (974.8 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 08:59:57.188085: step 4190, loss = 0.51 (1030.8 examples/sec; 0.248 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.64501\n",
      "2017-05-30 09:00:01.332421: step 4200, loss = 0.51 (617.7 examples/sec; 0.414 sec/batch)\n",
      "2017-05-30 09:00:04.590861: step 4210, loss = 0.45 (785.7 examples/sec; 0.326 sec/batch)\n",
      "2017-05-30 09:00:07.661528: step 4220, loss = 0.57 (833.7 examples/sec; 0.307 sec/batch)\n",
      "2017-05-30 09:00:10.522732: step 4230, loss = 0.53 (894.7 examples/sec; 0.286 sec/batch)\n",
      "2017-05-30 09:00:13.249518: step 4240, loss = 0.46 (938.8 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 09:00:15.906161: step 4250, loss = 0.44 (963.6 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:00:18.457528: step 4260, loss = 0.41 (1003.4 examples/sec; 0.255 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 3975 into /home/ipython/cnn-cifar10/tb_log/vggA/train/model.ckpt.\n",
      "2017-05-30 09:00:21.536966: step 4270, loss = 0.50 (831.3 examples/sec; 0.308 sec/batch)\n",
      "2017-05-30 09:00:23.941799: step 4280, loss = 0.52 (1064.5 examples/sec; 0.240 sec/batch)\n",
      "2017-05-30 09:00:26.497989: step 4290, loss = 0.49 (1001.5 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:00:30.959434: step 4300, loss = 0.38 (573.8 examples/sec; 0.446 sec/batch)\n",
      "2017-05-30 09:00:37.715132: step 4320, loss = 0.56 (843.1 examples/sec; 0.304 sec/batch)\n",
      "2017-05-30 09:00:40.343714: step 4330, loss = 0.45 (973.9 examples/sec; 0.263 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4287  Precision @ 1 eval: 0.8373\n",
      "INFO:tensorflow:global_step/sec: 2.39206\n",
      "2017-05-30 09:00:42.851110: step 4340, loss = 0.56 (1021.0 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:00:45.571432: step 4350, loss = 0.53 (941.1 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 09:00:48.188103: step 4360, loss = 0.47 (978.3 examples/sec; 0.262 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 09:00:50.769075: step 4370, loss = 0.35 (991.9 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:00:53.274390: step 4380, loss = 0.45 (1021.8 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:00:55.870807: step 4390, loss = 0.43 (986.0 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:00:58.449467: step 4400, loss = 0.37 (992.8 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:01:00.992273: step 4410, loss = 0.40 (1006.8 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:01:03.567896: step 4420, loss = 0.52 (993.9 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:01:06.150477: step 4430, loss = 0.51 (991.3 examples/sec; 0.258 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.65918\n",
      "2017-05-30 09:01:09.964286: step 4440, loss = 0.46 (671.2 examples/sec; 0.381 sec/batch)\n",
      "2017-05-30 09:01:12.649510: step 4450, loss = 0.46 (953.4 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 09:01:15.861262: step 4460, loss = 0.58 (797.1 examples/sec; 0.321 sec/batch)\n",
      "2017-05-30 09:01:19.186979: step 4470, loss = 0.45 (769.8 examples/sec; 0.333 sec/batch)\n",
      "2017-05-30 09:01:22.070351: step 4480, loss = 0.41 (887.8 examples/sec; 0.288 sec/batch)\n",
      "2017-05-30 09:01:24.690291: step 4490, loss = 0.42 (977.1 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:01:27.252787: step 4500, loss = 0.44 (999.0 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:01:29.725772: step 4510, loss = 0.54 (1035.2 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:01:32.352108: step 4520, loss = 0.45 (974.7 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:01:34.873526: step 4530, loss = 0.40 (1015.3 examples/sec; 0.252 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.45881\n",
      "2017-05-30 09:01:41.561930: step 4550, loss = 0.49 (953.4 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 09:01:44.002122: step 4560, loss = 0.56 (1049.1 examples/sec; 0.244 sec/batch)\n",
      "2017-05-30 09:01:46.674254: step 4570, loss = 0.38 (958.0 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 09:01:49.434122: step 4580, loss = 0.42 (927.6 examples/sec; 0.276 sec/batch)\n",
      "2017-05-30 09:01:52.640220: step 4590, loss = 0.55 (798.5 examples/sec; 0.321 sec/batch)\n",
      "2017-05-30 09:01:55.711266: step 4600, loss = 0.45 (833.6 examples/sec; 0.307 sec/batch)\n",
      "2017-05-30 09:01:58.549689: step 4610, loss = 0.46 (901.9 examples/sec; 0.284 sec/batch)\n",
      "2017-05-30 09:02:01.135001: step 4620, loss = 0.43 (990.2 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:02:03.705862: step 4630, loss = 0.55 (995.8 examples/sec; 0.257 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.4702\n",
      "2017-05-30 09:02:07.651002: step 4640, loss = 0.43 (648.9 examples/sec; 0.395 sec/batch)\n",
      "2017-05-30 09:02:10.239604: step 4650, loss = 0.41 (988.9 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:02:12.740406: step 4660, loss = 0.45 (1023.7 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:02:15.296140: step 4670, loss = 0.50 (1001.7 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:02:18.074870: step 4680, loss = 0.52 (921.3 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 09:02:20.640042: step 4690, loss = 0.35 (998.0 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:02:23.293726: step 4700, loss = 0.49 (964.7 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:02:25.910936: step 4710, loss = 0.46 (978.1 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:02:28.398519: step 4720, loss = 0.55 (1029.1 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:02:30.925480: step 4730, loss = 0.41 (1013.1 examples/sec; 0.253 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.58927\n",
      "2017-05-30 09:02:35.611555: step 4740, loss = 0.48 (546.3 examples/sec; 0.469 sec/batch)\n",
      "2017-05-30 09:02:38.888891: step 4750, loss = 0.44 (781.1 examples/sec; 0.328 sec/batch)\n",
      "2017-05-30 09:02:41.852648: step 4760, loss = 0.43 (863.8 examples/sec; 0.296 sec/batch)\n",
      "2017-05-30 09:02:47.017019: step 4780, loss = 0.46 (1000.7 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:02:49.734684: step 4790, loss = 0.51 (942.0 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 09:02:52.425780: step 4800, loss = 0.51 (951.3 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 09:02:54.954612: step 4810, loss = 0.52 (1012.3 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:02:57.435398: step 4820, loss = 0.42 (1031.9 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:03:00.070110: step 4830, loss = 0.41 (971.6 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:03:03.925220: step 4840, loss = 0.35 (664.1 examples/sec; 0.386 sec/batch)\n",
      "2017-05-30 09:03:06.544671: step 4850, loss = 0.43 (977.3 examples/sec; 0.262 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4639  Precision @ 1 train: 0.9061\n",
      "2017-05-30 09:03:09.101426: step 4860, loss = 0.48 (1001.3 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:03:11.577442: step 4870, loss = 0.52 (1033.9 examples/sec; 0.248 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4319  Precision @ 1 eval: 0.8436\n",
      "INFO:tensorflow:global_step/sec: 2.5855\n",
      "2017-05-30 09:03:13.952822: step 4880, loss = 0.37 (1077.7 examples/sec; 0.238 sec/batch)\n",
      "2017-05-30 09:03:16.563891: step 4890, loss = 0.47 (980.4 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:03:19.239128: step 4900, loss = 0.38 (956.9 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 09:03:22.030101: step 4910, loss = 0.39 (917.2 examples/sec; 0.279 sec/batch)\n",
      "2017-05-30 09:03:24.677585: step 4920, loss = 0.45 (967.0 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:03:27.224433: step 4930, loss = 0.44 (1005.2 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:03:29.702941: step 4940, loss = 0.47 (1032.9 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:03:32.356185: step 4950, loss = 0.44 (964.9 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:03:35.202590: step 4960, loss = 0.44 (899.4 examples/sec; 0.285 sec/batch)\n",
      "2017-05-30 09:03:38.461946: step 4970, loss = 0.36 (785.4 examples/sec; 0.326 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.39996\n",
      "2017-05-30 09:03:43.190993: step 4980, loss = 0.45 (541.3 examples/sec; 0.473 sec/batch)\n",
      "2017-05-30 09:03:45.843586: step 4990, loss = 0.45 (965.1 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:03:51.048251: step 5010, loss = 0.50 (930.8 examples/sec; 0.275 sec/batch)\n",
      "2017-05-30 09:03:53.802570: step 5020, loss = 0.53 (929.5 examples/sec; 0.275 sec/batch)\n",
      "2017-05-30 09:03:57.053515: step 5030, loss = 0.49 (787.5 examples/sec; 0.325 sec/batch)\n",
      "2017-05-30 09:04:00.075462: step 5040, loss = 0.52 (847.1 examples/sec; 0.302 sec/batch)\n",
      "2017-05-30 09:04:02.925682: step 5050, loss = 0.37 (898.2 examples/sec; 0.285 sec/batch)\n",
      "2017-05-30 09:04:05.573548: step 5060, loss = 0.36 (966.8 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:04:08.072409: step 5070, loss = 0.44 (1024.5 examples/sec; 0.250 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.43221\n",
      "2017-05-30 09:04:12.292501: step 5080, loss = 0.47 (606.6 examples/sec; 0.422 sec/batch)\n",
      "2017-05-30 09:04:14.817463: step 5090, loss = 0.46 (1013.9 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:04:17.280429: step 5100, loss = 0.45 (1039.4 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:04:22.919843: step 5120, loss = 0.50 (841.6 examples/sec; 0.304 sec/batch)\n",
      "2017-05-30 09:04:25.376765: step 5130, loss = 0.44 (1042.0 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:04:27.966901: step 5140, loss = 0.37 (988.4 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:04:30.551494: step 5150, loss = 0.45 (990.5 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:04:33.044212: step 5160, loss = 0.43 (1027.0 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:04:35.599958: step 5170, loss = 0.36 (1001.7 examples/sec; 0.256 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.64375\n",
      "2017-05-30 09:04:39.716011: step 5180, loss = 0.44 (622.0 examples/sec; 0.412 sec/batch)\n",
      "2017-05-30 09:04:42.180960: step 5190, loss = 0.41 (1038.6 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:04:44.844947: step 5200, loss = 0.53 (961.0 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:04:47.373033: step 5210, loss = 0.42 (1012.6 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:04:49.816873: step 5220, loss = 0.44 (1047.5 examples/sec; 0.244 sec/batch)\n",
      "2017-05-30 09:04:52.611519: step 5230, loss = 0.40 (916.0 examples/sec; 0.279 sec/batch)\n",
      "2017-05-30 09:04:55.833998: step 5240, loss = 0.37 (794.4 examples/sec; 0.322 sec/batch)\n",
      "2017-05-30 09:04:58.968550: step 5250, loss = 0.33 (816.7 examples/sec; 0.313 sec/batch)\n",
      "2017-05-30 09:05:01.910370: step 5260, loss = 0.39 (870.2 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 09:05:04.558980: step 5270, loss = 0.40 (966.5 examples/sec; 0.265 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.46206\n",
      "2017-05-30 09:05:08.607927: step 5280, loss = 0.55 (632.3 examples/sec; 0.405 sec/batch)\n",
      "2017-05-30 09:05:11.081915: step 5290, loss = 0.49 (1034.8 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:05:13.752561: step 5300, loss = 0.41 (958.6 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 09:05:16.239196: step 5310, loss = 0.38 (1029.5 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:05:18.738308: step 5320, loss = 0.41 (1024.4 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:05:21.375132: step 5330, loss = 0.48 (970.9 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:05:26.759489: step 5350, loss = 0.44 (995.0 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:05:29.363130: step 5360, loss = 0.43 (983.2 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:05:32.568021: step 5370, loss = 0.41 (798.8 examples/sec; 0.320 sec/batch)\n",
      "2017-05-30 09:05:37.669757: step 5380, loss = 0.38 (501.8 examples/sec; 0.510 sec/batch)\n",
      "2017-05-30 09:05:40.552468: step 5390, loss = 0.56 (888.1 examples/sec; 0.288 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4657  Precision @ 1 train: 0.9096\n",
      "2017-05-30 09:05:43.010192: step 5400, loss = 0.48 (1041.6 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:05:45.416138: step 5410, loss = 0.45 (1064.0 examples/sec; 0.241 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4319  Precision @ 1 eval: 0.8436\n",
      "INFO:tensorflow:global_step/sec: 2.527\n",
      "2017-05-30 09:05:47.897248: step 5420, loss = 0.41 (1031.8 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:05:50.503193: step 5430, loss = 0.41 (982.4 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:05:53.096182: step 5440, loss = 0.42 (987.3 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:05:58.613788: step 5460, loss = 0.42 (927.0 examples/sec; 0.276 sec/batch)\n",
      "2017-05-30 09:06:01.982259: step 5470, loss = 0.37 (760.0 examples/sec; 0.337 sec/batch)\n",
      "2017-05-30 09:06:04.917279: step 5480, loss = 0.35 (872.2 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 09:06:07.671906: step 5490, loss = 0.43 (929.3 examples/sec; 0.275 sec/batch)\n",
      "2017-05-30 09:06:10.306998: step 5500, loss = 0.37 (971.5 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:06:12.774866: step 5510, loss = 0.32 (1037.3 examples/sec; 0.247 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.41464\n",
      "2017-05-30 09:06:17.181045: step 5520, loss = 0.45 (581.0 examples/sec; 0.441 sec/batch)\n",
      "2017-05-30 09:06:19.410196: step 5530, loss = 0.42 (1148.4 examples/sec; 0.223 sec/batch)\n",
      "2017-05-30 09:06:21.868321: step 5540, loss = 0.37 (1041.4 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:06:24.647166: step 5550, loss = 0.41 (921.2 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 09:06:29.832599: step 5570, loss = 0.41 (1036.0 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:06:32.500796: step 5580, loss = 0.39 (959.4 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 09:06:35.051217: step 5590, loss = 0.47 (1003.8 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:06:37.501937: step 5600, loss = 0.46 (1044.6 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 09:06:40.079798: step 5610, loss = 0.39 (993.1 examples/sec; 0.258 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.68682\n",
      "2017-05-30 09:06:44.304729: step 5620, loss = 0.36 (605.9 examples/sec; 0.422 sec/batch)\n",
      "2017-05-30 09:06:46.542992: step 5630, loss = 0.37 (1143.7 examples/sec; 0.224 sec/batch)\n",
      "2017-05-30 09:06:49.157897: step 5640, loss = 0.40 (979.0 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:06:52.293839: step 5650, loss = 0.45 (816.3 examples/sec; 0.314 sec/batch)\n",
      "2017-05-30 09:06:55.683338: step 5660, loss = 0.35 (755.3 examples/sec; 0.339 sec/batch)\n",
      "2017-05-30 09:07:01.257770: step 5680, loss = 0.34 (982.9 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:07:03.801704: step 5690, loss = 0.39 (1006.3 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:07:06.301934: step 5700, loss = 0.46 (1023.9 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:07:08.863251: step 5710, loss = 0.43 (999.5 examples/sec; 0.256 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.47351\n",
      "2017-05-30 09:07:13.093702: step 5720, loss = 0.38 (605.1 examples/sec; 0.423 sec/batch)\n",
      "2017-05-30 09:07:15.386809: step 5730, loss = 0.45 (1116.4 examples/sec; 0.229 sec/batch)\n",
      "2017-05-30 09:07:18.021520: step 5740, loss = 0.36 (971.6 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:07:20.487560: step 5750, loss = 0.48 (1038.1 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:07:23.018589: step 5760, loss = 0.46 (1011.4 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:07:25.833816: step 5770, loss = 0.40 (909.3 examples/sec; 0.282 sec/batch)\n",
      "2017-05-30 09:07:28.424774: step 5780, loss = 0.33 (988.1 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:07:36.800617: step 5810, loss = 0.48 (805.1 examples/sec; 0.318 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.43121\n",
      "2017-05-30 09:07:42.239072: step 5820, loss = 0.42 (470.7 examples/sec; 0.544 sec/batch)\n",
      "2017-05-30 09:07:44.554527: step 5830, loss = 0.40 (1105.6 examples/sec; 0.232 sec/batch)\n",
      "2017-05-30 09:07:47.135504: step 5840, loss = 0.35 (991.9 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:07:49.626951: step 5850, loss = 0.36 (1027.5 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:07:52.245191: step 5860, loss = 0.37 (977.8 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:07:54.819559: step 5870, loss = 0.35 (994.4 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:07:57.554486: step 5880, loss = 0.46 (936.0 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 09:08:00.171458: step 5890, loss = 0.33 (978.2 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:08:03.014463: step 5900, loss = 0.34 (900.5 examples/sec; 0.284 sec/batch)\n",
      "2017-05-30 09:08:13.632440: step 5930, loss = 0.38 (1010.8 examples/sec; 0.253 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4685  Precision @ 1 train: 0.9150\n",
      "2017-05-30 09:08:16.003401: step 5940, loss = 0.42 (1079.7 examples/sec; 0.237 sec/batch)\n",
      "2017-05-30 09:08:18.458170: step 5950, loss = 0.37 (1042.9 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 09:08:21.060076: step 5960, loss = 0.39 (983.9 examples/sec; 0.260 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4372  Precision @ 1 eval: 0.8539\n",
      "INFO:tensorflow:global_step/sec: 2.54618\n",
      "2017-05-30 09:08:23.552820: step 5970, loss = 0.38 (1027.0 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:08:25.996143: step 5980, loss = 0.49 (1047.8 examples/sec; 0.244 sec/batch)\n",
      "2017-05-30 09:08:29.072639: step 5990, loss = 0.42 (832.1 examples/sec; 0.308 sec/batch)\n",
      "2017-05-30 09:08:31.636462: step 6000, loss = 0.40 (998.5 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:08:34.108742: step 6010, loss = 0.39 (1035.5 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:08:36.712684: step 6020, loss = 0.37 (983.1 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:08:39.288574: step 6030, loss = 0.29 (993.8 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:08:44.404775: step 6050, loss = 0.34 (976.8 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:08:46.992212: step 6060, loss = 0.35 (989.4 examples/sec; 0.259 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.61718\n",
      "2017-05-30 09:08:50.977000: step 6070, loss = 0.46 (642.4 examples/sec; 0.398 sec/batch)\n",
      "2017-05-30 09:08:53.628275: step 6080, loss = 0.39 (965.6 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:08:56.172976: step 6090, loss = 0.31 (1006.0 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:08:58.896740: step 6100, loss = 0.41 (939.9 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 09:09:01.725479: step 6110, loss = 0.37 (905.0 examples/sec; 0.283 sec/batch)\n",
      "2017-05-30 09:09:04.918544: step 6120, loss = 0.42 (801.7 examples/sec; 0.319 sec/batch)\n",
      "2017-05-30 09:09:08.051211: step 6130, loss = 0.52 (817.2 examples/sec; 0.313 sec/batch)\n",
      "2017-05-30 09:09:10.895212: step 6140, loss = 0.38 (900.1 examples/sec; 0.284 sec/batch)\n",
      "2017-05-30 09:09:16.070085: step 6160, loss = 0.42 (1016.2 examples/sec; 0.252 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.44542\n",
      "2017-05-30 09:09:20.000249: step 6170, loss = 0.37 (651.4 examples/sec; 0.393 sec/batch)\n",
      "2017-05-30 09:09:22.644227: step 6180, loss = 0.45 (968.2 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:09:25.106748: step 6190, loss = 0.44 (1039.6 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:09:27.984151: step 6200, loss = 0.37 (889.7 examples/sec; 0.288 sec/batch)\n",
      "2017-05-30 09:09:30.817295: step 6210, loss = 0.33 (903.6 examples/sec; 0.283 sec/batch)\n",
      "2017-05-30 09:09:33.303081: step 6220, loss = 0.35 (1029.9 examples/sec; 0.249 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 09:09:35.881350: step 6230, loss = 0.48 (992.9 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:09:38.487401: step 6240, loss = 0.32 (982.3 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:09:40.973939: step 6250, loss = 0.31 (1029.5 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:09:43.593711: step 6260, loss = 0.37 (977.2 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:09:48.178318: step 6270, loss = 0.46 (558.4 examples/sec; 0.458 sec/batch)\n",
      "2017-05-30 09:09:51.323553: step 6280, loss = 0.34 (813.9 examples/sec; 0.315 sec/batch)\n",
      "2017-05-30 09:09:54.260877: step 6290, loss = 0.30 (871.5 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 09:09:56.886352: step 6300, loss = 0.43 (975.1 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:09:59.571127: step 6310, loss = 0.40 (953.5 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 09:10:02.164418: step 6320, loss = 0.33 (987.2 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:10:04.792941: step 6330, loss = 0.37 (973.9 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:10:07.336948: step 6340, loss = 0.37 (1006.3 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:10:09.804095: step 6350, loss = 0.33 (1037.6 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:10:12.441305: step 6360, loss = 0.43 (970.7 examples/sec; 0.264 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.45048\n",
      "2017-05-30 09:10:17.173875: step 6370, loss = 0.39 (540.9 examples/sec; 0.473 sec/batch)\n",
      "2017-05-30 09:10:20.247129: step 6380, loss = 0.41 (833.0 examples/sec; 0.307 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 5921 into /home/ipython/cnn-cifar10/tb_log/vggA/train/model.ckpt.\n",
      "2017-05-30 09:10:23.476970: step 6390, loss = 0.29 (792.6 examples/sec; 0.323 sec/batch)\n",
      "2017-05-30 09:10:26.115572: step 6400, loss = 0.40 (970.2 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:10:28.645435: step 6410, loss = 0.36 (1011.9 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:10:31.524567: step 6420, loss = 0.37 (889.2 examples/sec; 0.288 sec/batch)\n",
      "2017-05-30 09:10:34.211833: step 6430, loss = 0.37 (952.6 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 09:10:36.673892: step 6440, loss = 0.33 (1039.8 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:10:39.214554: step 6450, loss = 0.32 (1007.6 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:10:41.913148: step 6460, loss = 0.45 (948.6 examples/sec; 0.270 sec/batch)\n",
      "2017-05-30 09:10:45.739771: step 6470, loss = 0.29 (669.0 examples/sec; 0.383 sec/batch)\n",
      "2017-05-30 09:10:48.440319: step 6480, loss = 0.36 (948.0 examples/sec; 0.270 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4717  Precision @ 1 train: 0.9213\n",
      "2017-05-30 09:10:53.347648: step 6500, loss = 0.44 (1047.5 examples/sec; 0.244 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4326  Precision @ 1 eval: 0.8449\n",
      "INFO:tensorflow:global_step/sec: 2.54552\n",
      "2017-05-30 09:10:55.859585: step 6510, loss = 0.30 (1019.1 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:10:58.480696: step 6520, loss = 0.44 (976.7 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:11:01.118519: step 6530, loss = 0.34 (970.5 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:11:03.811260: step 6540, loss = 0.44 (950.7 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 09:11:06.395949: step 6550, loss = 0.45 (990.4 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:11:08.866257: step 6560, loss = 0.31 (1036.3 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:11:11.407672: step 6570, loss = 0.48 (1007.3 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:11:14.089757: step 6580, loss = 0.39 (954.5 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 09:11:17.355142: step 6590, loss = 0.40 (784.0 examples/sec; 0.327 sec/batch)\n",
      "2017-05-30 09:11:20.400124: step 6600, loss = 0.34 (840.7 examples/sec; 0.304 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.40085\n",
      "2017-05-30 09:11:24.963382: step 6610, loss = 0.29 (561.0 examples/sec; 0.456 sec/batch)\n",
      "2017-05-30 09:11:27.510705: step 6620, loss = 0.31 (1005.0 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:11:29.979214: step 6630, loss = 0.34 (1037.1 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:11:33.044684: step 6640, loss = 0.30 (835.1 examples/sec; 0.307 sec/batch)\n",
      "2017-05-30 09:11:35.657563: step 6650, loss = 0.43 (979.8 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:11:38.134116: step 6660, loss = 0.31 (1033.7 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:11:40.771609: step 6670, loss = 0.37 (970.6 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:11:43.367460: step 6680, loss = 0.30 (986.2 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:11:45.894585: step 6690, loss = 0.42 (1013.0 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:11:48.541598: step 6700, loss = 0.34 (967.1 examples/sec; 0.265 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.51988\n",
      "2017-05-30 09:11:56.628353: step 6720, loss = 0.34 (850.5 examples/sec; 0.301 sec/batch)\n",
      "2017-05-30 09:11:59.414488: step 6730, loss = 0.33 (918.8 examples/sec; 0.279 sec/batch)\n",
      "2017-05-30 09:12:02.187794: step 6740, loss = 0.36 (923.1 examples/sec; 0.277 sec/batch)\n",
      "2017-05-30 09:12:04.834295: step 6750, loss = 0.34 (967.3 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:12:07.346322: step 6760, loss = 0.40 (1019.1 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:12:10.004542: step 6770, loss = 0.33 (963.1 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:12:12.511045: step 6780, loss = 0.43 (1021.3 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:12:15.018606: step 6790, loss = 0.44 (1020.9 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:12:17.647049: step 6800, loss = 0.31 (974.0 examples/sec; 0.263 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.5482\n",
      "2017-05-30 09:12:21.485978: step 6810, loss = 0.37 (666.9 examples/sec; 0.384 sec/batch)\n",
      "2017-05-30 09:12:24.121009: step 6820, loss = 0.39 (971.5 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:12:29.191240: step 6840, loss = 0.40 (1048.7 examples/sec; 0.244 sec/batch)\n",
      "2017-05-30 09:12:31.760332: step 6850, loss = 0.33 (996.5 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:12:34.704815: step 6860, loss = 0.42 (869.4 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 09:12:38.081628: step 6870, loss = 0.31 (758.1 examples/sec; 0.338 sec/batch)\n",
      "2017-05-30 09:12:41.052241: step 6880, loss = 0.47 (861.8 examples/sec; 0.297 sec/batch)\n",
      "2017-05-30 09:12:43.825499: step 6890, loss = 0.34 (923.1 examples/sec; 0.277 sec/batch)\n",
      "2017-05-30 09:12:46.434875: step 6900, loss = 0.28 (981.1 examples/sec; 0.261 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.47296\n",
      "2017-05-30 09:12:50.288510: step 6910, loss = 0.42 (664.3 examples/sec; 0.385 sec/batch)\n",
      "2017-05-30 09:12:53.011436: step 6920, loss = 0.33 (940.2 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 09:12:55.535774: step 6930, loss = 0.49 (1014.1 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:12:58.027249: step 6940, loss = 0.40 (1027.5 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:13:00.629627: step 6950, loss = 0.36 (983.7 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:13:03.225749: step 6960, loss = 0.35 (986.1 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:13:06.014768: step 6970, loss = 0.34 (917.9 examples/sec; 0.279 sec/batch)\n",
      "2017-05-30 09:13:08.624926: step 6980, loss = 0.29 (980.8 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:13:11.212015: step 6990, loss = 0.36 (989.5 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:13:13.746347: step 7000, loss = 0.39 (1010.1 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:13:17.791147: step 7010, loss = 0.32 (632.9 examples/sec; 0.404 sec/batch)\n",
      "2017-05-30 09:13:20.402800: step 7020, loss = 0.35 (980.2 examples/sec; 0.261 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4715  Precision @ 1 train: 0.9209\n",
      "2017-05-30 09:13:22.803981: step 7030, loss = 0.34 (1066.1 examples/sec; 0.240 sec/batch)\n",
      "2017-05-30 09:13:25.437019: step 7040, loss = 0.31 (972.3 examples/sec; 0.263 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4342  Precision @ 1 eval: 0.8480\n",
      "INFO:tensorflow:global_step/sec: 2.64272\n",
      "2017-05-30 09:13:27.906763: step 7050, loss = 0.37 (1036.5 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:13:30.356975: step 7060, loss = 0.35 (1044.8 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 09:13:33.140391: step 7070, loss = 0.41 (919.7 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 09:13:36.385298: step 7080, loss = 0.30 (788.9 examples/sec; 0.324 sec/batch)\n",
      "2017-05-30 09:13:39.746244: step 7090, loss = 0.42 (761.7 examples/sec; 0.336 sec/batch)\n",
      "2017-05-30 09:13:42.704697: step 7100, loss = 0.35 (865.3 examples/sec; 0.296 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 09:13:45.345383: step 7110, loss = 0.35 (969.4 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:13:47.884557: step 7120, loss = 0.36 (1008.2 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:13:50.412036: step 7130, loss = 0.37 (1012.9 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:13:53.056609: step 7140, loss = 0.33 (968.0 examples/sec; 0.264 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.40812\n",
      "2017-05-30 09:13:56.962526: step 7150, loss = 0.33 (655.4 examples/sec; 0.391 sec/batch)\n",
      "2017-05-30 09:13:59.488311: step 7160, loss = 0.30 (1013.5 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:14:02.163996: step 7170, loss = 0.29 (956.8 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 09:14:04.651412: step 7180, loss = 0.26 (1029.2 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:14:07.396426: step 7190, loss = 0.33 (932.6 examples/sec; 0.275 sec/batch)\n",
      "2017-05-30 09:14:10.096789: step 7200, loss = 0.37 (948.0 examples/sec; 0.270 sec/batch)\n",
      "2017-05-30 09:14:12.584232: step 7210, loss = 0.37 (1029.2 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:14:15.080935: step 7220, loss = 0.30 (1025.4 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:14:17.709257: step 7230, loss = 0.34 (974.0 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:14:20.880693: step 7240, loss = 0.37 (807.2 examples/sec; 0.317 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.43084\n",
      "2017-05-30 09:14:26.214176: step 7250, loss = 0.41 (480.0 examples/sec; 0.533 sec/batch)\n",
      "2017-05-30 09:14:28.858371: step 7260, loss = 0.31 (968.2 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:14:31.433495: step 7270, loss = 0.37 (994.1 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:14:34.048925: step 7280, loss = 0.36 (978.8 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:14:36.704124: step 7290, loss = 0.25 (964.1 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:14:39.508571: step 7300, loss = 0.32 (912.8 examples/sec; 0.280 sec/batch)\n",
      "2017-05-30 09:14:41.991425: step 7310, loss = 0.28 (1031.1 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:14:44.606025: step 7320, loss = 0.42 (979.1 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:14:47.189094: step 7330, loss = 0.35 (991.1 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:14:49.684201: step 7340, loss = 0.33 (1026.0 examples/sec; 0.250 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.60263\n",
      "2017-05-30 09:14:53.948269: step 7350, loss = 0.29 (600.4 examples/sec; 0.426 sec/batch)\n",
      "2017-05-30 09:14:56.464282: step 7360, loss = 0.38 (1017.5 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:14:58.953753: step 7370, loss = 0.37 (1028.3 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:15:01.613961: step 7380, loss = 0.34 (962.3 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:15:04.150920: step 7390, loss = 0.30 (1009.1 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:15:09.573558: step 7410, loss = 0.37 (875.1 examples/sec; 0.293 sec/batch)\n",
      "2017-05-30 09:15:12.797384: step 7420, loss = 0.28 (794.1 examples/sec; 0.322 sec/batch)\n",
      "2017-05-30 09:15:15.926547: step 7430, loss = 0.38 (818.1 examples/sec; 0.313 sec/batch)\n",
      "2017-05-30 09:15:18.829406: step 7440, loss = 0.34 (881.9 examples/sec; 0.290 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.449\n",
      "2017-05-30 09:15:22.963077: step 7450, loss = 0.45 (619.3 examples/sec; 0.413 sec/batch)\n",
      "2017-05-30 09:15:25.430286: step 7460, loss = 0.33 (1037.6 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:15:28.013760: step 7470, loss = 0.35 (990.9 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:15:30.606887: step 7480, loss = 0.34 (987.2 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:15:33.099334: step 7490, loss = 0.30 (1027.1 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:15:35.768669: step 7500, loss = 0.42 (959.0 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 09:15:38.378476: step 7510, loss = 0.32 (980.9 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:15:41.083814: step 7520, loss = 0.38 (946.3 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 09:15:43.686145: step 7530, loss = 0.40 (983.7 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:15:46.318343: step 7540, loss = 0.32 (972.6 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:15:50.060078: step 7550, loss = 0.33 (684.2 examples/sec; 0.374 sec/batch)\n",
      "2017-05-30 09:15:52.885188: step 7560, loss = 0.36 (906.2 examples/sec; 0.283 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4758  Precision @ 1 train: 0.9293\n",
      "2017-05-30 09:15:55.804534: step 7570, loss = 0.27 (876.9 examples/sec; 0.292 sec/batch)\n",
      "2017-05-30 09:15:59.341222: step 7580, loss = 0.33 (723.8 examples/sec; 0.354 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4397  Precision @ 1 eval: 0.8588\n",
      "INFO:tensorflow:global_step/sec: 2.52294\n",
      "2017-05-30 09:16:02.388700: step 7590, loss = 0.34 (840.0 examples/sec; 0.305 sec/batch)\n",
      "2017-05-30 09:16:05.017629: step 7600, loss = 0.39 (973.8 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:16:07.570058: step 7610, loss = 0.37 (1003.0 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:16:10.139131: step 7620, loss = 0.29 (996.5 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:16:15.539508: step 7640, loss = 0.43 (1004.1 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:16:18.032169: step 7650, loss = 0.34 (1027.0 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:16:20.607136: step 7660, loss = 0.33 (994.2 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:16:23.204116: step 7670, loss = 0.33 (985.8 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:16:25.665613: step 7680, loss = 0.28 (1040.0 examples/sec; 0.246 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.60082\n",
      "2017-05-30 09:16:29.836178: step 7690, loss = 0.33 (613.8 examples/sec; 0.417 sec/batch)\n",
      "2017-05-30 09:16:32.327824: step 7700, loss = 0.42 (1027.4 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:16:34.791581: step 7710, loss = 0.31 (1039.1 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:16:37.445281: step 7720, loss = 0.31 (964.7 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:16:40.152179: step 7730, loss = 0.35 (945.7 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 09:16:42.844228: step 7740, loss = 0.28 (950.9 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 09:16:48.525830: step 7760, loss = 0.40 (836.9 examples/sec; 0.306 sec/batch)\n",
      "2017-05-30 09:16:51.689383: step 7770, loss = 0.30 (809.2 examples/sec; 0.316 sec/batch)\n",
      "2017-05-30 09:16:54.619943: step 7780, loss = 0.40 (873.6 examples/sec; 0.293 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.44797\n",
      "2017-05-30 09:16:58.850064: step 7790, loss = 0.29 (605.2 examples/sec; 0.423 sec/batch)\n",
      "2017-05-30 09:17:01.255566: step 7800, loss = 0.38 (1064.2 examples/sec; 0.241 sec/batch)\n",
      "2017-05-30 09:17:03.833363: step 7810, loss = 0.25 (993.1 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:17:06.452558: step 7820, loss = 0.34 (977.4 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:17:08.936393: step 7830, loss = 0.29 (1030.7 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:17:11.644801: step 7840, loss = 0.37 (945.2 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 09:17:14.498501: step 7850, loss = 0.35 (897.1 examples/sec; 0.285 sec/batch)\n",
      "2017-05-30 09:17:19.476305: step 7870, loss = 0.37 (1014.8 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:17:22.091738: step 7880, loss = 0.30 (978.8 examples/sec; 0.262 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.4697\n",
      "2017-05-30 09:17:27.711094: step 7890, loss = 0.31 (455.6 examples/sec; 0.562 sec/batch)\n",
      "2017-05-30 09:17:30.591582: step 7900, loss = 0.37 (888.7 examples/sec; 0.288 sec/batch)\n",
      "2017-05-30 09:17:33.243509: step 7910, loss = 0.30 (965.3 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:17:35.805320: step 7920, loss = 0.39 (999.3 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:17:38.316351: step 7930, loss = 0.34 (1019.5 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:17:40.967088: step 7940, loss = 0.32 (965.8 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:17:44.460990: step 7950, loss = 0.30 (732.7 examples/sec; 0.349 sec/batch)\n",
      "2017-05-30 09:17:47.738239: step 7960, loss = 0.36 (781.1 examples/sec; 0.328 sec/batch)\n",
      "2017-05-30 09:17:50.682115: step 7970, loss = 0.35 (869.6 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 09:17:53.374109: step 7980, loss = 0.39 (951.0 examples/sec; 0.269 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.36697\n",
      "2017-05-30 09:17:57.385466: step 7990, loss = 0.31 (638.2 examples/sec; 0.401 sec/batch)\n",
      "2017-05-30 09:17:59.898834: step 8000, loss = 0.30 (1018.6 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:18:02.556505: step 8010, loss = 0.34 (963.2 examples/sec; 0.266 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 09:18:05.044332: step 8020, loss = 0.34 (1029.0 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:18:07.613744: step 8030, loss = 0.35 (996.3 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:18:10.223000: step 8040, loss = 0.34 (981.1 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:18:12.914547: step 8050, loss = 0.31 (951.1 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 09:18:15.555482: step 8060, loss = 0.32 (969.4 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:18:18.196164: step 8070, loss = 0.32 (969.4 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:18:24.733413: step 8090, loss = 0.26 (634.7 examples/sec; 0.403 sec/batch)\n",
      "2017-05-30 09:18:27.453317: step 8100, loss = 0.37 (941.2 examples/sec; 0.272 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4796  Precision @ 1 train: 0.9367\n",
      "2017-05-30 09:18:29.800389: step 8110, loss = 0.26 (1090.7 examples/sec; 0.235 sec/batch)\n",
      "2017-05-30 09:18:32.395344: step 8120, loss = 0.33 (986.5 examples/sec; 0.259 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4355  Precision @ 1 eval: 0.8506\n",
      "INFO:tensorflow:global_step/sec: 2.64307\n",
      "2017-05-30 09:18:34.913583: step 8130, loss = 0.32 (1016.6 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:18:37.393433: step 8140, loss = 0.27 (1032.3 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:18:40.118747: step 8150, loss = 0.34 (939.3 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 09:18:42.917215: step 8160, loss = 0.24 (914.8 examples/sec; 0.280 sec/batch)\n",
      "2017-05-30 09:18:46.695007: step 8170, loss = 0.38 (677.6 examples/sec; 0.378 sec/batch)\n",
      "2017-05-30 09:18:49.638836: step 8180, loss = 0.43 (869.6 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 09:18:52.404871: step 8190, loss = 0.32 (925.5 examples/sec; 0.277 sec/batch)\n",
      "2017-05-30 09:18:55.012002: step 8200, loss = 0.31 (981.9 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:18:57.470117: step 8210, loss = 0.38 (1041.4 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:19:00.022473: step 8220, loss = 0.35 (1003.0 examples/sec; 0.255 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.40989\n",
      "2017-05-30 09:19:04.242485: step 8230, loss = 0.23 (606.6 examples/sec; 0.422 sec/batch)\n",
      "2017-05-30 09:19:06.529238: step 8240, loss = 0.29 (1119.5 examples/sec; 0.229 sec/batch)\n",
      "2017-05-30 09:19:09.142725: step 8250, loss = 0.26 (979.5 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:19:11.747893: step 8260, loss = 0.24 (982.7 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:19:14.406519: step 8270, loss = 0.33 (962.9 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:19:17.139760: step 8280, loss = 0.41 (936.6 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 09:19:20.052505: step 8290, loss = 0.30 (878.9 examples/sec; 0.291 sec/batch)\n",
      "2017-05-30 09:19:23.291009: step 8300, loss = 0.37 (790.5 examples/sec; 0.324 sec/batch)\n",
      "2017-05-30 09:19:28.969432: step 8320, loss = 0.33 (955.9 examples/sec; 0.268 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.45926\n",
      "2017-05-30 09:19:33.148309: step 8330, loss = 0.28 (612.6 examples/sec; 0.418 sec/batch)\n",
      "2017-05-30 09:19:35.407746: step 8340, loss = 0.40 (1133.0 examples/sec; 0.226 sec/batch)\n",
      "2017-05-30 09:19:38.208978: step 8350, loss = 0.35 (913.9 examples/sec; 0.280 sec/batch)\n",
      "2017-05-30 09:19:40.732392: step 8360, loss = 0.30 (1014.5 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:19:43.279336: step 8370, loss = 0.32 (1005.1 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:19:46.290178: step 8380, loss = 0.35 (850.3 examples/sec; 0.301 sec/batch)\n",
      "2017-05-30 09:19:48.805621: step 8390, loss = 0.27 (1017.7 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:19:51.303902: step 8400, loss = 0.39 (1024.7 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:19:53.958999: step 8410, loss = 0.29 (964.2 examples/sec; 0.266 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.62035\n",
      "2017-05-30 09:20:00.769950: step 8430, loss = 0.30 (595.3 examples/sec; 0.430 sec/batch)\n",
      "2017-05-30 09:20:03.241476: step 8440, loss = 0.33 (1035.8 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:20:06.494146: step 8450, loss = 0.39 (787.0 examples/sec; 0.325 sec/batch)\n",
      "2017-05-30 09:20:09.500226: step 8460, loss = 0.29 (851.6 examples/sec; 0.301 sec/batch)\n",
      "2017-05-30 09:20:12.251382: step 8470, loss = 0.34 (930.5 examples/sec; 0.275 sec/batch)\n",
      "2017-05-30 09:20:14.912979: step 8480, loss = 0.28 (961.8 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:20:17.639334: step 8490, loss = 0.35 (939.0 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 09:20:20.191686: step 8500, loss = 0.26 (1003.0 examples/sec; 0.255 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 7874 into /home/ipython/cnn-cifar10/tb_log/vggA/train/model.ckpt.\n",
      "2017-05-30 09:20:23.096345: step 8510, loss = 0.33 (881.3 examples/sec; 0.290 sec/batch)\n",
      "2017-05-30 09:20:25.559428: step 8520, loss = 0.26 (1039.3 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:20:32.164611: step 8540, loss = 0.36 (1158.4 examples/sec; 0.221 sec/batch)\n",
      "2017-05-30 09:20:34.642281: step 8550, loss = 0.18 (1033.2 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:20:37.273446: step 8560, loss = 0.43 (973.0 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:20:39.820648: step 8570, loss = 0.33 (1005.0 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:20:42.369876: step 8580, loss = 0.36 (1004.2 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:20:45.068226: step 8590, loss = 0.38 (948.7 examples/sec; 0.270 sec/batch)\n",
      "2017-05-30 09:20:48.331667: step 8600, loss = 0.30 (784.4 examples/sec; 0.326 sec/batch)\n",
      "2017-05-30 09:20:51.691599: step 8610, loss = 0.34 (761.9 examples/sec; 0.336 sec/batch)\n",
      "2017-05-30 09:20:54.656707: step 8620, loss = 0.22 (863.4 examples/sec; 0.297 sec/batch)\n",
      "2017-05-30 09:20:59.070838: step 8630, loss = 0.32 (580.0 examples/sec; 0.441 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4813  Precision @ 1 train: 0.9400\n",
      "2017-05-30 09:21:03.722727: step 8650, loss = 0.37 (1040.8 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:21:06.350124: step 8660, loss = 0.33 (974.3 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:21:08.771002: step 8670, loss = 0.33 (1057.5 examples/sec; 0.242 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4393  Precision @ 1 eval: 0.8580\n",
      "INFO:tensorflow:global_step/sec: 2.54989\n",
      "2017-05-30 09:21:11.183267: step 8680, loss = 0.34 (1061.2 examples/sec; 0.241 sec/batch)\n",
      "2017-05-30 09:21:13.820245: step 8690, loss = 0.27 (970.8 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:21:16.362725: step 8700, loss = 0.30 (1006.9 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:21:19.160932: step 8710, loss = 0.27 (914.9 examples/sec; 0.280 sec/batch)\n",
      "2017-05-30 09:21:21.856495: step 8720, loss = 0.29 (949.7 examples/sec; 0.270 sec/batch)\n",
      "2017-05-30 09:21:24.385940: step 8730, loss = 0.37 (1012.1 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:21:26.877859: step 8740, loss = 0.28 (1027.3 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:21:29.515408: step 8750, loss = 0.27 (970.6 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:21:32.070537: step 8760, loss = 0.30 (1001.9 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:21:34.544321: step 8770, loss = 0.32 (1034.9 examples/sec; 0.247 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.59312\n",
      "2017-05-30 09:21:38.795680: step 8780, loss = 0.26 (602.2 examples/sec; 0.425 sec/batch)\n",
      "2017-05-30 09:21:42.150030: step 8790, loss = 0.33 (763.2 examples/sec; 0.335 sec/batch)\n",
      "2017-05-30 09:21:45.178811: step 8800, loss = 0.22 (845.2 examples/sec; 0.303 sec/batch)\n",
      "2017-05-30 09:21:48.088277: step 8810, loss = 0.29 (879.9 examples/sec; 0.291 sec/batch)\n",
      "2017-05-30 09:21:51.010947: step 8820, loss = 0.28 (875.9 examples/sec; 0.292 sec/batch)\n",
      "2017-05-30 09:21:53.514490: step 8830, loss = 0.26 (1022.6 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:21:56.051508: step 8840, loss = 0.36 (1009.1 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:21:58.693430: step 8850, loss = 0.29 (969.0 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:22:01.196383: step 8860, loss = 0.33 (1022.8 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:22:03.744722: step 8870, loss = 0.27 (1004.6 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:22:07.934925: step 8880, loss = 0.31 (610.9 examples/sec; 0.419 sec/batch)\n",
      "2017-05-30 09:22:10.443356: step 8890, loss = 0.29 (1020.6 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:22:13.087825: step 8900, loss = 0.30 (968.1 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:22:15.697652: step 8910, loss = 0.25 (980.9 examples/sec; 0.261 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 09:22:18.335112: step 8920, loss = 0.36 (970.6 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:22:21.117815: step 8930, loss = 0.26 (920.0 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 09:22:24.107515: step 8940, loss = 0.29 (856.3 examples/sec; 0.299 sec/batch)\n",
      "2017-05-30 09:22:27.359162: step 8950, loss = 0.35 (787.3 examples/sec; 0.325 sec/batch)\n",
      "2017-05-30 09:22:30.298446: step 8960, loss = 0.35 (871.0 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 09:22:33.055963: step 8970, loss = 0.28 (928.4 examples/sec; 0.276 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.42467\n",
      "2017-05-30 09:22:39.635907: step 8990, loss = 0.26 (1020.2 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:22:42.352380: step 9000, loss = 0.25 (942.4 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 09:22:44.868711: step 9010, loss = 0.30 (1017.4 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:22:47.356607: step 9020, loss = 0.31 (1029.0 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:22:50.220246: step 9030, loss = 0.33 (894.0 examples/sec; 0.286 sec/batch)\n",
      "2017-05-30 09:22:53.637311: step 9040, loss = 0.29 (749.2 examples/sec; 0.342 sec/batch)\n",
      "2017-05-30 09:22:56.774749: step 9050, loss = 0.34 (816.0 examples/sec; 0.314 sec/batch)\n",
      "2017-05-30 09:22:59.619953: step 9060, loss = 0.23 (899.8 examples/sec; 0.285 sec/batch)\n",
      "2017-05-30 09:23:02.271895: step 9070, loss = 0.29 (965.3 examples/sec; 0.265 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.4463\n",
      "2017-05-30 09:23:06.177679: step 9080, loss = 0.28 (655.4 examples/sec; 0.391 sec/batch)\n",
      "2017-05-30 09:23:11.352604: step 9100, loss = 0.26 (983.3 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:23:13.835507: step 9110, loss = 0.28 (1031.1 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:23:16.444135: step 9120, loss = 0.33 (981.4 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:23:19.039575: step 9130, loss = 0.24 (986.3 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:23:21.824231: step 9140, loss = 0.35 (919.3 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 09:23:24.398476: step 9150, loss = 0.30 (994.5 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:23:27.042065: step 9160, loss = 0.23 (968.4 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:23:29.506643: step 9170, loss = 0.22 (1038.7 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:23:33.461454: step 9180, loss = 0.26 (647.3 examples/sec; 0.395 sec/batch)\n",
      "2017-05-30 09:23:36.074364: step 9190, loss = 0.23 (979.8 examples/sec; 0.261 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4853  Precision @ 1 train: 0.9479\n",
      "2017-05-30 09:23:38.389653: step 9200, loss = 0.29 (1105.7 examples/sec; 0.232 sec/batch)\n",
      "2017-05-30 09:23:43.837238: step 9220, loss = 0.28 (893.0 examples/sec; 0.287 sec/batch)\n",
      "2017-05-30 09:23:47.090316: step 9230, loss = 0.35 (786.9 examples/sec; 0.325 sec/batch)\n",
      "2017-05-30 09:23:50.322837: step 9240, loss = 0.38 (792.0 examples/sec; 0.323 sec/batch)\n",
      "2017-05-30 09:23:53.336657: step 9250, loss = 0.30 (849.4 examples/sec; 0.301 sec/batch)\n",
      "2017-05-30 09:23:55.970371: step 9260, loss = 0.28 (972.0 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:23:58.438341: step 9270, loss = 0.26 (1037.3 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:24:01.102454: step 9280, loss = 0.35 (960.9 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:24:03.727947: step 9290, loss = 0.28 (975.1 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:24:06.227378: step 9300, loss = 0.32 (1024.2 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:24:08.813123: step 9310, loss = 0.25 (990.0 examples/sec; 0.259 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.32221\n",
      "2017-05-30 09:24:16.668907: step 9330, loss = 0.25 (828.7 examples/sec; 0.309 sec/batch)\n",
      "2017-05-30 09:24:19.536802: step 9340, loss = 0.31 (892.6 examples/sec; 0.287 sec/batch)\n",
      "2017-05-30 09:24:22.456918: step 9350, loss = 0.24 (876.7 examples/sec; 0.292 sec/batch)\n",
      "2017-05-30 09:24:25.089724: step 9360, loss = 0.29 (972.3 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:24:27.651988: step 9370, loss = 0.28 (999.1 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:24:30.246399: step 9380, loss = 0.30 (986.7 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:24:32.777123: step 9390, loss = 0.24 (1011.6 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:24:35.324330: step 9400, loss = 0.31 (1005.0 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:24:37.966295: step 9410, loss = 0.27 (969.0 examples/sec; 0.264 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.49686\n",
      "2017-05-30 09:24:41.868976: step 9420, loss = 0.31 (656.0 examples/sec; 0.390 sec/batch)\n",
      "2017-05-30 09:24:47.134484: step 9440, loss = 0.22 (988.4 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:24:49.623507: step 9450, loss = 0.22 (1028.5 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:24:52.468484: step 9460, loss = 0.31 (899.8 examples/sec; 0.284 sec/batch)\n",
      "2017-05-30 09:24:55.327760: step 9470, loss = 0.32 (895.3 examples/sec; 0.286 sec/batch)\n",
      "2017-05-30 09:24:58.638550: step 9480, loss = 0.24 (773.2 examples/sec; 0.331 sec/batch)\n",
      "2017-05-30 09:25:01.637577: step 9490, loss = 0.28 (853.6 examples/sec; 0.300 sec/batch)\n",
      "2017-05-30 09:25:04.410388: step 9500, loss = 0.27 (923.3 examples/sec; 0.277 sec/batch)\n",
      "2017-05-30 09:25:07.033121: step 9510, loss = 0.32 (976.1 examples/sec; 0.262 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.42749\n",
      "2017-05-30 09:25:11.044777: step 9520, loss = 0.28 (638.1 examples/sec; 0.401 sec/batch)\n",
      "2017-05-30 09:25:13.657429: step 9530, loss = 0.22 (979.8 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:25:16.233808: step 9540, loss = 0.28 (993.6 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:25:18.754304: step 9550, loss = 0.32 (1015.7 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:25:21.421530: step 9560, loss = 0.26 (959.8 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 09:25:24.798252: step 9570, loss = 0.21 (758.1 examples/sec; 0.338 sec/batch)\n",
      "2017-05-30 09:25:28.100917: step 9580, loss = 0.33 (775.1 examples/sec; 0.330 sec/batch)\n",
      "2017-05-30 09:25:31.055568: step 9590, loss = 0.27 (866.4 examples/sec; 0.295 sec/batch)\n",
      "2017-05-30 09:25:33.718886: step 9600, loss = 0.32 (961.2 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:25:36.281780: step 9610, loss = 0.21 (998.9 examples/sec; 0.256 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.43228\n",
      "2017-05-30 09:25:40.245567: step 9620, loss = 0.31 (645.8 examples/sec; 0.396 sec/batch)\n",
      "2017-05-30 09:25:42.916863: step 9630, loss = 0.22 (958.3 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 09:25:45.449537: step 9640, loss = 0.23 (1010.8 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:25:48.055419: step 9650, loss = 0.32 (982.4 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:25:50.672862: step 9660, loss = 0.34 (978.1 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:25:53.399274: step 9670, loss = 0.24 (939.0 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 09:25:56.151830: step 9680, loss = 0.32 (930.0 examples/sec; 0.275 sec/batch)\n",
      "2017-05-30 09:25:58.759365: step 9690, loss = 0.29 (981.8 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:26:01.226073: step 9700, loss = 0.30 (1037.8 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:26:03.807446: step 9710, loss = 0.27 (991.7 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:26:08.198520: step 9720, loss = 0.27 (583.0 examples/sec; 0.439 sec/batch)\n",
      "2017-05-30 09:26:11.952987: step 9730, loss = 0.28 (681.9 examples/sec; 0.375 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4874  Precision @ 1 train: 0.9520\n",
      "2017-05-30 09:26:14.998616: step 9740, loss = 0.17 (840.5 examples/sec; 0.305 sec/batch)\n",
      "2017-05-30 09:26:17.607396: step 9750, loss = 0.21 (981.3 examples/sec; 0.261 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4374  Precision @ 1 eval: 0.8543\n",
      "INFO:tensorflow:global_step/sec: 2.49223\n",
      "2017-05-30 09:26:20.060831: step 9760, loss = 0.26 (1043.4 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 09:26:22.529402: step 9770, loss = 0.27 (1037.0 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:26:25.279872: step 9780, loss = 0.28 (930.8 examples/sec; 0.275 sec/batch)\n",
      "2017-05-30 09:26:28.039298: step 9790, loss = 0.34 (927.7 examples/sec; 0.276 sec/batch)\n",
      "2017-05-30 09:26:30.508577: step 9800, loss = 0.29 (1036.7 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:26:33.270759: step 9810, loss = 0.33 (926.8 examples/sec; 0.276 sec/batch)\n",
      "2017-05-30 09:26:35.829101: step 9820, loss = 0.38 (1000.6 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:26:38.323535: step 9830, loss = 0.29 (1026.3 examples/sec; 0.249 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 09:26:40.909519: step 9840, loss = 0.30 (990.0 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:26:43.547144: step 9850, loss = 0.28 (970.6 examples/sec; 0.264 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.62872\n",
      "2017-05-30 09:26:47.442128: step 9860, loss = 0.25 (657.3 examples/sec; 0.389 sec/batch)\n",
      "2017-05-30 09:26:50.060739: step 9870, loss = 0.30 (977.6 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:26:56.707911: step 9890, loss = 0.31 (722.8 examples/sec; 0.354 sec/batch)\n",
      "2017-05-30 09:26:59.730084: step 9900, loss = 0.22 (847.1 examples/sec; 0.302 sec/batch)\n",
      "2017-05-30 09:27:02.388456: step 9910, loss = 0.26 (963.0 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:27:04.875535: step 9920, loss = 0.29 (1029.3 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:27:07.364588: step 9930, loss = 0.28 (1028.5 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:27:09.980478: step 9940, loss = 0.25 (978.6 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:27:12.554732: step 9950, loss = 0.24 (994.5 examples/sec; 0.257 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.44412\n",
      "2017-05-30 09:27:16.430672: step 9960, loss = 0.23 (660.5 examples/sec; 0.388 sec/batch)\n",
      "2017-05-30 09:27:19.053285: step 9970, loss = 0.24 (976.1 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:27:21.509514: step 9980, loss = 0.21 (1042.2 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:27:24.088487: step 9990, loss = 0.20 (992.6 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:27:26.975129: step 10000, loss = 0.32 (886.8 examples/sec; 0.289 sec/batch)\n",
      "2017-05-30 09:27:30.462603: step 10010, loss = 0.36 (734.1 examples/sec; 0.349 sec/batch)\n",
      "2017-05-30 09:27:33.485497: step 10020, loss = 0.31 (846.9 examples/sec; 0.302 sec/batch)\n",
      "2017-05-30 09:27:36.266080: step 10030, loss = 0.28 (920.7 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 09:27:38.887905: step 10040, loss = 0.24 (976.4 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:27:41.379671: step 10050, loss = 0.18 (1027.4 examples/sec; 0.249 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.43356\n",
      "2017-05-30 09:27:45.549299: step 10060, loss = 0.20 (614.0 examples/sec; 0.417 sec/batch)\n",
      "2017-05-30 09:27:48.134124: step 10070, loss = 0.24 (990.4 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:27:50.626939: step 10080, loss = 0.33 (1027.0 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:27:53.240631: step 10090, loss = 0.21 (979.5 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:27:55.931111: step 10100, loss = 0.29 (951.5 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 09:27:58.701752: step 10110, loss = 0.29 (924.0 examples/sec; 0.277 sec/batch)\n",
      "2017-05-30 09:28:01.303026: step 10120, loss = 0.33 (984.1 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:28:03.913732: step 10130, loss = 0.33 (980.6 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:28:06.402138: step 10140, loss = 0.33 (1028.8 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:28:08.997591: step 10150, loss = 0.31 (986.3 examples/sec; 0.260 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.53574\n",
      "2017-05-30 09:28:13.968506: step 10160, loss = 0.29 (515.0 examples/sec; 0.497 sec/batch)\n",
      "2017-05-30 09:28:17.030588: step 10170, loss = 0.33 (836.0 examples/sec; 0.306 sec/batch)\n",
      "2017-05-30 09:28:19.882379: step 10180, loss = 0.25 (897.7 examples/sec; 0.285 sec/batch)\n",
      "2017-05-30 09:28:22.523005: step 10190, loss = 0.32 (969.5 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:28:25.051150: step 10200, loss = 0.21 (1012.6 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:28:27.693556: step 10210, loss = 0.23 (968.8 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:28:30.498882: step 10220, loss = 0.29 (912.5 examples/sec; 0.281 sec/batch)\n",
      "2017-05-30 09:28:33.093099: step 10230, loss = 0.33 (986.8 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:28:35.606651: step 10240, loss = 0.29 (1018.5 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:28:38.240356: step 10250, loss = 0.26 (972.0 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:28:41.944842: step 10260, loss = 0.26 (691.1 examples/sec; 0.370 sec/batch)\n",
      "2017-05-30 09:28:44.676890: step 10270, loss = 0.24 (937.0 examples/sec; 0.273 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4890  Precision @ 1 train: 0.9551\n",
      "2017-05-30 09:28:47.268680: step 10280, loss = 0.31 (987.7 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:28:51.049620: step 10290, loss = 0.28 (677.1 examples/sec; 0.378 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4414  Precision @ 1 eval: 0.8621\n",
      "INFO:tensorflow:global_step/sec: 2.47394\n",
      "2017-05-30 09:28:54.089048: step 10300, loss = 0.30 (842.3 examples/sec; 0.304 sec/batch)\n",
      "2017-05-30 09:28:56.856498: step 10310, loss = 0.14 (925.0 examples/sec; 0.277 sec/batch)\n",
      "2017-05-30 09:28:59.743014: step 10320, loss = 0.29 (886.9 examples/sec; 0.289 sec/batch)\n",
      "2017-05-30 09:29:04.901901: step 10340, loss = 0.25 (1003.8 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:29:07.530528: step 10350, loss = 0.33 (973.9 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:29:10.043352: step 10360, loss = 0.29 (1018.8 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:29:12.614353: step 10370, loss = 0.24 (995.7 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:29:15.264588: step 10380, loss = 0.23 (966.0 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:29:17.731511: step 10390, loss = 0.26 (1037.7 examples/sec; 0.247 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.56792\n",
      "2017-05-30 09:29:21.843134: step 10400, loss = 0.24 (622.6 examples/sec; 0.411 sec/batch)\n",
      "2017-05-30 09:29:24.394241: step 10410, loss = 0.17 (1003.5 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:29:26.886192: step 10420, loss = 0.35 (1027.3 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:29:29.677822: step 10430, loss = 0.22 (917.0 examples/sec; 0.279 sec/batch)\n",
      "2017-05-30 09:29:36.148532: step 10450, loss = 0.20 (797.4 examples/sec; 0.321 sec/batch)\n",
      "2017-05-30 09:29:39.127788: step 10460, loss = 0.32 (859.3 examples/sec; 0.298 sec/batch)\n",
      "2017-05-30 09:29:41.787639: step 10470, loss = 0.29 (962.5 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:29:44.351172: step 10480, loss = 0.20 (998.6 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:29:46.816098: step 10490, loss = 0.22 (1038.6 examples/sec; 0.246 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.40074\n",
      "2017-05-30 09:29:51.214626: step 10500, loss = 0.23 (582.0 examples/sec; 0.440 sec/batch)\n",
      "2017-05-30 09:29:53.686092: step 10510, loss = 0.23 (1035.8 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:29:56.263835: step 10520, loss = 0.22 (993.1 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:29:58.930168: step 10530, loss = 0.23 (960.1 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 09:30:01.626616: step 10540, loss = 0.22 (949.4 examples/sec; 0.270 sec/batch)\n",
      "2017-05-30 09:30:04.280273: step 10550, loss = 0.30 (964.7 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:30:06.936926: step 10560, loss = 0.18 (963.6 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:30:09.421631: step 10570, loss = 0.29 (1030.3 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:30:11.957936: step 10580, loss = 0.24 (1009.3 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:30:14.573940: step 10590, loss = 0.24 (978.6 examples/sec; 0.262 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.46151\n",
      "2017-05-30 09:30:20.140091: step 10600, loss = 0.21 (459.9 examples/sec; 0.557 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 9807 into /home/ipython/cnn-cifar10/tb_log/vggA/train/model.ckpt.\n",
      "2017-05-30 09:30:23.410133: step 10610, loss = 0.30 (782.9 examples/sec; 0.327 sec/batch)\n",
      "2017-05-30 09:30:26.065170: step 10620, loss = 0.26 (964.2 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:30:28.613335: step 10630, loss = 0.22 (1004.6 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:30:31.183385: step 10640, loss = 0.22 (996.1 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:30:34.195016: step 10650, loss = 0.25 (850.0 examples/sec; 0.301 sec/batch)\n",
      "2017-05-30 09:30:39.252927: step 10670, loss = 0.30 (1023.7 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:30:41.905356: step 10680, loss = 0.29 (965.2 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:30:44.534319: step 10690, loss = 0.30 (973.8 examples/sec; 0.263 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.52683\n",
      "2017-05-30 09:30:48.472707: step 10700, loss = 0.28 (650.0 examples/sec; 0.394 sec/batch)\n",
      "2017-05-30 09:30:51.094986: step 10710, loss = 0.20 (976.3 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:30:54.430436: step 10720, loss = 0.23 (767.5 examples/sec; 0.334 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 09:30:57.475389: step 10730, loss = 0.25 (840.7 examples/sec; 0.304 sec/batch)\n",
      "2017-05-30 09:31:00.310692: step 10740, loss = 0.33 (902.9 examples/sec; 0.284 sec/batch)\n",
      "2017-05-30 09:31:03.327650: step 10750, loss = 0.28 (848.5 examples/sec; 0.302 sec/batch)\n",
      "2017-05-30 09:31:05.821078: step 10760, loss = 0.24 (1026.7 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:31:08.413478: step 10770, loss = 0.21 (987.5 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:31:11.033287: step 10780, loss = 0.18 (977.2 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:31:13.519648: step 10790, loss = 0.36 (1029.6 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:31:17.441806: step 10800, loss = 0.31 (652.7 examples/sec; 0.392 sec/batch)\n",
      "2017-05-30 09:31:20.193045: step 10810, loss = 0.31 (930.5 examples/sec; 0.275 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4860  Precision @ 1 train: 0.9492\n",
      "2017-05-30 09:31:22.553165: step 10820, loss = 0.35 (1084.7 examples/sec; 0.236 sec/batch)\n",
      "2017-05-30 09:31:25.127010: step 10830, loss = 0.40 (994.6 examples/sec; 0.257 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4391  Precision @ 1 eval: 0.8576\n",
      "INFO:tensorflow:global_step/sec: 2.53239\n",
      "2017-05-30 09:31:27.668146: step 10840, loss = 0.30 (1007.4 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:31:30.153039: step 10850, loss = 0.27 (1030.2 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:31:32.940244: step 10860, loss = 0.23 (918.5 examples/sec; 0.279 sec/batch)\n",
      "2017-05-30 09:31:35.771660: step 10870, loss = 0.21 (904.1 examples/sec; 0.283 sec/batch)\n",
      "2017-05-30 09:31:38.241148: step 10880, loss = 0.26 (1036.7 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:31:43.439977: step 10900, loss = 0.36 (966.8 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:31:45.910329: step 10910, loss = 0.30 (1036.3 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:31:48.460381: step 10920, loss = 0.33 (1003.9 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:31:51.084995: step 10930, loss = 0.32 (975.4 examples/sec; 0.262 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.64226\n",
      "2017-05-30 09:31:55.123438: step 10940, loss = 0.28 (633.9 examples/sec; 0.404 sec/batch)\n",
      "2017-05-30 09:31:57.525822: step 10950, loss = 0.22 (1065.6 examples/sec; 0.240 sec/batch)\n",
      "2017-05-30 09:32:00.457800: step 10960, loss = 0.33 (873.1 examples/sec; 0.293 sec/batch)\n",
      "2017-05-30 09:32:03.883891: step 10970, loss = 0.24 (747.2 examples/sec; 0.343 sec/batch)\n",
      "2017-05-30 09:32:07.188870: step 10980, loss = 0.24 (774.6 examples/sec; 0.330 sec/batch)\n",
      "2017-05-30 09:32:09.826254: step 10990, loss = 0.23 (970.7 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:32:12.419678: step 11000, loss = 0.26 (987.1 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:32:14.894457: step 11010, loss = 0.24 (1034.4 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:32:17.522722: step 11020, loss = 0.28 (974.0 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:32:20.106086: step 11030, loss = 0.28 (991.0 examples/sec; 0.258 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.41299\n",
      "2017-05-30 09:32:24.426266: step 11040, loss = 0.28 (592.6 examples/sec; 0.432 sec/batch)\n",
      "2017-05-30 09:32:26.815400: step 11050, loss = 0.24 (1071.5 examples/sec; 0.239 sec/batch)\n",
      "2017-05-30 09:32:30.043414: step 11060, loss = 0.23 (793.1 examples/sec; 0.323 sec/batch)\n",
      "2017-05-30 09:32:33.192731: step 11070, loss = 0.18 (812.9 examples/sec; 0.315 sec/batch)\n",
      "2017-05-30 09:32:36.358453: step 11080, loss = 0.24 (808.7 examples/sec; 0.317 sec/batch)\n",
      "2017-05-30 09:32:39.094678: step 11090, loss = 0.22 (935.6 examples/sec; 0.274 sec/batch)\n",
      "2017-05-30 09:32:41.656900: step 11100, loss = 0.27 (999.1 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:32:44.205242: step 11110, loss = 0.24 (1004.6 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:32:46.840926: step 11120, loss = 0.24 (971.3 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:32:49.323895: step 11130, loss = 0.21 (1031.0 examples/sec; 0.248 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.41658\n",
      "2017-05-30 09:32:53.692541: step 11140, loss = 0.20 (586.0 examples/sec; 0.437 sec/batch)\n",
      "2017-05-30 09:32:56.006548: step 11150, loss = 0.26 (1106.3 examples/sec; 0.231 sec/batch)\n",
      "2017-05-30 09:32:58.523273: step 11160, loss = 0.25 (1017.2 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:33:01.153069: step 11170, loss = 0.28 (973.5 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:33:03.992922: step 11180, loss = 0.26 (901.5 examples/sec; 0.284 sec/batch)\n",
      "2017-05-30 09:33:07.637778: step 11190, loss = 0.25 (702.4 examples/sec; 0.364 sec/batch)\n",
      "2017-05-30 09:33:10.817799: step 11200, loss = 0.23 (805.0 examples/sec; 0.318 sec/batch)\n",
      "2017-05-30 09:33:13.546245: step 11210, loss = 0.23 (938.3 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 09:33:16.133819: step 11220, loss = 0.23 (989.3 examples/sec; 0.259 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.41685\n",
      "2017-05-30 09:33:22.961148: step 11240, loss = 0.19 (587.0 examples/sec; 0.436 sec/batch)\n",
      "2017-05-30 09:33:25.231248: step 11250, loss = 0.21 (1127.7 examples/sec; 0.227 sec/batch)\n",
      "2017-05-30 09:33:27.758533: step 11260, loss = 0.25 (1012.9 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:33:30.412674: step 11270, loss = 0.25 (964.5 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:33:32.962027: step 11280, loss = 0.28 (1004.2 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:33:35.525477: step 11290, loss = 0.24 (998.7 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:33:38.465966: step 11300, loss = 0.26 (870.6 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 09:33:41.065287: step 11310, loss = 0.28 (984.9 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:33:43.555280: step 11320, loss = 0.21 (1028.1 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:33:46.165159: step 11330, loss = 0.22 (980.9 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:33:50.218628: step 11340, loss = 0.24 (631.6 examples/sec; 0.405 sec/batch)\n",
      "2017-05-30 09:33:52.513920: step 11350, loss = 0.33 (1115.3 examples/sec; 0.230 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4902  Precision @ 1 train: 0.9574\n",
      "2017-05-30 09:33:55.198020: step 11360, loss = 0.26 (953.8 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 09:33:58.812972: step 11370, loss = 0.31 (708.2 examples/sec; 0.361 sec/batch)\n",
      "2017-05-30 09:34:02.060307: step 11380, loss = 0.20 (788.3 examples/sec; 0.325 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4427  Precision @ 1 eval: 0.8646\n",
      "INFO:tensorflow:global_step/sec: 2.51893\n",
      "2017-05-30 09:34:04.831382: step 11390, loss = 0.21 (923.8 examples/sec; 0.277 sec/batch)\n",
      "2017-05-30 09:34:07.616208: step 11400, loss = 0.27 (919.3 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 09:34:10.368694: step 11410, loss = 0.19 (930.1 examples/sec; 0.275 sec/batch)\n",
      "2017-05-30 09:34:12.947239: step 11420, loss = 0.28 (992.8 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:34:15.560678: step 11430, loss = 0.22 (979.6 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:34:18.037191: step 11440, loss = 0.17 (1033.7 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:34:20.598850: step 11450, loss = 0.28 (999.4 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:34:25.753123: step 11470, loss = 0.23 (1023.5 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:34:28.314583: step 11480, loss = 0.25 (999.4 examples/sec; 0.256 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.58917\n",
      "2017-05-30 09:34:32.385311: step 11490, loss = 0.19 (628.9 examples/sec; 0.407 sec/batch)\n",
      "2017-05-30 09:34:34.883683: step 11500, loss = 0.21 (1024.7 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:34:37.700430: step 11510, loss = 0.29 (908.8 examples/sec; 0.282 sec/batch)\n",
      "2017-05-30 09:34:40.942915: step 11520, loss = 0.27 (789.5 examples/sec; 0.324 sec/batch)\n",
      "2017-05-30 09:34:44.185443: step 11530, loss = 0.23 (789.5 examples/sec; 0.324 sec/batch)\n",
      "2017-05-30 09:34:47.122131: step 11540, loss = 0.23 (871.7 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 09:34:49.785492: step 11550, loss = 0.24 (961.2 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:34:52.364216: step 11560, loss = 0.24 (992.7 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:34:57.556264: step 11580, loss = 0.21 (991.7 examples/sec; 0.258 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.37246\n",
      "2017-05-30 09:35:02.418682: step 11590, loss = 0.23 (526.5 examples/sec; 0.486 sec/batch)\n",
      "2017-05-30 09:35:05.474152: step 11600, loss = 0.23 (837.8 examples/sec; 0.306 sec/batch)\n",
      "2017-05-30 09:35:08.439395: step 11610, loss = 0.25 (863.3 examples/sec; 0.297 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 09:35:11.354199: step 11620, loss = 0.20 (878.3 examples/sec; 0.291 sec/batch)\n",
      "2017-05-30 09:35:13.835594: step 11630, loss = 0.26 (1031.7 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:35:16.374020: step 11640, loss = 0.19 (1008.5 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:35:19.009051: step 11650, loss = 0.30 (971.5 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:35:21.553537: step 11660, loss = 0.24 (1006.1 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:35:24.043144: step 11670, loss = 0.21 (1028.3 examples/sec; 0.249 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.47884\n",
      "2017-05-30 09:35:30.639321: step 11690, loss = 0.31 (643.7 examples/sec; 0.398 sec/batch)\n",
      "2017-05-30 09:35:33.261339: step 11700, loss = 0.19 (976.3 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:35:35.849851: step 11710, loss = 0.23 (989.0 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:35:38.332414: step 11720, loss = 0.24 (1031.2 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:35:41.203730: step 11730, loss = 0.26 (891.6 examples/sec; 0.287 sec/batch)\n",
      "2017-05-30 09:35:43.953253: step 11740, loss = 0.18 (931.1 examples/sec; 0.275 sec/batch)\n",
      "2017-05-30 09:35:46.408736: step 11750, loss = 0.17 (1042.6 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:35:48.963092: step 11760, loss = 0.17 (1002.2 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:35:51.604608: step 11770, loss = 0.30 (969.1 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:35:54.933613: step 11780, loss = 0.22 (769.0 examples/sec; 0.333 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.42946\n",
      "2017-05-30 09:36:02.607155: step 11800, loss = 0.23 (972.9 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:36:05.115475: step 11810, loss = 0.20 (1020.6 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:36:07.639426: step 11820, loss = 0.24 (1014.3 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:36:10.449951: step 11830, loss = 0.22 (910.9 examples/sec; 0.281 sec/batch)\n",
      "2017-05-30 09:36:13.274774: step 11840, loss = 0.27 (906.3 examples/sec; 0.282 sec/batch)\n",
      "2017-05-30 09:36:15.769450: step 11850, loss = 0.21 (1026.2 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:36:18.444508: step 11860, loss = 0.32 (957.0 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 09:36:20.970157: step 11870, loss = 0.20 (1013.6 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:36:23.472883: step 11880, loss = 0.29 (1022.9 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:36:27.591140: step 11890, loss = 0.27 (621.6 examples/sec; 0.412 sec/batch)\n",
      "2017-05-30 09:36:30.093651: step 11900, loss = 0.21 (1023.0 examples/sec; 0.250 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4964  Precision @ 1 train: 0.9695\n",
      "2017-05-30 09:36:32.512546: step 11910, loss = 0.23 (1058.3 examples/sec; 0.242 sec/batch)\n",
      "2017-05-30 09:36:35.172602: step 11920, loss = 0.23 (962.4 examples/sec; 0.266 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4439  Precision @ 1 eval: 0.8670\n",
      "INFO:tensorflow:global_step/sec: 2.61046\n",
      "2017-05-30 09:36:38.355200: step 11930, loss = 0.22 (804.4 examples/sec; 0.318 sec/batch)\n",
      "2017-05-30 09:36:41.622599: step 11940, loss = 0.25 (783.5 examples/sec; 0.327 sec/batch)\n",
      "2017-05-30 09:36:44.811745: step 11950, loss = 0.22 (802.7 examples/sec; 0.319 sec/batch)\n",
      "2017-05-30 09:36:47.432022: step 11960, loss = 0.26 (977.0 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:36:49.887272: step 11970, loss = 0.21 (1042.7 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:36:52.428913: step 11980, loss = 0.24 (1007.2 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:36:55.024069: step 11990, loss = 0.21 (986.5 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:36:57.540273: step 12000, loss = 0.24 (1017.4 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:37:00.017214: step 12010, loss = 0.24 (1033.5 examples/sec; 0.248 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.3088\n",
      "2017-05-30 09:37:08.089154: step 12030, loss = 0.26 (475.2 examples/sec; 0.539 sec/batch)\n",
      "2017-05-30 09:37:11.068299: step 12040, loss = 0.26 (859.3 examples/sec; 0.298 sec/batch)\n",
      "2017-05-30 09:37:14.129422: step 12050, loss = 0.22 (836.3 examples/sec; 0.306 sec/batch)\n",
      "2017-05-30 09:37:16.868283: step 12060, loss = 0.22 (934.7 examples/sec; 0.274 sec/batch)\n",
      "2017-05-30 09:37:19.368343: step 12070, loss = 0.28 (1024.0 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:37:22.026896: step 12080, loss = 0.19 (962.9 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:37:24.585992: step 12090, loss = 0.19 (1000.4 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:37:27.074565: step 12100, loss = 0.20 (1028.7 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:37:29.639884: step 12110, loss = 0.19 (997.9 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:37:32.256688: step 12120, loss = 0.20 (978.3 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:37:38.695218: step 12140, loss = 0.25 (976.1 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:37:41.250531: step 12150, loss = 0.19 (1001.8 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:37:43.933521: step 12160, loss = 0.26 (954.2 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 09:37:46.805668: step 12170, loss = 0.17 (891.3 examples/sec; 0.287 sec/batch)\n",
      "2017-05-30 09:37:49.908824: step 12180, loss = 0.19 (825.0 examples/sec; 0.310 sec/batch)\n",
      "2017-05-30 09:37:53.076827: step 12190, loss = 0.29 (808.1 examples/sec; 0.317 sec/batch)\n",
      "2017-05-30 09:37:55.991641: step 12200, loss = 0.28 (878.3 examples/sec; 0.291 sec/batch)\n",
      "2017-05-30 09:37:58.625115: step 12210, loss = 0.23 (972.1 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:38:01.151400: step 12220, loss = 0.25 (1013.3 examples/sec; 0.253 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.44953\n",
      "2017-05-30 09:38:05.093293: step 12230, loss = 0.23 (649.4 examples/sec; 0.394 sec/batch)\n",
      "2017-05-30 09:38:10.282430: step 12250, loss = 0.20 (1003.1 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:38:12.843948: step 12260, loss = 0.29 (999.4 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:38:15.723783: step 12270, loss = 0.28 (888.9 examples/sec; 0.288 sec/batch)\n",
      "2017-05-30 09:38:18.314184: step 12280, loss = 0.22 (988.3 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:38:20.865303: step 12290, loss = 0.22 (1003.5 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:38:23.507678: step 12300, loss = 0.27 (968.8 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:38:25.968403: step 12310, loss = 0.23 (1040.3 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:38:28.516082: step 12320, loss = 0.24 (1004.8 examples/sec; 0.255 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.63634\n",
      "2017-05-30 09:38:32.564308: step 12330, loss = 0.26 (632.4 examples/sec; 0.405 sec/batch)\n",
      "2017-05-30 09:38:35.062149: step 12340, loss = 0.22 (1024.9 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:38:37.654842: step 12350, loss = 0.29 (987.4 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:38:40.438674: step 12360, loss = 0.21 (919.6 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 09:38:43.735684: step 12370, loss = 0.30 (776.5 examples/sec; 0.330 sec/batch)\n",
      "2017-05-30 09:38:47.012871: step 12380, loss = 0.20 (781.2 examples/sec; 0.328 sec/batch)\n",
      "2017-05-30 09:38:49.948308: step 12390, loss = 0.20 (872.1 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 09:38:52.563108: step 12400, loss = 0.28 (979.0 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:38:55.033080: step 12410, loss = 0.27 (1036.4 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:38:57.603770: step 12420, loss = 0.27 (995.8 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:39:02.796463: step 12430, loss = 0.23 (493.0 examples/sec; 0.519 sec/batch)\n",
      "2017-05-30 09:39:06.291756: step 12440, loss = 0.16 (732.4 examples/sec; 0.350 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4935  Precision @ 1 train: 0.9639\n",
      "2017-05-30 09:39:09.092959: step 12450, loss = 0.25 (913.9 examples/sec; 0.280 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4381  Precision @ 1 eval: 0.8557\n",
      "INFO:tensorflow:global_step/sec: 2.39258\n",
      "2017-05-30 09:39:14.113374: step 12470, loss = 0.18 (1071.2 examples/sec; 0.239 sec/batch)\n",
      "2017-05-30 09:39:16.798057: step 12480, loss = 0.23 (953.6 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 09:39:19.694999: step 12490, loss = 0.16 (883.7 examples/sec; 0.290 sec/batch)\n",
      "2017-05-30 09:39:22.209453: step 12500, loss = 0.19 (1018.1 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:39:24.720143: step 12510, loss = 0.16 (1019.6 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:39:27.331461: step 12520, loss = 0.21 (980.3 examples/sec; 0.261 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 09:39:29.817242: step 12530, loss = 0.21 (1029.9 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:39:32.368359: step 12540, loss = 0.23 (1003.5 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:39:34.999130: step 12550, loss = 0.15 (973.1 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:39:37.521151: step 12560, loss = 0.22 (1015.1 examples/sec; 0.252 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.61691\n",
      "2017-05-30 09:39:41.569294: step 12570, loss = 0.17 (632.4 examples/sec; 0.405 sec/batch)\n",
      "2017-05-30 09:39:44.421921: step 12580, loss = 0.23 (897.4 examples/sec; 0.285 sec/batch)\n",
      "2017-05-30 09:39:47.877007: step 12590, loss = 0.23 (740.9 examples/sec; 0.346 sec/batch)\n",
      "2017-05-30 09:39:51.354045: step 12600, loss = 0.16 (736.3 examples/sec; 0.348 sec/batch)\n",
      "2017-05-30 09:39:54.095624: step 12610, loss = 0.23 (933.8 examples/sec; 0.274 sec/batch)\n",
      "2017-05-30 09:39:56.694911: step 12620, loss = 0.17 (984.9 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:39:59.157802: step 12630, loss = 0.20 (1039.4 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:40:01.941362: step 12640, loss = 0.23 (919.7 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 09:40:04.522436: step 12650, loss = 0.22 (991.8 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:40:07.009794: step 12660, loss = 0.24 (1029.2 examples/sec; 0.249 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.37731\n",
      "2017-05-30 09:40:11.112257: step 12670, loss = 0.12 (624.0 examples/sec; 0.410 sec/batch)\n",
      "2017-05-30 09:40:13.698459: step 12680, loss = 0.24 (989.9 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:40:19.044628: step 12700, loss = 0.19 (899.2 examples/sec; 0.285 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 11742 into /home/ipython/cnn-cifar10/tb_log/vggA/train/model.ckpt.\n",
      "2017-05-30 09:40:23.105343: step 12710, loss = 0.24 (630.4 examples/sec; 0.406 sec/batch)\n",
      "2017-05-30 09:40:26.115998: step 12720, loss = 0.19 (850.3 examples/sec; 0.301 sec/batch)\n",
      "2017-05-30 09:40:28.961901: step 12730, loss = 0.25 (899.5 examples/sec; 0.285 sec/batch)\n",
      "2017-05-30 09:40:31.560670: step 12740, loss = 0.22 (985.1 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:40:34.079434: step 12750, loss = 0.20 (1016.4 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:40:36.685885: step 12760, loss = 0.27 (982.2 examples/sec; 0.261 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.36947\n",
      "2017-05-30 09:40:40.994124: step 12770, loss = 0.22 (594.2 examples/sec; 0.431 sec/batch)\n",
      "2017-05-30 09:40:44.255780: step 12780, loss = 0.19 (784.9 examples/sec; 0.326 sec/batch)\n",
      "2017-05-30 09:40:50.105399: step 12800, loss = 0.27 (878.4 examples/sec; 0.291 sec/batch)\n",
      "2017-05-30 09:40:52.909066: step 12810, loss = 0.24 (913.1 examples/sec; 0.280 sec/batch)\n",
      "2017-05-30 09:40:55.399497: step 12820, loss = 0.22 (1027.9 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:40:58.018616: step 12830, loss = 0.17 (977.4 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:41:00.610461: step 12840, loss = 0.24 (987.7 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:41:03.149085: step 12850, loss = 0.23 (1008.4 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:41:05.738579: step 12860, loss = 0.22 (988.6 examples/sec; 0.259 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.3478\n",
      "2017-05-30 09:41:10.812581: step 12870, loss = 0.22 (504.5 examples/sec; 0.507 sec/batch)\n",
      "2017-05-30 09:41:13.930515: step 12880, loss = 0.28 (821.1 examples/sec; 0.312 sec/batch)\n",
      "2017-05-30 09:41:16.773126: step 12890, loss = 0.21 (900.6 examples/sec; 0.284 sec/batch)\n",
      "2017-05-30 09:41:22.229965: step 12910, loss = 0.17 (919.1 examples/sec; 0.279 sec/batch)\n",
      "2017-05-30 09:41:24.854160: step 12920, loss = 0.19 (975.5 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:41:27.472076: step 12930, loss = 0.21 (977.9 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:41:29.952286: step 12940, loss = 0.17 (1032.2 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:41:32.520295: step 12950, loss = 0.31 (996.9 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:41:35.120784: step 12960, loss = 0.27 (984.4 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:41:38.831985: step 12970, loss = 0.26 (689.8 examples/sec; 0.371 sec/batch)\n",
      "2017-05-30 09:41:41.566009: step 12980, loss = 0.11 (936.3 examples/sec; 0.273 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4957  Precision @ 1 train: 0.9682\n",
      "2017-05-30 09:41:44.113383: step 12990, loss = 0.22 (1005.0 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:41:46.527174: step 13000, loss = 0.18 (1060.6 examples/sec; 0.241 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4432  Precision @ 1 eval: 0.8656\n",
      "INFO:tensorflow:global_step/sec: 2.59827\n",
      "2017-05-30 09:41:48.957504: step 13010, loss = 0.22 (1053.4 examples/sec; 0.243 sec/batch)\n",
      "2017-05-30 09:41:55.480177: step 13030, loss = 0.18 (684.3 examples/sec; 0.374 sec/batch)\n",
      "2017-05-30 09:41:58.515521: step 13040, loss = 0.32 (843.4 examples/sec; 0.304 sec/batch)\n",
      "2017-05-30 09:42:01.309647: step 13050, loss = 0.27 (916.2 examples/sec; 0.279 sec/batch)\n",
      "2017-05-30 09:42:03.969609: step 13060, loss = 0.21 (962.4 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:42:06.431357: step 13070, loss = 0.23 (1039.9 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:42:09.013714: step 13080, loss = 0.29 (991.3 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:42:11.630902: step 13090, loss = 0.25 (978.1 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:42:14.111882: step 13100, loss = 0.24 (1031.8 examples/sec; 0.248 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.38204\n",
      "2017-05-30 09:42:18.285121: step 13110, loss = 0.23 (613.4 examples/sec; 0.417 sec/batch)\n",
      "2017-05-30 09:42:20.903945: step 13120, loss = 0.20 (977.5 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:42:26.653565: step 13140, loss = 0.25 (878.1 examples/sec; 0.292 sec/batch)\n",
      "2017-05-30 09:42:29.225134: step 13150, loss = 0.22 (995.5 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:42:31.707262: step 13160, loss = 0.29 (1031.4 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:42:34.379616: step 13170, loss = 0.21 (958.0 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 09:42:36.935605: step 13180, loss = 0.21 (1001.6 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:42:39.407226: step 13190, loss = 0.21 (1035.8 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:42:42.010879: step 13200, loss = 0.15 (983.2 examples/sec; 0.260 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.47737\n",
      "2017-05-30 09:42:47.075715: step 13210, loss = 0.24 (505.4 examples/sec; 0.506 sec/batch)\n",
      "2017-05-30 09:42:50.114217: step 13220, loss = 0.15 (842.5 examples/sec; 0.304 sec/batch)\n",
      "2017-05-30 09:42:53.197419: step 13230, loss = 0.20 (830.3 examples/sec; 0.308 sec/batch)\n",
      "2017-05-30 09:42:58.536654: step 13250, loss = 0.30 (1031.5 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:43:01.076062: step 13260, loss = 0.19 (1008.1 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:43:03.759067: step 13270, loss = 0.22 (954.2 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 09:43:06.225490: step 13280, loss = 0.25 (1037.9 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:43:08.799005: step 13290, loss = 0.20 (994.7 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:43:11.503952: step 13300, loss = 0.16 (946.4 examples/sec; 0.270 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.52929\n",
      "2017-05-30 09:43:15.359793: step 13310, loss = 0.23 (663.9 examples/sec; 0.386 sec/batch)\n",
      "2017-05-30 09:43:17.930058: step 13320, loss = 0.14 (996.0 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:43:20.540572: step 13330, loss = 0.24 (980.6 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:43:23.118894: step 13340, loss = 0.31 (992.9 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:43:26.001486: step 13350, loss = 0.23 (888.1 examples/sec; 0.288 sec/batch)\n",
      "2017-05-30 09:43:28.969816: step 13360, loss = 0.21 (862.4 examples/sec; 0.297 sec/batch)\n",
      "2017-05-30 09:43:32.255741: step 13370, loss = 0.22 (779.1 examples/sec; 0.329 sec/batch)\n",
      "2017-05-30 09:43:35.190804: step 13380, loss = 0.19 (872.2 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 09:43:37.902192: step 13390, loss = 0.21 (944.2 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 09:43:40.484615: step 13400, loss = 0.23 (991.3 examples/sec; 0.258 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.43987\n",
      "2017-05-30 09:43:44.416272: step 13410, loss = 0.25 (651.1 examples/sec; 0.393 sec/batch)\n",
      "2017-05-30 09:43:46.996132: step 13420, loss = 0.22 (992.3 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:43:49.530840: step 13430, loss = 0.19 (1010.0 examples/sec; 0.253 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 09:43:52.033965: step 13440, loss = 0.20 (1022.7 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:43:54.848807: step 13450, loss = 0.23 (909.5 examples/sec; 0.281 sec/batch)\n",
      "2017-05-30 09:43:58.249188: step 13460, loss = 0.25 (752.9 examples/sec; 0.340 sec/batch)\n",
      "2017-05-30 09:44:01.443635: step 13470, loss = 0.27 (801.4 examples/sec; 0.319 sec/batch)\n",
      "2017-05-30 09:44:04.403573: step 13480, loss = 0.25 (864.9 examples/sec; 0.296 sec/batch)\n",
      "2017-05-30 09:44:07.011870: step 13490, loss = 0.20 (981.5 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:44:09.577345: step 13500, loss = 0.24 (997.9 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:44:13.370296: step 13510, loss = 0.27 (674.9 examples/sec; 0.379 sec/batch)\n",
      "2017-05-30 09:44:16.178938: step 13520, loss = 0.19 (911.5 examples/sec; 0.281 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4953  Precision @ 1 train: 0.9674\n",
      "2017-05-30 09:44:18.511900: step 13530, loss = 0.30 (1097.3 examples/sec; 0.233 sec/batch)\n",
      "2017-05-30 09:44:21.040983: step 13540, loss = 0.17 (1012.2 examples/sec; 0.253 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4423  Precision @ 1 eval: 0.8639\n",
      "INFO:tensorflow:global_step/sec: 2.52916\n",
      "2017-05-30 09:44:23.688626: step 13550, loss = 0.26 (966.9 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:44:27.347202: step 13560, loss = 0.21 (699.7 examples/sec; 0.366 sec/batch)\n",
      "2017-05-30 09:44:36.007770: step 13590, loss = 0.16 (981.3 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:44:38.545781: step 13600, loss = 0.18 (1008.7 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:44:41.096564: step 13610, loss = 0.19 (1003.6 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:44:43.724253: step 13620, loss = 0.17 (974.2 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:44:46.220693: step 13630, loss = 0.17 (1025.5 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:44:48.747883: step 13640, loss = 0.24 (1013.0 examples/sec; 0.253 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.36633\n",
      "2017-05-30 09:44:53.394859: step 13650, loss = 0.20 (550.9 examples/sec; 0.465 sec/batch)\n",
      "2017-05-30 09:44:56.920521: step 13660, loss = 0.23 (726.1 examples/sec; 0.353 sec/batch)\n",
      "2017-05-30 09:45:00.179586: step 13670, loss = 0.23 (785.5 examples/sec; 0.326 sec/batch)\n",
      "2017-05-30 09:45:02.997003: step 13680, loss = 0.20 (908.6 examples/sec; 0.282 sec/batch)\n",
      "2017-05-30 09:45:08.042242: step 13700, loss = 0.18 (1031.1 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:45:10.632755: step 13710, loss = 0.15 (988.2 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:45:13.229284: step 13720, loss = 0.20 (985.9 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:45:15.747840: step 13730, loss = 0.18 (1016.5 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:45:18.371757: step 13740, loss = 0.17 (975.6 examples/sec; 0.262 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.41189\n",
      "2017-05-30 09:45:22.703435: step 13750, loss = 0.32 (591.0 examples/sec; 0.433 sec/batch)\n",
      "2017-05-30 09:45:25.000316: step 13760, loss = 0.15 (1114.6 examples/sec; 0.230 sec/batch)\n",
      "2017-05-30 09:45:28.015634: step 13770, loss = 0.23 (849.0 examples/sec; 0.302 sec/batch)\n",
      "2017-05-30 09:45:31.639589: step 13780, loss = 0.21 (706.4 examples/sec; 0.362 sec/batch)\n",
      "2017-05-30 09:45:34.645149: step 13790, loss = 0.18 (851.8 examples/sec; 0.301 sec/batch)\n",
      "2017-05-30 09:45:40.084451: step 13810, loss = 0.21 (969.0 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:45:42.579689: step 13820, loss = 0.20 (1026.0 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:45:45.117994: step 13830, loss = 0.18 (1008.5 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:45:47.775101: step 13840, loss = 0.24 (963.5 examples/sec; 0.266 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.42087\n",
      "2017-05-30 09:45:51.935771: step 13850, loss = 0.19 (615.3 examples/sec; 0.416 sec/batch)\n",
      "2017-05-30 09:45:54.280877: step 13860, loss = 0.26 (1091.6 examples/sec; 0.235 sec/batch)\n",
      "2017-05-30 09:45:57.052605: step 13870, loss = 0.21 (923.6 examples/sec; 0.277 sec/batch)\n",
      "2017-05-30 09:45:59.744096: step 13880, loss = 0.31 (951.1 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 09:46:02.404069: step 13890, loss = 0.26 (962.4 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:46:04.991756: step 13900, loss = 0.26 (989.3 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:46:07.569104: step 13910, loss = 0.19 (993.3 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:46:12.801699: step 13930, loss = 0.28 (980.2 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:46:15.257585: step 13940, loss = 0.21 (1042.4 examples/sec; 0.246 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.61192\n",
      "2017-05-30 09:46:19.622123: step 13950, loss = 0.18 (586.5 examples/sec; 0.436 sec/batch)\n",
      "2017-05-30 09:46:21.900694: step 13960, loss = 0.20 (1123.5 examples/sec; 0.228 sec/batch)\n",
      "2017-05-30 09:46:24.483400: step 13970, loss = 0.23 (991.2 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:46:27.263358: step 13980, loss = 0.16 (920.9 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 09:46:30.751047: step 13990, loss = 0.22 (734.0 examples/sec; 0.349 sec/batch)\n",
      "2017-05-30 09:46:34.027716: step 14000, loss = 0.25 (781.3 examples/sec; 0.328 sec/batch)\n",
      "2017-05-30 09:46:36.956750: step 14010, loss = 0.23 (874.0 examples/sec; 0.293 sec/batch)\n",
      "2017-05-30 09:46:39.584148: step 14020, loss = 0.20 (974.3 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:46:44.636796: step 14040, loss = 0.19 (1020.9 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:46:49.492410: step 14050, loss = 0.15 (527.2 examples/sec; 0.486 sec/batch)\n",
      "2017-05-30 09:46:52.747665: step 14060, loss = 0.27 (786.4 examples/sec; 0.326 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4937  Precision @ 1 train: 0.9643\n",
      "2017-05-30 09:46:55.856938: step 14070, loss = 0.19 (823.3 examples/sec; 0.311 sec/batch)\n",
      "2017-05-30 09:46:58.724887: step 14080, loss = 0.21 (892.6 examples/sec; 0.287 sec/batch)\n",
      "2017-05-30 09:47:01.638676: step 14090, loss = 0.16 (878.6 examples/sec; 0.291 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4383  Precision @ 1 eval: 0.8561\n",
      "INFO:tensorflow:global_step/sec: 2.35535\n",
      "2017-05-30 09:47:04.072062: step 14100, loss = 0.22 (1052.0 examples/sec; 0.243 sec/batch)\n",
      "2017-05-30 09:47:06.706985: step 14110, loss = 0.22 (971.6 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:47:09.255743: step 14120, loss = 0.26 (1004.4 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:47:11.757707: step 14130, loss = 0.21 (1023.2 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:47:17.021435: step 14150, loss = 0.22 (962.5 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:47:19.530810: step 14160, loss = 0.22 (1020.2 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:47:22.159897: step 14170, loss = 0.23 (973.7 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:47:24.762837: step 14180, loss = 0.23 (983.5 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:47:27.234297: step 14190, loss = 0.18 (1035.8 examples/sec; 0.247 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.56456\n",
      "2017-05-30 09:47:32.133147: step 14200, loss = 0.18 (522.6 examples/sec; 0.490 sec/batch)\n",
      "2017-05-30 09:47:35.398659: step 14210, loss = 0.19 (784.0 examples/sec; 0.327 sec/batch)\n",
      "2017-05-30 09:47:38.444148: step 14220, loss = 0.19 (840.6 examples/sec; 0.305 sec/batch)\n",
      "2017-05-30 09:47:41.355506: step 14230, loss = 0.21 (879.3 examples/sec; 0.291 sec/batch)\n",
      "2017-05-30 09:47:44.005803: step 14240, loss = 0.24 (965.9 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:47:48.991539: step 14260, loss = 0.13 (1019.7 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:47:51.610193: step 14270, loss = 0.19 (977.6 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:47:54.158846: step 14280, loss = 0.21 (1004.5 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:47:56.692719: step 14290, loss = 0.24 (1010.3 examples/sec; 0.253 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.43924\n",
      "2017-05-30 09:48:01.505070: step 14300, loss = 0.20 (532.0 examples/sec; 0.481 sec/batch)\n",
      "2017-05-30 09:48:05.064201: step 14310, loss = 0.17 (719.3 examples/sec; 0.356 sec/batch)\n",
      "2017-05-30 09:48:08.064306: step 14320, loss = 0.15 (853.3 examples/sec; 0.300 sec/batch)\n",
      "2017-05-30 09:48:10.698419: step 14330, loss = 0.15 (971.9 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:48:13.289038: step 14340, loss = 0.22 (988.2 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:48:15.783171: step 14350, loss = 0.19 (1026.4 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:48:20.952959: step 14370, loss = 0.17 (995.2 examples/sec; 0.257 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 09:48:23.470324: step 14380, loss = 0.19 (1016.9 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:48:26.125097: step 14390, loss = 0.21 (964.3 examples/sec; 0.265 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.38894\n",
      "2017-05-30 09:48:31.169146: step 14400, loss = 0.21 (507.5 examples/sec; 0.504 sec/batch)\n",
      "2017-05-30 09:48:34.613465: step 14410, loss = 0.19 (743.3 examples/sec; 0.344 sec/batch)\n",
      "2017-05-30 09:48:37.511839: step 14420, loss = 0.15 (883.3 examples/sec; 0.290 sec/batch)\n",
      "2017-05-30 09:48:40.118658: step 14430, loss = 0.23 (982.0 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:48:42.613015: step 14440, loss = 0.18 (1026.3 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:48:45.150727: step 14450, loss = 0.15 (1008.8 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:48:47.765321: step 14460, loss = 0.19 (979.1 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:48:52.800074: step 14480, loss = 0.20 (1007.8 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:48:55.439103: step 14490, loss = 0.17 (970.1 examples/sec; 0.264 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.32925\n",
      "2017-05-30 09:49:01.054038: step 14500, loss = 0.19 (455.9 examples/sec; 0.561 sec/batch)\n",
      "2017-05-30 09:49:04.620224: step 14510, loss = 0.21 (717.9 examples/sec; 0.357 sec/batch)\n",
      "2017-05-30 09:49:07.417195: step 14520, loss = 0.24 (915.3 examples/sec; 0.280 sec/batch)\n",
      "2017-05-30 09:49:09.933401: step 14530, loss = 0.24 (1017.4 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:49:12.451599: step 14540, loss = 0.15 (1016.6 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:49:15.065593: step 14550, loss = 0.19 (979.3 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:49:17.582102: step 14560, loss = 0.16 (1017.3 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:49:20.058699: step 14570, loss = 0.19 (1033.7 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:49:25.259371: step 14590, loss = 0.14 (991.6 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:49:29.057950: step 14600, loss = 0.19 (673.9 examples/sec; 0.380 sec/batch)\n",
      "2017-05-30 09:49:32.116549: step 14610, loss = 0.25 (837.0 examples/sec; 0.306 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4983  Precision @ 1 train: 0.9732\n",
      "2017-05-30 09:49:34.678724: step 14620, loss = 0.20 (999.2 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:49:37.165440: step 14630, loss = 0.20 (1029.5 examples/sec; 0.249 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4438  Precision @ 1 eval: 0.8668\n",
      "INFO:tensorflow:global_step/sec: 2.53716\n",
      "2017-05-30 09:49:39.724214: step 14640, loss = 0.10 (1000.5 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:49:42.266175: step 14650, loss = 0.21 (1007.1 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:49:44.816014: step 14660, loss = 0.20 (1004.0 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:49:47.417787: step 14670, loss = 0.21 (983.9 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:49:49.923492: step 14680, loss = 0.19 (1021.7 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:49:52.454078: step 14690, loss = 0.16 (1011.6 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:49:57.618518: step 14710, loss = 0.16 (1009.5 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:50:00.136148: step 14720, loss = 0.17 (1016.8 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:50:02.936438: step 14730, loss = 0.18 (914.2 examples/sec; 0.280 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.40215\n",
      "2017-05-30 09:50:09.020625: step 14740, loss = 0.16 (420.8 examples/sec; 0.608 sec/batch)\n",
      "2017-05-30 09:50:11.997673: step 14750, loss = 0.25 (859.9 examples/sec; 0.298 sec/batch)\n",
      "2017-05-30 09:50:14.657691: step 14760, loss = 0.26 (962.4 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:50:17.187557: step 14770, loss = 0.24 (1011.9 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:50:19.685311: step 14780, loss = 0.19 (1024.9 examples/sec; 0.250 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 13655 into /home/ipython/cnn-cifar10/tb_log/vggA/train/model.ckpt.\n",
      "2017-05-30 09:50:22.749841: step 14790, loss = 0.16 (835.4 examples/sec; 0.306 sec/batch)\n",
      "2017-05-30 09:50:25.154652: step 14800, loss = 0.18 (1064.5 examples/sec; 0.240 sec/batch)\n",
      "2017-05-30 09:50:27.647187: step 14810, loss = 0.17 (1027.1 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:50:30.340344: step 14820, loss = 0.15 (950.6 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 09:50:33.141392: step 14830, loss = 0.24 (913.9 examples/sec; 0.280 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.50704\n",
      "2017-05-30 09:50:37.470622: step 14840, loss = 0.14 (591.3 examples/sec; 0.433 sec/batch)\n",
      "2017-05-30 09:50:40.117239: step 14850, loss = 0.25 (967.3 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:50:42.604002: step 14860, loss = 0.23 (1029.5 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:50:45.136611: step 14870, loss = 0.18 (1010.8 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:50:47.786738: step 14880, loss = 0.25 (966.0 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:50:50.945863: step 14890, loss = 0.13 (810.4 examples/sec; 0.316 sec/batch)\n",
      "2017-05-30 09:50:54.072809: step 14900, loss = 0.20 (818.7 examples/sec; 0.313 sec/batch)\n",
      "2017-05-30 09:50:56.966608: step 14910, loss = 0.26 (884.7 examples/sec; 0.289 sec/batch)\n",
      "2017-05-30 09:50:59.624688: step 14920, loss = 0.16 (963.1 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:51:02.136476: step 14930, loss = 0.21 (1019.2 examples/sec; 0.251 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.41017\n",
      "2017-05-30 09:51:06.895994: step 14940, loss = 0.26 (537.9 examples/sec; 0.476 sec/batch)\n",
      "2017-05-30 09:51:09.940947: step 14950, loss = 0.22 (840.7 examples/sec; 0.304 sec/batch)\n",
      "2017-05-30 09:51:13.291048: step 14960, loss = 0.18 (764.2 examples/sec; 0.335 sec/batch)\n",
      "2017-05-30 09:51:16.250287: step 14970, loss = 0.21 (865.1 examples/sec; 0.296 sec/batch)\n",
      "2017-05-30 09:51:18.920933: step 14980, loss = 0.12 (958.6 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 09:51:21.475104: step 14990, loss = 0.19 (1002.3 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:51:23.962480: step 15000, loss = 0.15 (1029.2 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:51:26.575897: step 15010, loss = 0.16 (979.6 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:51:29.153869: step 15020, loss = 0.16 (993.0 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:51:31.670857: step 15030, loss = 0.15 (1017.1 examples/sec; 0.252 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.40535\n",
      "2017-05-30 09:51:36.243532: step 15040, loss = 0.21 (559.8 examples/sec; 0.457 sec/batch)\n",
      "2017-05-30 09:51:39.857257: step 15050, loss = 0.13 (708.4 examples/sec; 0.361 sec/batch)\n",
      "2017-05-30 09:51:42.864117: step 15060, loss = 0.19 (851.4 examples/sec; 0.301 sec/batch)\n",
      "2017-05-30 09:51:45.651011: step 15070, loss = 0.18 (918.6 examples/sec; 0.279 sec/batch)\n",
      "2017-05-30 09:51:48.285782: step 15080, loss = 0.17 (971.6 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:51:50.749791: step 15090, loss = 0.19 (1039.0 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 09:51:53.296477: step 15100, loss = 0.23 (1005.2 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:51:55.951524: step 15110, loss = 0.17 (964.2 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:51:58.465669: step 15120, loss = 0.16 (1018.2 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:52:00.976341: step 15130, loss = 0.20 (1019.6 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:52:05.212815: step 15140, loss = 0.19 (604.3 examples/sec; 0.424 sec/batch)\n",
      "2017-05-30 09:52:08.101071: step 15150, loss = 0.18 (886.3 examples/sec; 0.289 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4990  Precision @ 1 train: 0.9746\n",
      "2017-05-30 09:52:10.690388: step 15160, loss = 0.16 (988.7 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:52:13.756907: step 15170, loss = 0.14 (834.8 examples/sec; 0.307 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4424  Precision @ 1 eval: 0.8641\n",
      "INFO:tensorflow:global_step/sec: 2.43665\n",
      "2017-05-30 09:52:17.049066: step 15180, loss = 0.18 (777.6 examples/sec; 0.329 sec/batch)\n",
      "2017-05-30 09:52:20.027777: step 15190, loss = 0.22 (859.4 examples/sec; 0.298 sec/batch)\n",
      "2017-05-30 09:52:22.735131: step 15200, loss = 0.12 (945.6 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 09:52:25.360191: step 15210, loss = 0.15 (975.2 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:52:27.857318: step 15220, loss = 0.23 (1025.2 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:52:30.447057: step 15230, loss = 0.16 (988.5 examples/sec; 0.259 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 09:52:33.108533: step 15240, loss = 0.25 (961.9 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:52:35.665473: step 15250, loss = 0.13 (1001.2 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:52:38.626649: step 15260, loss = 0.18 (864.5 examples/sec; 0.296 sec/batch)\n",
      "2017-05-30 09:52:41.320515: step 15270, loss = 0.20 (950.3 examples/sec; 0.269 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.47653\n",
      "2017-05-30 09:52:45.384436: step 15280, loss = 0.17 (629.9 examples/sec; 0.406 sec/batch)\n",
      "2017-05-30 09:52:48.011479: step 15290, loss = 0.19 (974.5 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:52:50.549396: step 15300, loss = 0.19 (1008.7 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:52:53.101581: step 15310, loss = 0.18 (1003.1 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:52:55.742684: step 15320, loss = 0.19 (969.3 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:52:58.282564: step 15330, loss = 0.12 (1007.9 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:53:00.769843: step 15340, loss = 0.19 (1029.2 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:53:03.422754: step 15350, loss = 0.20 (965.0 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:53:10.183492: step 15370, loss = 0.11 (730.6 examples/sec; 0.350 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.38698\n",
      "2017-05-30 09:53:14.870786: step 15380, loss = 0.21 (546.2 examples/sec; 0.469 sec/batch)\n",
      "2017-05-30 09:53:17.441605: step 15390, loss = 0.21 (995.8 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:53:19.954585: step 15400, loss = 0.22 (1018.7 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:53:22.619350: step 15410, loss = 0.20 (960.7 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:53:25.249038: step 15420, loss = 0.19 (973.5 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:53:27.714289: step 15430, loss = 0.17 (1038.4 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:53:30.299270: step 15440, loss = 0.19 (990.3 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:53:32.919310: step 15450, loss = 0.14 (977.1 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:53:35.392945: step 15460, loss = 0.13 (1034.9 examples/sec; 0.247 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.49607\n",
      "2017-05-30 09:53:43.822855: step 15480, loss = 0.15 (455.7 examples/sec; 0.562 sec/batch)\n",
      "2017-05-30 09:53:46.863641: step 15490, loss = 0.18 (841.9 examples/sec; 0.304 sec/batch)\n",
      "2017-05-30 09:53:49.717836: step 15500, loss = 0.18 (896.9 examples/sec; 0.285 sec/batch)\n",
      "2017-05-30 09:53:52.367325: step 15510, loss = 0.18 (966.2 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:53:54.847682: step 15520, loss = 0.25 (1032.1 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:53:57.391672: step 15530, loss = 0.15 (1006.3 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:54:00.043975: step 15540, loss = 0.17 (965.2 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:54:02.659486: step 15550, loss = 0.28 (978.8 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:54:05.179852: step 15560, loss = 0.19 (1015.7 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:54:07.876253: step 15570, loss = 0.21 (949.4 examples/sec; 0.270 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.25947\n",
      "2017-05-30 09:54:14.260317: step 15580, loss = 0.19 (401.0 examples/sec; 0.638 sec/batch)\n",
      "2017-05-30 09:54:17.141178: step 15590, loss = 0.27 (888.6 examples/sec; 0.288 sec/batch)\n",
      "2017-05-30 09:54:19.821367: step 15600, loss = 0.18 (955.2 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 09:54:22.391476: step 15610, loss = 0.19 (996.1 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:54:24.870823: step 15620, loss = 0.19 (1032.5 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:54:27.525681: step 15630, loss = 0.17 (964.3 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:54:30.083792: step 15640, loss = 0.14 (1000.7 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:54:32.595899: step 15650, loss = 0.19 (1019.1 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:54:35.247390: step 15660, loss = 0.22 (965.5 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 09:54:37.861006: step 15670, loss = 0.15 (979.5 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:54:45.618890: step 15690, loss = 0.16 (798.1 examples/sec; 0.321 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4996  Precision @ 1 train: 0.9758\n",
      "2017-05-30 09:54:49.081230: step 15700, loss = 0.18 (739.4 examples/sec; 0.346 sec/batch)\n",
      "2017-05-30 09:54:52.274689: step 15710, loss = 0.14 (801.6 examples/sec; 0.319 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4397  Precision @ 1 eval: 0.8588\n",
      "INFO:tensorflow:global_step/sec: 2.44004\n",
      "2017-05-30 09:54:54.898501: step 15720, loss = 0.21 (975.7 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:54:57.464916: step 15730, loss = 0.16 (997.5 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:54:59.971532: step 15740, loss = 0.27 (1021.3 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:55:02.606681: step 15750, loss = 0.17 (971.5 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:55:05.187302: step 15760, loss = 0.15 (992.0 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:55:07.699463: step 15770, loss = 0.19 (1019.0 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:55:10.382208: step 15780, loss = 0.22 (954.2 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 09:55:15.997949: step 15800, loss = 0.22 (992.3 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:55:18.620641: step 15810, loss = 0.15 (976.1 examples/sec; 0.262 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.43563\n",
      "2017-05-30 09:55:23.790641: step 15820, loss = 0.17 (495.2 examples/sec; 0.517 sec/batch)\n",
      "2017-05-30 09:55:26.739307: step 15830, loss = 0.23 (868.2 examples/sec; 0.295 sec/batch)\n",
      "2017-05-30 09:55:29.575697: step 15840, loss = 0.14 (902.6 examples/sec; 0.284 sec/batch)\n",
      "2017-05-30 09:55:32.232558: step 15850, loss = 0.20 (963.5 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 09:55:34.739650: step 15860, loss = 0.17 (1021.1 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:55:37.278701: step 15870, loss = 0.24 (1008.3 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:55:39.965020: step 15880, loss = 0.21 (953.0 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 09:55:42.760204: step 15890, loss = 0.19 (915.9 examples/sec; 0.280 sec/batch)\n",
      "2017-05-30 09:55:45.367424: step 15900, loss = 0.23 (981.9 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:55:47.985414: step 15910, loss = 0.16 (977.8 examples/sec; 0.262 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.54841\n",
      "2017-05-30 09:55:51.964378: step 15920, loss = 0.18 (643.4 examples/sec; 0.398 sec/batch)\n",
      "2017-05-30 09:55:54.548156: step 15930, loss = 0.18 (990.8 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 09:55:57.141324: step 15940, loss = 0.15 (987.2 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:55:59.608578: step 15950, loss = 0.21 (1037.6 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 09:56:02.200386: step 15960, loss = 0.23 (987.7 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:56:04.917549: step 15970, loss = 0.17 (942.2 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 09:56:08.243982: step 15980, loss = 0.14 (769.6 examples/sec; 0.333 sec/batch)\n",
      "2017-05-30 09:56:11.387452: step 15990, loss = 0.17 (814.4 examples/sec; 0.314 sec/batch)\n",
      "2017-05-30 09:56:14.460594: step 16000, loss = 0.17 (833.0 examples/sec; 0.307 sec/batch)\n",
      "2017-05-30 09:56:17.176654: step 16010, loss = 0.16 (942.5 examples/sec; 0.272 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.41809\n",
      "2017-05-30 09:56:21.194800: step 16020, loss = 0.26 (637.1 examples/sec; 0.402 sec/batch)\n",
      "2017-05-30 09:56:23.744193: step 16030, loss = 0.24 (1004.2 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:56:26.264205: step 16040, loss = 0.16 (1015.9 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 09:56:28.815661: step 16050, loss = 0.22 (1003.3 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:56:31.437305: step 16060, loss = 0.23 (976.5 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:56:34.024530: step 16070, loss = 0.19 (989.5 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:56:36.515689: step 16080, loss = 0.14 (1027.6 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:56:39.206309: step 16090, loss = 0.17 (951.5 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 09:56:41.849953: step 16100, loss = 0.15 (968.4 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:56:44.635023: step 16110, loss = 0.15 (919.2 examples/sec; 0.279 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.58877\n",
      "2017-05-30 09:56:49.067407: step 16120, loss = 0.13 (577.6 examples/sec; 0.443 sec/batch)\n",
      "2017-05-30 09:56:52.297572: step 16130, loss = 0.12 (792.5 examples/sec; 0.323 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 09:56:55.283884: step 16140, loss = 0.14 (857.2 examples/sec; 0.299 sec/batch)\n",
      "2017-05-30 09:56:58.106637: step 16150, loss = 0.17 (906.9 examples/sec; 0.282 sec/batch)\n",
      "2017-05-30 09:57:00.733645: step 16160, loss = 0.18 (974.5 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:57:03.260942: step 16170, loss = 0.20 (1012.9 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:57:05.864800: step 16180, loss = 0.12 (983.2 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 09:57:08.545133: step 16190, loss = 0.16 (955.1 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 09:57:11.037205: step 16200, loss = 0.16 (1027.3 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:57:13.746560: step 16210, loss = 0.17 (944.9 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 09:57:19.128516: step 16220, loss = 0.23 (475.7 examples/sec; 0.538 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5013  Precision @ 1 train: 0.9791\n",
      "2017-05-30 09:57:25.657256: step 16240, loss = 0.14 (887.8 examples/sec; 0.288 sec/batch)\n",
      "2017-05-30 09:57:28.310952: step 16250, loss = 0.12 (964.7 examples/sec; 0.265 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4442  Precision @ 1 eval: 0.8676\n",
      "INFO:tensorflow:global_step/sec: 2.38564\n",
      "2017-05-30 09:57:30.689579: step 16260, loss = 0.17 (1076.3 examples/sec; 0.238 sec/batch)\n",
      "2017-05-30 09:57:33.245272: step 16270, loss = 0.18 (1001.7 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:57:35.868301: step 16280, loss = 0.13 (976.0 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:57:38.413927: step 16290, loss = 0.16 (1005.6 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 09:57:40.891565: step 16300, loss = 0.12 (1033.2 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:57:43.607452: step 16310, loss = 0.14 (942.6 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 09:57:46.428405: step 16320, loss = 0.23 (907.5 examples/sec; 0.282 sec/batch)\n",
      "2017-05-30 09:57:49.070300: step 16330, loss = 0.14 (969.0 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 09:57:51.704850: step 16340, loss = 0.18 (971.7 examples/sec; 0.263 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.56686\n",
      "2017-05-30 09:57:58.723166: step 16360, loss = 0.32 (571.7 examples/sec; 0.448 sec/batch)\n",
      "2017-05-30 09:58:01.058379: step 16370, loss = 0.18 (1096.3 examples/sec; 0.234 sec/batch)\n",
      "2017-05-30 09:58:03.563317: step 16380, loss = 0.15 (1022.0 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 09:58:06.119983: step 16390, loss = 0.25 (1001.3 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:58:08.747786: step 16400, loss = 0.27 (974.2 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:58:11.229155: step 16410, loss = 0.15 (1031.7 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:58:13.907139: step 16420, loss = 0.18 (955.9 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 09:58:16.904852: step 16430, loss = 0.25 (854.0 examples/sec; 0.300 sec/batch)\n",
      "2017-05-30 09:58:20.527508: step 16440, loss = 0.17 (706.7 examples/sec; 0.362 sec/batch)\n",
      "2017-05-30 09:58:23.530490: step 16450, loss = 0.16 (852.5 examples/sec; 0.300 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.37109\n",
      "2017-05-30 09:58:28.386829: step 16460, loss = 0.21 (527.1 examples/sec; 0.486 sec/batch)\n",
      "2017-05-30 09:58:30.609538: step 16470, loss = 0.26 (1151.7 examples/sec; 0.222 sec/batch)\n",
      "2017-05-30 09:58:33.093427: step 16480, loss = 0.19 (1030.6 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 09:58:35.762128: step 16490, loss = 0.17 (959.3 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 09:58:38.319342: step 16500, loss = 0.19 (1001.1 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 09:58:40.887116: step 16510, loss = 0.15 (997.0 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 09:58:43.566631: step 16520, loss = 0.19 (955.4 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 09:58:46.945034: step 16530, loss = 0.18 (757.8 examples/sec; 0.338 sec/batch)\n",
      "2017-05-30 09:58:50.446038: step 16540, loss = 0.18 (731.2 examples/sec; 0.350 sec/batch)\n",
      "2017-05-30 09:58:53.428791: step 16550, loss = 0.22 (858.3 examples/sec; 0.298 sec/batch)\n",
      "2017-05-30 09:58:59.919343: step 16570, loss = 0.15 (1140.3 examples/sec; 0.225 sec/batch)\n",
      "2017-05-30 09:59:02.642846: step 16580, loss = 0.15 (940.0 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 09:59:05.260173: step 16590, loss = 0.22 (978.1 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:59:07.792139: step 16600, loss = 0.22 (1011.1 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 09:59:10.377654: step 16610, loss = 0.16 (990.1 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:59:13.002568: step 16620, loss = 0.18 (975.3 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 09:59:15.616763: step 16630, loss = 0.16 (979.3 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 09:59:18.467012: step 16640, loss = 0.22 (898.2 examples/sec; 0.285 sec/batch)\n",
      "2017-05-30 09:59:21.182386: step 16650, loss = 0.14 (942.8 examples/sec; 0.272 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.6072\n",
      "2017-05-30 09:59:25.396395: step 16660, loss = 0.15 (607.5 examples/sec; 0.421 sec/batch)\n",
      "2017-05-30 09:59:27.731073: step 16670, loss = 0.21 (1096.5 examples/sec; 0.233 sec/batch)\n",
      "2017-05-30 09:59:32.775651: step 16690, loss = 0.16 (1017.9 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 09:59:35.410375: step 16700, loss = 0.17 (971.6 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 09:59:37.953697: step 16710, loss = 0.17 (1006.6 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 09:59:40.442348: step 16720, loss = 0.20 (1028.7 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 09:59:43.035617: step 16730, loss = 0.15 (987.2 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 09:59:46.041537: step 16740, loss = 0.12 (851.7 examples/sec; 0.301 sec/batch)\n",
      "2017-05-30 09:59:49.671166: step 16750, loss = 0.20 (705.3 examples/sec; 0.363 sec/batch)\n",
      "2017-05-30 09:59:54.832000: step 16760, loss = 0.20 (496.0 examples/sec; 0.516 sec/batch)\n",
      "2017-05-30 09:59:57.178677: step 16770, loss = 0.17 (1090.9 examples/sec; 0.235 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4994  Precision @ 1 train: 0.9754\n",
      "2017-05-30 09:59:59.565851: step 16780, loss = 0.14 (1072.4 examples/sec; 0.239 sec/batch)\n",
      "2017-05-30 10:00:04.755672: step 16800, loss = 0.20 (970.8 examples/sec; 0.264 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4411  Precision @ 1 eval: 0.8615\n",
      "INFO:tensorflow:global_step/sec: 2.51486\n",
      "2017-05-30 10:00:07.162750: step 16810, loss = 0.19 (1063.5 examples/sec; 0.241 sec/batch)\n",
      "2017-05-30 10:00:09.702653: step 16820, loss = 0.28 (1007.9 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:00:12.346990: step 16830, loss = 0.16 (968.1 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:00:14.850065: step 16840, loss = 0.17 (1022.7 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 10:00:17.512500: step 16850, loss = 0.13 (961.5 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 10:00:20.600075: step 16860, loss = 0.14 (829.1 examples/sec; 0.309 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 15563 into /home/ipython/cnn-cifar10/tb_log/vggA/train/model.ckpt.\n",
      "2017-05-30 10:00:24.466266: step 16870, loss = 0.13 (662.2 examples/sec; 0.387 sec/batch)\n",
      "2017-05-30 10:00:27.497663: step 16880, loss = 0.25 (844.5 examples/sec; 0.303 sec/batch)\n",
      "2017-05-30 10:00:30.267326: step 16890, loss = 0.17 (924.3 examples/sec; 0.277 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.34895\n",
      "2017-05-30 10:00:36.743587: step 16910, loss = 0.15 (668.5 examples/sec; 0.383 sec/batch)\n",
      "2017-05-30 10:00:39.373499: step 16920, loss = 0.25 (973.4 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:00:41.962701: step 16930, loss = 0.21 (988.7 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:00:44.537853: step 16940, loss = 0.16 (994.1 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:00:47.116749: step 16950, loss = 0.16 (992.7 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:00:50.403206: step 16960, loss = 0.19 (779.0 examples/sec; 0.329 sec/batch)\n",
      "2017-05-30 10:00:54.049151: step 16970, loss = 0.12 (702.1 examples/sec; 0.365 sec/batch)\n",
      "2017-05-30 10:00:57.013471: step 16980, loss = 0.16 (863.6 examples/sec; 0.296 sec/batch)\n",
      "2017-05-30 10:00:59.652710: step 16990, loss = 0.16 (970.0 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:01:02.223911: step 17000, loss = 0.17 (995.6 examples/sec; 0.257 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.39653\n",
      "2017-05-30 10:01:08.931474: step 17020, loss = 0.14 (965.0 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 10:01:11.450788: step 17030, loss = 0.16 (1016.2 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:01:14.006509: step 17040, loss = 0.14 (1001.7 examples/sec; 0.256 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 10:01:16.670310: step 17050, loss = 0.17 (961.0 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 10:01:19.332796: step 17060, loss = 0.17 (961.5 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 10:01:22.175396: step 17070, loss = 0.18 (900.6 examples/sec; 0.284 sec/batch)\n",
      "2017-05-30 10:01:25.165165: step 17080, loss = 0.19 (856.3 examples/sec; 0.299 sec/batch)\n",
      "2017-05-30 10:01:28.485384: step 17090, loss = 0.15 (771.0 examples/sec; 0.332 sec/batch)\n",
      "2017-05-30 10:01:31.486591: step 17100, loss = 0.18 (853.0 examples/sec; 0.300 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.37239\n",
      "2017-05-30 10:01:35.919719: step 17110, loss = 0.16 (577.5 examples/sec; 0.443 sec/batch)\n",
      "2017-05-30 10:01:38.475852: step 17120, loss = 0.14 (1001.5 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:01:40.953191: step 17130, loss = 0.20 (1033.4 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:01:43.572270: step 17140, loss = 0.12 (977.4 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:01:46.130357: step 17150, loss = 0.13 (1000.7 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:01:48.598107: step 17160, loss = 0.12 (1037.4 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:01:51.513831: step 17170, loss = 0.27 (878.0 examples/sec; 0.292 sec/batch)\n",
      "2017-05-30 10:01:54.936378: step 17180, loss = 0.16 (748.0 examples/sec; 0.342 sec/batch)\n",
      "2017-05-30 10:01:58.139864: step 17190, loss = 0.17 (799.1 examples/sec; 0.320 sec/batch)\n",
      "2017-05-30 10:02:01.056004: step 17200, loss = 0.19 (877.9 examples/sec; 0.292 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.40552\n",
      "2017-05-30 10:02:05.263222: step 17210, loss = 0.20 (608.5 examples/sec; 0.421 sec/batch)\n",
      "2017-05-30 10:02:07.835174: step 17220, loss = 0.14 (995.4 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 10:02:10.430030: step 17230, loss = 0.12 (986.6 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:02:13.056885: step 17240, loss = 0.20 (974.5 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:02:15.519226: step 17250, loss = 0.14 (1039.7 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 10:02:18.049166: step 17260, loss = 0.21 (1011.9 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 10:02:20.843733: step 17270, loss = 0.15 (916.1 examples/sec; 0.279 sec/batch)\n",
      "2017-05-30 10:02:24.646339: step 17280, loss = 0.14 (673.2 examples/sec; 0.380 sec/batch)\n",
      "2017-05-30 10:02:27.936115: step 17290, loss = 0.18 (778.2 examples/sec; 0.329 sec/batch)\n",
      "2017-05-30 10:02:30.687342: step 17300, loss = 0.20 (930.5 examples/sec; 0.275 sec/batch)\n",
      "2017-05-30 10:02:34.723519: step 17310, loss = 0.15 (634.3 examples/sec; 0.404 sec/batch)\n",
      "2017-05-30 10:02:37.238652: step 17320, loss = 0.16 (1017.8 examples/sec; 0.252 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5008  Precision @ 1 train: 0.9781\n",
      "2017-05-30 10:02:39.786602: step 17330, loss = 0.17 (1004.7 examples/sec; 0.255 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4423  Precision @ 1 eval: 0.8639\n",
      "INFO:tensorflow:global_step/sec: 2.51409\n",
      "2017-05-30 10:02:44.744581: step 17350, loss = 0.13 (1075.7 examples/sec; 0.238 sec/batch)\n",
      "2017-05-30 10:02:47.450914: step 17360, loss = 0.13 (945.9 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 10:02:50.000108: step 17370, loss = 0.19 (1004.2 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:02:52.812256: step 17380, loss = 0.17 (910.3 examples/sec; 0.281 sec/batch)\n",
      "2017-05-30 10:02:55.730101: step 17390, loss = 0.19 (877.4 examples/sec; 0.292 sec/batch)\n",
      "2017-05-30 10:02:58.282829: step 17400, loss = 0.22 (1002.8 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:03:00.750166: step 17410, loss = 0.21 (1037.6 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:03:03.469525: step 17420, loss = 0.14 (941.4 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 10:03:06.016196: step 17430, loss = 0.15 (1005.2 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:03:08.530314: step 17440, loss = 0.11 (1018.2 examples/sec; 0.251 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.53179\n",
      "2017-05-30 10:03:15.356230: step 17460, loss = 0.16 (1023.4 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 10:03:17.914198: step 17470, loss = 0.12 (1000.8 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:03:20.545269: step 17480, loss = 0.22 (973.0 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:03:23.335805: step 17490, loss = 0.19 (917.4 examples/sec; 0.279 sec/batch)\n",
      "2017-05-30 10:03:26.204128: step 17500, loss = 0.16 (892.5 examples/sec; 0.287 sec/batch)\n",
      "2017-05-30 10:03:28.889098: step 17510, loss = 0.07 (953.5 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 10:03:31.371744: step 17520, loss = 0.14 (1031.2 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:03:33.923462: step 17530, loss = 0.18 (1003.2 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:03:36.553759: step 17540, loss = 0.13 (973.3 examples/sec; 0.263 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.44772\n",
      "2017-05-30 10:03:42.060276: step 17550, loss = 0.13 (464.9 examples/sec; 0.551 sec/batch)\n",
      "2017-05-30 10:03:47.706025: step 17570, loss = 0.20 (972.4 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:03:50.242505: step 17580, loss = 0.12 (1009.3 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:03:52.936861: step 17590, loss = 0.18 (950.1 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 10:03:55.831813: step 17600, loss = 0.18 (884.3 examples/sec; 0.289 sec/batch)\n",
      "2017-05-30 10:03:58.442820: step 17610, loss = 0.19 (980.5 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:04:00.962115: step 17620, loss = 0.17 (1016.2 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:04:03.808305: step 17630, loss = 0.19 (899.4 examples/sec; 0.285 sec/batch)\n",
      "2017-05-30 10:04:07.030135: step 17640, loss = 0.19 (794.6 examples/sec; 0.322 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.32141\n",
      "2017-05-30 10:04:12.167319: step 17650, loss = 0.16 (498.3 examples/sec; 0.514 sec/batch)\n",
      "2017-05-30 10:04:14.918219: step 17660, loss = 0.15 (930.6 examples/sec; 0.275 sec/batch)\n",
      "2017-05-30 10:04:19.999441: step 17680, loss = 0.16 (1027.2 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:04:22.629311: step 17690, loss = 0.16 (973.4 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:04:25.525150: step 17700, loss = 0.16 (884.0 examples/sec; 0.290 sec/batch)\n",
      "2017-05-30 10:04:28.194889: step 17710, loss = 0.18 (958.9 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 10:04:30.792656: step 17720, loss = 0.17 (985.5 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:04:33.398442: step 17730, loss = 0.12 (982.4 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:04:35.917028: step 17740, loss = 0.21 (1016.4 examples/sec; 0.252 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.55762\n",
      "2017-05-30 10:04:40.073621: step 17750, loss = 0.16 (615.9 examples/sec; 0.416 sec/batch)\n",
      "2017-05-30 10:04:42.673771: step 17760, loss = 0.09 (984.6 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:04:45.156351: step 17770, loss = 0.17 (1031.2 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:04:47.794548: step 17780, loss = 0.22 (970.4 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:04:52.912632: step 17800, loss = 0.13 (1012.2 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 10:04:55.809449: step 17810, loss = 0.12 (883.7 examples/sec; 0.290 sec/batch)\n",
      "2017-05-30 10:04:59.197569: step 17820, loss = 0.21 (755.6 examples/sec; 0.339 sec/batch)\n",
      "2017-05-30 10:05:02.451900: step 17830, loss = 0.15 (786.6 examples/sec; 0.325 sec/batch)\n",
      "2017-05-30 10:05:05.424150: step 17840, loss = 0.15 (861.3 examples/sec; 0.297 sec/batch)\n",
      "2017-05-30 10:05:09.447131: step 17850, loss = 0.17 (636.3 examples/sec; 0.402 sec/batch)\n",
      "2017-05-30 10:05:12.042629: step 17860, loss = 0.18 (986.3 examples/sec; 0.260 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5033  Precision @ 1 train: 0.9830\n",
      "2017-05-30 10:05:14.512895: step 17870, loss = 0.20 (1036.3 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:05:17.150012: step 17880, loss = 0.10 (970.8 examples/sec; 0.264 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4457  Precision @ 1 eval: 0.8705\n",
      "INFO:tensorflow:global_step/sec: 2.51577\n",
      "2017-05-30 10:05:19.512744: step 17890, loss = 0.14 (1083.5 examples/sec; 0.236 sec/batch)\n",
      "2017-05-30 10:05:24.884340: step 17910, loss = 0.18 (917.3 examples/sec; 0.279 sec/batch)\n",
      "2017-05-30 10:05:28.609043: step 17920, loss = 0.16 (687.4 examples/sec; 0.372 sec/batch)\n",
      "2017-05-30 10:05:31.912558: step 17930, loss = 0.19 (774.9 examples/sec; 0.330 sec/batch)\n",
      "2017-05-30 10:05:34.679286: step 17940, loss = 0.19 (925.3 examples/sec; 0.277 sec/batch)\n",
      "2017-05-30 10:05:37.306800: step 17950, loss = 0.13 (974.3 examples/sec; 0.263 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 10:05:39.806387: step 17960, loss = 0.12 (1024.2 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 10:05:42.405206: step 17970, loss = 0.22 (985.1 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:05:45.019749: step 17980, loss = 0.17 (979.1 examples/sec; 0.261 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.37902\n",
      "2017-05-30 10:05:48.868913: step 17990, loss = 0.10 (665.1 examples/sec; 0.385 sec/batch)\n",
      "2017-05-30 10:05:51.492339: step 18000, loss = 0.11 (975.8 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:05:56.683016: step 18020, loss = 0.12 (969.4 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:05:59.583734: step 18030, loss = 0.18 (882.5 examples/sec; 0.290 sec/batch)\n",
      "2017-05-30 10:06:02.631922: step 18040, loss = 0.14 (839.8 examples/sec; 0.305 sec/batch)\n",
      "2017-05-30 10:06:05.869205: step 18050, loss = 0.12 (790.8 examples/sec; 0.324 sec/batch)\n",
      "2017-05-30 10:06:08.844589: step 18060, loss = 0.19 (860.4 examples/sec; 0.298 sec/batch)\n",
      "2017-05-30 10:06:11.503081: step 18070, loss = 0.17 (963.0 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 10:06:14.128599: step 18080, loss = 0.08 (975.0 examples/sec; 0.263 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.4457\n",
      "2017-05-30 10:06:17.899731: step 18090, loss = 0.18 (678.8 examples/sec; 0.377 sec/batch)\n",
      "2017-05-30 10:06:20.550236: step 18100, loss = 0.14 (965.9 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 10:06:23.105814: step 18110, loss = 0.22 (1001.7 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:06:28.505325: step 18130, loss = 0.17 (893.0 examples/sec; 0.287 sec/batch)\n",
      "2017-05-30 10:06:32.259696: step 18140, loss = 0.22 (681.9 examples/sec; 0.375 sec/batch)\n",
      "2017-05-30 10:06:35.416535: step 18150, loss = 0.12 (810.9 examples/sec; 0.316 sec/batch)\n",
      "2017-05-30 10:06:38.279661: step 18160, loss = 0.19 (894.1 examples/sec; 0.286 sec/batch)\n",
      "2017-05-30 10:06:40.910994: step 18170, loss = 0.16 (972.9 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:06:43.414139: step 18180, loss = 0.20 (1022.7 examples/sec; 0.250 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.37639\n",
      "2017-05-30 10:06:47.532247: step 18190, loss = 0.17 (621.6 examples/sec; 0.412 sec/batch)\n",
      "2017-05-30 10:06:50.105337: step 18200, loss = 0.24 (994.9 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 10:06:52.608721: step 18210, loss = 0.11 (1022.6 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 10:06:55.259106: step 18220, loss = 0.21 (965.9 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 10:07:00.846129: step 18240, loss = 0.20 (904.6 examples/sec; 0.283 sec/batch)\n",
      "2017-05-30 10:07:03.548510: step 18250, loss = 0.14 (947.3 examples/sec; 0.270 sec/batch)\n",
      "2017-05-30 10:07:06.149867: step 18260, loss = 0.22 (984.1 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:07:08.648060: step 18270, loss = 0.17 (1024.7 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 10:07:11.253547: step 18280, loss = 0.26 (982.5 examples/sec; 0.261 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.47832\n",
      "2017-05-30 10:07:16.365651: step 18290, loss = 0.16 (500.8 examples/sec; 0.511 sec/batch)\n",
      "2017-05-30 10:07:19.461022: step 18300, loss = 0.26 (827.0 examples/sec; 0.310 sec/batch)\n",
      "2017-05-30 10:07:22.266241: step 18310, loss = 0.12 (912.6 examples/sec; 0.281 sec/batch)\n",
      "2017-05-30 10:07:24.897557: step 18320, loss = 0.14 (972.9 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:07:27.400315: step 18330, loss = 0.17 (1022.9 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 10:07:33.057506: step 18350, loss = 0.11 (890.6 examples/sec; 0.287 sec/batch)\n",
      "2017-05-30 10:07:35.548753: step 18360, loss = 0.16 (1027.6 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:07:38.066320: step 18370, loss = 0.17 (1016.9 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:07:40.697879: step 18380, loss = 0.15 (972.8 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:07:44.335879: step 18390, loss = 0.20 (703.7 examples/sec; 0.364 sec/batch)\n",
      "2017-05-30 10:07:47.102748: step 18400, loss = 0.10 (925.2 examples/sec; 0.277 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5022  Precision @ 1 train: 0.9809\n",
      "2017-05-30 10:07:49.839599: step 18410, loss = 0.15 (935.4 examples/sec; 0.274 sec/batch)\n",
      "2017-05-30 10:07:53.506019: step 18420, loss = 0.17 (698.2 examples/sec; 0.367 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4427  Precision @ 1 eval: 0.8646\n",
      "INFO:tensorflow:global_step/sec: 2.47527\n",
      "2017-05-30 10:07:56.529514: step 18430, loss = 0.08 (846.7 examples/sec; 0.302 sec/batch)\n",
      "2017-05-30 10:07:59.465230: step 18440, loss = 0.20 (872.0 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 10:08:04.822989: step 18460, loss = 0.20 (1023.9 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 10:08:07.397709: step 18470, loss = 0.19 (994.3 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 10:08:10.007758: step 18480, loss = 0.13 (980.8 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:08:12.515408: step 18490, loss = 0.22 (1020.9 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 10:08:15.095628: step 18500, loss = 0.13 (992.2 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:08:17.739329: step 18510, loss = 0.22 (968.3 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:08:20.200641: step 18520, loss = 0.13 (1040.1 examples/sec; 0.246 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.54555\n",
      "2017-05-30 10:08:24.414321: step 18530, loss = 0.16 (607.5 examples/sec; 0.421 sec/batch)\n",
      "2017-05-30 10:08:26.870330: step 18540, loss = 0.13 (1042.3 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 10:08:29.550673: step 18550, loss = 0.19 (955.1 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 10:08:32.555354: step 18560, loss = 0.18 (852.0 examples/sec; 0.300 sec/batch)\n",
      "2017-05-30 10:08:37.708601: step 18580, loss = 0.20 (1011.8 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 10:08:40.354729: step 18590, loss = 0.11 (967.5 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 10:08:42.916596: step 18600, loss = 0.18 (999.3 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:08:45.406979: step 18610, loss = 0.17 (1028.0 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:08:48.022781: step 18620, loss = 0.25 (978.7 examples/sec; 0.262 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.62996\n",
      "2017-05-30 10:08:51.985994: step 18630, loss = 0.11 (645.9 examples/sec; 0.396 sec/batch)\n",
      "2017-05-30 10:08:54.471388: step 18640, loss = 0.27 (1030.0 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:08:57.165773: step 18650, loss = 0.22 (950.1 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 10:09:00.748712: step 18660, loss = 0.18 (714.5 examples/sec; 0.358 sec/batch)\n",
      "2017-05-30 10:09:04.517401: step 18670, loss = 0.16 (679.3 examples/sec; 0.377 sec/batch)\n",
      "2017-05-30 10:09:07.449455: step 18680, loss = 0.19 (873.1 examples/sec; 0.293 sec/batch)\n",
      "2017-05-30 10:09:10.032339: step 18690, loss = 0.11 (991.1 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:09:12.532990: step 18700, loss = 0.18 (1023.7 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 10:09:15.127415: step 18710, loss = 0.12 (986.7 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:09:17.715167: step 18720, loss = 0.17 (989.3 examples/sec; 0.259 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.36694\n",
      "2017-05-30 10:09:21.665463: step 18730, loss = 0.15 (648.1 examples/sec; 0.395 sec/batch)\n",
      "2017-05-30 10:09:24.247159: step 18740, loss = 0.13 (991.6 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:09:27.285632: step 18750, loss = 0.16 (842.5 examples/sec; 0.304 sec/batch)\n",
      "2017-05-30 10:09:30.647386: step 18760, loss = 0.14 (761.5 examples/sec; 0.336 sec/batch)\n",
      "2017-05-30 10:09:33.915172: step 18770, loss = 0.20 (783.4 examples/sec; 0.327 sec/batch)\n",
      "2017-05-30 10:09:36.717359: step 18780, loss = 0.15 (913.6 examples/sec; 0.280 sec/batch)\n",
      "2017-05-30 10:09:41.744366: step 18800, loss = 0.15 (1014.0 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:09:44.401998: step 18810, loss = 0.16 (963.3 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 10:09:46.949053: step 18820, loss = 0.11 (1005.1 examples/sec; 0.255 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.40707\n",
      "2017-05-30 10:09:51.009518: step 18830, loss = 0.18 (630.5 examples/sec; 0.406 sec/batch)\n",
      "2017-05-30 10:09:53.706253: step 18840, loss = 0.16 (949.3 examples/sec; 0.270 sec/batch)\n",
      "2017-05-30 10:09:56.969453: step 18850, loss = 0.19 (784.5 examples/sec; 0.326 sec/batch)\n",
      "2017-05-30 10:09:59.990238: step 18860, loss = 0.13 (847.5 examples/sec; 0.302 sec/batch)\n",
      "2017-05-30 10:10:03.153986: step 18870, loss = 0.18 (809.2 examples/sec; 0.316 sec/batch)\n",
      "2017-05-30 10:10:06.103664: step 18880, loss = 0.18 (867.9 examples/sec; 0.295 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 10:10:08.591139: step 18890, loss = 0.18 (1029.2 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:10:13.805902: step 18910, loss = 0.14 (974.8 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:10:16.264112: step 18920, loss = 0.12 (1041.4 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 10:10:20.151931: step 18930, loss = 0.12 (658.5 examples/sec; 0.389 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 17500 into /home/ipython/cnn-cifar10/tb_log/vggA/train/model.ckpt.\n",
      "2017-05-30 10:10:24.223362: step 18940, loss = 0.12 (628.8 examples/sec; 0.407 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5030  Precision @ 1 train: 0.9824\n",
      "2017-05-30 10:10:27.654563: step 18950, loss = 0.18 (746.1 examples/sec; 0.343 sec/batch)\n",
      "2017-05-30 10:10:30.647977: step 18960, loss = 0.16 (855.2 examples/sec; 0.299 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4467  Precision @ 1 eval: 0.8725\n",
      "INFO:tensorflow:global_step/sec: 2.33618\n",
      "2017-05-30 10:10:33.530436: step 18970, loss = 0.15 (888.1 examples/sec; 0.288 sec/batch)\n",
      "2017-05-30 10:10:36.269381: step 18980, loss = 0.14 (934.7 examples/sec; 0.274 sec/batch)\n",
      "2017-05-30 10:10:38.933501: step 18990, loss = 0.13 (960.9 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 10:10:44.052622: step 19010, loss = 0.14 (1030.5 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:10:46.613647: step 19020, loss = 0.18 (999.6 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:10:49.215898: step 19030, loss = 0.16 (983.8 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:10:51.711739: step 19040, loss = 0.17 (1025.7 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 10:10:54.273413: step 19050, loss = 0.13 (999.3 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:10:56.906897: step 19060, loss = 0.13 (972.1 examples/sec; 0.263 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.62696\n",
      "2017-05-30 10:11:01.101592: step 19070, loss = 0.15 (610.3 examples/sec; 0.419 sec/batch)\n",
      "2017-05-30 10:11:03.637839: step 19080, loss = 0.09 (1009.4 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:11:06.851214: step 19090, loss = 0.12 (796.7 examples/sec; 0.321 sec/batch)\n",
      "2017-05-30 10:11:10.437408: step 19100, loss = 0.12 (713.8 examples/sec; 0.359 sec/batch)\n",
      "2017-05-30 10:11:16.039680: step 19120, loss = 0.14 (975.7 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:11:18.602197: step 19130, loss = 0.17 (999.0 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:11:21.144321: step 19140, loss = 0.12 (1007.0 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:11:23.761593: step 19150, loss = 0.19 (978.1 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:11:26.348693: step 19160, loss = 0.12 (989.5 examples/sec; 0.259 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.40663\n",
      "2017-05-30 10:11:30.456320: step 19170, loss = 0.15 (623.2 examples/sec; 0.411 sec/batch)\n",
      "2017-05-30 10:11:32.835492: step 19180, loss = 0.17 (1076.0 examples/sec; 0.238 sec/batch)\n",
      "2017-05-30 10:11:35.678712: step 19190, loss = 0.19 (900.4 examples/sec; 0.284 sec/batch)\n",
      "2017-05-30 10:11:38.563146: step 19200, loss = 0.18 (887.5 examples/sec; 0.288 sec/batch)\n",
      "2017-05-30 10:11:41.184897: step 19210, loss = 0.25 (976.4 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:11:43.683341: step 19220, loss = 0.12 (1024.6 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 10:11:48.868242: step 19240, loss = 0.16 (966.0 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 10:11:52.091475: step 19250, loss = 0.18 (794.2 examples/sec; 0.322 sec/batch)\n",
      "2017-05-30 10:11:55.177154: step 19260, loss = 0.15 (829.6 examples/sec; 0.309 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.39037\n",
      "2017-05-30 10:11:59.952524: step 19270, loss = 0.21 (536.1 examples/sec; 0.478 sec/batch)\n",
      "2017-05-30 10:12:02.244683: step 19280, loss = 0.16 (1116.9 examples/sec; 0.229 sec/batch)\n",
      "2017-05-30 10:12:04.903643: step 19290, loss = 0.23 (962.8 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 10:12:07.803152: step 19300, loss = 0.12 (882.9 examples/sec; 0.290 sec/batch)\n",
      "2017-05-30 10:12:10.469564: step 19310, loss = 0.11 (960.1 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 10:12:13.004989: step 19320, loss = 0.16 (1009.7 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:12:15.599002: step 19330, loss = 0.14 (986.9 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:12:21.705905: step 19350, loss = 0.11 (793.8 examples/sec; 0.323 sec/batch)\n",
      "2017-05-30 10:12:24.724156: step 19360, loss = 0.13 (848.2 examples/sec; 0.302 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.40418\n",
      "2017-05-30 10:12:29.328065: step 19370, loss = 0.20 (556.0 examples/sec; 0.460 sec/batch)\n",
      "2017-05-30 10:12:31.527487: step 19380, loss = 0.14 (1163.9 examples/sec; 0.220 sec/batch)\n",
      "2017-05-30 10:12:34.058337: step 19390, loss = 0.17 (1011.5 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 10:12:36.971716: step 19400, loss = 0.21 (878.7 examples/sec; 0.291 sec/batch)\n",
      "2017-05-30 10:12:39.828604: step 19410, loss = 0.16 (896.1 examples/sec; 0.286 sec/batch)\n",
      "2017-05-30 10:12:42.367658: step 19420, loss = 0.17 (1008.2 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:12:45.018824: step 19430, loss = 0.20 (965.6 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 10:12:47.511334: step 19440, loss = 0.14 (1027.1 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:12:52.755642: step 19460, loss = 0.12 (938.2 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 10:12:56.840176: step 19470, loss = 0.15 (626.8 examples/sec; 0.408 sec/batch)\n",
      "2017-05-30 10:12:59.186790: step 19480, loss = 0.10 (1090.9 examples/sec; 0.235 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5021  Precision @ 1 train: 0.9807\n",
      "2017-05-30 10:13:01.965198: step 19490, loss = 0.10 (921.4 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 10:13:05.816246: step 19500, loss = 0.10 (664.8 examples/sec; 0.385 sec/batch)\n",
      "2017-05-30 10:13:09.415831: step 19510, loss = 0.13 (711.2 examples/sec; 0.360 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4461  Precision @ 1 eval: 0.8713\n",
      "INFO:tensorflow:global_step/sec: 2.46276\n",
      "2017-05-30 10:13:12.281789: step 19520, loss = 0.14 (893.2 examples/sec; 0.287 sec/batch)\n",
      "2017-05-30 10:13:14.832008: step 19530, loss = 0.18 (1003.8 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:13:17.290940: step 19540, loss = 0.14 (1041.1 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 10:13:19.948557: step 19550, loss = 0.22 (963.3 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 10:13:25.044765: step 19570, loss = 0.19 (1021.8 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 10:13:27.704809: step 19580, loss = 0.17 (962.4 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 10:13:30.523057: step 19590, loss = 0.13 (908.4 examples/sec; 0.282 sec/batch)\n",
      "2017-05-30 10:13:33.855883: step 19600, loss = 0.10 (768.1 examples/sec; 0.333 sec/batch)\n",
      "2017-05-30 10:13:36.918630: step 19610, loss = 0.19 (835.9 examples/sec; 0.306 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.32074\n",
      "2017-05-30 10:13:42.007831: step 19620, loss = 0.13 (503.0 examples/sec; 0.509 sec/batch)\n",
      "2017-05-30 10:13:44.560075: step 19630, loss = 0.16 (1003.0 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:13:47.149546: step 19640, loss = 0.17 (988.6 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:13:49.777354: step 19650, loss = 0.12 (974.2 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:13:52.252033: step 19660, loss = 0.13 (1034.5 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:13:57.503127: step 19680, loss = 0.15 (966.8 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 10:13:59.998478: step 19690, loss = 0.14 (1025.9 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 10:14:02.675974: step 19700, loss = 0.20 (956.1 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 10:14:05.291275: step 19710, loss = 0.12 (978.9 examples/sec; 0.262 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.66418\n",
      "2017-05-30 10:14:09.230454: step 19720, loss = 0.21 (649.9 examples/sec; 0.394 sec/batch)\n",
      "2017-05-30 10:14:12.157396: step 19730, loss = 0.16 (874.6 examples/sec; 0.293 sec/batch)\n",
      "2017-05-30 10:14:15.224123: step 19740, loss = 0.17 (834.8 examples/sec; 0.307 sec/batch)\n",
      "2017-05-30 10:14:18.410447: step 19750, loss = 0.15 (803.4 examples/sec; 0.319 sec/batch)\n",
      "2017-05-30 10:14:21.403613: step 19760, loss = 0.08 (855.3 examples/sec; 0.299 sec/batch)\n",
      "2017-05-30 10:14:24.102099: step 19770, loss = 0.14 (948.7 examples/sec; 0.270 sec/batch)\n",
      "2017-05-30 10:14:29.196699: step 19790, loss = 0.16 (1014.4 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:14:31.808446: step 19800, loss = 0.11 (980.2 examples/sec; 0.261 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 10:14:34.448419: step 19810, loss = 0.17 (969.7 examples/sec; 0.264 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.41899\n",
      "2017-05-30 10:14:38.352250: step 19820, loss = 0.20 (655.8 examples/sec; 0.390 sec/batch)\n",
      "2017-05-30 10:14:41.338034: step 19830, loss = 0.19 (857.4 examples/sec; 0.299 sec/batch)\n",
      "2017-05-30 10:14:45.085743: step 19840, loss = 0.17 (683.1 examples/sec; 0.375 sec/batch)\n",
      "2017-05-30 10:14:48.166396: step 19850, loss = 0.12 (831.0 examples/sec; 0.308 sec/batch)\n",
      "2017-05-30 10:14:50.983521: step 19860, loss = 0.13 (908.7 examples/sec; 0.282 sec/batch)\n",
      "2017-05-30 10:14:53.630054: step 19870, loss = 0.15 (967.3 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 10:14:56.112094: step 19880, loss = 0.12 (1031.4 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:15:01.080866: step 19900, loss = 0.14 (1043.8 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 10:15:03.568824: step 19910, loss = 0.10 (1029.0 examples/sec; 0.249 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.40041\n",
      "2017-05-30 10:15:07.998183: step 19920, loss = 0.18 (578.0 examples/sec; 0.443 sec/batch)\n",
      "2017-05-30 10:15:11.020699: step 19930, loss = 0.22 (847.0 examples/sec; 0.302 sec/batch)\n",
      "2017-05-30 10:15:13.940390: step 19940, loss = 0.21 (876.8 examples/sec; 0.292 sec/batch)\n",
      "2017-05-30 10:15:16.551951: step 19950, loss = 0.18 (980.3 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:15:19.142726: step 19960, loss = 0.16 (988.1 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:15:21.775705: step 19970, loss = 0.16 (972.3 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:15:24.248631: step 19980, loss = 0.20 (1035.2 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:15:26.772431: step 19990, loss = 0.18 (1014.3 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:15:31.839760: step 20010, loss = 0.11 (1044.6 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 10:15:35.944679: step 20020, loss = 0.11 (623.6 examples/sec; 0.410 sec/batch)\n",
      "2017-05-30 10:15:38.599513: step 20030, loss = 0.13 (964.3 examples/sec; 0.265 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5020  Precision @ 1 train: 0.9805\n",
      "2017-05-30 10:15:41.023298: step 20040, loss = 0.09 (1056.2 examples/sec; 0.242 sec/batch)\n",
      "2017-05-30 10:15:44.058365: step 20050, loss = 0.09 (843.5 examples/sec; 0.304 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4428  Precision @ 1 eval: 0.8648\n",
      "INFO:tensorflow:global_step/sec: 2.55163\n",
      "2017-05-30 10:15:47.226237: step 20060, loss = 0.20 (808.1 examples/sec; 0.317 sec/batch)\n",
      "2017-05-30 10:15:50.459707: step 20070, loss = 0.15 (791.7 examples/sec; 0.323 sec/batch)\n",
      "2017-05-30 10:15:53.446240: step 20080, loss = 0.14 (857.2 examples/sec; 0.299 sec/batch)\n",
      "2017-05-30 10:15:56.093327: step 20090, loss = 0.15 (967.1 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 10:15:58.673203: step 20100, loss = 0.16 (992.3 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:16:01.152896: step 20110, loss = 0.10 (1032.4 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:16:03.799705: step 20120, loss = 0.11 (967.2 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 10:16:06.359575: step 20130, loss = 0.16 (1000.1 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:16:08.849831: step 20140, loss = 0.13 (1028.0 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:16:11.493466: step 20150, loss = 0.19 (968.4 examples/sec; 0.264 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.25148\n",
      "2017-05-30 10:16:17.660851: step 20160, loss = 0.19 (415.1 examples/sec; 0.617 sec/batch)\n",
      "2017-05-30 10:16:20.738269: step 20170, loss = 0.13 (831.9 examples/sec; 0.308 sec/batch)\n",
      "2017-05-30 10:16:23.479399: step 20180, loss = 0.14 (933.9 examples/sec; 0.274 sec/batch)\n",
      "2017-05-30 10:16:26.145200: step 20190, loss = 0.17 (960.3 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 10:16:28.657507: step 20200, loss = 0.14 (1019.0 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 10:16:31.200056: step 20210, loss = 0.10 (1006.9 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:16:36.366100: step 20230, loss = 0.09 (1031.8 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:16:38.909503: step 20240, loss = 0.14 (1006.5 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:16:41.731312: step 20250, loss = 0.19 (907.2 examples/sec; 0.282 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.22592\n",
      "2017-05-30 10:16:48.467101: step 20260, loss = 0.09 (380.1 examples/sec; 0.674 sec/batch)\n",
      "2017-05-30 10:16:51.408172: step 20270, loss = 0.17 (870.4 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 10:16:54.039811: step 20280, loss = 0.10 (972.8 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:16:56.516187: step 20290, loss = 0.17 (1033.8 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:16:59.031567: step 20300, loss = 0.15 (1017.7 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:17:01.666133: step 20310, loss = 0.16 (971.7 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:17:04.232784: step 20320, loss = 0.11 (997.4 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 10:17:09.457727: step 20340, loss = 0.13 (959.9 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 10:17:11.974614: step 20350, loss = 0.13 (1017.1 examples/sec; 0.252 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.51457\n",
      "2017-05-30 10:17:16.788187: step 20360, loss = 0.22 (531.8 examples/sec; 0.481 sec/batch)\n",
      "2017-05-30 10:17:19.474582: step 20370, loss = 0.13 (952.9 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 10:17:21.945788: step 20380, loss = 0.11 (1035.9 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:17:24.606616: step 20390, loss = 0.15 (962.1 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 10:17:27.138711: step 20400, loss = 0.15 (1011.0 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 10:17:29.629253: step 20410, loss = 0.23 (1027.9 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:17:32.272797: step 20420, loss = 0.13 (968.4 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:17:34.859493: step 20430, loss = 0.17 (989.7 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:17:37.337699: step 20440, loss = 0.17 (1033.0 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:17:39.943095: step 20450, loss = 0.14 (982.6 examples/sec; 0.261 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.53972\n",
      "2017-05-30 10:17:45.395188: step 20460, loss = 0.08 (469.5 examples/sec; 0.545 sec/batch)\n",
      "2017-05-30 10:17:48.714771: step 20470, loss = 0.17 (771.2 examples/sec; 0.332 sec/batch)\n",
      "2017-05-30 10:17:51.681117: step 20480, loss = 0.21 (863.0 examples/sec; 0.297 sec/batch)\n",
      "2017-05-30 10:17:54.323496: step 20490, loss = 0.14 (968.8 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:17:56.798757: step 20500, loss = 0.15 (1034.2 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:17:59.348621: step 20510, loss = 0.18 (1004.0 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:18:01.945147: step 20520, loss = 0.11 (985.9 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:18:04.484335: step 20530, loss = 0.13 (1008.2 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:18:07.032751: step 20540, loss = 0.08 (1004.5 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:18:13.358297: step 20560, loss = 0.13 (687.1 examples/sec; 0.373 sec/batch)\n",
      "2017-05-30 10:18:16.442208: step 20570, loss = 0.12 (830.1 examples/sec; 0.308 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5055  Precision @ 1 train: 0.9873\n",
      "2017-05-30 10:18:20.003715: step 20580, loss = 0.14 (718.8 examples/sec; 0.356 sec/batch)\n",
      "2017-05-30 10:18:23.655283: step 20590, loss = 0.10 (701.1 examples/sec; 0.365 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4471  Precision @ 1 eval: 0.8732\n",
      "INFO:tensorflow:global_step/sec: 2.3933\n",
      "2017-05-30 10:18:26.516423: step 20600, loss = 0.13 (894.7 examples/sec; 0.286 sec/batch)\n",
      "2017-05-30 10:18:29.146567: step 20610, loss = 0.17 (973.3 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:18:31.711086: step 20620, loss = 0.12 (998.2 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:18:34.216129: step 20630, loss = 0.16 (1021.9 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 10:18:36.850142: step 20640, loss = 0.19 (971.9 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:18:39.379433: step 20650, loss = 0.20 (1012.1 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 10:18:44.525497: step 20670, loss = 0.11 (963.7 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 10:18:47.282304: step 20680, loss = 0.17 (928.6 examples/sec; 0.276 sec/batch)\n",
      "2017-05-30 10:18:49.974779: step 20690, loss = 0.06 (950.8 examples/sec; 0.269 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.54763\n",
      "2017-05-30 10:18:54.463134: step 20700, loss = 0.15 (570.4 examples/sec; 0.449 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 10:18:57.750595: step 20710, loss = 0.12 (778.7 examples/sec; 0.329 sec/batch)\n",
      "2017-05-30 10:19:00.704331: step 20720, loss = 0.11 (866.7 examples/sec; 0.295 sec/batch)\n",
      "2017-05-30 10:19:03.660984: step 20730, loss = 0.16 (865.8 examples/sec; 0.296 sec/batch)\n",
      "2017-05-30 10:19:06.313986: step 20740, loss = 0.10 (964.9 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 10:19:08.800594: step 20750, loss = 0.13 (1029.5 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:19:11.402278: step 20760, loss = 0.14 (984.0 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:19:16.608888: step 20780, loss = 0.20 (986.9 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:19:19.443093: step 20790, loss = 0.10 (903.3 examples/sec; 0.283 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.31008\n",
      "2017-05-30 10:19:24.682211: step 20800, loss = 0.12 (488.6 examples/sec; 0.524 sec/batch)\n",
      "2017-05-30 10:19:27.787191: step 20810, loss = 0.17 (824.5 examples/sec; 0.310 sec/batch)\n",
      "2017-05-30 10:19:30.653016: step 20820, loss = 0.19 (893.3 examples/sec; 0.287 sec/batch)\n",
      "2017-05-30 10:19:33.308738: step 20830, loss = 0.15 (964.0 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 10:19:35.781071: step 20840, loss = 0.23 (1035.5 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:19:38.259256: step 20850, loss = 0.16 (1033.0 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:19:40.870014: step 20860, loss = 0.09 (980.6 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:19:43.408597: step 20870, loss = 0.13 (1008.4 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:19:48.891243: step 20890, loss = 0.14 (879.3 examples/sec; 0.291 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.44675\n",
      "2017-05-30 10:19:53.541028: step 20900, loss = 0.17 (550.6 examples/sec; 0.465 sec/batch)\n",
      "2017-05-30 10:19:56.117366: step 20910, loss = 0.08 (993.7 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:19:58.682210: step 20920, loss = 0.12 (998.1 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:20:01.174826: step 20930, loss = 0.22 (1027.0 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:20:03.766543: step 20940, loss = 0.16 (987.8 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:20:06.355445: step 20950, loss = 0.14 (988.8 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:20:08.842623: step 20960, loss = 0.11 (1029.3 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:20:11.434374: step 20970, loss = 0.14 (987.7 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:20:14.050583: step 20980, loss = 0.17 (978.5 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:20:16.520429: step 20990, loss = 0.18 (1036.5 examples/sec; 0.247 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.62118\n",
      "2017-05-30 10:20:21.326436: step 21000, loss = 0.14 (532.7 examples/sec; 0.481 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 19408 into /home/ipython/cnn-cifar10/tb_log/vggA/train/model.ckpt.\n",
      "2017-05-30 10:20:25.267240: step 21010, loss = 0.13 (649.6 examples/sec; 0.394 sec/batch)\n",
      "2017-05-30 10:20:28.296473: step 21020, loss = 0.16 (845.1 examples/sec; 0.303 sec/batch)\n",
      "2017-05-30 10:20:31.164678: step 21030, loss = 0.17 (892.5 examples/sec; 0.287 sec/batch)\n",
      "2017-05-30 10:20:33.797489: step 21040, loss = 0.16 (972.3 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:20:36.271424: step 21050, loss = 0.15 (1034.8 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:20:38.842230: step 21060, loss = 0.18 (995.8 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 10:20:41.551635: step 21070, loss = 0.09 (944.9 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 10:20:44.036272: step 21080, loss = 0.12 (1030.3 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:20:46.580236: step 21090, loss = 0.16 (1006.3 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:20:51.737546: step 21100, loss = 0.10 (496.4 examples/sec; 0.516 sec/batch)\n",
      "2017-05-30 10:20:56.020056: step 21110, loss = 0.12 (597.8 examples/sec; 0.428 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5031  Precision @ 1 train: 0.9826\n",
      "2017-05-30 10:20:58.950038: step 21120, loss = 0.14 (873.7 examples/sec; 0.293 sec/batch)\n",
      "2017-05-30 10:21:01.598535: step 21130, loss = 0.18 (966.6 examples/sec; 0.265 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4457  Precision @ 1 eval: 0.8705\n",
      "INFO:tensorflow:global_step/sec: 2.32285\n",
      "2017-05-30 10:21:04.044459: step 21140, loss = 0.09 (1046.6 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 10:21:06.569029: step 21150, loss = 0.14 (1014.0 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:21:09.190216: step 21160, loss = 0.11 (976.7 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:21:11.724850: step 21170, loss = 0.16 (1010.0 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 10:21:14.240109: step 21180, loss = 0.10 (1017.8 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:21:16.975410: step 21190, loss = 0.17 (935.9 examples/sec; 0.274 sec/batch)\n",
      "2017-05-30 10:21:19.567492: step 21200, loss = 0.13 (987.6 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:21:25.372164: step 21220, loss = 0.12 (864.8 examples/sec; 0.296 sec/batch)\n",
      "2017-05-30 10:21:27.915911: step 21230, loss = 0.23 (1006.4 examples/sec; 0.254 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.56931\n",
      "2017-05-30 10:21:31.897745: step 21240, loss = 0.18 (642.9 examples/sec; 0.398 sec/batch)\n",
      "2017-05-30 10:21:34.555692: step 21250, loss = 0.13 (963.1 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 10:21:37.030359: step 21260, loss = 0.14 (1034.5 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:21:39.574846: step 21270, loss = 0.10 (1006.1 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:21:42.294593: step 21280, loss = 0.15 (941.3 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 10:21:45.716685: step 21290, loss = 0.14 (748.1 examples/sec; 0.342 sec/batch)\n",
      "2017-05-30 10:21:48.725006: step 21300, loss = 0.11 (851.0 examples/sec; 0.301 sec/batch)\n",
      "2017-05-30 10:21:51.720146: step 21310, loss = 0.17 (854.7 examples/sec; 0.300 sec/batch)\n",
      "2017-05-30 10:21:57.258317: step 21330, loss = 0.23 (983.8 examples/sec; 0.260 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.3724\n",
      "2017-05-30 10:22:01.458780: step 21340, loss = 0.11 (609.5 examples/sec; 0.420 sec/batch)\n",
      "2017-05-30 10:22:04.622330: step 21350, loss = 0.17 (809.2 examples/sec; 0.316 sec/batch)\n",
      "2017-05-30 10:22:07.693476: step 21360, loss = 0.13 (833.6 examples/sec; 0.307 sec/batch)\n",
      "2017-05-30 10:22:10.575971: step 21370, loss = 0.17 (888.1 examples/sec; 0.288 sec/batch)\n",
      "2017-05-30 10:22:13.287290: step 21380, loss = 0.17 (944.2 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 10:22:15.797782: step 21390, loss = 0.09 (1019.7 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 10:22:18.296386: step 21400, loss = 0.14 (1024.6 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 10:22:21.015979: step 21410, loss = 0.13 (941.3 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 10:22:23.859070: step 21420, loss = 0.09 (900.4 examples/sec; 0.284 sec/batch)\n",
      "2017-05-30 10:22:26.699216: step 21430, loss = 0.11 (901.4 examples/sec; 0.284 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.3441\n",
      "2017-05-30 10:22:31.399805: step 21440, loss = 0.09 (544.6 examples/sec; 0.470 sec/batch)\n",
      "2017-05-30 10:22:34.551230: step 21450, loss = 0.11 (812.3 examples/sec; 0.315 sec/batch)\n",
      "2017-05-30 10:22:37.562823: step 21460, loss = 0.16 (850.0 examples/sec; 0.301 sec/batch)\n",
      "2017-05-30 10:22:40.201037: step 21470, loss = 0.14 (970.4 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:22:42.817966: step 21480, loss = 0.19 (978.2 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:22:45.279674: step 21490, loss = 0.12 (1039.9 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 10:22:47.875770: step 21500, loss = 0.09 (986.1 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:22:50.491123: step 21510, loss = 0.10 (978.8 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:22:53.246916: step 21520, loss = 0.10 (929.0 examples/sec; 0.276 sec/batch)\n",
      "2017-05-30 10:22:56.122410: step 21530, loss = 0.14 (890.3 examples/sec; 0.288 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.48428\n",
      "2017-05-30 10:23:00.090924: step 21540, loss = 0.11 (645.1 examples/sec; 0.397 sec/batch)\n",
      "2017-05-30 10:23:02.627000: step 21550, loss = 0.13 (1009.4 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:23:05.267171: step 21560, loss = 0.19 (969.6 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:23:07.803901: step 21570, loss = 0.08 (1009.2 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:23:10.247384: step 21580, loss = 0.13 (1047.7 examples/sec; 0.244 sec/batch)\n",
      "2017-05-30 10:23:12.907453: step 21590, loss = 0.15 (962.4 examples/sec; 0.266 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 10:23:15.914400: step 21600, loss = 0.17 (851.4 examples/sec; 0.301 sec/batch)\n",
      "2017-05-30 10:23:19.149895: step 21610, loss = 0.14 (791.2 examples/sec; 0.324 sec/batch)\n",
      "2017-05-30 10:23:22.239486: step 21620, loss = 0.17 (828.6 examples/sec; 0.309 sec/batch)\n",
      "2017-05-30 10:23:25.230951: step 21630, loss = 0.09 (855.8 examples/sec; 0.299 sec/batch)\n",
      "2017-05-30 10:23:32.000509: step 21650, loss = 0.08 (930.1 examples/sec; 0.275 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5036  Precision @ 1 train: 0.9836\n",
      "2017-05-30 10:23:34.560345: step 21660, loss = 0.11 (1000.1 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:23:36.981102: step 21670, loss = 0.15 (1057.5 examples/sec; 0.242 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4434  Precision @ 1 eval: 0.8660\n",
      "INFO:tensorflow:global_step/sec: 2.52126\n",
      "2017-05-30 10:23:39.438497: step 21680, loss = 0.12 (1041.8 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 10:23:42.071571: step 21690, loss = 0.16 (972.2 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:23:44.549212: step 21700, loss = 0.14 (1033.2 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:23:47.017995: step 21710, loss = 0.09 (1036.9 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:23:49.688127: step 21720, loss = 0.10 (958.8 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 10:23:52.208106: step 21730, loss = 0.16 (1015.9 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:23:55.026509: step 21740, loss = 0.12 (908.3 examples/sec; 0.282 sec/batch)\n",
      "2017-05-30 10:23:57.951803: step 21750, loss = 0.11 (875.1 examples/sec; 0.293 sec/batch)\n",
      "2017-05-30 10:24:04.507415: step 21770, loss = 0.13 (824.0 examples/sec; 0.311 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.36709\n",
      "2017-05-30 10:24:09.137712: step 21780, loss = 0.19 (552.9 examples/sec; 0.463 sec/batch)\n",
      "2017-05-30 10:24:11.408473: step 21790, loss = 0.12 (1127.4 examples/sec; 0.227 sec/batch)\n",
      "2017-05-30 10:24:13.886300: step 21800, loss = 0.10 (1033.2 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:24:16.490517: step 21810, loss = 0.16 (983.0 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:24:19.045046: step 21820, loss = 0.09 (1002.1 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:24:21.497434: step 21830, loss = 0.11 (1043.9 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 10:24:24.251136: step 21840, loss = 0.13 (929.7 examples/sec; 0.275 sec/batch)\n",
      "2017-05-30 10:24:27.477783: step 21850, loss = 0.12 (793.4 examples/sec; 0.323 sec/batch)\n",
      "2017-05-30 10:24:31.068937: step 21860, loss = 0.11 (712.9 examples/sec; 0.359 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.38361\n",
      "2017-05-30 10:24:38.691885: step 21880, loss = 0.15 (570.9 examples/sec; 0.448 sec/batch)\n",
      "2017-05-30 10:24:40.854389: step 21890, loss = 0.12 (1183.8 examples/sec; 0.216 sec/batch)\n",
      "2017-05-30 10:24:43.409650: step 21900, loss = 0.09 (1001.9 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:24:46.081382: step 21910, loss = 0.11 (958.2 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 10:24:48.529026: step 21920, loss = 0.14 (1045.9 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 10:24:51.037349: step 21930, loss = 0.13 (1020.6 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 10:24:53.735163: step 21940, loss = 0.10 (948.9 examples/sec; 0.270 sec/batch)\n",
      "2017-05-30 10:24:56.633622: step 21950, loss = 0.16 (883.2 examples/sec; 0.290 sec/batch)\n",
      "2017-05-30 10:24:59.513930: step 21960, loss = 0.12 (888.8 examples/sec; 0.288 sec/batch)\n",
      "2017-05-30 10:25:02.171482: step 21970, loss = 0.12 (963.3 examples/sec; 0.266 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.43257\n",
      "2017-05-30 10:25:07.824214: step 21980, loss = 0.16 (452.9 examples/sec; 0.565 sec/batch)\n",
      "2017-05-30 10:25:09.990644: step 21990, loss = 0.17 (1181.7 examples/sec; 0.217 sec/batch)\n",
      "2017-05-30 10:25:12.456623: step 22000, loss = 0.14 (1038.1 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:25:15.064118: step 22010, loss = 0.10 (981.8 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:25:18.013302: step 22020, loss = 0.15 (868.0 examples/sec; 0.295 sec/batch)\n",
      "2017-05-30 10:25:20.649946: step 22030, loss = 0.16 (970.9 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:25:23.262006: step 22040, loss = 0.12 (980.1 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:25:26.184424: step 22050, loss = 0.09 (876.0 examples/sec; 0.292 sec/batch)\n",
      "2017-05-30 10:25:29.125488: step 22060, loss = 0.11 (870.4 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 10:25:31.837824: step 22070, loss = 0.13 (943.8 examples/sec; 0.271 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.48395\n",
      "2017-05-30 10:25:38.812988: step 22090, loss = 0.20 (1120.2 examples/sec; 0.229 sec/batch)\n",
      "2017-05-30 10:25:41.246529: step 22100, loss = 0.09 (1052.0 examples/sec; 0.243 sec/batch)\n",
      "2017-05-30 10:25:43.873572: step 22110, loss = 0.12 (974.5 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:25:46.759545: step 22120, loss = 0.12 (887.0 examples/sec; 0.289 sec/batch)\n",
      "2017-05-30 10:25:49.211509: step 22130, loss = 0.15 (1044.1 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 10:25:51.762683: step 22140, loss = 0.11 (1003.5 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:25:54.575294: step 22150, loss = 0.14 (910.2 examples/sec; 0.281 sec/batch)\n",
      "2017-05-30 10:25:57.399142: step 22160, loss = 0.11 (906.6 examples/sec; 0.282 sec/batch)\n",
      "2017-05-30 10:26:00.314354: step 22170, loss = 0.13 (878.2 examples/sec; 0.292 sec/batch)\n",
      "2017-05-30 10:26:06.348008: step 22180, loss = 0.14 (424.3 examples/sec; 0.603 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5028  Precision @ 1 train: 0.9820\n",
      "2017-05-30 10:26:12.008509: step 22200, loss = 0.14 (916.5 examples/sec; 0.279 sec/batch)\n",
      "2017-05-30 10:26:15.017168: step 22210, loss = 0.19 (850.9 examples/sec; 0.301 sec/batch)\n",
      "2017-05-30 10:26:17.420145: step 22220, loss = 0.11 (1065.3 examples/sec; 0.240 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4440  Precision @ 1 eval: 0.8672\n",
      "INFO:tensorflow:global_step/sec: 2.40793\n",
      "2017-05-30 10:26:20.196869: step 22230, loss = 0.11 (922.0 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 10:26:22.751778: step 22240, loss = 0.12 (1002.0 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:26:25.374217: step 22250, loss = 0.15 (976.2 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:26:28.322300: step 22260, loss = 0.10 (868.4 examples/sec; 0.295 sec/batch)\n",
      "2017-05-30 10:26:31.511209: step 22270, loss = 0.14 (802.8 examples/sec; 0.319 sec/batch)\n",
      "2017-05-30 10:26:34.923045: step 22280, loss = 0.15 (750.3 examples/sec; 0.341 sec/batch)\n",
      "2017-05-30 10:26:38.025562: step 22290, loss = 0.11 (825.1 examples/sec; 0.310 sec/batch)\n",
      "2017-05-30 10:26:43.220590: step 22310, loss = 0.10 (995.1 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 10:26:45.773654: step 22320, loss = 0.10 (1002.7 examples/sec; 0.255 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.31199\n",
      "2017-05-30 10:26:50.034232: step 22330, loss = 0.12 (600.9 examples/sec; 0.426 sec/batch)\n",
      "2017-05-30 10:26:52.671991: step 22340, loss = 0.14 (970.5 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:26:55.208225: step 22350, loss = 0.15 (1009.4 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:26:58.268738: step 22360, loss = 0.18 (836.5 examples/sec; 0.306 sec/batch)\n",
      "2017-05-30 10:27:02.129402: step 22370, loss = 0.19 (663.1 examples/sec; 0.386 sec/batch)\n",
      "2017-05-30 10:27:05.438860: step 22380, loss = 0.14 (773.5 examples/sec; 0.331 sec/batch)\n",
      "2017-05-30 10:27:08.220760: step 22390, loss = 0.16 (920.2 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 10:27:10.769496: step 22400, loss = 0.16 (1004.4 examples/sec; 0.255 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.33282\n",
      "2017-05-30 10:27:19.967746: step 22430, loss = 0.09 (614.0 examples/sec; 0.417 sec/batch)\n",
      "2017-05-30 10:27:22.490579: step 22440, loss = 0.14 (1014.7 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:27:25.171579: step 22450, loss = 0.16 (954.9 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 10:27:27.985329: step 22460, loss = 0.16 (909.8 examples/sec; 0.281 sec/batch)\n",
      "2017-05-30 10:27:30.714765: step 22470, loss = 0.19 (937.9 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 10:27:33.430404: step 22480, loss = 0.11 (942.7 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 10:27:35.899356: step 22490, loss = 0.08 (1036.9 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:27:38.314720: step 22500, loss = 0.16 (1059.9 examples/sec; 0.242 sec/batch)\n",
      "2017-05-30 10:27:40.924251: step 22510, loss = 0.11 (981.0 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:27:43.867481: step 22520, loss = 0.09 (869.8 examples/sec; 0.294 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 10:27:49.367929: step 22530, loss = 0.17 (465.4 examples/sec; 0.550 sec/batch)\n",
      "2017-05-30 10:27:52.071367: step 22540, loss = 0.11 (946.9 examples/sec; 0.270 sec/batch)\n",
      "2017-05-30 10:27:54.664737: step 22550, loss = 0.16 (987.1 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:27:57.239575: step 22560, loss = 0.15 (994.2 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 10:28:00.071707: step 22570, loss = 0.12 (903.9 examples/sec; 0.283 sec/batch)\n",
      "2017-05-30 10:28:03.018807: step 22580, loss = 0.11 (868.7 examples/sec; 0.295 sec/batch)\n",
      "2017-05-30 10:28:05.507671: step 22590, loss = 0.10 (1028.6 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:28:08.116123: step 22600, loss = 0.09 (981.4 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:28:10.704897: step 22610, loss = 0.13 (988.9 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:28:13.174290: step 22620, loss = 0.14 (1036.7 examples/sec; 0.247 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.559\n",
      "2017-05-30 10:28:17.228769: step 22630, loss = 0.11 (631.4 examples/sec; 0.405 sec/batch)\n",
      "2017-05-30 10:28:19.777657: step 22640, loss = 0.16 (1004.4 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:28:22.265359: step 22650, loss = 0.07 (1029.1 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:28:24.886760: step 22660, loss = 0.19 (976.6 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:28:27.483297: step 22670, loss = 0.13 (985.9 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:28:30.158460: step 22680, loss = 0.09 (957.0 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 10:28:33.076858: step 22690, loss = 0.15 (877.2 examples/sec; 0.292 sec/batch)\n",
      "2017-05-30 10:28:35.681951: step 22700, loss = 0.09 (982.7 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:28:38.112542: step 22710, loss = 0.09 (1053.2 examples/sec; 0.243 sec/batch)\n",
      "2017-05-30 10:28:40.726416: step 22720, loss = 0.12 (979.4 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:28:45.857723: step 22730, loss = 0.15 (498.9 examples/sec; 0.513 sec/batch)\n",
      "2017-05-30 10:28:49.163982: step 22740, loss = 0.15 (774.3 examples/sec; 0.331 sec/batch)\n",
      "2017-05-30 10:28:51.920191: step 22750, loss = 0.17 (928.8 examples/sec; 0.276 sec/batch)\n",
      "2017-05-30 10:28:54.571505: step 22760, loss = 0.12 (965.6 examples/sec; 0.265 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4427  Precision @ 1 eval: 0.8646\n",
      "INFO:tensorflow:global_step/sec: 2.50028\n",
      "2017-05-30 10:28:56.995695: step 22770, loss = 0.12 (1056.0 examples/sec; 0.242 sec/batch)\n",
      "2017-05-30 10:28:59.681595: step 22780, loss = 0.13 (953.1 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 10:29:03.002813: step 22790, loss = 0.12 (770.8 examples/sec; 0.332 sec/batch)\n",
      "2017-05-30 10:29:06.875353: step 22800, loss = 0.16 (661.1 examples/sec; 0.387 sec/batch)\n",
      "2017-05-30 10:29:09.794102: step 22810, loss = 0.11 (877.1 examples/sec; 0.292 sec/batch)\n",
      "2017-05-30 10:29:12.509232: step 22820, loss = 0.13 (942.9 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 10:29:15.071708: step 22830, loss = 0.12 (999.0 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:29:17.623178: step 22840, loss = 0.16 (1003.3 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:29:20.185826: step 22850, loss = 0.07 (999.0 examples/sec; 0.256 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.34814\n",
      "2017-05-30 10:29:26.545060: step 22870, loss = 0.13 (681.9 examples/sec; 0.375 sec/batch)\n",
      "2017-05-30 10:29:29.234843: step 22880, loss = 0.15 (951.7 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 10:29:32.679737: step 22890, loss = 0.11 (743.1 examples/sec; 0.344 sec/batch)\n",
      "2017-05-30 10:29:36.223587: step 22900, loss = 0.13 (722.4 examples/sec; 0.354 sec/batch)\n",
      "2017-05-30 10:29:39.369034: step 22910, loss = 0.14 (813.9 examples/sec; 0.315 sec/batch)\n",
      "2017-05-30 10:29:41.987452: step 22920, loss = 0.12 (977.7 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:29:44.507282: step 22930, loss = 0.13 (1015.9 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:29:46.968949: step 22940, loss = 0.12 (1039.9 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 10:29:49.547360: step 22950, loss = 0.16 (992.9 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:29:52.016459: step 22960, loss = 0.10 (1036.8 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:29:56.009374: step 22970, loss = 0.07 (641.1 examples/sec; 0.399 sec/batch)\n",
      "2017-05-30 10:29:58.645481: step 22980, loss = 0.16 (971.1 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:30:01.183146: step 22990, loss = 0.10 (1008.8 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:30:04.039192: step 23000, loss = 0.12 (896.3 examples/sec; 0.286 sec/batch)\n",
      "2017-05-30 10:30:07.130976: step 23010, loss = 0.13 (828.0 examples/sec; 0.309 sec/batch)\n",
      "2017-05-30 10:30:10.620237: step 23020, loss = 0.10 (733.7 examples/sec; 0.349 sec/batch)\n",
      "2017-05-30 10:30:13.615136: step 23030, loss = 0.08 (854.8 examples/sec; 0.299 sec/batch)\n",
      "2017-05-30 10:30:16.328744: step 23040, loss = 0.15 (943.4 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 10:30:19.592470: step 23050, loss = 0.13 (784.4 examples/sec; 0.326 sec/batch)\n",
      "2017-05-30 10:30:22.145424: step 23060, loss = 0.09 (1002.8 examples/sec; 0.255 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 21298 into /home/ipython/cnn-cifar10/tb_log/vggA/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.00748\n",
      "2017-05-30 10:30:29.192371: step 23070, loss = 0.09 (363.3 examples/sec; 0.705 sec/batch)\n",
      "2017-05-30 10:30:32.658360: step 23080, loss = 0.12 (738.6 examples/sec; 0.347 sec/batch)\n",
      "2017-05-30 10:30:35.485357: step 23090, loss = 0.11 (905.6 examples/sec; 0.283 sec/batch)\n",
      "2017-05-30 10:30:38.091713: step 23100, loss = 0.11 (982.2 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:30:40.685560: step 23110, loss = 0.15 (987.0 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:30:43.294807: step 23120, loss = 0.08 (981.1 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:30:45.752129: step 23130, loss = 0.16 (1041.8 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 10:30:48.324753: step 23140, loss = 0.10 (995.1 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 10:30:50.921170: step 23150, loss = 0.14 (986.0 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:30:53.436288: step 23160, loss = 0.12 (1017.8 examples/sec; 0.252 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.54553\n",
      "2017-05-30 10:31:03.903830: step 23190, loss = 0.10 (736.4 examples/sec; 0.348 sec/batch)\n",
      "2017-05-30 10:31:07.148499: step 23200, loss = 0.12 (789.0 examples/sec; 0.324 sec/batch)\n",
      "2017-05-30 10:31:10.009978: step 23210, loss = 0.15 (894.6 examples/sec; 0.286 sec/batch)\n",
      "2017-05-30 10:31:12.515826: step 23220, loss = 0.13 (1021.6 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 10:31:15.002045: step 23230, loss = 0.12 (1029.7 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:31:17.585861: step 23240, loss = 0.13 (990.8 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:31:20.060849: step 23250, loss = 0.12 (1034.3 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:31:22.539536: step 23260, loss = 0.14 (1032.8 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:31:26.590156: step 23270, loss = 0.14 (632.0 examples/sec; 0.405 sec/batch)\n",
      "2017-05-30 10:31:29.116817: step 23280, loss = 0.08 (1013.2 examples/sec; 0.253 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5034  Precision @ 1 train: 0.9832\n",
      "2017-05-30 10:31:31.749533: step 23290, loss = 0.09 (972.4 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:31:34.906767: step 23300, loss = 0.09 (810.8 examples/sec; 0.316 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4416  Precision @ 1 eval: 0.8625\n",
      "INFO:tensorflow:global_step/sec: 2.43045\n",
      "2017-05-30 10:31:38.785759: step 23310, loss = 0.12 (660.0 examples/sec; 0.388 sec/batch)\n",
      "2017-05-30 10:31:42.049415: step 23320, loss = 0.21 (784.4 examples/sec; 0.326 sec/batch)\n",
      "2017-05-30 10:31:45.199502: step 23330, loss = 0.11 (812.7 examples/sec; 0.315 sec/batch)\n",
      "2017-05-30 10:31:47.714261: step 23340, loss = 0.17 (1018.0 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 10:31:50.148966: step 23350, loss = 0.13 (1051.5 examples/sec; 0.243 sec/batch)\n",
      "2017-05-30 10:31:52.732161: step 23360, loss = 0.16 (991.0 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:31:55.270359: step 23370, loss = 0.07 (1008.6 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:31:57.829623: step 23380, loss = 0.09 (1000.3 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:32:00.362587: step 23390, loss = 0.10 (1010.7 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 10:32:03.054531: step 23400, loss = 0.14 (951.0 examples/sec; 0.269 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.38691\n",
      "2017-05-30 10:32:07.649995: step 23410, loss = 0.12 (557.1 examples/sec; 0.460 sec/batch)\n",
      "2017-05-30 10:32:10.332542: step 23420, loss = 0.14 (954.3 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 10:32:12.824763: step 23430, loss = 0.10 (1027.2 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:32:15.287118: step 23440, loss = 0.14 (1039.7 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 10:32:17.849508: step 23450, loss = 0.16 (999.1 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:32:20.974699: step 23460, loss = 0.11 (819.2 examples/sec; 0.313 sec/batch)\n",
      "2017-05-30 10:32:24.119092: step 23470, loss = 0.10 (814.1 examples/sec; 0.314 sec/batch)\n",
      "2017-05-30 10:32:27.050943: step 23480, loss = 0.13 (873.2 examples/sec; 0.293 sec/batch)\n",
      "2017-05-30 10:32:29.643909: step 23490, loss = 0.16 (987.3 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:32:32.107553: step 23500, loss = 0.12 (1039.1 examples/sec; 0.246 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.45292\n",
      "2017-05-30 10:32:39.530429: step 23520, loss = 0.18 (896.3 examples/sec; 0.286 sec/batch)\n",
      "2017-05-30 10:32:42.082449: step 23530, loss = 0.14 (1003.1 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:32:44.694811: step 23540, loss = 0.13 (980.0 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:32:47.306303: step 23550, loss = 0.09 (980.3 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:32:49.742128: step 23560, loss = 0.14 (1051.0 examples/sec; 0.244 sec/batch)\n",
      "2017-05-30 10:32:52.290935: step 23570, loss = 0.13 (1004.4 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:32:54.986062: step 23580, loss = 0.15 (949.9 examples/sec; 0.270 sec/batch)\n",
      "2017-05-30 10:32:58.375541: step 23590, loss = 0.07 (755.3 examples/sec; 0.339 sec/batch)\n",
      "2017-05-30 10:33:01.281822: step 23600, loss = 0.17 (880.9 examples/sec; 0.291 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.44033\n",
      "2017-05-30 10:33:05.707235: step 23610, loss = 0.06 (578.5 examples/sec; 0.443 sec/batch)\n",
      "2017-05-30 10:33:11.249743: step 23630, loss = 0.20 (944.2 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 10:33:13.897475: step 23640, loss = 0.12 (966.9 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 10:33:16.360499: step 23650, loss = 0.12 (1039.4 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 10:33:18.777437: step 23660, loss = 0.17 (1059.2 examples/sec; 0.242 sec/batch)\n",
      "2017-05-30 10:33:21.398500: step 23670, loss = 0.12 (976.7 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:33:24.428352: step 23680, loss = 0.12 (844.9 examples/sec; 0.303 sec/batch)\n",
      "2017-05-30 10:33:27.595928: step 23690, loss = 0.09 (808.2 examples/sec; 0.317 sec/batch)\n",
      "2017-05-30 10:33:30.535275: step 23700, loss = 0.07 (870.9 examples/sec; 0.294 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.44105\n",
      "2017-05-30 10:33:34.771093: step 23710, loss = 0.13 (604.4 examples/sec; 0.424 sec/batch)\n",
      "2017-05-30 10:33:37.505172: step 23720, loss = 0.12 (936.3 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 10:33:43.031362: step 23740, loss = 0.09 (955.5 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 10:33:45.486161: step 23750, loss = 0.09 (1042.9 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 10:33:47.999891: step 23760, loss = 0.13 (1018.4 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 10:33:50.623968: step 23770, loss = 0.11 (975.6 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:33:53.071146: step 23780, loss = 0.20 (1046.1 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 10:33:55.558844: step 23790, loss = 0.10 (1029.1 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:33:58.139872: step 23800, loss = 0.16 (991.9 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:34:01.814723: step 23810, loss = 0.18 (696.6 examples/sec; 0.367 sec/batch)\n",
      "2017-05-30 10:34:05.496449: step 23820, loss = 0.12 (695.3 examples/sec; 0.368 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5034  Precision @ 1 train: 0.9832\n",
      "2017-05-30 10:34:09.133155: step 23830, loss = 0.10 (703.9 examples/sec; 0.364 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4450  Precision @ 1 eval: 0.8691\n",
      "INFO:tensorflow:global_step/sec: 2.4079\n",
      "2017-05-30 10:34:15.987901: step 23850, loss = 0.09 (848.7 examples/sec; 0.302 sec/batch)\n",
      "2017-05-30 10:34:18.603143: step 23860, loss = 0.11 (978.9 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:34:21.077319: step 23870, loss = 0.10 (1034.7 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:34:23.598266: step 23880, loss = 0.13 (1015.5 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:34:26.210881: step 23890, loss = 0.18 (979.9 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:34:28.672205: step 23900, loss = 0.14 (1040.1 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 10:34:31.110297: step 23910, loss = 0.10 (1050.0 examples/sec; 0.244 sec/batch)\n",
      "2017-05-30 10:34:33.753582: step 23920, loss = 0.13 (968.5 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:34:36.350636: step 23930, loss = 0.16 (985.7 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:34:39.118503: step 23940, loss = 0.15 (924.9 examples/sec; 0.277 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.49867\n",
      "2017-05-30 10:34:44.338121: step 23950, loss = 0.11 (490.5 examples/sec; 0.522 sec/batch)\n",
      "2017-05-30 10:34:47.451773: step 23960, loss = 0.06 (822.2 examples/sec; 0.311 sec/batch)\n",
      "2017-05-30 10:34:50.371584: step 23970, loss = 0.12 (876.8 examples/sec; 0.292 sec/batch)\n",
      "2017-05-30 10:34:52.998645: step 23980, loss = 0.17 (974.5 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:34:55.546069: step 23990, loss = 0.11 (1004.9 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:34:57.966788: step 24000, loss = 0.17 (1057.5 examples/sec; 0.242 sec/batch)\n",
      "2017-05-30 10:35:00.532575: step 24010, loss = 0.09 (997.7 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 10:35:03.112269: step 24020, loss = 0.15 (992.4 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:35:05.562635: step 24030, loss = 0.12 (1044.7 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 10:35:08.299701: step 24040, loss = 0.07 (935.3 examples/sec; 0.274 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.31308\n",
      "2017-05-30 10:35:14.581664: step 24050, loss = 0.12 (407.5 examples/sec; 0.628 sec/batch)\n",
      "2017-05-30 10:35:20.203743: step 24070, loss = 0.10 (940.6 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 10:35:22.842455: step 24080, loss = 0.12 (970.2 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:35:25.287762: step 24090, loss = 0.13 (1046.9 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 10:35:27.796980: step 24100, loss = 0.13 (1020.2 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 10:35:30.392038: step 24110, loss = 0.06 (986.5 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:35:32.866188: step 24120, loss = 0.10 (1034.7 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:35:35.319791: step 24130, loss = 0.10 (1043.4 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 10:35:38.089044: step 24140, loss = 0.17 (924.4 examples/sec; 0.277 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.54177\n",
      "2017-05-30 10:35:42.757369: step 24150, loss = 0.11 (548.4 examples/sec; 0.467 sec/batch)\n",
      "2017-05-30 10:35:45.420421: step 24160, loss = 0.09 (961.3 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 10:35:51.533379: step 24180, loss = 0.20 (803.9 examples/sec; 0.318 sec/batch)\n",
      "2017-05-30 10:35:54.507029: step 24190, loss = 0.12 (860.9 examples/sec; 0.297 sec/batch)\n",
      "2017-05-30 10:35:57.177443: step 24200, loss = 0.14 (958.7 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 10:35:59.712066: step 24210, loss = 0.12 (1010.0 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 10:36:02.148529: step 24220, loss = 0.12 (1050.7 examples/sec; 0.244 sec/batch)\n",
      "2017-05-30 10:36:04.720280: step 24230, loss = 0.15 (995.4 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 10:36:07.302252: step 24240, loss = 0.21 (991.5 examples/sec; 0.258 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.42785\n",
      "2017-05-30 10:36:11.924567: step 24250, loss = 0.12 (553.8 examples/sec; 0.462 sec/batch)\n",
      "2017-05-30 10:36:14.794714: step 24260, loss = 0.12 (891.9 examples/sec; 0.287 sec/batch)\n",
      "2017-05-30 10:36:17.282979: step 24270, loss = 0.10 (1028.8 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:36:19.805192: step 24280, loss = 0.13 (1015.0 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:36:22.399777: step 24290, loss = 0.18 (986.7 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:36:25.620810: step 24300, loss = 0.15 (794.8 examples/sec; 0.322 sec/batch)\n",
      "2017-05-30 10:36:28.688740: step 24310, loss = 0.12 (834.4 examples/sec; 0.307 sec/batch)\n",
      "2017-05-30 10:36:31.524473: step 24320, loss = 0.11 (902.8 examples/sec; 0.284 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 10:36:34.143864: step 24330, loss = 0.09 (977.3 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:36:36.617821: step 24340, loss = 0.10 (1034.8 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:36:40.700981: step 24350, loss = 0.16 (627.0 examples/sec; 0.408 sec/batch)\n",
      "2017-05-30 10:36:44.580691: step 24360, loss = 0.09 (659.8 examples/sec; 0.388 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5043  Precision @ 1 train: 0.9850\n",
      "2017-05-30 10:36:48.381667: step 24370, loss = 0.09 (673.5 examples/sec; 0.380 sec/batch)\n",
      "2017-05-30 10:36:51.419544: step 24380, loss = 0.10 (842.7 examples/sec; 0.304 sec/batch)\n",
      "2017-05-30 10:36:56.496939: step 24400, loss = 0.14 (1027.2 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:36:58.929149: step 24410, loss = 0.12 (1052.5 examples/sec; 0.243 sec/batch)\n",
      "2017-05-30 10:37:01.552752: step 24420, loss = 0.11 (975.8 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:37:04.134970: step 24430, loss = 0.15 (991.4 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:37:06.557606: step 24440, loss = 0.11 (1056.7 examples/sec; 0.242 sec/batch)\n",
      "2017-05-30 10:37:09.104543: step 24450, loss = 0.06 (1005.1 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:37:12.384628: step 24460, loss = 0.12 (780.5 examples/sec; 0.328 sec/batch)\n",
      "2017-05-30 10:37:15.957522: step 24470, loss = 0.17 (716.5 examples/sec; 0.357 sec/batch)\n",
      "2017-05-30 10:37:19.177041: step 24480, loss = 0.11 (795.1 examples/sec; 0.322 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.39359\n",
      "2017-05-30 10:37:23.471245: step 24490, loss = 0.12 (596.2 examples/sec; 0.429 sec/batch)\n",
      "2017-05-30 10:37:28.783317: step 24510, loss = 0.13 (861.0 examples/sec; 0.297 sec/batch)\n",
      "2017-05-30 10:37:31.326192: step 24520, loss = 0.18 (1006.7 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:37:33.780930: step 24530, loss = 0.10 (1042.9 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 10:37:36.307355: step 24540, loss = 0.08 (1013.3 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 10:37:38.862187: step 24550, loss = 0.15 (1002.0 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:37:41.512419: step 24560, loss = 0.11 (966.0 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 10:37:44.325921: step 24570, loss = 0.08 (909.9 examples/sec; 0.281 sec/batch)\n",
      "2017-05-30 10:37:47.169690: step 24580, loss = 0.08 (900.2 examples/sec; 0.284 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.59444\n",
      "2017-05-30 10:37:51.290483: step 24590, loss = 0.12 (621.2 examples/sec; 0.412 sec/batch)\n",
      "2017-05-30 10:37:53.597595: step 24600, loss = 0.12 (1109.6 examples/sec; 0.231 sec/batch)\n",
      "2017-05-30 10:37:56.148772: step 24610, loss = 0.11 (1003.5 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:37:58.562821: step 24620, loss = 0.14 (1060.5 examples/sec; 0.241 sec/batch)\n",
      "2017-05-30 10:38:01.130469: step 24630, loss = 0.08 (997.0 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 10:38:03.707151: step 24640, loss = 0.12 (993.5 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:38:06.147735: step 24650, loss = 0.17 (1048.9 examples/sec; 0.244 sec/batch)\n",
      "2017-05-30 10:38:08.668232: step 24660, loss = 0.12 (1015.7 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:38:11.232088: step 24670, loss = 0.14 (998.5 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:38:13.969824: step 24680, loss = 0.08 (935.1 examples/sec; 0.274 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.63027\n",
      "2017-05-30 10:38:18.837781: step 24690, loss = 0.11 (525.9 examples/sec; 0.487 sec/batch)\n",
      "2017-05-30 10:38:22.135230: step 24700, loss = 0.09 (776.4 examples/sec; 0.330 sec/batch)\n",
      "2017-05-30 10:38:25.163498: step 24710, loss = 0.19 (845.4 examples/sec; 0.303 sec/batch)\n",
      "2017-05-30 10:38:27.916601: step 24720, loss = 0.10 (929.9 examples/sec; 0.275 sec/batch)\n",
      "2017-05-30 10:38:32.973721: step 24740, loss = 0.13 (1039.2 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 10:38:35.481956: step 24750, loss = 0.18 (1020.6 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 10:38:38.105333: step 24760, loss = 0.09 (975.8 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:38:40.569368: step 24770, loss = 0.08 (1038.9 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 10:38:43.250178: step 24780, loss = 0.16 (954.9 examples/sec; 0.268 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.25301\n",
      "2017-05-30 10:38:49.577726: step 24790, loss = 0.09 (404.6 examples/sec; 0.633 sec/batch)\n",
      "2017-05-30 10:38:52.301775: step 24800, loss = 0.08 (939.8 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 10:38:55.159242: step 24810, loss = 0.10 (895.9 examples/sec; 0.286 sec/batch)\n",
      "2017-05-30 10:38:57.759173: step 24820, loss = 0.18 (984.6 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:39:00.283528: step 24830, loss = 0.15 (1014.1 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:39:02.882311: step 24840, loss = 0.14 (985.1 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:39:05.488525: step 24850, loss = 0.08 (982.3 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:39:08.068270: step 24860, loss = 0.10 (992.3 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:39:10.500317: step 24870, loss = 0.14 (1052.6 examples/sec; 0.243 sec/batch)\n",
      "2017-05-30 10:39:13.279504: step 24880, loss = 0.18 (921.1 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 10:39:19.992126: step 24890, loss = 0.14 (381.4 examples/sec; 0.671 sec/batch)\n",
      "2017-05-30 10:39:23.041086: step 24900, loss = 0.10 (839.6 examples/sec; 0.305 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5044  Precision @ 1 train: 0.9852\n",
      "2017-05-30 10:39:25.674764: step 24910, loss = 0.10 (972.0 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:39:28.194515: step 24920, loss = 0.14 (1016.0 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:39:30.602840: step 24930, loss = 0.15 (1063.0 examples/sec; 0.241 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4431  Precision @ 1 eval: 0.8654\n",
      "INFO:tensorflow:global_step/sec: 2.41326\n",
      "2017-05-30 10:39:35.763919: step 24950, loss = 0.09 (967.1 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 10:39:38.473834: step 24960, loss = 0.11 (944.7 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 10:39:41.784341: step 24970, loss = 0.09 (773.3 examples/sec; 0.331 sec/batch)\n",
      "2017-05-30 10:39:45.030684: step 24980, loss = 0.11 (788.6 examples/sec; 0.325 sec/batch)\n",
      "2017-05-30 10:39:48.328285: step 24990, loss = 0.11 (776.3 examples/sec; 0.330 sec/batch)\n",
      "2017-05-30 10:39:51.234104: step 25000, loss = 0.12 (881.0 examples/sec; 0.291 sec/batch)\n",
      "2017-05-30 10:39:53.678014: step 25010, loss = 0.08 (1047.5 examples/sec; 0.244 sec/batch)\n",
      "2017-05-30 10:39:56.232481: step 25020, loss = 0.11 (1002.2 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:39:58.801712: step 25030, loss = 0.17 (996.4 examples/sec; 0.257 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.1929\n",
      "2017-05-30 10:40:04.314599: step 25040, loss = 0.09 (464.4 examples/sec; 0.551 sec/batch)\n",
      "2017-05-30 10:40:07.230954: step 25050, loss = 0.08 (877.8 examples/sec; 0.292 sec/batch)\n",
      "2017-05-30 10:40:09.781939: step 25060, loss = 0.09 (1003.5 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:40:12.314697: step 25070, loss = 0.12 (1010.8 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 10:40:14.899397: step 25080, loss = 0.13 (990.4 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:40:17.848495: step 25090, loss = 0.13 (868.1 examples/sec; 0.295 sec/batch)\n",
      "2017-05-30 10:40:20.687751: step 25100, loss = 0.09 (901.6 examples/sec; 0.284 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 23176 into /home/ipython/cnn-cifar10/tb_log/vggA/train/model.ckpt.\n",
      "2017-05-30 10:40:23.660033: step 25110, loss = 0.11 (861.3 examples/sec; 0.297 sec/batch)\n",
      "2017-05-30 10:40:26.222527: step 25120, loss = 0.14 (999.0 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:40:28.716203: step 25130, loss = 0.08 (1026.6 examples/sec; 0.249 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.51626\n",
      "2017-05-30 10:40:32.585600: step 25140, loss = 0.10 (661.6 examples/sec; 0.387 sec/batch)\n",
      "2017-05-30 10:40:35.179532: step 25150, loss = 0.11 (986.9 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:40:40.161355: step 25170, loss = 0.13 (1021.6 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 10:40:42.781773: step 25180, loss = 0.21 (976.9 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:40:45.396517: step 25190, loss = 0.17 (979.1 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:40:48.221490: step 25200, loss = 0.16 (906.2 examples/sec; 0.282 sec/batch)\n",
      "2017-05-30 10:40:51.101902: step 25210, loss = 0.09 (888.8 examples/sec; 0.288 sec/batch)\n",
      "2017-05-30 10:40:54.549448: step 25220, loss = 0.07 (742.6 examples/sec; 0.345 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 10:40:57.501280: step 25230, loss = 0.14 (867.3 examples/sec; 0.295 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.40563\n",
      "2017-05-30 10:41:01.982849: step 25240, loss = 0.12 (571.2 examples/sec; 0.448 sec/batch)\n",
      "2017-05-30 10:41:04.533819: step 25250, loss = 0.12 (1003.5 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:41:06.971671: step 25260, loss = 0.08 (1050.1 examples/sec; 0.244 sec/batch)\n",
      "2017-05-30 10:41:12.084315: step 25280, loss = 0.13 (1028.7 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:41:14.588741: step 25290, loss = 0.14 (1022.2 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 10:41:17.392651: step 25300, loss = 0.14 (913.0 examples/sec; 0.280 sec/batch)\n",
      "2017-05-30 10:41:20.217377: step 25310, loss = 0.08 (906.3 examples/sec; 0.282 sec/batch)\n",
      "2017-05-30 10:41:22.950865: step 25320, loss = 0.09 (936.5 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 10:41:25.549747: step 25330, loss = 0.12 (985.0 examples/sec; 0.260 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.51875\n",
      "2017-05-30 10:41:30.734383: step 25340, loss = 0.11 (493.8 examples/sec; 0.518 sec/batch)\n",
      "2017-05-30 10:41:33.691043: step 25350, loss = 0.12 (865.8 examples/sec; 0.296 sec/batch)\n",
      "2017-05-30 10:41:36.435195: step 25360, loss = 0.13 (932.9 examples/sec; 0.274 sec/batch)\n",
      "2017-05-30 10:41:39.029487: step 25370, loss = 0.10 (986.8 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:41:43.977441: step 25390, loss = 0.14 (1027.2 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:41:46.641187: step 25400, loss = 0.14 (961.1 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 10:41:49.424938: step 25410, loss = 0.14 (919.6 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 10:41:52.155456: step 25420, loss = 0.12 (937.6 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 10:41:54.962058: step 25430, loss = 0.07 (912.1 examples/sec; 0.281 sec/batch)\n",
      "2017-05-30 10:42:00.577958: step 25440, loss = 0.07 (455.8 examples/sec; 0.562 sec/batch)\n",
      "2017-05-30 10:42:03.756513: step 25450, loss = 0.13 (805.4 examples/sec; 0.318 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5054  Precision @ 1 train: 0.9871\n",
      "2017-05-30 10:42:06.295464: step 25460, loss = 0.09 (1008.3 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:42:08.848342: step 25470, loss = 0.10 (1002.8 examples/sec; 0.255 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4469  Precision @ 1 eval: 0.8729\n",
      "INFO:tensorflow:global_step/sec: 2.42803\n",
      "2017-05-30 10:42:11.225090: step 25480, loss = 0.18 (1077.1 examples/sec; 0.238 sec/batch)\n",
      "2017-05-30 10:42:16.357818: step 25500, loss = 0.09 (1021.4 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 10:42:18.991248: step 25510, loss = 0.09 (972.1 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:42:21.852238: step 25520, loss = 0.12 (894.8 examples/sec; 0.286 sec/batch)\n",
      "2017-05-30 10:42:24.696004: step 25530, loss = 0.09 (900.2 examples/sec; 0.284 sec/batch)\n",
      "2017-05-30 10:42:27.183226: step 25540, loss = 0.13 (1029.3 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:42:29.831002: step 25550, loss = 0.06 (966.8 examples/sec; 0.265 sec/batch)\n",
      "2017-05-30 10:42:32.369022: step 25560, loss = 0.12 (1008.7 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:42:34.805912: step 25570, loss = 0.08 (1050.5 examples/sec; 0.244 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.5919\n",
      "2017-05-30 10:42:38.875288: step 25580, loss = 0.09 (629.1 examples/sec; 0.407 sec/batch)\n",
      "2017-05-30 10:42:41.326639: step 25590, loss = 0.12 (1044.3 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 10:42:43.854930: step 25600, loss = 0.10 (1012.5 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 10:42:46.471200: step 25610, loss = 0.14 (978.5 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:42:49.816448: step 25620, loss = 0.07 (765.3 examples/sec; 0.335 sec/batch)\n",
      "2017-05-30 10:42:53.466361: step 25630, loss = 0.10 (701.4 examples/sec; 0.365 sec/batch)\n",
      "2017-05-30 10:42:56.544641: step 25640, loss = 0.17 (831.6 examples/sec; 0.308 sec/batch)\n",
      "2017-05-30 10:42:59.328293: step 25650, loss = 0.10 (919.7 examples/sec; 0.278 sec/batch)\n",
      "2017-05-30 10:43:01.761819: step 25660, loss = 0.12 (1052.0 examples/sec; 0.243 sec/batch)\n",
      "2017-05-30 10:43:04.273168: step 25670, loss = 0.18 (1019.4 examples/sec; 0.251 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.38176\n",
      "2017-05-30 10:43:08.341828: step 25680, loss = 0.15 (629.2 examples/sec; 0.407 sec/batch)\n",
      "2017-05-30 10:43:10.780586: step 25690, loss = 0.12 (1049.7 examples/sec; 0.244 sec/batch)\n",
      "2017-05-30 10:43:13.369499: step 25700, loss = 0.10 (988.8 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:43:15.902371: step 25710, loss = 0.07 (1010.7 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 10:43:18.383768: step 25720, loss = 0.14 (1031.7 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:43:21.115136: step 25730, loss = 0.08 (937.3 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 10:43:24.432986: step 25740, loss = 0.13 (771.6 examples/sec; 0.332 sec/batch)\n",
      "2017-05-30 10:43:28.011543: step 25750, loss = 0.09 (715.4 examples/sec; 0.358 sec/batch)\n",
      "2017-05-30 10:43:31.079491: step 25760, loss = 0.10 (834.4 examples/sec; 0.307 sec/batch)\n",
      "2017-05-30 10:43:33.681466: step 25770, loss = 0.15 (983.9 examples/sec; 0.260 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.43012\n",
      "2017-05-30 10:43:37.527026: step 25780, loss = 0.12 (665.7 examples/sec; 0.385 sec/batch)\n",
      "2017-05-30 10:43:40.020447: step 25790, loss = 0.11 (1026.7 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:43:42.658223: step 25800, loss = 0.11 (970.5 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:43:45.087767: step 25810, loss = 0.09 (1053.7 examples/sec; 0.243 sec/batch)\n",
      "2017-05-30 10:43:47.561974: step 25820, loss = 0.11 (1034.7 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:43:53.936845: step 25840, loss = 0.16 (698.2 examples/sec; 0.367 sec/batch)\n",
      "2017-05-30 10:43:57.449764: step 25850, loss = 0.11 (728.7 examples/sec; 0.351 sec/batch)\n",
      "2017-05-30 10:44:00.468470: step 25860, loss = 0.15 (848.0 examples/sec; 0.302 sec/batch)\n",
      "2017-05-30 10:44:03.288366: step 25870, loss = 0.08 (907.8 examples/sec; 0.282 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.3788\n",
      "2017-05-30 10:44:07.120922: step 25880, loss = 0.12 (668.0 examples/sec; 0.383 sec/batch)\n",
      "2017-05-30 10:44:09.725093: step 25890, loss = 0.12 (983.0 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:44:12.280026: step 25900, loss = 0.11 (1002.0 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:44:14.744339: step 25910, loss = 0.12 (1038.8 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 10:44:17.313670: step 25920, loss = 0.10 (996.4 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 10:44:19.848748: step 25930, loss = 0.09 (1009.8 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:44:22.559605: step 25940, loss = 0.11 (944.4 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 10:44:25.403418: step 25950, loss = 0.10 (900.2 examples/sec; 0.284 sec/batch)\n",
      "2017-05-30 10:44:28.214793: step 25960, loss = 0.10 (910.6 examples/sec; 0.281 sec/batch)\n",
      "2017-05-30 10:44:30.653341: step 25970, loss = 0.11 (1049.8 examples/sec; 0.244 sec/batch)\n",
      "2017-05-30 10:44:34.812491: step 25980, loss = 0.14 (615.5 examples/sec; 0.416 sec/batch)\n",
      "2017-05-30 10:44:37.394633: step 25990, loss = 0.12 (991.4 examples/sec; 0.258 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5062  Precision @ 1 train: 0.9887\n",
      "2017-05-30 10:44:39.790609: step 26000, loss = 0.06 (1068.5 examples/sec; 0.240 sec/batch)\n",
      "2017-05-30 10:44:42.438490: step 26010, loss = 0.07 (966.8 examples/sec; 0.265 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4449  Precision @ 1 eval: 0.8689\n",
      "INFO:tensorflow:global_step/sec: 2.63244\n",
      "2017-05-30 10:44:44.846531: step 26020, loss = 0.13 (1063.1 examples/sec; 0.241 sec/batch)\n",
      "2017-05-30 10:44:47.287680: step 26030, loss = 0.14 (1048.7 examples/sec; 0.244 sec/batch)\n",
      "2017-05-30 10:44:49.882029: step 26040, loss = 0.08 (986.8 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:44:56.763988: step 26060, loss = 0.12 (721.2 examples/sec; 0.355 sec/batch)\n",
      "2017-05-30 10:44:59.887018: step 26070, loss = 0.07 (819.7 examples/sec; 0.312 sec/batch)\n",
      "2017-05-30 10:45:02.580136: step 26080, loss = 0.11 (950.6 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 10:45:05.118812: step 26090, loss = 0.11 (1008.4 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:45:07.623766: step 26100, loss = 0.16 (1022.0 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 10:45:10.214479: step 26110, loss = 0.17 (988.1 examples/sec; 0.259 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.38534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 10:45:14.114136: step 26120, loss = 0.06 (656.5 examples/sec; 0.390 sec/batch)\n",
      "2017-05-30 10:45:16.673309: step 26130, loss = 0.12 (1000.3 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:45:19.253386: step 26140, loss = 0.16 (992.2 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:45:21.822255: step 26150, loss = 0.10 (996.5 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 10:45:27.653109: step 26170, loss = 0.11 (846.2 examples/sec; 0.303 sec/batch)\n",
      "2017-05-30 10:45:31.210969: step 26180, loss = 0.20 (719.5 examples/sec; 0.356 sec/batch)\n",
      "2017-05-30 10:45:34.163192: step 26190, loss = 0.13 (867.1 examples/sec; 0.295 sec/batch)\n",
      "2017-05-30 10:45:36.872855: step 26200, loss = 0.10 (944.8 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 10:45:39.458548: step 26210, loss = 0.11 (990.1 examples/sec; 0.259 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.43299\n",
      "2017-05-30 10:45:43.248165: step 26220, loss = 0.10 (675.5 examples/sec; 0.379 sec/batch)\n",
      "2017-05-30 10:45:45.865245: step 26230, loss = 0.11 (978.2 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:45:48.415892: step 26240, loss = 0.09 (1003.7 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:45:50.881328: step 26250, loss = 0.11 (1038.4 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:45:53.731687: step 26260, loss = 0.14 (898.1 examples/sec; 0.285 sec/batch)\n",
      "2017-05-30 10:45:59.385932: step 26280, loss = 0.11 (939.6 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 10:46:02.045256: step 26290, loss = 0.09 (962.6 examples/sec; 0.266 sec/batch)\n",
      "2017-05-30 10:46:04.607558: step 26300, loss = 0.09 (999.1 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:46:07.054437: step 26310, loss = 0.15 (1046.2 examples/sec; 0.245 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.57025\n",
      "2017-05-30 10:46:11.309383: step 26320, loss = 0.11 (601.7 examples/sec; 0.425 sec/batch)\n",
      "2017-05-30 10:46:13.888897: step 26330, loss = 0.06 (992.4 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:46:16.402248: step 26340, loss = 0.10 (1018.6 examples/sec; 0.251 sec/batch)\n",
      "2017-05-30 10:46:18.999583: step 26350, loss = 0.17 (985.6 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:46:22.281959: step 26360, loss = 0.13 (779.9 examples/sec; 0.328 sec/batch)\n",
      "2017-05-30 10:46:25.630732: step 26370, loss = 0.10 (764.5 examples/sec; 0.335 sec/batch)\n",
      "2017-05-30 10:46:31.619484: step 26390, loss = 0.11 (881.8 examples/sec; 0.290 sec/batch)\n",
      "2017-05-30 10:46:34.166006: step 26400, loss = 0.11 (1005.3 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:46:36.678671: step 26410, loss = 0.10 (1018.8 examples/sec; 0.251 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.34165\n",
      "2017-05-30 10:46:41.391432: step 26420, loss = 0.16 (543.2 examples/sec; 0.471 sec/batch)\n",
      "2017-05-30 10:46:44.538486: step 26430, loss = 0.12 (813.5 examples/sec; 0.315 sec/batch)\n",
      "2017-05-30 10:46:47.457194: step 26440, loss = 0.09 (877.1 examples/sec; 0.292 sec/batch)\n",
      "2017-05-30 10:46:50.036143: step 26450, loss = 0.13 (992.7 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:46:52.597251: step 26460, loss = 0.15 (999.6 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:46:55.176389: step 26470, loss = 0.09 (992.6 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:46:58.111227: step 26480, loss = 0.08 (872.3 examples/sec; 0.293 sec/batch)\n",
      "2017-05-30 10:47:03.493833: step 26500, loss = 0.16 (981.0 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:47:06.093181: step 26510, loss = 0.10 (984.9 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:47:09.825450: step 26520, loss = 0.06 (685.9 examples/sec; 0.373 sec/batch)\n",
      "2017-05-30 10:47:12.665210: step 26530, loss = 0.13 (901.5 examples/sec; 0.284 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5061  Precision @ 1 train: 0.9885\n",
      "2017-05-30 10:47:15.221906: step 26540, loss = 0.13 (1001.3 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:47:18.889992: step 26550, loss = 0.08 (697.9 examples/sec; 0.367 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4479  Precision @ 1 eval: 0.8748\n",
      "INFO:tensorflow:global_step/sec: 2.44594\n",
      "2017-05-30 10:47:21.963195: step 26560, loss = 0.14 (833.0 examples/sec; 0.307 sec/batch)\n",
      "2017-05-30 10:47:24.762173: step 26570, loss = 0.11 (914.6 examples/sec; 0.280 sec/batch)\n",
      "2017-05-30 10:47:27.622107: step 26580, loss = 0.13 (895.1 examples/sec; 0.286 sec/batch)\n",
      "2017-05-30 10:47:30.371444: step 26590, loss = 0.16 (931.1 examples/sec; 0.275 sec/batch)\n",
      "2017-05-30 10:47:35.825412: step 26610, loss = 0.07 (1000.4 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:47:38.279502: step 26620, loss = 0.12 (1043.2 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 10:47:40.798930: step 26630, loss = 0.06 (1016.1 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:47:43.534393: step 26640, loss = 0.13 (935.9 examples/sec; 0.274 sec/batch)\n",
      "2017-05-30 10:47:45.989412: step 26650, loss = 0.07 (1042.8 examples/sec; 0.246 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.50869\n",
      "2017-05-30 10:47:50.139383: step 26660, loss = 0.10 (616.9 examples/sec; 0.415 sec/batch)\n",
      "2017-05-30 10:47:52.656777: step 26670, loss = 0.11 (1016.9 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:47:55.141881: step 26680, loss = 0.06 (1030.1 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:47:58.129069: step 26690, loss = 0.13 (857.0 examples/sec; 0.299 sec/batch)\n",
      "2017-05-30 10:48:00.914550: step 26700, loss = 0.13 (919.1 examples/sec; 0.279 sec/batch)\n",
      "2017-05-30 10:48:03.714690: step 26710, loss = 0.14 (914.2 examples/sec; 0.280 sec/batch)\n",
      "2017-05-30 10:48:06.341956: step 26720, loss = 0.14 (974.4 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:48:08.870041: step 26730, loss = 0.09 (1012.6 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 10:48:11.361954: step 26740, loss = 0.11 (1027.3 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:48:13.997358: step 26750, loss = 0.09 (971.4 examples/sec; 0.264 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.60422\n",
      "2017-05-30 10:48:17.891747: step 26760, loss = 0.14 (657.4 examples/sec; 0.389 sec/batch)\n",
      "2017-05-30 10:48:20.319740: step 26770, loss = 0.14 (1054.4 examples/sec; 0.243 sec/batch)\n",
      "2017-05-30 10:48:22.934712: step 26780, loss = 0.11 (979.0 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:48:26.106448: step 26790, loss = 0.09 (807.1 examples/sec; 0.317 sec/batch)\n",
      "2017-05-30 10:48:29.508798: step 26800, loss = 0.10 (752.4 examples/sec; 0.340 sec/batch)\n",
      "2017-05-30 10:48:32.727259: step 26810, loss = 0.12 (795.4 examples/sec; 0.322 sec/batch)\n",
      "2017-05-30 10:48:35.606860: step 26820, loss = 0.13 (889.0 examples/sec; 0.288 sec/batch)\n",
      "2017-05-30 10:48:40.684439: step 26840, loss = 0.10 (999.7 examples/sec; 0.256 sec/batch)\n",
      "2017-05-30 10:48:43.341777: step 26850, loss = 0.08 (963.4 examples/sec; 0.266 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.41124\n",
      "2017-05-30 10:48:47.215860: step 26860, loss = 0.11 (660.8 examples/sec; 0.387 sec/batch)\n",
      "2017-05-30 10:48:49.745081: step 26870, loss = 0.12 (1012.2 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 10:48:52.294896: step 26880, loss = 0.07 (1004.0 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:48:54.756416: step 26890, loss = 0.08 (1040.0 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 10:48:57.332004: step 26900, loss = 0.09 (993.9 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:49:00.337825: step 26910, loss = 0.06 (851.7 examples/sec; 0.301 sec/batch)\n",
      "2017-05-30 10:49:04.263188: step 26920, loss = 0.10 (652.2 examples/sec; 0.393 sec/batch)\n",
      "2017-05-30 10:49:07.702392: step 26930, loss = 0.07 (744.4 examples/sec; 0.344 sec/batch)\n",
      "2017-05-30 10:49:10.396291: step 26940, loss = 0.08 (950.3 examples/sec; 0.269 sec/batch)\n",
      "2017-05-30 10:49:12.915177: step 26950, loss = 0.12 (1016.3 examples/sec; 0.252 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.34778\n",
      "2017-05-30 10:49:17.105251: step 26960, loss = 0.12 (611.0 examples/sec; 0.419 sec/batch)\n",
      "2017-05-30 10:49:19.641700: step 26970, loss = 0.11 (1009.3 examples/sec; 0.254 sec/batch)\n",
      "2017-05-30 10:49:22.143714: step 26980, loss = 0.08 (1023.2 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 10:49:24.690921: step 26990, loss = 0.06 (1005.0 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:49:27.311496: step 27000, loss = 0.16 (976.9 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:49:29.792033: step 27010, loss = 0.10 (1032.0 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:49:32.640637: step 27020, loss = 0.13 (898.7 examples/sec; 0.285 sec/batch)\n",
      "2017-05-30 10:49:35.618229: step 27030, loss = 0.09 (859.8 examples/sec; 0.298 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-30 10:49:39.280632: step 27040, loss = 0.13 (699.0 examples/sec; 0.366 sec/batch)\n",
      "2017-05-30 10:49:46.405009: step 27060, loss = 0.07 (613.0 examples/sec; 0.418 sec/batch)\n",
      "2017-05-30 10:49:49.046850: step 27070, loss = 0.10 (969.0 examples/sec; 0.264 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5058  Precision @ 1 train: 0.9879\n",
      "2017-05-30 10:49:51.412751: step 27080, loss = 0.07 (1082.0 examples/sec; 0.237 sec/batch)\n",
      "2017-05-30 10:49:54.054662: step 27090, loss = 0.10 (969.0 examples/sec; 0.264 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4461  Precision @ 1 eval: 0.8713\n",
      "INFO:tensorflow:global_step/sec: 2.51594\n",
      "2017-05-30 10:49:56.554840: step 27100, loss = 0.07 (1023.9 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 10:49:59.002802: step 27110, loss = 0.14 (1045.8 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 10:50:01.960660: step 27120, loss = 0.16 (865.5 examples/sec; 0.296 sec/batch)\n",
      "2017-05-30 10:50:04.779271: step 27130, loss = 0.10 (908.2 examples/sec; 0.282 sec/batch)\n",
      "2017-05-30 10:50:07.491948: step 27140, loss = 0.13 (943.7 examples/sec; 0.271 sec/batch)\n",
      "2017-05-30 10:50:10.099621: step 27150, loss = 0.15 (981.7 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:50:16.272957: step 27170, loss = 0.07 (804.7 examples/sec; 0.318 sec/batch)\n",
      "2017-05-30 10:50:19.203782: step 27180, loss = 0.09 (873.5 examples/sec; 0.293 sec/batch)\n",
      "2017-05-30 10:50:21.827995: step 27190, loss = 0.13 (975.5 examples/sec; 0.262 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 25094 into /home/ipython/cnn-cifar10/tb_log/vggA/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.2741\n",
      "2017-05-30 10:50:27.097738: step 27200, loss = 0.18 (485.8 examples/sec; 0.527 sec/batch)\n",
      "2017-05-30 10:50:29.614075: step 27210, loss = 0.15 (1017.4 examples/sec; 0.252 sec/batch)\n",
      "2017-05-30 10:50:32.282486: step 27220, loss = 0.14 (959.4 examples/sec; 0.267 sec/batch)\n",
      "2017-05-30 10:50:35.054288: step 27230, loss = 0.09 (923.6 examples/sec; 0.277 sec/batch)\n",
      "2017-05-30 10:50:38.285363: step 27240, loss = 0.11 (792.3 examples/sec; 0.323 sec/batch)\n",
      "2017-05-30 10:50:41.099753: step 27250, loss = 0.08 (909.6 examples/sec; 0.281 sec/batch)\n",
      "2017-05-30 10:50:43.735599: step 27260, loss = 0.15 (971.2 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:50:48.760225: step 27280, loss = 0.13 (1012.0 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 10:50:51.372996: step 27290, loss = 0.11 (979.8 examples/sec; 0.261 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.51663\n",
      "2017-05-30 10:50:55.536096: step 27300, loss = 0.11 (614.9 examples/sec; 0.416 sec/batch)\n",
      "2017-05-30 10:50:57.848823: step 27310, loss = 0.15 (1106.9 examples/sec; 0.231 sec/batch)\n",
      "2017-05-30 10:51:00.761134: step 27320, loss = 0.10 (879.0 examples/sec; 0.291 sec/batch)\n",
      "2017-05-30 10:51:04.351445: step 27330, loss = 0.09 (713.0 examples/sec; 0.359 sec/batch)\n",
      "2017-05-30 10:51:07.668793: step 27340, loss = 0.09 (771.7 examples/sec; 0.332 sec/batch)\n",
      "2017-05-30 10:51:10.571037: step 27350, loss = 0.10 (882.1 examples/sec; 0.290 sec/batch)\n",
      "2017-05-30 10:51:13.309728: step 27360, loss = 0.11 (934.8 examples/sec; 0.274 sec/batch)\n",
      "2017-05-30 10:51:15.777779: step 27370, loss = 0.07 (1037.3 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:51:20.935960: step 27390, loss = 0.09 (1019.2 examples/sec; 0.251 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.35887\n",
      "2017-05-30 10:51:25.305980: step 27400, loss = 0.12 (585.8 examples/sec; 0.437 sec/batch)\n",
      "2017-05-30 10:51:27.607009: step 27410, loss = 0.14 (1112.6 examples/sec; 0.230 sec/batch)\n",
      "2017-05-30 10:51:30.042400: step 27420, loss = 0.12 (1051.1 examples/sec; 0.244 sec/batch)\n",
      "2017-05-30 10:51:32.743581: step 27430, loss = 0.12 (947.7 examples/sec; 0.270 sec/batch)\n",
      "2017-05-30 10:51:35.701522: step 27440, loss = 0.07 (865.5 examples/sec; 0.296 sec/batch)\n",
      "2017-05-30 10:51:39.472709: step 27450, loss = 0.19 (678.8 examples/sec; 0.377 sec/batch)\n",
      "2017-05-30 10:51:42.709814: step 27460, loss = 0.17 (790.8 examples/sec; 0.324 sec/batch)\n",
      "2017-05-30 10:51:45.429225: step 27470, loss = 0.10 (941.4 examples/sec; 0.272 sec/batch)\n",
      "2017-05-30 10:51:48.036077: step 27480, loss = 0.10 (982.0 examples/sec; 0.261 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.38551\n",
      "2017-05-30 10:51:54.846410: step 27500, loss = 0.11 (587.1 examples/sec; 0.436 sec/batch)\n",
      "2017-05-30 10:51:57.080847: step 27510, loss = 0.09 (1145.7 examples/sec; 0.223 sec/batch)\n",
      "2017-05-30 10:51:59.540104: step 27520, loss = 0.09 (1041.0 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 10:52:02.177517: step 27530, loss = 0.09 (970.6 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:52:05.117402: step 27540, loss = 0.08 (870.8 examples/sec; 0.294 sec/batch)\n",
      "2017-05-30 10:52:07.853326: step 27550, loss = 0.06 (935.7 examples/sec; 0.274 sec/batch)\n",
      "2017-05-30 10:52:10.682846: step 27560, loss = 0.13 (904.7 examples/sec; 0.283 sec/batch)\n",
      "2017-05-30 10:52:13.183650: step 27570, loss = 0.05 (1023.7 examples/sec; 0.250 sec/batch)\n",
      "2017-05-30 10:52:15.637578: step 27580, loss = 0.14 (1043.2 examples/sec; 0.245 sec/batch)\n",
      "2017-05-30 10:52:18.313727: step 27590, loss = 0.11 (956.6 examples/sec; 0.268 sec/batch)\n",
      "2017-05-30 10:52:24.743100: step 27610, loss = 0.09 (1115.3 examples/sec; 0.230 sec/batch)\n",
      "  Num examples: 5120  Num correct: 5044  Precision @ 1 train: 0.9852\n",
      "2017-05-30 10:52:27.375754: step 27620, loss = 0.10 (972.4 examples/sec; 0.263 sec/batch)\n",
      "2017-05-30 10:52:31.112106: step 27630, loss = 0.15 (685.2 examples/sec; 0.374 sec/batch)\n",
      "2017-05-30 10:52:34.683769: step 27640, loss = 0.11 (716.8 examples/sec; 0.357 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4431  Precision @ 1 eval: 0.8654\n",
      "INFO:tensorflow:global_step/sec: 2.47387\n",
      "2017-05-30 10:52:37.682033: step 27650, loss = 0.11 (853.8 examples/sec; 0.300 sec/batch)\n",
      "2017-05-30 10:52:40.529776: step 27660, loss = 0.12 (899.0 examples/sec; 0.285 sec/batch)\n",
      "2017-05-30 10:52:43.083179: step 27670, loss = 0.06 (1002.6 examples/sec; 0.255 sec/batch)\n",
      "2017-05-30 10:52:45.676067: step 27680, loss = 0.12 (987.3 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:52:48.271565: step 27690, loss = 0.12 (986.3 examples/sec; 0.260 sec/batch)\n",
      "2017-05-30 10:52:50.698370: step 27700, loss = 0.10 (1054.9 examples/sec; 0.243 sec/batch)\n",
      "2017-05-30 10:52:53.271460: step 27710, loss = 0.07 (994.9 examples/sec; 0.257 sec/batch)\n",
      "2017-05-30 10:52:55.974033: step 27720, loss = 0.08 (947.2 examples/sec; 0.270 sec/batch)\n",
      "2017-05-30 10:52:59.288791: step 27730, loss = 0.10 (772.3 examples/sec; 0.331 sec/batch)\n",
      "2017-05-30 10:53:02.309732: step 27740, loss = 0.14 (847.4 examples/sec; 0.302 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.31035\n",
      "2017-05-30 10:53:07.477638: step 27750, loss = 0.13 (495.4 examples/sec; 0.517 sec/batch)\n",
      "2017-05-30 10:53:10.203588: step 27760, loss = 0.07 (939.1 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 10:53:12.843765: step 27770, loss = 0.11 (969.6 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:53:15.426610: step 27780, loss = 0.07 (991.2 examples/sec; 0.258 sec/batch)\n",
      "2017-05-30 10:53:17.909649: step 27790, loss = 0.09 (1031.0 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:53:20.394214: step 27800, loss = 0.06 (1030.4 examples/sec; 0.248 sec/batch)\n",
      "2017-05-30 10:53:22.999682: step 27810, loss = 0.07 (982.5 examples/sec; 0.261 sec/batch)\n",
      "2017-05-30 10:53:27.979571: step 27830, loss = 0.09 (1035.9 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:53:30.604746: step 27840, loss = 0.13 (975.2 examples/sec; 0.263 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.53419\n",
      "2017-05-30 10:53:36.185952: step 27850, loss = 0.08 (458.7 examples/sec; 0.558 sec/batch)\n",
      "2017-05-30 10:53:39.468127: step 27860, loss = 0.04 (780.0 examples/sec; 0.328 sec/batch)\n",
      "2017-05-30 10:53:42.428035: step 27870, loss = 0.09 (864.9 examples/sec; 0.296 sec/batch)\n",
      "2017-05-30 10:53:45.066818: step 27880, loss = 0.10 (970.1 examples/sec; 0.264 sec/batch)\n",
      "2017-05-30 10:53:47.536264: step 27890, loss = 0.09 (1036.7 examples/sec; 0.247 sec/batch)\n",
      "2017-05-30 10:53:50.122909: step 27900, loss = 0.09 (989.7 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:53:52.708469: step 27910, loss = 0.14 (990.1 examples/sec; 0.259 sec/batch)\n",
      "2017-05-30 10:53:55.198226: step 27920, loss = 0.11 (1028.2 examples/sec; 0.249 sec/batch)\n",
      "2017-05-30 10:54:00.360108: step 27940, loss = 0.11 (999.6 examples/sec; 0.256 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.46999\n",
      "2017-05-30 10:54:04.464438: step 27950, loss = 0.07 (623.7 examples/sec; 0.410 sec/batch)\n",
      "2017-05-30 10:54:07.383331: step 27960, loss = 0.13 (877.0 examples/sec; 0.292 sec/batch)\n",
      "2017-05-30 10:54:11.163593: step 27970, loss = 0.12 (677.2 examples/sec; 0.378 sec/batch)\n",
      "2017-05-30 10:54:14.433181: step 27980, loss = 0.11 (783.0 examples/sec; 0.327 sec/batch)\n",
      "2017-05-30 10:54:17.159419: step 27990, loss = 0.14 (939.0 examples/sec; 0.273 sec/batch)\n",
      "2017-05-30 10:54:19.782346: step 28000, loss = 0.06 (976.0 examples/sec; 0.262 sec/batch)\n",
      "2017-05-30 10:54:22.247251: step 28010, loss = 0.13 (1038.6 examples/sec; 0.246 sec/batch)\n",
      "2017-05-30 10:54:24.772296: step 28020, loss = 0.10 (1013.8 examples/sec; 0.253 sec/batch)\n",
      "2017-05-30 10:54:27.354844: step 28030, loss = 0.12 (991.3 examples/sec; 0.258 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.39389\n",
      "2017-05-30 10:54:33.858209: step 28050, loss = 0.11 (636.1 examples/sec; 0.402 sec/batch)\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "Arguments.set_inference(\"vggA\")\n",
    "print(Arguments.train_dir)\n",
    "print(Arguments.eval_dir)\n",
    "print(Arguments.checkpoint_dir)\n",
    "\n",
    "cifar10_train.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
