{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# restart notebook when retrain model as some initial problem\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from cifar10 import cifar10_train\n",
    "from cifar10.cifar10_args import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "/home/ipython/cnn-cifar10/tb_log/test-softmax/train\n",
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "(128,)\n",
      "INFO:tensorflow:Summary name conv1/weight_loss (raw) is illegal; using conv1/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name conv2/weight_loss (raw) is illegal; using conv2/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local3/weight_loss (raw) is illegal; using local3/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local4/weight_loss (raw) is illegal; using local4/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name softmax_linear/weight_loss (raw) is illegal; using softmax_linear/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name cross_entropy (raw) is illegal; using cross_entropy__raw_ instead.\n",
      "INFO:tensorflow:Summary name total_loss (raw) is illegal; using total_loss__raw_ instead.\n",
      "10000000\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /home/ipython/cnn-cifar10/tb_log/test-softmax/train/model.ckpt.\n",
      "2017-05-25 12:20:25.212680: step 0, loss = 4.69 (119.4 examples/sec; 1.072 sec/batch)\n",
      "2017-05-25 12:20:25.880780: step 10, loss = 4.63 (1915.9 examples/sec; 0.067 sec/batch)\n",
      "2017-05-25 12:20:26.659313: step 20, loss = 4.56 (1644.1 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:20:27.440997: step 30, loss = 4.59 (1637.5 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:20:28.214002: step 40, loss = 4.50 (1655.9 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:20:28.994623: step 50, loss = 4.36 (1639.7 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:20:29.779102: step 60, loss = 4.38 (1631.7 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:20:30.587009: step 70, loss = 4.27 (1584.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:20:31.363168: step 80, loss = 4.38 (1649.1 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:20:32.142593: step 90, loss = 4.27 (1642.2 examples/sec; 0.078 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 12.4829\n",
      "2017-05-25 12:20:33.071431: step 100, loss = 4.28 (1378.1 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 12:20:33.731536: step 110, loss = 4.07 (1939.1 examples/sec; 0.066 sec/batch)\n",
      "2017-05-25 12:20:34.507860: step 120, loss = 4.31 (1648.8 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:20:35.276511: step 130, loss = 4.23 (1665.3 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:20:36.052598: step 140, loss = 4.22 (1649.3 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:20:36.871100: step 150, loss = 4.53 (1563.8 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:20:37.652089: step 160, loss = 4.06 (1638.9 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:20:38.426805: step 170, loss = 4.06 (1652.2 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:20:39.209102: step 180, loss = 4.02 (1636.2 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:20:40.011576: step 190, loss = 3.97 (1595.1 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 12.6371\n",
      "2017-05-25 12:20:40.986653: step 200, loss = 3.98 (1312.7 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 12:20:43.172648: step 230, loss = 4.14 (1644.7 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:20:43.952984: step 240, loss = 4.10 (1640.3 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:20:44.721676: step 250, loss = 3.74 (1665.2 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:20:45.504922: step 260, loss = 3.84 (1634.2 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:20:46.282662: step 270, loss = 3.83 (1645.8 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:20:47.074133: step 280, loss = 3.65 (1617.2 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:20:47.858464: step 290, loss = 3.69 (1632.0 examples/sec; 0.078 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 12.801\n",
      "2017-05-25 12:20:48.798304: step 300, loss = 3.77 (1361.9 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:20:49.479673: step 310, loss = 3.74 (1878.6 examples/sec; 0.068 sec/batch)\n",
      "2017-05-25 12:20:50.284129: step 320, loss = 3.65 (1591.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:20:51.052406: step 330, loss = 3.44 (1666.1 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:20:51.843706: step 340, loss = 3.61 (1617.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:20:52.628105: step 350, loss = 3.74 (1631.8 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:20:53.405377: step 360, loss = 3.60 (1646.8 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:20:54.193349: step 370, loss = 3.62 (1624.4 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:20:54.963737: step 380, loss = 3.46 (1661.5 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:20:55.741288: step 390, loss = 3.51 (1646.2 examples/sec; 0.078 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 12.6961\n",
      "2017-05-25 12:20:56.675085: step 400, loss = 3.63 (1370.7 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 12:20:57.359612: step 410, loss = 3.56 (1869.9 examples/sec; 0.068 sec/batch)\n",
      "2017-05-25 12:20:58.137117: step 420, loss = 3.63 (1646.3 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:20:58.922878: step 430, loss = 3.37 (1629.0 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:20:59.710926: step 440, loss = 3.35 (1624.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:21:00.501943: step 450, loss = 3.33 (1618.2 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:21:01.286251: step 460, loss = 3.35 (1632.0 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:21:02.060836: step 470, loss = 3.23 (1652.5 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:21:02.835195: step 480, loss = 3.32 (1653.0 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:21:03.611428: step 490, loss = 3.29 (1649.0 examples/sec; 0.078 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 12.7095\n",
      "2017-05-25 12:21:04.541365: step 500, loss = 3.16 (1376.4 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 12:21:05.223009: step 510, loss = 3.28 (1877.8 examples/sec; 0.068 sec/batch)\n",
      "2017-05-25 12:21:06.008446: step 520, loss = 3.12 (1629.7 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:21:06.805204: step 530, loss = 3.21 (1606.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:21:07.581825: step 540, loss = 2.96 (1648.2 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:21:08.378427: step 550, loss = 3.24 (1606.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:21:09.164670: step 560, loss = 3.10 (1628.0 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:21:09.982651: step 570, loss = 3.20 (1564.8 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:21:10.773684: step 580, loss = 3.09 (1618.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:21:11.593152: step 590, loss = 3.03 (1562.0 examples/sec; 0.082 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 12.5126\n",
      "2017-05-25 12:21:12.533463: step 600, loss = 3.12 (1361.2 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:21:14.793490: step 630, loss = 2.91 (1618.7 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:21:15.588350: step 640, loss = 3.00 (1610.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:21:16.416712: step 650, loss = 3.14 (1545.2 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:21:17.222942: step 660, loss = 3.03 (1587.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:21:18.012059: step 670, loss = 2.80 (1622.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:21:18.818435: step 680, loss = 2.94 (1587.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:21:19.603895: step 690, loss = 3.10 (1629.6 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 12.4504\n",
      "2017-05-25 12:21:20.565464: step 700, loss = 2.94 (1331.2 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 12:21:21.268568: step 710, loss = 2.72 (1820.5 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:21:22.062653: step 720, loss = 2.90 (1611.9 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:21:22.833524: step 730, loss = 2.70 (1660.5 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:21:23.615540: step 740, loss = 2.89 (1636.8 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:21:24.395946: step 750, loss = 2.94 (1640.2 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:21:25.187663: step 760, loss = 2.88 (1616.7 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:21:25.999629: step 770, loss = 2.81 (1576.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:21:26.795662: step 780, loss = 3.09 (1608.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:21:27.602567: step 790, loss = 2.65 (1586.3 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 12.4942\n",
      "2017-05-25 12:21:28.569096: step 800, loss = 2.70 (1324.3 examples/sec; 0.097 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:21:29.239715: step 810, loss = 2.96 (1908.7 examples/sec; 0.067 sec/batch)\n",
      "2017-05-25 12:21:30.300030: step 820, loss = 2.61 (1207.2 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:21:31.334527: step 830, loss = 2.77 (1237.3 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:21:32.380636: step 840, loss = 2.68 (1223.6 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:21:33.373151: step 850, loss = 2.81 (1289.7 examples/sec; 0.099 sec/batch)\n",
      "2017-05-25 12:21:34.237721: step 860, loss = 2.85 (1480.5 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:21:35.131924: step 870, loss = 2.84 (1431.4 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:21:35.988118: step 880, loss = 2.50 (1495.0 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:21:36.861070: step 890, loss = 2.65 (1466.3 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.8026\n",
      "2017-05-25 12:21:37.827873: step 900, loss = 2.47 (1323.9 examples/sec; 0.097 sec/batch)\n",
      "2017-05-25 12:21:38.514476: step 910, loss = 2.78 (1864.3 examples/sec; 0.069 sec/batch)\n",
      "2017-05-25 12:21:39.323189: step 920, loss = 2.63 (1582.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:21:40.129404: step 930, loss = 2.56 (1587.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:21:40.933390: step 940, loss = 2.43 (1592.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:21:41.721363: step 950, loss = 2.47 (1624.4 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:21:42.509350: step 960, loss = 2.48 (1624.4 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:21:43.294677: step 970, loss = 2.49 (1629.9 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:21:44.070968: step 980, loss = 2.47 (1648.9 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:21:47.270656: step 1020, loss = 2.46 (1609.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:21:48.053918: step 1030, loss = 2.47 (1634.2 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:21:48.850634: step 1040, loss = 2.65 (1606.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:21:49.768231: step 1050, loss = 2.47 (1394.9 examples/sec; 0.092 sec/batch)\n",
      "2017-05-25 12:21:50.827224: step 1060, loss = 2.62 (1208.7 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:21:51.860310: step 1070, loss = 2.40 (1239.0 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:21:52.901415: step 1080, loss = 2.46 (1229.5 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:21:53.812325: step 1090, loss = 2.49 (1405.2 examples/sec; 0.091 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.0336\n",
      "2017-05-25 12:21:54.857824: step 1100, loss = 2.57 (1224.3 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:21:55.619420: step 1110, loss = 2.25 (1680.7 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 12:21:56.472997: step 1120, loss = 2.33 (1499.6 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:21:57.333937: step 1130, loss = 2.36 (1486.7 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:21:58.128734: step 1140, loss = 2.25 (1610.5 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:21:58.922417: step 1150, loss = 2.37 (1612.7 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:21:59.729336: step 1160, loss = 2.24 (1586.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:22:00.546256: step 1170, loss = 2.42 (1566.9 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:22:01.337384: step 1180, loss = 2.35 (1617.9 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:22:02.128292: step 1190, loss = 2.23 (1618.4 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 12.1766\n",
      "2017-05-25 12:22:03.068576: step 1200, loss = 2.12 (1361.3 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:22:03.730957: step 1210, loss = 2.23 (1932.4 examples/sec; 0.066 sec/batch)\n",
      "2017-05-25 12:22:04.501205: step 1220, loss = 2.25 (1661.8 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:22:05.282816: step 1230, loss = 2.10 (1637.6 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:22:06.079396: step 1240, loss = 2.27 (1606.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:22:06.880234: step 1250, loss = 2.34 (1598.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:22:07.663806: step 1260, loss = 2.30 (1633.5 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:22:08.459273: step 1270, loss = 2.18 (1609.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:22:09.283146: step 1280, loss = 2.32 (1553.6 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:22:10.325317: step 1290, loss = 2.19 (1228.2 examples/sec; 0.104 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7602\n",
      "2017-05-25 12:22:11.572440: step 1300, loss = 2.32 (1026.4 examples/sec; 0.125 sec/batch)\n",
      "2017-05-25 12:22:12.452552: step 1310, loss = 2.03 (1454.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:22:13.447301: step 1320, loss = 2.11 (1286.8 examples/sec; 0.099 sec/batch)\n",
      "2017-05-25 12:22:14.306464: step 1330, loss = 2.17 (1489.8 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:22:15.201193: step 1340, loss = 2.22 (1430.6 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:22:16.062481: step 1350, loss = 2.27 (1486.1 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:22:18.556220: step 1380, loss = 2.15 (1615.7 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:22:19.347612: step 1390, loss = 1.90 (1617.4 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.4253\n",
      "2017-05-25 12:22:20.324661: step 1400, loss = 2.22 (1310.1 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 12:22:21.006571: step 1410, loss = 2.01 (1877.1 examples/sec; 0.068 sec/batch)\n",
      "2017-05-25 12:22:21.873469: step 1420, loss = 1.93 (1476.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:22:22.730157: step 1430, loss = 2.39 (1494.1 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:22:23.603416: step 1440, loss = 2.06 (1465.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:22:24.479950: step 1450, loss = 1.91 (1460.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:22:25.350617: step 1460, loss = 2.04 (1470.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:22:26.142380: step 1470, loss = 2.08 (1616.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:22:26.935660: step 1480, loss = 1.85 (1613.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:22:27.731003: step 1490, loss = 2.10 (1609.4 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 12.0023\n",
      "2017-05-25 12:22:28.655802: step 1500, loss = 1.87 (1384.1 examples/sec; 0.092 sec/batch)\n",
      "2017-05-25 12:22:29.384742: step 1510, loss = 2.14 (1756.0 examples/sec; 0.073 sec/batch)\n",
      "2017-05-25 12:22:30.315239: step 1520, loss = 1.97 (1375.6 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 12:22:31.189763: step 1530, loss = 2.08 (1463.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:22:32.062655: step 1540, loss = 2.02 (1466.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:22:32.926786: step 1550, loss = 2.13 (1481.2 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:22:33.757553: step 1560, loss = 2.00 (1540.7 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:22:34.560207: step 1570, loss = 1.90 (1594.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:22:35.357652: step 1580, loss = 1.92 (1605.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:22:36.148675: step 1590, loss = 1.86 (1618.2 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.811\n",
      "2017-05-25 12:22:37.123727: step 1600, loss = 1.96 (1312.7 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 12:22:37.836394: step 1610, loss = 1.83 (1796.1 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:22:38.707679: step 1620, loss = 1.95 (1469.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:22:39.582280: step 1630, loss = 1.94 (1463.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:22:40.530529: step 1640, loss = 1.87 (1349.9 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:22:41.381898: step 1650, loss = 1.88 (1503.5 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:22:42.179923: step 1660, loss = 2.00 (1604.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:22:42.980430: step 1670, loss = 2.14 (1599.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:22:43.793474: step 1680, loss = 1.88 (1574.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:22:44.581820: step 1690, loss = 1.98 (1623.7 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.827\n",
      "2017-05-25 12:22:45.577808: step 1700, loss = 1.84 (1285.2 examples/sec; 0.100 sec/batch)\n",
      "2017-05-25 12:22:46.328292: step 1710, loss = 1.99 (1705.6 examples/sec; 0.075 sec/batch)\n",
      "2017-05-25 12:22:47.206059: step 1720, loss = 2.03 (1458.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:22:48.060743: step 1730, loss = 2.03 (1497.6 examples/sec; 0.085 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:22:52.984335: step 1790, loss = 2.02 (1611.3 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.871\n",
      "2017-05-25 12:22:54.003640: step 1800, loss = 1.99 (1255.8 examples/sec; 0.102 sec/batch)\n",
      "2017-05-25 12:22:54.767887: step 1810, loss = 2.06 (1674.9 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 12:22:55.635381: step 1820, loss = 1.88 (1475.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:22:56.496955: step 1830, loss = 1.84 (1485.6 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:22:57.359402: step 1840, loss = 1.84 (1484.1 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:22:58.141268: step 1850, loss = 2.05 (1637.1 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:22:58.949957: step 1860, loss = 1.91 (1582.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:22:59.745285: step 1870, loss = 1.71 (1609.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:23:00.571468: step 1880, loss = 1.74 (1549.3 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:23:01.376833: step 1890, loss = 1.76 (1589.3 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8012\n",
      "2017-05-25 12:23:02.477321: step 1900, loss = 1.74 (1163.1 examples/sec; 0.110 sec/batch)\n",
      "2017-05-25 12:23:03.188130: step 1910, loss = 1.76 (1800.8 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:23:04.061950: step 1920, loss = 1.69 (1464.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:23:04.928483: step 1930, loss = 1.87 (1477.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:23:05.767924: step 1940, loss = 1.64 (1524.8 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:23:06.560322: step 1950, loss = 1.65 (1615.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:23:07.364619: step 1960, loss = 1.80 (1591.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:23:08.150400: step 1970, loss = 1.68 (1629.0 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:23:08.954051: step 1980, loss = 1.71 (1592.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:23:09.785993: step 1990, loss = 1.82 (1538.6 examples/sec; 0.083 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9591\n",
      "2017-05-25 12:23:10.839306: step 2000, loss = 1.85 (1215.2 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:23:11.590065: step 2010, loss = 1.80 (1704.9 examples/sec; 0.075 sec/batch)\n",
      "2017-05-25 12:23:12.472935: step 2020, loss = 1.65 (1449.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:23:13.351041: step 2030, loss = 1.65 (1457.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:23:14.138309: step 2040, loss = 1.66 (1625.9 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:23:14.935868: step 2050, loss = 1.85 (1604.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:23:15.722270: step 2060, loss = 1.82 (1627.7 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:23:16.515501: step 2070, loss = 1.72 (1613.7 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:23:17.337603: step 2080, loss = 1.66 (1557.0 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:23:18.193646: step 2090, loss = 1.67 (1495.3 examples/sec; 0.086 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.932\n",
      "2017-05-25 12:23:19.219529: step 2100, loss = 1.61 (1247.7 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:23:20.012644: step 2110, loss = 1.57 (1613.9 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:23:20.881189: step 2120, loss = 1.75 (1473.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:23:21.721890: step 2130, loss = 1.77 (1522.5 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:23:24.894790: step 2170, loss = 1.44 (1605.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:23:25.738125: step 2180, loss = 1.98 (1517.8 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:23:26.615148: step 2190, loss = 1.80 (1459.5 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8554\n",
      "2017-05-25 12:23:27.655030: step 2200, loss = 1.70 (1230.9 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:23:28.417732: step 2210, loss = 1.55 (1678.2 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 12:23:29.292228: step 2220, loss = 1.68 (1463.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:23:30.102197: step 2230, loss = 1.99 (1580.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:23:30.901442: step 2240, loss = 1.55 (1601.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:23:31.690035: step 2250, loss = 1.63 (1623.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:23:32.504122: step 2260, loss = 1.66 (1572.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:23:33.314231: step 2270, loss = 1.58 (1580.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:23:34.190202: step 2280, loss = 1.57 (1461.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:23:35.049622: step 2290, loss = 1.82 (1489.4 examples/sec; 0.086 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.862\n",
      "2017-05-25 12:23:36.083627: step 2300, loss = 1.53 (1237.9 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:23:36.854825: step 2310, loss = 1.63 (1659.8 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:23:37.683482: step 2320, loss = 1.50 (1544.7 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:23:38.475910: step 2330, loss = 1.62 (1615.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:23:39.264721: step 2340, loss = 1.49 (1622.7 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:23:40.085978: step 2350, loss = 1.59 (1558.6 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:23:40.889392: step 2360, loss = 1.54 (1593.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:23:41.712605: step 2370, loss = 1.73 (1554.9 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:23:42.588878: step 2380, loss = 1.62 (1460.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:23:43.456558: step 2390, loss = 1.38 (1475.2 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9047\n",
      "2017-05-25 12:23:44.485215: step 2400, loss = 1.37 (1244.3 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:23:45.259321: step 2410, loss = 1.46 (1653.5 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:23:46.055343: step 2420, loss = 1.37 (1608.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:23:46.849239: step 2430, loss = 1.57 (1612.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:23:47.638719: step 2440, loss = 1.54 (1621.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:23:48.451372: step 2450, loss = 1.59 (1575.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:23:49.256673: step 2460, loss = 1.45 (1589.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:23:50.139968: step 2470, loss = 1.47 (1449.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:23:51.013379: step 2480, loss = 1.72 (1465.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:23:51.879399: step 2490, loss = 1.35 (1478.0 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8332\n",
      "2017-05-25 12:23:52.934256: step 2500, loss = 1.43 (1213.4 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:23:53.716904: step 2510, loss = 1.29 (1635.5 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:23:54.504776: step 2520, loss = 1.45 (1624.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:23:56.895346: step 2550, loss = 1.48 (1594.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:23:57.715771: step 2560, loss = 1.54 (1560.2 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:23:58.579393: step 2570, loss = 1.54 (1482.1 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:23:59.454398: step 2580, loss = 1.41 (1462.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:24:00.352447: step 2590, loss = 1.46 (1425.3 examples/sec; 0.090 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7652\n",
      "2017-05-25 12:24:01.434106: step 2600, loss = 1.56 (1183.4 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 12:24:02.076014: step 2610, loss = 1.28 (1994.1 examples/sec; 0.064 sec/batch)\n",
      "2017-05-25 12:24:02.883705: step 2620, loss = 1.51 (1584.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:24:03.684203: step 2630, loss = 1.39 (1599.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:24:04.464525: step 2640, loss = 1.38 (1640.3 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:24:05.266191: step 2650, loss = 1.39 (1596.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:24:06.136424: step 2660, loss = 1.39 (1470.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:24:07.014996: step 2670, loss = 1.41 (1456.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:24:07.893952: step 2680, loss = 1.35 (1456.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:24:08.761174: step 2690, loss = 1.38 (1476.0 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 12.0072\n",
      "2017-05-25 12:24:09.762146: step 2700, loss = 1.60 (1278.8 examples/sec; 0.100 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:24:10.482914: step 2710, loss = 1.33 (1775.9 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:24:11.281656: step 2720, loss = 1.52 (1602.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:24:12.071002: step 2730, loss = 1.50 (1621.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:24:12.865411: step 2740, loss = 1.36 (1611.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:24:13.693152: step 2750, loss = 1.33 (1546.4 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:24:14.562886: step 2760, loss = 1.46 (1471.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:24:15.445595: step 2770, loss = 1.36 (1450.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:24:16.305249: step 2780, loss = 1.38 (1489.0 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:24:17.177285: step 2790, loss = 1.38 (1467.8 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9231\n",
      "2017-05-25 12:24:18.149393: step 2800, loss = 1.17 (1316.7 examples/sec; 0.097 sec/batch)\n",
      "2017-05-25 12:24:18.848640: step 2810, loss = 1.57 (1830.5 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:24:19.642446: step 2820, loss = 1.36 (1612.5 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:24:20.454536: step 2830, loss = 1.51 (1576.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:24:21.252957: step 2840, loss = 1.32 (1603.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:24:22.125221: step 2850, loss = 1.30 (1467.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:24:22.996836: step 2860, loss = 1.49 (1468.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:24:23.871970: step 2870, loss = 1.60 (1462.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:24:24.742110: step 2880, loss = 1.40 (1471.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:24:25.589945: step 2890, loss = 1.34 (1509.7 examples/sec; 0.085 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9539\n",
      "2017-05-25 12:24:26.514889: step 2900, loss = 1.32 (1383.9 examples/sec; 0.092 sec/batch)\n",
      "2017-05-25 12:24:28.822733: step 2930, loss = 1.49 (1599.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:24:29.640693: step 2940, loss = 1.18 (1564.9 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:24:30.531542: step 2950, loss = 1.35 (1436.8 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:24:31.392953: step 2960, loss = 1.33 (1485.9 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:24:32.252363: step 2970, loss = 1.24 (1489.4 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:24:33.146116: step 2980, loss = 1.19 (1432.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:24:33.959376: step 2990, loss = 1.27 (1573.9 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9416\n",
      "2017-05-25 12:24:34.890456: step 3000, loss = 1.38 (1374.7 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 12:24:35.613767: step 3010, loss = 1.18 (1769.6 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:24:36.423220: step 3020, loss = 1.32 (1581.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:24:37.231368: step 3030, loss = 1.21 (1583.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:24:38.079329: step 3040, loss = 1.37 (1509.5 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:24:38.954956: step 3050, loss = 1.45 (1461.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:24:39.829782: step 3060, loss = 1.22 (1463.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:24:40.712874: step 3070, loss = 1.38 (1449.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:24:41.568939: step 3080, loss = 1.32 (1495.2 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:24:42.492997: step 3090, loss = 1.24 (1385.2 examples/sec; 0.092 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.5305\n",
      "2017-05-25 12:24:43.562886: step 3100, loss = 1.49 (1196.4 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:24:44.208925: step 3110, loss = 1.30 (1981.3 examples/sec; 0.065 sec/batch)\n",
      "2017-05-25 12:24:45.013982: step 3120, loss = 1.15 (1589.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:24:45.867655: step 3130, loss = 1.21 (1499.4 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:24:46.766992: step 3140, loss = 1.22 (1423.3 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:24:47.633837: step 3150, loss = 1.40 (1476.6 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:24:48.498727: step 3160, loss = 1.08 (1480.0 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:24:49.363252: step 3170, loss = 1.19 (1480.6 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:24:50.205252: step 3180, loss = 1.18 (1520.2 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:24:50.993788: step 3190, loss = 1.28 (1623.3 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9347\n",
      "2017-05-25 12:24:51.940003: step 3200, loss = 1.20 (1352.8 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:24:52.630873: step 3210, loss = 1.15 (1852.7 examples/sec; 0.069 sec/batch)\n",
      "2017-05-25 12:24:53.451222: step 3220, loss = 1.35 (1560.3 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:24:54.323811: step 3230, loss = 1.47 (1466.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:24:55.215480: step 3240, loss = 1.22 (1435.5 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:24:56.109272: step 3250, loss = 1.15 (1432.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:24:56.978770: step 3260, loss = 1.23 (1472.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:24:57.814174: step 3270, loss = 1.18 (1532.2 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:25:01.067138: step 3310, loss = 1.14 (1843.5 examples/sec; 0.069 sec/batch)\n",
      "2017-05-25 12:25:01.918079: step 3320, loss = 1.29 (1504.2 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:25:02.790190: step 3330, loss = 1.44 (1467.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:25:03.670044: step 3340, loss = 1.32 (1454.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:25:04.534898: step 3350, loss = 1.28 (1480.0 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:25:05.409641: step 3360, loss = 1.35 (1463.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:25:06.210815: step 3370, loss = 1.40 (1597.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:25:07.002417: step 3380, loss = 1.18 (1617.0 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:25:07.797894: step 3390, loss = 1.17 (1609.1 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9412\n",
      "2017-05-25 12:25:08.747440: step 3400, loss = 1.49 (1348.0 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:25:09.429789: step 3410, loss = 1.21 (1875.9 examples/sec; 0.068 sec/batch)\n",
      "2017-05-25 12:25:10.325322: step 3420, loss = 1.44 (1429.3 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:25:11.209016: step 3430, loss = 1.27 (1448.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:25:12.065436: step 3440, loss = 1.21 (1494.6 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:25:12.944808: step 3450, loss = 1.33 (1455.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:25:13.797499: step 3460, loss = 1.15 (1501.1 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:25:14.584813: step 3470, loss = 1.15 (1625.8 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:25:15.387377: step 3480, loss = 1.24 (1594.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:25:16.183809: step 3490, loss = 1.19 (1607.2 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8823\n",
      "2017-05-25 12:25:17.163195: step 3500, loss = 1.27 (1306.9 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 12:25:17.842285: step 3510, loss = 1.13 (1884.9 examples/sec; 0.068 sec/batch)\n",
      "2017-05-25 12:25:18.715385: step 3520, loss = 1.33 (1466.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:25:19.581380: step 3530, loss = 1.36 (1478.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:25:20.459830: step 3540, loss = 1.12 (1457.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:25:21.338738: step 3550, loss = 1.39 (1456.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:25:22.143904: step 3560, loss = 1.29 (1589.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:25:22.947401: step 3570, loss = 1.22 (1593.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:25:23.749162: step 3580, loss = 1.30 (1596.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:25:24.544894: step 3590, loss = 1.21 (1608.6 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 12.0124\n",
      "2017-05-25 12:25:25.488006: step 3600, loss = 1.22 (1357.2 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:25:26.248568: step 3610, loss = 1.13 (1683.0 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 12:25:27.116275: step 3620, loss = 1.21 (1475.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:25:27.997914: step 3630, loss = 1.29 (1451.8 examples/sec; 0.088 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:25:28.852477: step 3640, loss = 1.20 (1497.8 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:25:29.868073: step 3650, loss = 1.16 (1260.3 examples/sec; 0.102 sec/batch)\n",
      "2017-05-25 12:26:53.125916: step 4590, loss = 1.21 (1606.5 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7175\n",
      "2017-05-25 12:26:54.197228: step 4600, loss = 1.08 (1194.8 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:26:54.890148: step 4610, loss = 1.12 (1847.3 examples/sec; 0.069 sec/batch)\n",
      "2017-05-25 12:26:55.789697: step 4620, loss = 1.14 (1422.9 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:26:56.658161: step 4630, loss = 1.19 (1473.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:26:57.520012: step 4640, loss = 1.18 (1485.2 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:26:58.313438: step 4650, loss = 1.11 (1613.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:26:59.099271: step 4660, loss = 0.93 (1628.8 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:26:59.905755: step 4670, loss = 0.81 (1587.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:27:00.719935: step 4680, loss = 1.22 (1572.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:27:01.528796: step 4690, loss = 1.14 (1582.5 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8388\n",
      "2017-05-25 12:27:02.642555: step 4700, loss = 1.17 (1149.3 examples/sec; 0.111 sec/batch)\n",
      "2017-05-25 12:27:03.336703: step 4710, loss = 1.08 (1844.0 examples/sec; 0.069 sec/batch)\n",
      "2017-05-25 12:27:04.201845: step 4720, loss = 1.23 (1479.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:27:05.073095: step 4730, loss = 0.99 (1469.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:27:05.907225: step 4740, loss = 1.01 (1534.5 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:27:06.705919: step 4750, loss = 1.30 (1602.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:27:07.494102: step 4760, loss = 0.98 (1624.0 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:27:08.293035: step 4770, loss = 1.18 (1602.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:27:09.080547: step 4780, loss = 1.29 (1625.4 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:27:09.907615: step 4790, loss = 0.99 (1547.6 examples/sec; 0.083 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 12.0289\n",
      "2017-05-25 12:27:10.955171: step 4800, loss = 1.14 (1221.9 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:27:11.725341: step 4810, loss = 1.15 (1662.0 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:27:12.600076: step 4820, loss = 1.11 (1463.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:27:13.470160: step 4830, loss = 1.10 (1471.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:27:14.259648: step 4840, loss = 0.93 (1621.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:27:15.058564: step 4850, loss = 1.00 (1602.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:27:15.855985: step 4860, loss = 0.96 (1605.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:27:16.649725: step 4870, loss = 0.97 (1612.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:27:17.441719: step 4880, loss = 0.84 (1616.2 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:27:18.301120: step 4890, loss = 1.05 (1489.4 examples/sec; 0.086 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9014\n",
      "2017-05-25 12:27:19.357693: step 4900, loss = 1.13 (1211.5 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:27:20.130237: step 4910, loss = 1.11 (1656.9 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:27:21.001793: step 4920, loss = 1.02 (1468.6 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:27:21.837066: step 4930, loss = 1.04 (1532.4 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:27:22.637135: step 4940, loss = 1.08 (1599.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:27:25.044206: step 4970, loss = 0.92 (1577.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:27:25.882297: step 4980, loss = 0.94 (1527.3 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:27:26.759266: step 4990, loss = 1.03 (1459.6 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8733\n",
      "2017-05-25 12:27:27.780172: step 5000, loss = 0.93 (1253.8 examples/sec; 0.102 sec/batch)\n",
      "2017-05-25 12:27:28.554557: step 5010, loss = 0.91 (1652.9 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:27:29.416661: step 5020, loss = 1.02 (1484.7 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:27:30.250062: step 5030, loss = 1.01 (1535.9 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:27:31.040383: step 5040, loss = 1.00 (1619.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:27:31.837306: step 5050, loss = 1.20 (1606.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:27:32.629098: step 5060, loss = 1.21 (1616.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:27:33.422390: step 5070, loss = 1.14 (1613.5 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:27:34.292791: step 5080, loss = 1.00 (1470.6 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:27:35.161597: step 5090, loss = 0.97 (1473.3 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8061\n",
      "2017-05-25 12:27:36.250377: step 5100, loss = 1.20 (1175.6 examples/sec; 0.109 sec/batch)\n",
      "2017-05-25 12:27:36.958787: step 5110, loss = 1.08 (1806.9 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:27:37.809395: step 5120, loss = 1.17 (1504.8 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:27:38.598894: step 5130, loss = 0.97 (1621.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:27:39.404404: step 5140, loss = 1.04 (1589.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:27:40.220528: step 5150, loss = 1.31 (1568.4 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:27:41.034416: step 5160, loss = 1.05 (1572.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:27:41.861162: step 5170, loss = 1.02 (1548.2 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:27:42.717084: step 5180, loss = 0.95 (1495.5 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:27:43.581572: step 5190, loss = 1.06 (1480.6 examples/sec; 0.086 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9732\n",
      "2017-05-25 12:27:44.604117: step 5200, loss = 1.05 (1251.8 examples/sec; 0.102 sec/batch)\n",
      "2017-05-25 12:27:45.385931: step 5210, loss = 1.05 (1637.2 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:27:46.200231: step 5220, loss = 1.10 (1571.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:27:46.990778: step 5230, loss = 1.04 (1619.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:27:47.802077: step 5240, loss = 1.11 (1577.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:27:48.591130: step 5250, loss = 0.89 (1622.2 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:27:49.383907: step 5260, loss = 1.06 (1614.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:27:50.271228: step 5270, loss = 0.97 (1442.5 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:27:51.132758: step 5280, loss = 1.06 (1485.7 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:27:52.011776: step 5290, loss = 1.02 (1456.2 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7735\n",
      "2017-05-25 12:27:53.096378: step 5300, loss = 1.00 (1180.2 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 12:27:53.775559: step 5310, loss = 1.22 (1884.6 examples/sec; 0.068 sec/batch)\n",
      "2017-05-25 12:27:56.974803: step 5350, loss = 1.11 (1608.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:27:57.801835: step 5360, loss = 1.01 (1547.7 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:27:58.680042: step 5370, loss = 1.03 (1457.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:27:59.545615: step 5380, loss = 0.99 (1478.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:28:00.452070: step 5390, loss = 1.05 (1412.1 examples/sec; 0.091 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8225\n",
      "2017-05-25 12:28:01.554977: step 5400, loss = 1.04 (1160.6 examples/sec; 0.110 sec/batch)\n",
      "2017-05-25 12:28:02.520970: step 5410, loss = 0.94 (1325.1 examples/sec; 0.097 sec/batch)\n",
      "2017-05-25 12:28:03.738235: step 5420, loss = 0.97 (1051.5 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 12:28:04.949079: step 5430, loss = 1.07 (1057.1 examples/sec; 0.121 sec/batch)\n",
      "2017-05-25 12:28:06.069022: step 5440, loss = 1.08 (1142.9 examples/sec; 0.112 sec/batch)\n",
      "2017-05-25 12:28:07.094504: step 5450, loss = 1.06 (1248.2 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:28:08.144022: step 5460, loss = 0.99 (1219.6 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:28:09.172305: step 5470, loss = 1.17 (1244.8 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:28:10.108576: step 5480, loss = 0.95 (1367.1 examples/sec; 0.094 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:28:10.994945: step 5490, loss = 1.04 (1444.1 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.53472\n",
      "2017-05-25 12:28:12.043520: step 5500, loss = 0.94 (1220.7 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:28:12.802293: step 5510, loss = 1.12 (1686.9 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 12:28:13.663456: step 5520, loss = 0.90 (1486.4 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:28:14.471084: step 5530, loss = 1.05 (1584.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:28:15.275246: step 5540, loss = 1.14 (1591.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:28:16.078795: step 5550, loss = 0.99 (1592.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:28:16.873871: step 5560, loss = 0.97 (1609.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:28:17.672007: step 5570, loss = 1.19 (1603.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:28:18.536579: step 5580, loss = 1.18 (1480.5 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:28:19.419498: step 5590, loss = 0.97 (1449.7 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8847\n",
      "2017-05-25 12:28:20.456326: step 5600, loss = 1.03 (1234.5 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:28:21.222902: step 5610, loss = 1.14 (1669.8 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:28:22.039181: step 5620, loss = 1.01 (1568.1 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:28:22.842025: step 5630, loss = 1.07 (1594.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:28:23.634075: step 5640, loss = 1.08 (1616.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:28:24.427796: step 5650, loss = 0.93 (1612.7 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:28:25.228922: step 5660, loss = 0.85 (1597.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:28:26.082532: step 5670, loss = 0.95 (1499.5 examples/sec; 0.085 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8139\n",
      "2017-05-25 12:28:28.921292: step 5700, loss = 1.01 (1188.0 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 12:28:29.622881: step 5710, loss = 1.00 (1824.4 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:28:30.434774: step 5720, loss = 1.11 (1576.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:28:31.232695: step 5730, loss = 1.10 (1604.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:28:32.007992: step 5740, loss = 0.97 (1651.0 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:28:32.821892: step 5750, loss = 0.94 (1572.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:28:33.632337: step 5760, loss = 1.17 (1579.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:28:34.511462: step 5770, loss = 0.91 (1456.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:28:35.390237: step 5780, loss = 0.86 (1456.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:28:36.271546: step 5790, loss = 0.90 (1452.4 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9348\n",
      "2017-05-25 12:28:37.300080: step 5800, loss = 0.96 (1244.5 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:28:38.254855: step 5810, loss = 1.09 (1340.7 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:28:39.460375: step 5820, loss = 1.02 (1061.8 examples/sec; 0.121 sec/batch)\n",
      "2017-05-25 12:28:40.717071: step 5830, loss = 1.04 (1018.5 examples/sec; 0.126 sec/batch)\n",
      "2017-05-25 12:28:41.862085: step 5840, loss = 1.01 (1117.9 examples/sec; 0.115 sec/batch)\n",
      "2017-05-25 12:28:42.887382: step 5850, loss = 0.92 (1248.4 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:28:43.913886: step 5860, loss = 1.12 (1247.0 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:28:44.949040: step 5870, loss = 1.02 (1236.5 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:28:45.932402: step 5880, loss = 1.01 (1301.7 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 12:28:46.800546: step 5890, loss = 0.95 (1474.4 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.46151\n",
      "2017-05-25 12:28:47.869083: step 5900, loss = 1.00 (1197.9 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:28:48.589002: step 5910, loss = 1.03 (1778.0 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:28:49.450522: step 5920, loss = 0.98 (1485.7 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:28:50.323189: step 5930, loss = 1.21 (1466.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:28:51.119273: step 5940, loss = 0.97 (1607.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:28:51.927841: step 5950, loss = 0.97 (1583.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:28:52.728967: step 5960, loss = 1.11 (1597.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:28:53.520331: step 5970, loss = 1.08 (1617.5 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:28:54.393012: step 5980, loss = 1.05 (1466.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:28:55.271060: step 5990, loss = 1.03 (1457.8 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7698\n",
      "2017-05-25 12:28:56.367548: step 6000, loss = 1.17 (1167.4 examples/sec; 0.110 sec/batch)\n",
      "2017-05-25 12:28:57.072254: step 6010, loss = 0.96 (1816.4 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:28:57.917465: step 6020, loss = 1.05 (1514.4 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:29:01.119702: step 6060, loss = 1.00 (1631.2 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:29:01.952520: step 6070, loss = 1.05 (1537.0 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:29:02.833045: step 6080, loss = 0.97 (1453.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:29:03.708099: step 6090, loss = 1.05 (1462.8 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8862\n",
      "2017-05-25 12:29:04.778720: step 6100, loss = 0.99 (1195.6 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:29:05.497725: step 6110, loss = 0.99 (1780.2 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:29:06.309461: step 6120, loss = 1.12 (1576.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:29:07.095353: step 6130, loss = 0.94 (1628.7 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:29:07.881371: step 6140, loss = 1.05 (1628.5 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:29:08.693168: step 6150, loss = 1.01 (1576.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:29:09.493919: step 6160, loss = 1.22 (1598.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:29:10.420206: step 6170, loss = 0.99 (1381.9 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 12:29:11.286064: step 6180, loss = 1.01 (1478.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:29:12.144628: step 6190, loss = 1.04 (1490.9 examples/sec; 0.086 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9211\n",
      "2017-05-25 12:29:13.167518: step 6200, loss = 1.16 (1251.4 examples/sec; 0.102 sec/batch)\n",
      "2017-05-25 12:29:13.918648: step 6210, loss = 0.93 (1704.1 examples/sec; 0.075 sec/batch)\n",
      "2017-05-25 12:29:14.709541: step 6220, loss = 1.02 (1618.4 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:29:15.516989: step 6230, loss = 1.17 (1585.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:29:16.309107: step 6240, loss = 1.24 (1615.9 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:29:17.095664: step 6250, loss = 0.92 (1627.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:29:17.955325: step 6260, loss = 1.17 (1489.0 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:29:18.829331: step 6270, loss = 1.10 (1464.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:29:19.723554: step 6280, loss = 0.95 (1431.4 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:29:20.615784: step 6290, loss = 1.01 (1434.6 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7355\n",
      "2017-05-25 12:29:21.687806: step 6300, loss = 0.99 (1194.0 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:29:22.334341: step 6310, loss = 1.15 (1979.8 examples/sec; 0.065 sec/batch)\n",
      "2017-05-25 12:29:23.128807: step 6320, loss = 1.00 (1611.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:29:23.933958: step 6330, loss = 0.94 (1589.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:29:24.747999: step 6340, loss = 1.04 (1572.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:29:25.544117: step 6350, loss = 0.90 (1607.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:29:26.406394: step 6360, loss = 1.08 (1484.4 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:29:27.273117: step 6370, loss = 0.90 (1476.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:29:28.156668: step 6380, loss = 1.03 (1448.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:29:29.017559: step 6390, loss = 1.06 (1486.8 examples/sec; 0.086 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9919\n",
      "2017-05-25 12:29:30.026991: step 6400, loss = 1.22 (1268.0 examples/sec; 0.101 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:29:33.156023: step 6440, loss = 0.90 (1587.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:29:33.986478: step 6450, loss = 1.13 (1541.3 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:29:34.877531: step 6460, loss = 0.93 (1436.5 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:29:35.749005: step 6470, loss = 1.05 (1468.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:29:36.607413: step 6480, loss = 1.00 (1491.1 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:29:37.468557: step 6490, loss = 1.11 (1486.4 examples/sec; 0.086 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9026\n",
      "2017-05-25 12:29:38.430363: step 6500, loss = 1.00 (1330.8 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 12:29:39.138315: step 6510, loss = 1.11 (1808.0 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:29:39.929379: step 6520, loss = 0.94 (1618.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:29:40.750976: step 6530, loss = 0.98 (1557.9 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:29:41.543268: step 6540, loss = 1.05 (1615.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:29:42.415478: step 6550, loss = 0.88 (1467.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:29:43.286455: step 6560, loss = 1.10 (1469.6 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:29:44.154888: step 6570, loss = 1.16 (1473.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:29:45.023678: step 6580, loss = 1.10 (1473.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:29:45.860047: step 6590, loss = 0.78 (1530.4 examples/sec; 0.084 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8897\n",
      "2017-05-25 12:29:46.838817: step 6600, loss = 1.04 (1307.8 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 12:29:47.675764: step 6610, loss = 0.98 (1529.4 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:29:48.493053: step 6620, loss = 1.00 (1566.2 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:29:49.288256: step 6630, loss = 1.10 (1609.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:29:50.149923: step 6640, loss = 1.10 (1485.5 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:29:51.034169: step 6650, loss = 1.04 (1447.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:29:51.899688: step 6660, loss = 0.90 (1478.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:29:52.766082: step 6670, loss = 0.89 (1477.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:29:53.636902: step 6680, loss = 1.34 (1469.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:29:54.443147: step 6690, loss = 0.88 (1587.6 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6049\n",
      "2017-05-25 12:29:55.457980: step 6700, loss = 0.95 (1261.3 examples/sec; 0.101 sec/batch)\n",
      "2017-05-25 12:29:56.088841: step 6710, loss = 0.94 (2029.0 examples/sec; 0.063 sec/batch)\n",
      "2017-05-25 12:29:56.886652: step 6720, loss = 1.01 (1604.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:29:57.695667: step 6730, loss = 0.99 (1582.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:29:58.567576: step 6740, loss = 0.91 (1468.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:29:59.438015: step 6750, loss = 0.91 (1470.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:30:00.327455: step 6760, loss = 0.89 (1439.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:30:01.193085: step 6770, loss = 0.95 (1478.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:30:02.035068: step 6780, loss = 1.00 (1520.2 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:30:05.287120: step 6820, loss = 0.99 (1585.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:30:06.120532: step 6830, loss = 0.83 (1535.9 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:30:06.991562: step 6840, loss = 1.00 (1469.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:30:07.867846: step 6850, loss = 0.80 (1460.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:30:08.732850: step 6860, loss = 0.98 (1479.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:30:09.609709: step 6870, loss = 0.85 (1459.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:30:10.863086: step 6880, loss = 1.00 (1021.2 examples/sec; 0.125 sec/batch)\n",
      "2017-05-25 12:30:12.062283: step 6890, loss = 0.84 (1067.4 examples/sec; 0.120 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.2407\n",
      "2017-05-25 12:30:13.531020: step 6900, loss = 0.93 (871.5 examples/sec; 0.147 sec/batch)\n",
      "2017-05-25 12:30:14.422088: step 6910, loss = 1.15 (1436.5 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:30:15.481124: step 6920, loss = 1.07 (1208.6 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:30:16.494137: step 6930, loss = 0.95 (1263.6 examples/sec; 0.101 sec/batch)\n",
      "2017-05-25 12:30:17.533537: step 6940, loss = 1.01 (1231.5 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:30:18.433079: step 6950, loss = 1.00 (1422.9 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:30:19.294225: step 6960, loss = 0.95 (1486.4 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:30:20.194117: step 6970, loss = 1.14 (1422.4 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:30:21.059202: step 6980, loss = 0.98 (1479.6 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:30:21.932875: step 6990, loss = 1.01 (1465.1 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.7172\n",
      "2017-05-25 12:30:22.858362: step 7000, loss = 0.99 (1383.1 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 12:30:23.556659: step 7010, loss = 0.94 (1833.0 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:30:24.375844: step 7020, loss = 0.94 (1562.5 examples/sec; 0.082 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 7030 into /home/ipython/cnn-cifar10/tb_log/test-softmax/train/model.ckpt.\n",
      "2017-05-25 12:30:25.237417: step 7030, loss = 0.87 (1485.7 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:30:26.046435: step 7040, loss = 0.93 (1582.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:30:26.906770: step 7050, loss = 0.86 (1487.8 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:30:27.792123: step 7060, loss = 1.05 (1445.8 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:30:28.664632: step 7070, loss = 0.86 (1467.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:30:29.523600: step 7080, loss = 0.99 (1490.2 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:30:30.367620: step 7090, loss = 0.88 (1516.6 examples/sec; 0.084 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8089\n",
      "2017-05-25 12:30:31.326375: step 7100, loss = 1.05 (1335.1 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 12:30:32.015637: step 7110, loss = 0.99 (1857.1 examples/sec; 0.069 sec/batch)\n",
      "2017-05-25 12:30:32.809639: step 7120, loss = 1.30 (1612.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:30:33.628270: step 7130, loss = 0.98 (1563.6 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:30:34.487405: step 7140, loss = 1.01 (1489.9 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:30:37.130550: step 7170, loss = 1.07 (1470.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:30:37.966729: step 7180, loss = 1.11 (1530.8 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:30:38.776596: step 7190, loss = 0.87 (1580.5 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9082\n",
      "2017-05-25 12:30:39.725267: step 7200, loss = 0.99 (1349.3 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:30:40.432809: step 7210, loss = 1.11 (1809.1 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:30:41.237616: step 7220, loss = 1.04 (1590.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:30:42.064138: step 7230, loss = 1.02 (1548.7 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:30:42.936955: step 7240, loss = 0.93 (1466.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:30:43.819052: step 7250, loss = 0.94 (1451.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:30:44.686227: step 7260, loss = 1.11 (1476.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:30:45.561759: step 7270, loss = 0.83 (1462.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:30:46.374596: step 7280, loss = 1.06 (1574.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:30:47.166245: step 7290, loss = 0.93 (1616.9 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9212\n",
      "2017-05-25 12:30:48.112398: step 7300, loss = 0.84 (1352.8 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:30:48.811551: step 7310, loss = 1.04 (1830.8 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:30:49.606973: step 7320, loss = 0.99 (1609.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:30:50.497954: step 7330, loss = 1.09 (1436.6 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:30:51.390647: step 7340, loss = 0.82 (1433.9 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:30:52.259625: step 7350, loss = 0.93 (1473.0 examples/sec; 0.087 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:30:53.199880: step 7360, loss = 1.11 (1361.3 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:30:54.021017: step 7370, loss = 0.84 (1558.8 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:30:54.820978: step 7380, loss = 0.90 (1600.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:30:55.630873: step 7390, loss = 1.08 (1580.4 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.84\n",
      "2017-05-25 12:30:56.558266: step 7400, loss = 1.08 (1380.2 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 12:30:57.259229: step 7410, loss = 0.97 (1826.1 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:30:58.098279: step 7420, loss = 1.01 (1525.5 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:30:58.978057: step 7430, loss = 1.08 (1454.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:30:59.847332: step 7440, loss = 0.95 (1472.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:31:00.734955: step 7450, loss = 1.09 (1442.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:31:01.610168: step 7460, loss = 0.97 (1462.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:31:02.410796: step 7470, loss = 1.06 (1598.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:31:03.206324: step 7480, loss = 0.94 (1609.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:31:04.011227: step 7490, loss = 1.02 (1590.3 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8844\n",
      "2017-05-25 12:31:04.974108: step 7500, loss = 0.99 (1329.3 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 12:31:05.661599: step 7510, loss = 0.95 (1861.9 examples/sec; 0.069 sec/batch)\n",
      "2017-05-25 12:31:09.143379: step 7550, loss = 1.08 (1468.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:31:10.016368: step 7560, loss = 0.84 (1466.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:31:10.820630: step 7570, loss = 1.05 (1591.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:31:11.623763: step 7580, loss = 0.88 (1593.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:31:12.413764: step 7590, loss = 0.88 (1620.2 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8551\n",
      "2017-05-25 12:31:13.407925: step 7600, loss = 1.01 (1287.5 examples/sec; 0.099 sec/batch)\n",
      "2017-05-25 12:31:14.079599: step 7610, loss = 1.21 (1905.7 examples/sec; 0.067 sec/batch)\n",
      "2017-05-25 12:31:14.940716: step 7620, loss = 1.12 (1486.4 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:31:15.840689: step 7630, loss = 1.29 (1422.3 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:31:16.709103: step 7640, loss = 1.10 (1474.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:31:17.575376: step 7650, loss = 1.00 (1477.6 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:31:18.390018: step 7660, loss = 1.04 (1571.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:31:19.177497: step 7670, loss = 0.94 (1625.4 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:31:19.996714: step 7680, loss = 0.88 (1562.5 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:31:20.790687: step 7690, loss = 1.05 (1612.1 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.86\n",
      "2017-05-25 12:31:21.839834: step 7700, loss = 1.05 (1220.0 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:31:22.545669: step 7710, loss = 1.05 (1813.5 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:31:23.437626: step 7720, loss = 0.98 (1435.0 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:31:24.314283: step 7730, loss = 0.98 (1460.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:31:25.191988: step 7740, loss = 1.02 (1458.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:31:26.019182: step 7750, loss = 0.85 (1547.4 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:31:26.822489: step 7760, loss = 0.88 (1593.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:31:27.624797: step 7770, loss = 0.98 (1595.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:31:28.424392: step 7780, loss = 0.84 (1600.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:31:29.230089: step 7790, loss = 0.80 (1588.7 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8846\n",
      "2017-05-25 12:31:30.256071: step 7800, loss = 0.80 (1247.6 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:31:31.009382: step 7810, loss = 0.95 (1699.2 examples/sec; 0.075 sec/batch)\n",
      "2017-05-25 12:31:31.877312: step 7820, loss = 0.85 (1474.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:31:32.746746: step 7830, loss = 0.97 (1472.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:31:33.622186: step 7840, loss = 0.87 (1462.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:31:34.421806: step 7850, loss = 0.86 (1600.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:31:35.222067: step 7860, loss = 0.95 (1599.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:31:36.027744: step 7870, loss = 1.02 (1588.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:31:36.822208: step 7880, loss = 1.02 (1611.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:31:37.622933: step 7890, loss = 0.89 (1598.5 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9285\n",
      "2017-05-25 12:31:41.171019: step 7930, loss = 0.98 (1476.6 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:31:42.173482: step 7940, loss = 0.89 (1276.9 examples/sec; 0.100 sec/batch)\n",
      "2017-05-25 12:31:43.387886: step 7950, loss = 0.97 (1054.0 examples/sec; 0.121 sec/batch)\n",
      "2017-05-25 12:31:44.606504: step 7960, loss = 1.12 (1050.4 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 12:31:45.826422: step 7970, loss = 1.04 (1049.2 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 12:31:46.837841: step 7980, loss = 1.07 (1265.5 examples/sec; 0.101 sec/batch)\n",
      "2017-05-25 12:31:47.885345: step 7990, loss = 0.93 (1222.0 examples/sec; 0.105 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.47834\n",
      "2017-05-25 12:31:49.189969: step 8000, loss = 1.01 (981.1 examples/sec; 0.130 sec/batch)\n",
      "2017-05-25 12:31:50.002601: step 8010, loss = 0.85 (1575.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:31:50.864370: step 8020, loss = 1.07 (1485.3 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:31:51.737222: step 8030, loss = 1.04 (1466.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:31:52.601620: step 8040, loss = 1.12 (1480.8 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:31:53.484112: step 8050, loss = 0.92 (1450.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:31:54.308164: step 8060, loss = 0.88 (1553.3 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:31:55.116776: step 8070, loss = 0.98 (1583.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:31:55.898634: step 8080, loss = 0.88 (1637.1 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:31:56.703152: step 8090, loss = 0.94 (1591.0 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7832\n",
      "2017-05-25 12:31:57.674082: step 8100, loss = 0.81 (1318.3 examples/sec; 0.097 sec/batch)\n",
      "2017-05-25 12:31:58.394571: step 8110, loss = 0.94 (1776.6 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:31:59.265982: step 8120, loss = 1.05 (1468.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:32:00.166801: step 8130, loss = 1.05 (1420.9 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:32:01.035550: step 8140, loss = 0.86 (1473.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:32:01.901236: step 8150, loss = 0.90 (1478.6 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:32:02.691883: step 8160, loss = 1.04 (1618.9 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:32:03.493250: step 8170, loss = 0.89 (1597.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:32:04.287453: step 8180, loss = 1.00 (1611.7 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:32:05.109320: step 8190, loss = 0.88 (1557.4 examples/sec; 0.082 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8921\n",
      "2017-05-25 12:32:06.083306: step 8200, loss = 1.28 (1314.2 examples/sec; 0.097 sec/batch)\n",
      "2017-05-25 12:32:06.856349: step 8210, loss = 0.90 (1655.8 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:32:07.728419: step 8220, loss = 1.00 (1467.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:32:08.625034: step 8230, loss = 0.97 (1427.6 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:32:09.481666: step 8240, loss = 0.87 (1494.2 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:32:10.325775: step 8250, loss = 0.87 (1516.4 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:32:12.715359: step 8280, loss = 0.87 (1609.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:32:13.515055: step 8290, loss = 0.92 (1600.6 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.763\n",
      "2017-05-25 12:32:14.585956: step 8300, loss = 1.02 (1195.3 examples/sec; 0.107 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:32:15.289602: step 8310, loss = 0.96 (1819.1 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:32:16.165333: step 8320, loss = 1.01 (1461.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:32:17.039005: step 8330, loss = 0.94 (1465.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:32:17.891839: step 8340, loss = 1.02 (1500.9 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:32:18.700937: step 8350, loss = 0.89 (1582.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:32:19.482653: step 8360, loss = 0.92 (1637.4 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:32:20.303101: step 8370, loss = 1.13 (1560.1 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:32:21.105761: step 8380, loss = 1.01 (1594.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:32:21.908277: step 8390, loss = 0.89 (1595.0 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9508\n",
      "2017-05-25 12:32:22.951990: step 8400, loss = 0.92 (1226.4 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:32:23.703274: step 8410, loss = 0.96 (1703.8 examples/sec; 0.075 sec/batch)\n",
      "2017-05-25 12:32:24.587615: step 8420, loss = 0.85 (1447.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:32:25.457084: step 8430, loss = 1.08 (1472.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:32:26.271890: step 8440, loss = 0.91 (1570.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:32:27.062344: step 8450, loss = 0.90 (1619.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:32:27.860923: step 8460, loss = 0.94 (1602.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:32:28.653457: step 8470, loss = 0.93 (1615.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:32:29.466001: step 8480, loss = 0.94 (1575.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:32:30.339612: step 8490, loss = 0.76 (1465.2 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.897\n",
      "2017-05-25 12:32:31.357541: step 8500, loss = 0.83 (1257.5 examples/sec; 0.102 sec/batch)\n",
      "2017-05-25 12:32:32.135346: step 8510, loss = 0.91 (1645.7 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:32:33.017568: step 8520, loss = 0.98 (1450.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:32:33.887749: step 8530, loss = 0.95 (1471.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:32:34.672117: step 8540, loss = 0.93 (1631.9 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:32:35.472801: step 8550, loss = 0.99 (1598.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:32:36.262621: step 8560, loss = 0.89 (1620.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:32:37.043908: step 8570, loss = 0.97 (1638.3 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:32:37.862296: step 8580, loss = 0.88 (1564.1 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:32:38.729556: step 8590, loss = 1.29 (1475.9 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7909\n",
      "2017-05-25 12:32:39.838390: step 8600, loss = 0.78 (1154.4 examples/sec; 0.111 sec/batch)\n",
      "2017-05-25 12:32:40.522515: step 8610, loss = 0.88 (1871.0 examples/sec; 0.068 sec/batch)\n",
      "2017-05-25 12:32:41.402602: step 8620, loss = 1.14 (1454.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:32:42.241054: step 8630, loss = 0.74 (1526.6 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:32:44.625033: step 8660, loss = 0.95 (1596.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:32:45.430021: step 8670, loss = 0.94 (1590.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:32:46.297923: step 8680, loss = 0.85 (1474.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:32:47.173092: step 8690, loss = 0.85 (1462.6 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9708\n",
      "2017-05-25 12:32:48.192473: step 8700, loss = 0.99 (1255.7 examples/sec; 0.102 sec/batch)\n",
      "2017-05-25 12:32:48.972729: step 8710, loss = 0.94 (1640.5 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:32:49.844953: step 8720, loss = 0.90 (1467.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:32:50.664200: step 8730, loss = 0.96 (1562.4 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:32:51.468778: step 8740, loss = 0.84 (1590.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:32:52.258694: step 8750, loss = 0.91 (1620.4 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:32:53.053093: step 8760, loss = 0.89 (1611.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:32:53.863002: step 8770, loss = 0.83 (1580.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:32:54.729500: step 8780, loss = 0.94 (1477.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:32:55.597477: step 8790, loss = 1.02 (1474.7 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7615\n",
      "2017-05-25 12:32:56.696120: step 8800, loss = 0.94 (1165.1 examples/sec; 0.110 sec/batch)\n",
      "2017-05-25 12:32:57.465244: step 8810, loss = 0.99 (1664.2 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:32:58.555122: step 8820, loss = 0.98 (1174.4 examples/sec; 0.109 sec/batch)\n",
      "2017-05-25 12:32:59.763465: step 8830, loss = 0.92 (1059.3 examples/sec; 0.121 sec/batch)\n",
      "2017-05-25 12:33:00.998553: step 8840, loss = 1.22 (1036.4 examples/sec; 0.124 sec/batch)\n",
      "2017-05-25 12:33:02.147988: step 8850, loss = 0.84 (1113.6 examples/sec; 0.115 sec/batch)\n",
      "2017-05-25 12:33:03.201491: step 8860, loss = 0.83 (1215.0 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:33:04.218409: step 8870, loss = 0.87 (1258.7 examples/sec; 0.102 sec/batch)\n",
      "2017-05-25 12:33:05.251943: step 8880, loss = 0.91 (1238.5 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:33:06.212554: step 8890, loss = 0.91 (1332.5 examples/sec; 0.096 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.48272\n",
      "2017-05-25 12:33:07.240431: step 8900, loss = 0.79 (1245.3 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:33:08.004067: step 8910, loss = 0.97 (1676.2 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 12:33:08.873371: step 8920, loss = 0.75 (1472.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:33:09.744552: step 8930, loss = 0.92 (1469.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:33:10.560552: step 8940, loss = 0.88 (1568.6 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:33:11.357776: step 8950, loss = 0.84 (1605.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:33:12.158386: step 8960, loss = 0.85 (1598.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:33:12.950155: step 8970, loss = 0.76 (1616.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:33:13.747942: step 8980, loss = 0.95 (1604.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:33:17.304941: step 9020, loss = 0.93 (1471.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:33:18.139957: step 9030, loss = 0.77 (1532.9 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:33:18.968804: step 9040, loss = 1.06 (1544.3 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:33:19.766279: step 9050, loss = 0.80 (1605.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:33:20.578951: step 9060, loss = 0.93 (1575.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:33:21.368169: step 9070, loss = 0.88 (1621.9 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:33:22.219553: step 9080, loss = 0.85 (1503.4 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:33:23.090829: step 9090, loss = 0.87 (1469.1 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8091\n",
      "2017-05-25 12:33:24.110745: step 9100, loss = 0.99 (1255.0 examples/sec; 0.102 sec/batch)\n",
      "2017-05-25 12:33:24.875113: step 9110, loss = 1.28 (1674.6 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 12:33:25.749054: step 9120, loss = 0.82 (1464.6 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:33:26.540579: step 9130, loss = 1.03 (1617.2 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:33:27.348574: step 9140, loss = 0.86 (1584.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:33:28.144912: step 9150, loss = 1.01 (1607.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:33:28.948551: step 9160, loss = 1.01 (1592.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:33:29.739231: step 9170, loss = 1.06 (1618.9 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:33:30.643437: step 9180, loss = 0.99 (1415.6 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:33:31.526130: step 9190, loss = 1.07 (1450.1 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8547\n",
      "2017-05-25 12:33:32.546097: step 9200, loss = 0.92 (1254.9 examples/sec; 0.102 sec/batch)\n",
      "2017-05-25 12:33:33.317915: step 9210, loss = 0.89 (1658.4 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:33:34.170264: step 9220, loss = 0.86 (1501.7 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:33:34.964967: step 9230, loss = 0.88 (1610.7 examples/sec; 0.079 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:33:35.765883: step 9240, loss = 0.89 (1598.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:33:36.566471: step 9250, loss = 0.99 (1598.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:33:37.366425: step 9260, loss = 0.84 (1600.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:33:38.198025: step 9270, loss = 0.82 (1539.2 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:33:39.064108: step 9280, loss = 0.86 (1477.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:33:39.931965: step 9290, loss = 0.89 (1474.9 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8578\n",
      "2017-05-25 12:33:40.981924: step 9300, loss = 0.92 (1219.1 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:33:41.767021: step 9310, loss = 0.93 (1630.4 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:33:42.715727: step 9320, loss = 1.08 (1349.2 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:33:43.531011: step 9330, loss = 1.07 (1570.0 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:33:44.325119: step 9340, loss = 0.92 (1611.9 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:33:45.141344: step 9350, loss = 0.94 (1568.2 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:33:45.959663: step 9360, loss = 0.99 (1564.2 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:33:48.578564: step 9390, loss = 0.89 (1476.0 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.5639\n",
      "2017-05-25 12:33:49.627287: step 9400, loss = 1.09 (1220.5 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:33:51.134677: step 9410, loss = 1.01 (849.2 examples/sec; 0.151 sec/batch)\n",
      "2017-05-25 12:33:52.615976: step 9420, loss = 0.88 (864.1 examples/sec; 0.148 sec/batch)\n",
      "2017-05-25 12:33:54.076611: step 9430, loss = 0.92 (876.3 examples/sec; 0.146 sec/batch)\n",
      "2017-05-25 12:33:55.378413: step 9440, loss = 0.84 (983.3 examples/sec; 0.130 sec/batch)\n",
      "2017-05-25 12:33:56.737542: step 9450, loss = 1.01 (941.8 examples/sec; 0.136 sec/batch)\n",
      "2017-05-25 12:33:58.162439: step 9460, loss = 0.83 (898.3 examples/sec; 0.142 sec/batch)\n",
      "2017-05-25 12:33:59.218912: step 9470, loss = 0.83 (1211.6 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:34:00.146353: step 9480, loss = 0.94 (1380.1 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 12:34:01.478546: step 9490, loss = 0.82 (960.8 examples/sec; 0.133 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 7.69986\n",
      "2017-05-25 12:34:02.615418: step 9500, loss = 0.91 (1125.9 examples/sec; 0.114 sec/batch)\n",
      "2017-05-25 12:34:03.743502: step 9510, loss = 1.01 (1134.7 examples/sec; 0.113 sec/batch)\n",
      "2017-05-25 12:34:04.646248: step 9520, loss = 1.05 (1417.9 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:34:05.628315: step 9530, loss = 0.84 (1303.4 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 12:34:06.676245: step 9540, loss = 0.91 (1221.5 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:34:07.644812: step 9550, loss = 1.13 (1321.5 examples/sec; 0.097 sec/batch)\n",
      "2017-05-25 12:34:08.595131: step 9560, loss = 0.98 (1346.9 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:34:09.716336: step 9570, loss = 0.87 (1141.6 examples/sec; 0.112 sec/batch)\n",
      "2017-05-25 12:34:10.766326: step 9580, loss = 0.80 (1219.1 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:34:12.050038: step 9590, loss = 0.83 (997.1 examples/sec; 0.128 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.54026\n",
      "2017-05-25 12:34:13.096327: step 9600, loss = 1.07 (1223.4 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:34:13.984578: step 9610, loss = 0.79 (1441.0 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:34:14.966536: step 9620, loss = 0.80 (1303.5 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 12:34:15.988744: step 9630, loss = 1.09 (1252.2 examples/sec; 0.102 sec/batch)\n",
      "2017-05-25 12:34:16.933740: step 9640, loss = 0.90 (1354.5 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:34:17.851813: step 9650, loss = 1.00 (1394.2 examples/sec; 0.092 sec/batch)\n",
      "2017-05-25 12:34:21.248927: step 9690, loss = 0.82 (1500.9 examples/sec; 0.085 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.9238\n",
      "2017-05-25 12:34:22.250902: step 9700, loss = 1.00 (1277.5 examples/sec; 0.100 sec/batch)\n",
      "2017-05-25 12:34:23.017350: step 9710, loss = 1.05 (1670.0 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:34:23.899518: step 9720, loss = 0.97 (1451.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:34:24.779889: step 9730, loss = 1.11 (1453.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:34:25.666329: step 9740, loss = 0.93 (1444.0 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:34:26.520769: step 9750, loss = 1.01 (1498.1 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:34:27.326994: step 9760, loss = 0.82 (1587.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:34:28.126438: step 9770, loss = 0.90 (1601.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:34:28.938064: step 9780, loss = 0.86 (1577.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:34:29.745119: step 9790, loss = 0.87 (1586.0 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6163\n",
      "2017-05-25 12:34:30.859493: step 9800, loss = 0.81 (1148.6 examples/sec; 0.111 sec/batch)\n",
      "2017-05-25 12:34:31.574913: step 9810, loss = 0.90 (1789.2 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:34:32.450644: step 9820, loss = 0.99 (1461.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:34:33.343183: step 9830, loss = 0.70 (1434.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:34:34.216517: step 9840, loss = 0.93 (1465.6 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:34:35.018758: step 9850, loss = 0.94 (1595.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:34:35.820097: step 9860, loss = 0.98 (1597.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:34:36.622596: step 9870, loss = 0.91 (1595.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:34:37.419682: step 9880, loss = 0.96 (1605.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:34:38.265345: step 9890, loss = 0.91 (1513.6 examples/sec; 0.085 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7224\n",
      "2017-05-25 12:34:39.392059: step 9900, loss = 0.81 (1136.0 examples/sec; 0.113 sec/batch)\n",
      "2017-05-25 12:34:40.113408: step 9910, loss = 0.75 (1774.5 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:34:40.983843: step 9920, loss = 1.10 (1470.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:34:41.862992: step 9930, loss = 0.97 (1456.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:34:42.677157: step 9940, loss = 0.91 (1572.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:34:43.495114: step 9950, loss = 0.94 (1564.9 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:34:44.295664: step 9960, loss = 1.00 (1598.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:34:45.105138: step 9970, loss = 1.04 (1581.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:34:45.907802: step 9980, loss = 0.80 (1594.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:34:46.791804: step 9990, loss = 1.09 (1448.0 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8608\n",
      "2017-05-25 12:34:47.821174: step 10000, loss = 0.96 (1243.5 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:34:48.602539: step 10010, loss = 1.04 (1638.2 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:34:49.475588: step 10020, loss = 0.93 (1466.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:34:50.332132: step 10030, loss = 0.86 (1494.4 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:34:53.586215: step 10070, loss = 0.75 (1534.6 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:34:54.444806: step 10080, loss = 0.74 (1490.8 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:34:55.318758: step 10090, loss = 1.11 (1464.6 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.725\n",
      "2017-05-25 12:34:56.352303: step 10100, loss = 0.98 (1239.4 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:34:57.136371: step 10110, loss = 1.13 (1630.9 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:34:58.090635: step 10120, loss = 0.91 (1341.3 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:34:59.303010: step 10130, loss = 1.06 (1055.8 examples/sec; 0.121 sec/batch)\n",
      "2017-05-25 12:35:00.537092: step 10140, loss = 0.77 (1037.2 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 12:35:01.750363: step 10150, loss = 0.90 (1055.0 examples/sec; 0.121 sec/batch)\n",
      "2017-05-25 12:35:02.805214: step 10160, loss = 0.81 (1213.4 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:35:03.861542: step 10170, loss = 0.84 (1211.7 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:35:04.910965: step 10180, loss = 1.04 (1219.7 examples/sec; 0.105 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:35:05.943971: step 10190, loss = 0.94 (1239.1 examples/sec; 0.103 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.35862\n",
      "2017-05-25 12:35:07.037957: step 10200, loss = 0.77 (1170.0 examples/sec; 0.109 sec/batch)\n",
      "2017-05-25 12:35:07.767029: step 10210, loss = 0.86 (1755.7 examples/sec; 0.073 sec/batch)\n",
      "2017-05-25 12:35:08.663249: step 10220, loss = 0.86 (1428.2 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:35:09.535084: step 10230, loss = 0.94 (1468.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:35:10.383790: step 10240, loss = 0.94 (1508.2 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:35:11.256097: step 10250, loss = 0.99 (1467.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:35:12.091380: step 10260, loss = 0.94 (1532.4 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:35:12.936766: step 10270, loss = 0.92 (1514.1 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:35:13.778254: step 10280, loss = 0.91 (1521.1 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:35:14.688029: step 10290, loss = 0.84 (1406.9 examples/sec; 0.091 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.52\n",
      "2017-05-25 12:35:15.716504: step 10300, loss = 0.89 (1244.6 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:35:16.497147: step 10310, loss = 0.94 (1639.7 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:35:17.378034: step 10320, loss = 0.96 (1453.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:35:18.217251: step 10330, loss = 1.14 (1525.2 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:35:19.025788: step 10340, loss = 0.84 (1583.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:35:19.826193: step 10350, loss = 1.27 (1599.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:35:20.659256: step 10360, loss = 0.89 (1536.5 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:35:21.471656: step 10370, loss = 0.89 (1575.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:35:22.330983: step 10380, loss = 1.06 (1489.5 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:35:25.067146: step 10410, loss = 0.86 (1714.9 examples/sec; 0.075 sec/batch)\n",
      "2017-05-25 12:35:25.940263: step 10420, loss = 0.81 (1466.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:35:26.742334: step 10430, loss = 0.83 (1595.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:35:27.543843: step 10440, loss = 0.90 (1597.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:35:28.357556: step 10450, loss = 0.97 (1573.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:35:29.161314: step 10460, loss = 1.04 (1592.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:35:29.968254: step 10470, loss = 1.13 (1586.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:35:30.870130: step 10480, loss = 0.86 (1419.3 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:35:31.751924: step 10490, loss = 1.07 (1451.6 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8357\n",
      "2017-05-25 12:35:32.769813: step 10500, loss = 0.89 (1257.5 examples/sec; 0.102 sec/batch)\n",
      "2017-05-25 12:35:33.578329: step 10510, loss = 0.92 (1583.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:35:34.405729: step 10520, loss = 1.14 (1547.0 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:35:35.247851: step 10530, loss = 0.96 (1520.0 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:35:36.054949: step 10540, loss = 1.06 (1585.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:35:36.860158: step 10550, loss = 0.87 (1589.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:35:37.654353: step 10560, loss = 0.89 (1611.7 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:35:38.538539: step 10570, loss = 0.88 (1447.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:35:39.425236: step 10580, loss = 0.87 (1443.6 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:35:40.322866: step 10590, loss = 0.91 (1426.0 examples/sec; 0.090 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.5419\n",
      "2017-05-25 12:35:41.435768: step 10600, loss = 0.70 (1150.1 examples/sec; 0.111 sec/batch)\n",
      "2017-05-25 12:35:42.124802: step 10610, loss = 0.90 (1857.7 examples/sec; 0.069 sec/batch)\n",
      "2017-05-25 12:35:42.922671: step 10620, loss = 0.94 (1604.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:35:43.727786: step 10630, loss = 0.79 (1589.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:35:44.533857: step 10640, loss = 0.85 (1587.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:35:45.339595: step 10650, loss = 0.92 (1588.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:35:46.166371: step 10660, loss = 0.95 (1548.2 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:35:47.045923: step 10670, loss = 0.95 (1455.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:35:47.928651: step 10680, loss = 0.82 (1450.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:35:48.814229: step 10690, loss = 0.91 (1445.4 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8959\n",
      "2017-05-25 12:35:49.840398: step 10700, loss = 0.99 (1247.4 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:35:50.900434: step 10710, loss = 0.74 (1207.5 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:35:52.141202: step 10720, loss = 0.99 (1031.6 examples/sec; 0.124 sec/batch)\n",
      "2017-05-25 12:35:53.364951: step 10730, loss = 0.95 (1046.0 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 12:35:54.483526: step 10740, loss = 0.97 (1144.3 examples/sec; 0.112 sec/batch)\n",
      "2017-05-25 12:35:56.591085: step 10760, loss = 0.92 (1217.7 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:35:57.634631: step 10770, loss = 1.03 (1226.6 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:35:58.564972: step 10780, loss = 0.89 (1375.8 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 12:35:59.441138: step 10790, loss = 0.90 (1460.9 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.3782\n",
      "2017-05-25 12:36:00.503013: step 10800, loss = 0.89 (1205.4 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:36:01.277200: step 10810, loss = 0.86 (1653.4 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:36:02.130382: step 10820, loss = 0.80 (1500.3 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:36:02.935069: step 10830, loss = 0.98 (1590.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:36:03.746418: step 10840, loss = 0.74 (1577.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:36:04.555812: step 10850, loss = 0.96 (1581.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:36:05.360361: step 10860, loss = 0.78 (1591.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:36:06.205561: step 10870, loss = 0.97 (1514.4 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:36:07.087132: step 10880, loss = 0.96 (1452.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:36:07.966703: step 10890, loss = 0.87 (1455.3 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7552\n",
      "2017-05-25 12:36:09.010157: step 10900, loss = 1.01 (1226.7 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:36:09.792890: step 10910, loss = 1.03 (1635.3 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:36:10.623461: step 10920, loss = 0.82 (1541.1 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:36:11.423397: step 10930, loss = 0.84 (1600.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:36:12.239457: step 10940, loss = 1.04 (1568.5 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:36:13.047710: step 10950, loss = 0.80 (1583.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:36:13.859425: step 10960, loss = 0.82 (1576.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:36:14.727153: step 10970, loss = 0.84 (1475.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:36:15.593998: step 10980, loss = 1.04 (1476.6 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:36:16.480036: step 10990, loss = 0.87 (1444.6 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.5133\n",
      "2017-05-25 12:36:17.695277: step 11000, loss = 0.87 (1053.3 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 12:36:18.348309: step 11010, loss = 0.79 (1960.1 examples/sec; 0.065 sec/batch)\n",
      "2017-05-25 12:36:19.162217: step 11020, loss = 0.87 (1572.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:36:19.964495: step 11030, loss = 1.02 (1595.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:36:20.779291: step 11040, loss = 0.91 (1570.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:36:21.583858: step 11050, loss = 0.84 (1590.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:36:22.433212: step 11060, loss = 1.00 (1507.0 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:36:23.314700: step 11070, loss = 0.92 (1452.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:36:24.198147: step 11080, loss = 1.06 (1448.9 examples/sec; 0.088 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:36:25.072772: step 11090, loss = 1.08 (1463.5 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9193\n",
      "2017-05-25 12:36:26.086492: step 11100, loss = 1.00 (1262.7 examples/sec; 0.101 sec/batch)\n",
      "2017-05-25 12:36:29.219799: step 11140, loss = 0.91 (1575.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:36:30.043081: step 11150, loss = 0.86 (1554.8 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:36:30.955212: step 11160, loss = 0.89 (1403.3 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 12:36:31.935618: step 11170, loss = 0.87 (1305.6 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 12:36:32.806744: step 11180, loss = 0.79 (1469.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:36:33.681167: step 11190, loss = 0.81 (1463.8 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6902\n",
      "2017-05-25 12:36:34.639288: step 11200, loss = 1.02 (1335.9 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 12:36:35.359180: step 11210, loss = 1.02 (1778.0 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:36:36.171005: step 11220, loss = 1.04 (1576.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:36:36.954767: step 11230, loss = 0.86 (1633.1 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:36:37.770931: step 11240, loss = 1.01 (1568.3 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:36:38.629078: step 11250, loss = 0.98 (1491.6 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:36:39.520342: step 11260, loss = 0.91 (1436.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:36:40.421868: step 11270, loss = 0.75 (1419.8 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:36:41.305872: step 11280, loss = 0.86 (1448.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:36:42.156101: step 11290, loss = 1.02 (1505.5 examples/sec; 0.085 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8251\n",
      "2017-05-25 12:36:43.095760: step 11300, loss = 0.98 (1362.2 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:36:43.804281: step 11310, loss = 0.88 (1806.6 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:36:44.605935: step 11320, loss = 1.01 (1596.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:36:45.421957: step 11330, loss = 0.96 (1568.6 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:36:46.262380: step 11340, loss = 0.87 (1523.0 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:36:47.133751: step 11350, loss = 0.85 (1469.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:36:48.012381: step 11360, loss = 0.77 (1456.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:36:48.887281: step 11370, loss = 0.95 (1463.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:36:49.769494: step 11380, loss = 0.78 (1450.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:36:50.602806: step 11390, loss = 0.72 (1536.0 examples/sec; 0.083 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8293\n",
      "2017-05-25 12:36:51.549362: step 11400, loss = 0.82 (1352.3 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:36:52.247485: step 11410, loss = 0.74 (1833.5 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:36:53.045244: step 11420, loss = 0.84 (1604.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:36:53.854488: step 11430, loss = 1.08 (1581.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:36:54.719004: step 11440, loss = 0.92 (1480.6 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:36:55.605734: step 11450, loss = 0.93 (1443.5 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:36:56.478748: step 11460, loss = 1.04 (1466.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:36:57.346594: step 11470, loss = 1.11 (1474.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:36:58.340023: step 11480, loss = 0.94 (1288.5 examples/sec; 0.099 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.4997\n",
      "2017-05-25 12:37:01.077140: step 11500, loss = 0.97 (846.2 examples/sec; 0.151 sec/batch)\n",
      "2017-05-25 12:37:02.114552: step 11510, loss = 1.00 (1233.8 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:37:03.183017: step 11520, loss = 0.95 (1198.0 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:37:04.244332: step 11530, loss = 0.84 (1206.0 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:37:05.295125: step 11540, loss = 1.22 (1218.1 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:37:06.273543: step 11550, loss = 0.80 (1308.2 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 12:37:07.153247: step 11560, loss = 0.85 (1455.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:37:08.038439: step 11570, loss = 0.97 (1446.0 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:37:08.929193: step 11580, loss = 0.93 (1437.0 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:37:09.799150: step 11590, loss = 1.04 (1471.3 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.3275\n",
      "2017-05-25 12:37:10.756899: step 11600, loss = 0.77 (1336.5 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 12:37:11.484429: step 11610, loss = 0.86 (1759.4 examples/sec; 0.073 sec/batch)\n",
      "2017-05-25 12:37:12.301205: step 11620, loss = 0.95 (1567.1 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:37:13.098347: step 11630, loss = 1.34 (1605.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:37:13.905217: step 11640, loss = 0.97 (1586.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:37:14.787167: step 11650, loss = 0.83 (1451.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:37:15.676650: step 11660, loss = 1.21 (1439.0 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:37:16.574954: step 11670, loss = 0.97 (1424.9 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:37:17.452333: step 11680, loss = 0.82 (1458.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:37:18.297848: step 11690, loss = 0.99 (1513.9 examples/sec; 0.085 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7801\n",
      "2017-05-25 12:37:19.245076: step 11700, loss = 0.89 (1351.3 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:37:19.952810: step 11710, loss = 0.68 (1808.6 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:37:20.786336: step 11720, loss = 1.02 (1535.6 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:37:21.585756: step 11730, loss = 1.10 (1601.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:37:22.430928: step 11740, loss = 0.91 (1514.5 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:37:23.313651: step 11750, loss = 0.77 (1450.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:37:24.218265: step 11760, loss = 0.87 (1415.0 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:37:25.085268: step 11770, loss = 1.02 (1476.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:37:25.975943: step 11780, loss = 0.94 (1437.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:37:26.788628: step 11790, loss = 1.13 (1575.0 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7036\n",
      "2017-05-25 12:37:27.789755: step 11800, loss = 0.82 (1278.6 examples/sec; 0.100 sec/batch)\n",
      "2017-05-25 12:37:28.443838: step 11810, loss = 0.77 (1956.9 examples/sec; 0.065 sec/batch)\n",
      "2017-05-25 12:37:29.236598: step 11820, loss = 0.80 (1614.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:37:30.070000: step 11830, loss = 1.02 (1535.9 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:37:32.733043: step 11860, loss = 0.90 (1449.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:37:33.608358: step 11870, loss = 0.97 (1462.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:37:34.437635: step 11880, loss = 0.87 (1543.6 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:37:35.247375: step 11890, loss = 0.72 (1580.7 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9022\n",
      "2017-05-25 12:37:36.191486: step 11900, loss = 1.07 (1355.8 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:37:36.896399: step 11910, loss = 0.91 (1815.8 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:37:37.701921: step 11920, loss = 0.78 (1589.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:37:38.561546: step 11930, loss = 0.91 (1489.0 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:37:39.447878: step 11940, loss = 0.73 (1444.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:37:40.342913: step 11950, loss = 0.99 (1430.1 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:37:41.228507: step 11960, loss = 1.13 (1445.4 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:37:42.093978: step 11970, loss = 0.74 (1479.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:37:42.898594: step 11980, loss = 0.86 (1590.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:37:43.703547: step 11990, loss = 0.84 (1590.2 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8335\n",
      "2017-05-25 12:37:44.642399: step 12000, loss = 0.82 (1363.4 examples/sec; 0.094 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:37:45.353585: step 12010, loss = 0.90 (1799.8 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:37:46.175828: step 12020, loss = 0.80 (1556.7 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:37:47.047098: step 12030, loss = 0.85 (1469.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:37:47.926781: step 12040, loss = 0.79 (1455.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:37:48.798761: step 12050, loss = 0.90 (1467.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:37:49.685355: step 12060, loss = 1.05 (1443.7 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:37:50.525959: step 12070, loss = 0.89 (1522.7 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:37:51.318681: step 12080, loss = 0.93 (1614.7 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:37:52.131621: step 12090, loss = 0.94 (1574.5 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8665\n",
      "2017-05-25 12:37:53.070494: step 12100, loss = 0.71 (1363.3 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:37:53.774479: step 12110, loss = 0.95 (1818.2 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:37:54.656080: step 12120, loss = 0.85 (1451.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:37:55.531031: step 12130, loss = 1.17 (1462.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:37:56.409470: step 12140, loss = 1.05 (1457.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:37:57.300624: step 12150, loss = 0.76 (1436.3 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:37:58.146150: step 12160, loss = 0.86 (1513.9 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:37:58.952917: step 12170, loss = 0.89 (1586.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:37:59.750051: step 12180, loss = 0.95 (1605.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:38:00.562005: step 12190, loss = 0.89 (1576.4 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8715\n",
      "2017-05-25 12:38:01.492642: step 12200, loss = 0.89 (1375.4 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 12:38:02.233723: step 12210, loss = 1.11 (1727.2 examples/sec; 0.074 sec/batch)\n",
      "2017-05-25 12:38:04.893419: step 12240, loss = 0.96 (1471.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:38:05.772059: step 12250, loss = 0.81 (1456.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:38:06.894958: step 12260, loss = 0.88 (1139.9 examples/sec; 0.112 sec/batch)\n",
      "2017-05-25 12:38:08.109798: step 12270, loss = 0.73 (1053.6 examples/sec; 0.121 sec/batch)\n",
      "2017-05-25 12:38:09.343726: step 12280, loss = 0.96 (1037.3 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 12:38:10.512678: step 12290, loss = 0.80 (1095.0 examples/sec; 0.117 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.65433\n",
      "2017-05-25 12:38:11.851698: step 12300, loss = 0.81 (955.9 examples/sec; 0.134 sec/batch)\n",
      "2017-05-25 12:38:12.695026: step 12310, loss = 0.98 (1517.8 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:38:13.751543: step 12320, loss = 0.88 (1211.5 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:38:14.675558: step 12330, loss = 0.90 (1385.3 examples/sec; 0.092 sec/batch)\n",
      "2017-05-25 12:38:15.543565: step 12340, loss = 0.87 (1474.6 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:38:16.414640: step 12350, loss = 0.71 (1469.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:38:17.282940: step 12360, loss = 0.90 (1474.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:38:18.152485: step 12370, loss = 0.77 (1472.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:38:18.944388: step 12380, loss = 0.89 (1616.4 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:38:19.750213: step 12390, loss = 0.99 (1588.4 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.2848\n",
      "2017-05-25 12:38:20.714250: step 12400, loss = 1.04 (1327.7 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 12:38:21.418123: step 12410, loss = 1.11 (1818.5 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:38:22.232591: step 12420, loss = 0.88 (1571.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:38:23.112520: step 12430, loss = 0.76 (1454.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:38:23.998442: step 12440, loss = 0.92 (1444.8 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:38:24.888690: step 12450, loss = 0.74 (1437.8 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:38:25.766659: step 12460, loss = 1.00 (1457.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:38:26.603306: step 12470, loss = 1.02 (1529.9 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:38:27.414147: step 12480, loss = 0.78 (1578.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:38:28.220182: step 12490, loss = 0.94 (1588.0 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8664\n",
      "2017-05-25 12:38:29.139233: step 12500, loss = 1.00 (1392.7 examples/sec; 0.092 sec/batch)\n",
      "2017-05-25 12:38:29.902760: step 12510, loss = 0.89 (1676.4 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 12:38:30.777740: step 12520, loss = 0.92 (1462.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:38:31.712958: step 12530, loss = 0.93 (1368.7 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:38:32.598960: step 12540, loss = 0.98 (1444.7 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:38:33.474197: step 12550, loss = 0.90 (1462.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:38:34.325379: step 12560, loss = 0.75 (1503.8 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:38:36.727311: step 12590, loss = 0.90 (1600.8 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7073\n",
      "2017-05-25 12:38:37.681255: step 12600, loss = 0.81 (1341.8 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:38:38.410604: step 12610, loss = 0.87 (1755.0 examples/sec; 0.073 sec/batch)\n",
      "2017-05-25 12:38:39.297818: step 12620, loss = 0.77 (1442.7 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:38:40.182477: step 12630, loss = 0.83 (1446.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:38:41.050429: step 12640, loss = 1.00 (1474.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:38:41.938573: step 12650, loss = 1.07 (1441.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:38:42.762821: step 12660, loss = 0.92 (1552.9 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:38:43.557715: step 12670, loss = 0.99 (1610.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:38:44.365850: step 12680, loss = 1.01 (1583.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:38:45.172328: step 12690, loss = 0.81 (1587.2 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8362\n",
      "2017-05-25 12:38:46.131028: step 12700, loss = 0.80 (1335.1 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 12:38:46.921088: step 12710, loss = 0.88 (1620.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:38:47.794010: step 12720, loss = 0.83 (1466.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:38:48.672871: step 12730, loss = 0.92 (1456.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:38:49.539690: step 12740, loss = 1.01 (1476.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:38:50.410225: step 12750, loss = 1.15 (1470.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:38:51.222072: step 12760, loss = 0.85 (1576.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:38:52.026279: step 12770, loss = 1.08 (1591.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:38:52.832278: step 12780, loss = 1.03 (1588.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:38:53.625426: step 12790, loss = 0.81 (1613.8 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7738\n",
      "2017-05-25 12:38:54.623776: step 12800, loss = 0.71 (1282.1 examples/sec; 0.100 sec/batch)\n",
      "2017-05-25 12:38:55.414598: step 12810, loss = 0.81 (1618.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:38:56.284716: step 12820, loss = 0.93 (1471.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:38:57.184752: step 12830, loss = 1.03 (1422.2 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:38:58.060347: step 12840, loss = 1.13 (1461.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:38:58.871575: step 12850, loss = 0.91 (1577.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:38:59.673139: step 12860, loss = 0.83 (1596.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:39:00.492336: step 12870, loss = 0.88 (1562.5 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:39:01.305018: step 12880, loss = 1.11 (1575.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:39:02.193525: step 12890, loss = 0.96 (1440.6 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.4387\n",
      "2017-05-25 12:39:03.365573: step 12900, loss = 1.07 (1092.1 examples/sec; 0.117 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:39:04.107442: step 12910, loss = 0.73 (1725.4 examples/sec; 0.074 sec/batch)\n",
      "2017-05-25 12:39:04.985935: step 12920, loss = 0.92 (1457.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:39:05.896118: step 12930, loss = 0.87 (1406.3 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 12:39:10.822121: step 12990, loss = 0.95 (1403.6 examples/sec; 0.091 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7646\n",
      "2017-05-25 12:39:11.867541: step 13000, loss = 0.99 (1224.4 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:39:12.630793: step 13010, loss = 0.83 (1677.0 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 12:39:13.521233: step 13020, loss = 0.90 (1437.5 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:39:14.382075: step 13030, loss = 1.00 (1486.9 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:39:15.183661: step 13040, loss = 0.80 (1596.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:39:15.979108: step 13050, loss = 0.95 (1609.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:39:16.776159: step 13060, loss = 0.89 (1605.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:39:17.593364: step 13070, loss = 0.86 (1566.3 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:39:18.420668: step 13080, loss = 0.89 (1547.2 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:39:19.305304: step 13090, loss = 0.90 (1446.9 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7793\n",
      "2017-05-25 12:39:20.354979: step 13100, loss = 0.66 (1219.4 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:39:21.130326: step 13110, loss = 0.94 (1650.9 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:39:22.001455: step 13120, loss = 0.90 (1469.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:39:22.819957: step 13130, loss = 0.70 (1563.8 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:39:23.619311: step 13140, loss = 0.70 (1601.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:39:24.442656: step 13150, loss = 0.95 (1554.6 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:39:25.264061: step 13160, loss = 0.89 (1558.3 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:39:26.053878: step 13170, loss = 0.92 (1620.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:39:26.932057: step 13180, loss = 0.71 (1457.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:39:27.827872: step 13190, loss = 0.78 (1428.9 examples/sec; 0.090 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7606\n",
      "2017-05-25 12:39:28.858382: step 13200, loss = 0.86 (1242.1 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:39:29.627737: step 13210, loss = 0.86 (1663.7 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:39:30.708825: step 13220, loss = 0.89 (1184.0 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 12:39:31.917377: step 13230, loss = 0.82 (1059.1 examples/sec; 0.121 sec/batch)\n",
      "2017-05-25 12:39:33.154379: step 13240, loss = 0.93 (1034.8 examples/sec; 0.124 sec/batch)\n",
      "2017-05-25 12:39:34.337604: step 13250, loss = 0.85 (1081.8 examples/sec; 0.118 sec/batch)\n",
      "2017-05-25 12:39:35.397789: step 13260, loss = 0.65 (1207.3 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:39:36.441769: step 13270, loss = 1.02 (1226.1 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:39:37.479371: step 13280, loss = 0.94 (1233.6 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:39:38.450301: step 13290, loss = 0.90 (1318.3 examples/sec; 0.097 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.40677\n",
      "2017-05-25 12:39:39.488672: step 13300, loss = 0.82 (1232.7 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:39:40.278738: step 13310, loss = 0.79 (1620.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:39:42.869484: step 13340, loss = 0.80 (1541.1 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:39:43.669070: step 13350, loss = 0.90 (1600.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:39:44.471927: step 13360, loss = 0.80 (1594.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:39:45.296990: step 13370, loss = 0.94 (1551.4 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:39:46.114880: step 13380, loss = 0.78 (1565.0 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:39:46.991163: step 13390, loss = 1.03 (1460.7 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6248\n",
      "2017-05-25 12:39:48.090881: step 13400, loss = 0.83 (1163.9 examples/sec; 0.110 sec/batch)\n",
      "2017-05-25 12:39:48.797652: step 13410, loss = 1.09 (1811.0 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:39:49.693554: step 13420, loss = 0.76 (1428.7 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:39:50.554784: step 13430, loss = 0.85 (1486.2 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:39:51.364802: step 13440, loss = 0.79 (1580.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:39:52.164557: step 13450, loss = 0.89 (1600.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:39:52.979495: step 13460, loss = 0.78 (1570.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:39:53.787721: step 13470, loss = 0.88 (1583.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:39:54.647620: step 13480, loss = 0.90 (1488.5 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:39:55.524239: step 13490, loss = 0.84 (1460.2 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7381\n",
      "2017-05-25 12:39:56.611560: step 13500, loss = 0.88 (1177.2 examples/sec; 0.109 sec/batch)\n",
      "2017-05-25 12:39:57.333220: step 13510, loss = 0.88 (1773.7 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:39:58.203262: step 13520, loss = 0.98 (1471.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:39:59.004752: step 13530, loss = 0.86 (1597.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:39:59.816109: step 13540, loss = 0.93 (1577.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:40:00.630727: step 13550, loss = 0.81 (1571.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:40:01.437886: step 13560, loss = 1.03 (1585.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:40:02.253539: step 13570, loss = 0.83 (1569.3 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:40:03.124196: step 13580, loss = 0.77 (1470.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:40:04.008508: step 13590, loss = 0.98 (1447.5 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8554\n",
      "2017-05-25 12:40:05.046095: step 13600, loss = 0.74 (1233.6 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:40:05.822104: step 13610, loss = 0.82 (1649.5 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:40:06.648897: step 13620, loss = 0.80 (1548.2 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:40:07.474093: step 13630, loss = 0.90 (1551.1 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:40:08.265815: step 13640, loss = 1.02 (1616.7 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:40:09.055832: step 13650, loss = 0.87 (1620.2 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:40:09.859189: step 13660, loss = 0.75 (1593.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:40:10.732169: step 13670, loss = 0.93 (1466.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:40:11.618800: step 13680, loss = 0.82 (1443.7 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:40:12.502507: step 13690, loss = 0.85 (1448.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:40:15.098607: step 13720, loss = 0.87 (1601.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:40:15.899695: step 13730, loss = 0.87 (1597.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:40:16.702117: step 13740, loss = 0.87 (1595.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:40:17.505986: step 13750, loss = 0.76 (1592.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:40:18.327967: step 13760, loss = 0.86 (1557.2 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:40:19.206814: step 13770, loss = 0.86 (1456.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:40:20.119326: step 13780, loss = 0.95 (1402.7 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 12:40:20.991357: step 13790, loss = 0.73 (1467.8 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7696\n",
      "2017-05-25 12:40:22.026984: step 13800, loss = 0.71 (1236.0 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:40:22.731877: step 13810, loss = 0.72 (1815.9 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:40:23.547554: step 13820, loss = 0.99 (1569.2 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:40:24.355227: step 13830, loss = 0.92 (1584.8 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 13841 into /home/ipython/cnn-cifar10/tb_log/test-softmax/train/model.ckpt.\n",
      "2017-05-25 12:40:25.252866: step 13840, loss = 0.90 (1426.0 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:40:25.981323: step 13850, loss = 0.86 (1757.1 examples/sec; 0.073 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:40:26.860137: step 13860, loss = 0.93 (1456.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:40:27.741587: step 13870, loss = 0.77 (1452.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:40:28.610051: step 13880, loss = 0.85 (1473.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:40:29.486803: step 13890, loss = 0.88 (1459.9 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.4759\n",
      "2017-05-25 12:40:30.741704: step 13900, loss = 0.99 (1020.0 examples/sec; 0.125 sec/batch)\n",
      "2017-05-25 12:40:31.799575: step 13910, loss = 0.81 (1210.0 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:40:33.026954: step 13920, loss = 0.69 (1042.9 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 12:40:34.259651: step 13930, loss = 0.92 (1038.4 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 12:40:35.313724: step 13940, loss = 0.82 (1214.3 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:40:36.372853: step 13950, loss = 0.77 (1208.5 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:40:37.424620: step 13960, loss = 0.92 (1217.0 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:40:38.415102: step 13970, loss = 0.79 (1292.3 examples/sec; 0.099 sec/batch)\n",
      "2017-05-25 12:40:39.294654: step 13980, loss = 1.04 (1455.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:40:40.195112: step 13990, loss = 0.75 (1421.5 examples/sec; 0.090 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.52816\n",
      "2017-05-25 12:40:41.236714: step 14000, loss = 0.79 (1228.9 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:40:42.014470: step 14010, loss = 0.73 (1645.8 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:40:42.826594: step 14020, loss = 0.87 (1576.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:40:43.642925: step 14030, loss = 0.95 (1568.0 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:40:44.460747: step 14040, loss = 0.86 (1565.1 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:40:46.960430: step 14070, loss = 0.88 (1462.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:40:47.836552: step 14080, loss = 0.90 (1461.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:40:48.727546: step 14090, loss = 1.01 (1436.6 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7141\n",
      "2017-05-25 12:40:49.774468: step 14100, loss = 0.80 (1222.6 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:40:50.534248: step 14110, loss = 1.01 (1684.7 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 12:40:51.338302: step 14120, loss = 0.78 (1591.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:40:52.155560: step 14130, loss = 0.81 (1566.2 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:40:52.958089: step 14140, loss = 0.82 (1595.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:40:53.767833: step 14150, loss = 0.92 (1580.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:40:54.621976: step 14160, loss = 0.83 (1498.6 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:40:55.498538: step 14170, loss = 0.95 (1460.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:40:56.375413: step 14180, loss = 0.92 (1459.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:40:57.258173: step 14190, loss = 0.95 (1450.0 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6398\n",
      "2017-05-25 12:40:58.365971: step 14200, loss = 0.84 (1155.4 examples/sec; 0.111 sec/batch)\n",
      "2017-05-25 12:40:59.059741: step 14210, loss = 1.09 (1845.0 examples/sec; 0.069 sec/batch)\n",
      "2017-05-25 12:40:59.864114: step 14220, loss = 0.91 (1591.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:41:00.664577: step 14230, loss = 0.82 (1599.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:41:01.462074: step 14240, loss = 0.90 (1605.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:41:02.288157: step 14250, loss = 0.90 (1549.5 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:41:03.162912: step 14260, loss = 0.94 (1463.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:41:04.044579: step 14270, loss = 0.82 (1451.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:41:04.945650: step 14280, loss = 0.93 (1420.5 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:41:05.815912: step 14290, loss = 0.83 (1470.8 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7905\n",
      "2017-05-25 12:41:06.844899: step 14300, loss = 0.69 (1243.9 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:41:07.509141: step 14310, loss = 0.79 (1927.0 examples/sec; 0.066 sec/batch)\n",
      "2017-05-25 12:41:08.324844: step 14320, loss = 1.06 (1569.2 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:41:09.120153: step 14330, loss = 0.85 (1609.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:41:09.923927: step 14340, loss = 0.81 (1592.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:41:10.803253: step 14350, loss = 0.97 (1455.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:41:11.678329: step 14360, loss = 0.86 (1462.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:41:12.569653: step 14370, loss = 0.92 (1436.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:41:13.446323: step 14380, loss = 0.97 (1460.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:41:14.312908: step 14390, loss = 0.98 (1477.1 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8772\n",
      "2017-05-25 12:41:15.264327: step 14400, loss = 0.82 (1345.4 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:41:15.961975: step 14410, loss = 0.89 (1834.7 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:41:19.274175: step 14450, loss = 0.73 (1453.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:41:20.167453: step 14460, loss = 0.85 (1432.9 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:41:21.035048: step 14470, loss = 0.93 (1475.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:41:21.945113: step 14480, loss = 0.92 (1406.5 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 12:41:22.773910: step 14490, loss = 0.86 (1544.4 examples/sec; 0.083 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7786\n",
      "2017-05-25 12:41:23.754695: step 14500, loss = 0.69 (1305.1 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 12:41:24.427519: step 14510, loss = 0.97 (1902.4 examples/sec; 0.067 sec/batch)\n",
      "2017-05-25 12:41:25.231150: step 14520, loss = 0.72 (1592.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:41:26.035875: step 14530, loss = 0.79 (1590.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:41:26.902716: step 14540, loss = 0.87 (1476.6 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:41:27.790921: step 14550, loss = 0.93 (1441.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:41:28.685207: step 14560, loss = 0.85 (1431.3 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:41:29.589149: step 14570, loss = 0.89 (1416.0 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:41:30.468915: step 14580, loss = 0.91 (1454.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:41:31.262834: step 14590, loss = 0.76 (1612.3 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8576\n",
      "2017-05-25 12:41:32.187945: step 14600, loss = 1.13 (1383.6 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 12:41:32.911297: step 14610, loss = 0.78 (1769.5 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:41:33.716343: step 14620, loss = 0.87 (1590.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:41:34.555651: step 14630, loss = 0.98 (1525.1 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:41:35.429034: step 14640, loss = 1.08 (1465.6 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:41:36.339550: step 14650, loss = 0.98 (1405.8 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 12:41:37.229066: step 14660, loss = 0.78 (1439.0 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:41:38.103239: step 14670, loss = 0.68 (1464.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:41:38.915365: step 14680, loss = 0.96 (1576.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:41:39.728199: step 14690, loss = 0.85 (1574.7 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7073\n",
      "2017-05-25 12:41:40.729733: step 14700, loss = 0.87 (1278.0 examples/sec; 0.100 sec/batch)\n",
      "2017-05-25 12:41:41.416168: step 14710, loss = 0.87 (1864.7 examples/sec; 0.069 sec/batch)\n",
      "2017-05-25 12:41:42.217520: step 14720, loss = 0.91 (1597.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:41:43.090362: step 14730, loss = 0.79 (1466.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:41:43.966173: step 14740, loss = 1.00 (1461.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:41:44.852042: step 14750, loss = 0.85 (1444.9 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:41:45.736916: step 14760, loss = 0.92 (1446.5 examples/sec; 0.088 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:41:46.777593: step 14770, loss = 0.79 (1230.0 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:41:48.000770: step 14780, loss = 1.01 (1046.5 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 12:41:50.678747: step 14800, loss = 0.81 (887.6 examples/sec; 0.144 sec/batch)\n",
      "2017-05-25 12:41:51.565820: step 14810, loss = 0.74 (1443.0 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:41:52.618087: step 14820, loss = 0.75 (1216.4 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:41:53.672604: step 14830, loss = 1.00 (1213.8 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:41:54.637783: step 14840, loss = 0.74 (1326.2 examples/sec; 0.097 sec/batch)\n",
      "2017-05-25 12:41:55.521936: step 14850, loss = 0.73 (1447.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:41:56.420779: step 14860, loss = 0.81 (1424.1 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:41:57.300880: step 14870, loss = 0.84 (1454.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:41:58.173875: step 14880, loss = 0.84 (1466.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:41:58.985375: step 14890, loss = 0.88 (1577.3 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.8026\n",
      "2017-05-25 12:41:59.935927: step 14900, loss = 1.00 (1346.6 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:42:00.655827: step 14910, loss = 0.98 (1778.0 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:42:01.451317: step 14920, loss = 1.10 (1609.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:42:02.276184: step 14930, loss = 0.86 (1551.8 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:42:03.161148: step 14940, loss = 0.77 (1446.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:42:04.036185: step 14950, loss = 0.92 (1462.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:42:04.922531: step 14960, loss = 0.73 (1444.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:42:05.797892: step 14970, loss = 0.91 (1462.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:42:06.642146: step 14980, loss = 0.88 (1516.1 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:42:07.450167: step 14990, loss = 0.85 (1584.1 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8244\n",
      "2017-05-25 12:42:08.391716: step 15000, loss = 0.91 (1359.5 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:42:09.101620: step 15010, loss = 0.81 (1803.1 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:42:09.914672: step 15020, loss = 1.05 (1574.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:42:10.791243: step 15030, loss = 0.85 (1460.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:42:11.670777: step 15040, loss = 0.72 (1455.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:42:12.547445: step 15050, loss = 0.66 (1460.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:42:13.432199: step 15060, loss = 0.94 (1446.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:42:14.310795: step 15070, loss = 0.83 (1456.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:42:15.105598: step 15080, loss = 0.90 (1610.5 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:42:15.911750: step 15090, loss = 0.89 (1587.8 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8291\n",
      "2017-05-25 12:42:16.846822: step 15100, loss = 0.95 (1368.9 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:42:17.559108: step 15110, loss = 0.77 (1797.0 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:42:18.382374: step 15120, loss = 0.81 (1554.8 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:42:19.277195: step 15130, loss = 0.77 (1430.5 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:42:20.178399: step 15140, loss = 0.76 (1420.3 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:42:22.783354: step 15170, loss = 0.97 (1541.8 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:42:23.586735: step 15180, loss = 0.90 (1593.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:42:24.400144: step 15190, loss = 0.73 (1573.6 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7688\n",
      "2017-05-25 12:42:25.342046: step 15200, loss = 1.02 (1358.9 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:42:26.051701: step 15210, loss = 0.92 (1803.7 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:42:26.955691: step 15220, loss = 0.92 (1415.9 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:42:27.827312: step 15230, loss = 0.86 (1468.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:42:28.718349: step 15240, loss = 0.95 (1436.5 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:42:29.603876: step 15250, loss = 1.07 (1445.5 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:42:30.471117: step 15260, loss = 0.79 (1475.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:42:31.289904: step 15270, loss = 1.02 (1563.3 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:42:32.068811: step 15280, loss = 0.79 (1643.3 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:42:32.876737: step 15290, loss = 0.82 (1584.3 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7935\n",
      "2017-05-25 12:42:33.821303: step 15300, loss = 0.86 (1355.1 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:42:34.551843: step 15310, loss = 0.92 (1752.1 examples/sec; 0.073 sec/batch)\n",
      "2017-05-25 12:42:35.432918: step 15320, loss = 0.99 (1452.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:42:36.318125: step 15330, loss = 0.71 (1446.0 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:42:37.186620: step 15340, loss = 1.03 (1473.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:42:38.059332: step 15350, loss = 0.75 (1466.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:42:38.875802: step 15360, loss = 0.94 (1567.7 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:42:39.689427: step 15370, loss = 0.88 (1573.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:42:40.505096: step 15380, loss = 0.74 (1569.3 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:42:41.315606: step 15390, loss = 0.88 (1579.3 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.839\n",
      "2017-05-25 12:42:42.267962: step 15400, loss = 1.01 (1344.0 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:42:43.031842: step 15410, loss = 0.84 (1675.7 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 12:42:43.912612: step 15420, loss = 0.98 (1453.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:42:44.783918: step 15430, loss = 1.00 (1469.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:42:45.666563: step 15440, loss = 0.84 (1450.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:42:46.528588: step 15450, loss = 0.71 (1484.9 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:42:47.331937: step 15460, loss = 1.02 (1593.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:42:48.133067: step 15470, loss = 0.88 (1597.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:42:48.945125: step 15480, loss = 0.97 (1576.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:42:49.756935: step 15490, loss = 0.90 (1576.7 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7802\n",
      "2017-05-25 12:42:50.759317: step 15500, loss = 0.87 (1277.0 examples/sec; 0.100 sec/batch)\n",
      "2017-05-25 12:42:51.520681: step 15510, loss = 0.87 (1681.2 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 12:42:52.415554: step 15520, loss = 1.02 (1430.4 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:42:55.360565: step 15550, loss = 0.80 (1070.1 examples/sec; 0.120 sec/batch)\n",
      "2017-05-25 12:42:56.581427: step 15560, loss = 0.96 (1048.4 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 12:42:57.825395: step 15570, loss = 0.76 (1029.0 examples/sec; 0.124 sec/batch)\n",
      "2017-05-25 12:42:58.943135: step 15580, loss = 0.75 (1145.2 examples/sec; 0.112 sec/batch)\n",
      "2017-05-25 12:42:59.993301: step 15590, loss = 0.84 (1218.9 examples/sec; 0.105 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.52398\n",
      "2017-05-25 12:43:01.257690: step 15600, loss = 0.92 (1012.3 examples/sec; 0.126 sec/batch)\n",
      "2017-05-25 12:43:02.214169: step 15610, loss = 0.94 (1338.2 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 12:43:03.092027: step 15620, loss = 0.82 (1458.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:43:03.968291: step 15630, loss = 0.78 (1460.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:43:04.862302: step 15640, loss = 0.91 (1431.7 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:43:05.759455: step 15650, loss = 0.80 (1426.7 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:43:06.605591: step 15660, loss = 0.90 (1512.8 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:43:07.409946: step 15670, loss = 0.87 (1591.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:43:08.221311: step 15680, loss = 0.84 (1577.6 examples/sec; 0.081 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:43:09.024087: step 15690, loss = 0.85 (1594.5 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.4586\n",
      "2017-05-25 12:43:09.985264: step 15700, loss = 0.84 (1331.7 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 12:43:10.749382: step 15710, loss = 0.68 (1675.1 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 12:43:11.628123: step 15720, loss = 0.93 (1456.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:43:12.509984: step 15730, loss = 0.81 (1451.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:43:13.388501: step 15740, loss = 1.07 (1457.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:43:14.264826: step 15750, loss = 0.76 (1460.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:43:15.065304: step 15760, loss = 0.84 (1599.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:43:15.865705: step 15770, loss = 0.97 (1599.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:43:16.662923: step 15780, loss = 0.75 (1605.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:43:17.464598: step 15790, loss = 0.79 (1596.7 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.86\n",
      "2017-05-25 12:43:18.415962: step 15800, loss = 0.89 (1345.4 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:43:19.196443: step 15810, loss = 0.92 (1640.0 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:43:20.103792: step 15820, loss = 0.86 (1410.7 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 12:43:21.007147: step 15830, loss = 0.74 (1416.9 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:43:21.897802: step 15840, loss = 0.86 (1437.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:43:22.738458: step 15850, loss = 0.84 (1522.6 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:43:23.543819: step 15860, loss = 0.79 (1589.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:43:24.345680: step 15870, loss = 0.87 (1596.3 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6787\n",
      "2017-05-25 12:43:26.980105: step 15900, loss = 1.16 (1242.2 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:43:27.743493: step 15910, loss = 0.92 (1676.7 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 12:43:28.626458: step 15920, loss = 0.83 (1449.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:43:29.505382: step 15930, loss = 0.70 (1456.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:43:30.395193: step 15940, loss = 0.88 (1438.5 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:43:31.199531: step 15950, loss = 1.00 (1591.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:43:31.998500: step 15960, loss = 0.78 (1602.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:43:32.808012: step 15970, loss = 0.96 (1581.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:43:33.650141: step 15980, loss = 0.99 (1520.0 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:43:34.470704: step 15990, loss = 0.77 (1559.9 examples/sec; 0.082 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7218\n",
      "2017-05-25 12:43:35.509723: step 16000, loss = 0.84 (1231.9 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:43:36.299767: step 16010, loss = 0.78 (1620.2 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:43:37.166777: step 16020, loss = 0.80 (1476.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:43:38.053830: step 16030, loss = 0.74 (1443.0 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:43:38.883838: step 16040, loss = 1.01 (1542.2 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:43:39.681111: step 16050, loss = 0.88 (1605.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:43:40.514771: step 16060, loss = 0.90 (1535.4 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:43:41.332237: step 16070, loss = 0.92 (1565.8 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:43:42.124431: step 16080, loss = 0.74 (1615.8 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:43:42.989719: step 16090, loss = 0.86 (1479.3 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7406\n",
      "2017-05-25 12:43:44.027081: step 16100, loss = 0.83 (1233.9 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:43:44.796656: step 16110, loss = 0.89 (1663.3 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:43:45.682239: step 16120, loss = 0.99 (1445.4 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:43:46.553483: step 16130, loss = 0.81 (1469.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:43:47.348743: step 16140, loss = 0.80 (1609.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:43:48.156649: step 16150, loss = 0.73 (1584.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:43:48.959079: step 16160, loss = 0.91 (1595.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:43:49.760988: step 16170, loss = 0.84 (1596.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:43:50.604593: step 16180, loss = 0.91 (1517.3 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:43:51.487263: step 16190, loss = 0.82 (1450.1 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7612\n",
      "2017-05-25 12:43:52.529424: step 16200, loss = 0.91 (1228.2 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:43:53.350560: step 16210, loss = 0.75 (1558.8 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:43:54.229894: step 16220, loss = 0.80 (1455.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:43:55.033019: step 16230, loss = 0.96 (1593.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:43:55.846978: step 16240, loss = 0.81 (1572.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:43:59.125731: step 16280, loss = 1.02 (1455.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:44:00.008894: step 16290, loss = 0.77 (1449.3 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7096\n",
      "2017-05-25 12:44:01.069343: step 16300, loss = 0.71 (1207.0 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:44:01.868454: step 16310, loss = 0.72 (1601.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:44:03.024762: step 16320, loss = 0.76 (1107.0 examples/sec; 0.116 sec/batch)\n",
      "2017-05-25 12:44:04.247142: step 16330, loss = 0.75 (1047.1 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 12:44:05.472259: step 16340, loss = 0.88 (1044.8 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 12:44:06.640539: step 16350, loss = 0.90 (1095.6 examples/sec; 0.117 sec/batch)\n",
      "2017-05-25 12:44:07.695226: step 16360, loss = 0.79 (1213.6 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:44:08.732137: step 16370, loss = 0.82 (1234.4 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:44:09.786354: step 16380, loss = 0.79 (1214.2 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:44:10.784432: step 16390, loss = 1.07 (1282.5 examples/sec; 0.100 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.31406\n",
      "2017-05-25 12:44:11.807619: step 16400, loss = 0.90 (1251.0 examples/sec; 0.102 sec/batch)\n",
      "2017-05-25 12:44:12.584847: step 16410, loss = 0.84 (1646.9 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:44:13.469132: step 16420, loss = 0.90 (1447.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:44:14.351169: step 16430, loss = 0.98 (1451.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:44:15.152822: step 16440, loss = 0.98 (1596.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:44:15.958381: step 16450, loss = 0.73 (1589.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:44:16.760204: step 16460, loss = 0.63 (1596.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:44:17.567154: step 16470, loss = 0.81 (1586.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:44:18.380039: step 16480, loss = 1.05 (1574.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:44:19.270885: step 16490, loss = 1.05 (1436.8 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.738\n",
      "2017-05-25 12:44:20.324981: step 16500, loss = 1.06 (1214.3 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:44:21.107106: step 16510, loss = 0.69 (1636.6 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:44:21.985375: step 16520, loss = 0.77 (1457.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:44:22.810352: step 16530, loss = 0.83 (1551.6 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:44:23.612021: step 16540, loss = 0.90 (1596.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:44:24.410710: step 16550, loss = 0.78 (1602.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:44:25.223214: step 16560, loss = 0.97 (1575.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:44:26.016394: step 16570, loss = 0.96 (1613.8 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:44:26.872954: step 16580, loss = 0.80 (1494.3 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:44:27.754011: step 16590, loss = 0.82 (1452.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:44:31.263904: step 16630, loss = 0.93 (1585.0 examples/sec; 0.081 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:44:32.075680: step 16640, loss = 0.93 (1576.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:44:32.885407: step 16650, loss = 0.79 (1580.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:44:33.698566: step 16660, loss = 0.80 (1574.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:44:34.520054: step 16670, loss = 0.88 (1558.1 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:44:35.392630: step 16680, loss = 0.94 (1466.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:44:36.276567: step 16690, loss = 0.79 (1448.1 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7381\n",
      "2017-05-25 12:44:37.315294: step 16700, loss = 0.84 (1232.3 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:44:38.095385: step 16710, loss = 0.82 (1640.8 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:44:38.910604: step 16720, loss = 0.93 (1570.1 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:44:39.714634: step 16730, loss = 0.93 (1592.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:44:40.539593: step 16740, loss = 0.96 (1551.6 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:44:41.346131: step 16750, loss = 0.86 (1587.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:44:42.141563: step 16760, loss = 0.87 (1609.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:44:42.991003: step 16770, loss = 0.70 (1506.9 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:44:43.873639: step 16780, loss = 0.91 (1450.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:44:44.750987: step 16790, loss = 0.74 (1458.9 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8088\n",
      "2017-05-25 12:44:45.784090: step 16800, loss = 1.07 (1239.0 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:44:46.581416: step 16810, loss = 0.85 (1605.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:44:47.387718: step 16820, loss = 0.77 (1587.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:44:48.194644: step 16830, loss = 0.95 (1586.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:44:49.003757: step 16840, loss = 0.77 (1582.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:44:49.808075: step 16850, loss = 0.95 (1591.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:44:50.657209: step 16860, loss = 0.86 (1507.4 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:44:51.536505: step 16870, loss = 0.86 (1455.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:44:52.411639: step 16880, loss = 0.86 (1462.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:44:53.304853: step 16890, loss = 1.00 (1433.0 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.691\n",
      "2017-05-25 12:44:54.334724: step 16900, loss = 0.93 (1242.9 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:44:55.406260: step 16910, loss = 0.89 (1194.6 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:44:56.636555: step 16920, loss = 0.84 (1040.4 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 12:44:57.857902: step 16930, loss = 0.73 (1048.0 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 12:44:58.971785: step 16940, loss = 0.66 (1149.1 examples/sec; 0.111 sec/batch)\n",
      "2017-05-25 12:45:00.072461: step 16950, loss = 0.87 (1162.9 examples/sec; 0.110 sec/batch)\n",
      "2017-05-25 12:45:03.965948: step 16990, loss = 0.68 (1475.1 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.36659\n",
      "2017-05-25 12:45:05.013236: step 17000, loss = 0.94 (1222.2 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:45:05.780313: step 17010, loss = 0.77 (1668.7 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:45:06.643180: step 17020, loss = 0.87 (1483.4 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:45:07.442700: step 17030, loss = 0.87 (1601.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:45:08.251393: step 17040, loss = 0.70 (1582.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:45:09.047450: step 17050, loss = 0.89 (1607.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:45:09.861246: step 17060, loss = 0.89 (1572.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:45:10.708691: step 17070, loss = 0.79 (1510.4 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:45:11.590436: step 17080, loss = 0.79 (1451.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:45:12.464222: step 17090, loss = 0.79 (1464.9 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7744\n",
      "2017-05-25 12:45:13.504391: step 17100, loss = 0.63 (1230.6 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:45:14.288419: step 17110, loss = 0.73 (1632.6 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:45:15.108728: step 17120, loss = 0.85 (1560.4 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:45:15.901816: step 17130, loss = 0.95 (1613.9 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:45:16.710631: step 17140, loss = 0.75 (1582.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:45:17.511544: step 17150, loss = 0.96 (1598.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:45:18.311958: step 17160, loss = 0.97 (1599.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:45:19.184167: step 17170, loss = 0.81 (1467.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:45:20.087939: step 17180, loss = 0.85 (1416.3 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:45:20.969515: step 17190, loss = 0.83 (1451.9 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7502\n",
      "2017-05-25 12:45:22.015060: step 17200, loss = 0.87 (1224.2 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:45:22.748261: step 17210, loss = 0.96 (1745.8 examples/sec; 0.073 sec/batch)\n",
      "2017-05-25 12:45:23.568322: step 17220, loss = 0.93 (1560.9 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:45:24.361734: step 17230, loss = 0.95 (1613.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:45:25.162760: step 17240, loss = 0.98 (1597.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:45:25.960356: step 17250, loss = 0.77 (1604.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:45:26.820316: step 17260, loss = 1.00 (1488.4 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:45:27.687879: step 17270, loss = 0.95 (1475.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:45:28.582232: step 17280, loss = 0.95 (1431.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:45:29.463983: step 17290, loss = 1.00 (1451.7 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7157\n",
      "2017-05-25 12:45:30.550320: step 17300, loss = 1.03 (1178.3 examples/sec; 0.109 sec/batch)\n",
      "2017-05-25 12:45:31.220771: step 17310, loss = 1.02 (1909.2 examples/sec; 0.067 sec/batch)\n",
      "2017-05-25 12:45:32.021286: step 17320, loss = 0.79 (1599.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:45:32.840178: step 17330, loss = 0.96 (1563.1 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:45:36.256155: step 17370, loss = 0.89 (1445.7 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:45:37.162462: step 17380, loss = 0.77 (1412.3 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 12:45:38.035336: step 17390, loss = 0.84 (1466.4 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8073\n",
      "2017-05-25 12:45:39.020967: step 17400, loss = 1.26 (1298.7 examples/sec; 0.099 sec/batch)\n",
      "2017-05-25 12:45:39.752517: step 17410, loss = 0.83 (1749.7 examples/sec; 0.073 sec/batch)\n",
      "2017-05-25 12:45:40.564719: step 17420, loss = 0.79 (1576.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:45:41.371077: step 17430, loss = 0.83 (1587.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:45:42.176409: step 17440, loss = 0.98 (1589.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:45:43.019712: step 17450, loss = 0.88 (1517.8 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:45:43.909078: step 17460, loss = 0.86 (1439.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:45:44.794803: step 17470, loss = 0.83 (1445.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:45:45.675589: step 17480, loss = 0.85 (1453.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:45:46.548579: step 17490, loss = 0.84 (1466.2 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7603\n",
      "2017-05-25 12:45:47.522961: step 17500, loss = 0.79 (1313.7 examples/sec; 0.097 sec/batch)\n",
      "2017-05-25 12:45:48.203133: step 17510, loss = 0.85 (1881.9 examples/sec; 0.068 sec/batch)\n",
      "2017-05-25 12:45:48.999906: step 17520, loss = 0.85 (1606.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:45:49.796698: step 17530, loss = 0.80 (1606.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:45:50.639656: step 17540, loss = 0.93 (1518.5 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:45:51.505564: step 17550, loss = 0.73 (1478.2 examples/sec; 0.087 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:45:52.388867: step 17560, loss = 0.91 (1449.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:45:53.263803: step 17570, loss = 0.97 (1463.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:45:54.135778: step 17580, loss = 1.21 (1467.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:45:54.960787: step 17590, loss = 0.89 (1551.5 examples/sec; 0.083 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9197\n",
      "2017-05-25 12:45:55.912675: step 17600, loss = 0.82 (1344.7 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:45:56.617608: step 17610, loss = 0.78 (1815.8 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:45:57.426901: step 17620, loss = 0.75 (1581.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:45:58.230287: step 17630, loss = 0.94 (1593.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:45:59.087692: step 17640, loss = 0.82 (1492.9 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:45:59.975092: step 17650, loss = 0.89 (1442.4 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:46:00.881166: step 17660, loss = 0.68 (1412.7 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 12:46:01.749893: step 17670, loss = 0.79 (1473.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:46:02.614279: step 17680, loss = 0.90 (1480.8 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:46:03.421131: step 17690, loss = 0.84 (1586.4 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8409\n",
      "2017-05-25 12:46:04.357573: step 17700, loss = 0.86 (1366.9 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:46:05.068216: step 17710, loss = 0.88 (1801.2 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:46:07.614684: step 17740, loss = 0.76 (1460.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:46:08.484766: step 17750, loss = 0.81 (1471.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:46:09.381520: step 17760, loss = 0.91 (1427.4 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:46:10.271420: step 17770, loss = 0.69 (1438.4 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:46:11.085574: step 17780, loss = 1.01 (1572.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:46:11.906527: step 17790, loss = 0.97 (1559.2 examples/sec; 0.082 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8072\n",
      "2017-05-25 12:46:12.827359: step 17800, loss = 0.83 (1390.0 examples/sec; 0.092 sec/batch)\n",
      "2017-05-25 12:46:13.536259: step 17810, loss = 0.93 (1805.6 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:46:14.340768: step 17820, loss = 0.86 (1591.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:46:15.223670: step 17830, loss = 0.95 (1449.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:46:16.107097: step 17840, loss = 0.94 (1448.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:46:16.985982: step 17850, loss = 0.91 (1456.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:46:17.876185: step 17860, loss = 0.78 (1437.9 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:46:18.720684: step 17870, loss = 0.84 (1515.7 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:46:19.525084: step 17880, loss = 0.96 (1591.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:46:20.326979: step 17890, loss = 1.18 (1596.2 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8468\n",
      "2017-05-25 12:46:21.269679: step 17900, loss = 0.92 (1357.8 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:46:21.976247: step 17910, loss = 0.70 (1811.6 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:46:22.819936: step 17920, loss = 0.86 (1517.1 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:46:23.694929: step 17930, loss = 0.87 (1462.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:46:24.569909: step 17940, loss = 0.98 (1462.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:46:25.453652: step 17950, loss = 0.83 (1448.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:46:26.343573: step 17960, loss = 0.86 (1438.3 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:46:27.534596: step 17970, loss = 0.88 (1074.7 examples/sec; 0.119 sec/batch)\n",
      "2017-05-25 12:46:28.761506: step 17980, loss = 0.99 (1043.3 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 12:46:29.969489: step 17990, loss = 0.93 (1059.6 examples/sec; 0.121 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.97061\n",
      "2017-05-25 12:46:31.298262: step 18000, loss = 0.76 (963.3 examples/sec; 0.133 sec/batch)\n",
      "2017-05-25 12:46:32.281014: step 18010, loss = 0.94 (1302.5 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 12:46:33.394377: step 18020, loss = 0.90 (1149.7 examples/sec; 0.111 sec/batch)\n",
      "2017-05-25 12:46:34.443001: step 18030, loss = 0.83 (1220.6 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:46:35.361456: step 18040, loss = 0.85 (1393.6 examples/sec; 0.092 sec/batch)\n",
      "2017-05-25 12:46:36.242239: step 18050, loss = 0.83 (1453.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:46:37.126467: step 18060, loss = 0.84 (1447.6 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.7364\n",
      "2017-05-25 12:46:40.613729: step 18100, loss = 1.02 (1312.0 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 12:46:41.312919: step 18110, loss = 1.02 (1830.7 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:46:42.120212: step 18120, loss = 0.76 (1585.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:46:42.958461: step 18130, loss = 0.88 (1527.0 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:46:43.843278: step 18140, loss = 0.76 (1446.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:46:44.723262: step 18150, loss = 0.88 (1454.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:46:45.600220: step 18160, loss = 0.86 (1459.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:46:46.483284: step 18170, loss = 0.80 (1449.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:46:47.286336: step 18180, loss = 0.81 (1593.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:46:48.084563: step 18190, loss = 0.88 (1603.6 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7888\n",
      "2017-05-25 12:46:49.096097: step 18200, loss = 0.77 (1265.4 examples/sec; 0.101 sec/batch)\n",
      "2017-05-25 12:46:49.756412: step 18210, loss = 0.76 (1938.5 examples/sec; 0.066 sec/batch)\n",
      "2017-05-25 12:46:50.578224: step 18220, loss = 0.85 (1557.5 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:46:51.451992: step 18230, loss = 0.89 (1464.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:46:52.320330: step 18240, loss = 0.86 (1474.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:46:53.203407: step 18250, loss = 0.71 (1449.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:46:54.081542: step 18260, loss = 0.87 (1457.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:46:55.174972: step 18270, loss = 0.75 (1170.6 examples/sec; 0.109 sec/batch)\n",
      "2017-05-25 12:46:56.405279: step 18280, loss = 0.74 (1040.4 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 12:46:57.619663: step 18290, loss = 0.81 (1054.0 examples/sec; 0.121 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.0982\n",
      "2017-05-25 12:46:58.997701: step 18300, loss = 0.86 (928.9 examples/sec; 0.138 sec/batch)\n",
      "2017-05-25 12:46:59.902159: step 18310, loss = 0.97 (1415.2 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:47:00.965957: step 18320, loss = 0.83 (1203.2 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:47:02.021052: step 18330, loss = 0.84 (1213.2 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:47:02.993422: step 18340, loss = 0.98 (1316.4 examples/sec; 0.097 sec/batch)\n",
      "2017-05-25 12:47:03.863720: step 18350, loss = 0.89 (1470.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:47:04.742758: step 18360, loss = 0.78 (1456.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:47:05.619571: step 18370, loss = 0.96 (1459.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:47:06.500716: step 18380, loss = 0.82 (1452.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:47:07.321371: step 18390, loss = 0.77 (1559.7 examples/sec; 0.082 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.8026\n",
      "2017-05-25 12:47:08.253841: step 18400, loss = 0.90 (1372.7 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 12:47:08.967442: step 18410, loss = 0.84 (1793.7 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:47:12.365258: step 18450, loss = 1.04 (1458.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:47:13.249167: step 18460, loss = 0.75 (1448.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:47:14.136691: step 18470, loss = 0.82 (1442.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:47:14.967432: step 18480, loss = 0.81 (1540.8 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:47:15.805855: step 18490, loss = 0.88 (1526.7 examples/sec; 0.084 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 11.726\n",
      "2017-05-25 12:47:16.783539: step 18500, loss = 0.86 (1309.2 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 12:47:17.450292: step 18510, loss = 0.78 (1919.8 examples/sec; 0.067 sec/batch)\n",
      "2017-05-25 12:47:18.244276: step 18520, loss = 0.99 (1612.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:47:19.109630: step 18530, loss = 0.81 (1479.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:47:19.995498: step 18540, loss = 0.64 (1444.9 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:47:20.914239: step 18550, loss = 0.93 (1393.2 examples/sec; 0.092 sec/batch)\n",
      "2017-05-25 12:47:21.789837: step 18560, loss = 0.82 (1461.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:47:22.653871: step 18570, loss = 0.77 (1481.4 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:47:23.446299: step 18580, loss = 0.91 (1615.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:47:24.251541: step 18590, loss = 0.76 (1589.6 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.881\n",
      "2017-05-25 12:47:25.198673: step 18600, loss = 0.88 (1351.4 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:47:25.906376: step 18610, loss = 0.91 (1808.7 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:47:26.730822: step 18620, loss = 0.97 (1552.6 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:47:27.613046: step 18630, loss = 0.78 (1450.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:47:28.503736: step 18640, loss = 0.96 (1437.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:47:29.388051: step 18650, loss = 0.82 (1447.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:47:30.308848: step 18660, loss = 1.01 (1390.1 examples/sec; 0.092 sec/batch)\n",
      "2017-05-25 12:47:31.139739: step 18670, loss = 0.94 (1540.5 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:47:31.941199: step 18680, loss = 0.84 (1597.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:47:32.749775: step 18690, loss = 0.84 (1583.0 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7574\n",
      "2017-05-25 12:47:33.704418: step 18700, loss = 0.90 (1340.8 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:47:34.422356: step 18710, loss = 0.76 (1782.9 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:47:35.316498: step 18720, loss = 0.92 (1431.5 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:47:36.190634: step 18730, loss = 0.83 (1464.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:47:37.061819: step 18740, loss = 0.91 (1469.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:47:37.939667: step 18750, loss = 1.01 (1458.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:47:38.802957: step 18760, loss = 0.69 (1482.7 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:47:39.591833: step 18770, loss = 0.75 (1622.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:47:40.416856: step 18780, loss = 0.75 (1551.5 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:47:41.224191: step 18790, loss = 0.73 (1585.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:47:43.793876: step 18820, loss = 0.90 (1439.6 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:47:44.672778: step 18830, loss = 0.83 (1456.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:47:45.547694: step 18840, loss = 0.88 (1463.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:47:46.436756: step 18850, loss = 0.85 (1439.7 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:47:47.253880: step 18860, loss = 0.94 (1566.5 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:47:48.066493: step 18870, loss = 0.60 (1575.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:47:48.867067: step 18880, loss = 0.90 (1598.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:47:49.664832: step 18890, loss = 0.93 (1604.5 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.646\n",
      "2017-05-25 12:47:50.747867: step 18900, loss = 0.87 (1181.9 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 12:47:51.421719: step 18910, loss = 0.84 (1899.5 examples/sec; 0.067 sec/batch)\n",
      "2017-05-25 12:47:52.312933: step 18920, loss = 0.80 (1436.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:47:53.188418: step 18930, loss = 0.89 (1462.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:47:54.074958: step 18940, loss = 0.79 (1443.8 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:47:54.920019: step 18950, loss = 0.87 (1514.7 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:47:55.717705: step 18960, loss = 1.03 (1604.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:47:56.540915: step 18970, loss = 0.68 (1554.9 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:47:57.340716: step 18980, loss = 1.04 (1600.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:47:58.138315: step 18990, loss = 0.82 (1604.8 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8837\n",
      "2017-05-25 12:47:59.165333: step 19000, loss = 0.78 (1246.3 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:47:59.947000: step 19010, loss = 0.92 (1637.5 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:48:00.826384: step 19020, loss = 0.80 (1455.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:48:01.708608: step 19030, loss = 0.74 (1450.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:48:02.585148: step 19040, loss = 0.95 (1460.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:48:03.380355: step 19050, loss = 0.78 (1609.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:48:04.190402: step 19060, loss = 0.95 (1580.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:48:04.991567: step 19070, loss = 0.85 (1597.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:48:05.799729: step 19080, loss = 0.88 (1583.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:48:06.613740: step 19090, loss = 0.89 (1572.5 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7851\n",
      "2017-05-25 12:48:07.648718: step 19100, loss = 0.64 (1236.7 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:48:08.423188: step 19110, loss = 0.94 (1652.7 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:48:09.323257: step 19120, loss = 0.80 (1422.1 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:48:10.224569: step 19130, loss = 0.89 (1420.2 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:48:11.331496: step 19140, loss = 0.86 (1156.4 examples/sec; 0.111 sec/batch)\n",
      "2017-05-25 12:48:12.560500: step 19150, loss = 0.70 (1041.5 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 12:48:15.988525: step 19180, loss = 0.83 (1215.4 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:48:17.023146: step 19190, loss = 0.90 (1237.2 examples/sec; 0.103 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.40666\n",
      "2017-05-25 12:48:18.281424: step 19200, loss = 0.89 (1017.3 examples/sec; 0.126 sec/batch)\n",
      "2017-05-25 12:48:19.081339: step 19210, loss = 1.05 (1600.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:48:19.972521: step 19220, loss = 0.74 (1436.3 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:48:20.866023: step 19230, loss = 0.97 (1432.6 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:48:21.752842: step 19240, loss = 0.91 (1443.4 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:48:22.624783: step 19250, loss = 0.87 (1468.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:48:23.428526: step 19260, loss = 0.94 (1592.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:48:24.232448: step 19270, loss = 0.86 (1592.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:48:25.030058: step 19280, loss = 0.86 (1604.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:48:25.818345: step 19290, loss = 0.71 (1623.8 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6239\n",
      "2017-05-25 12:48:26.881795: step 19300, loss = 0.94 (1203.6 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:48:27.553177: step 19310, loss = 0.86 (1906.5 examples/sec; 0.067 sec/batch)\n",
      "2017-05-25 12:48:28.438542: step 19320, loss = 0.76 (1445.7 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:48:29.312628: step 19330, loss = 0.81 (1464.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:48:30.210754: step 19340, loss = 0.82 (1425.2 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:48:31.033600: step 19350, loss = 0.75 (1555.6 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:48:31.860067: step 19360, loss = 1.06 (1548.8 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:48:32.688194: step 19370, loss = 0.74 (1545.7 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:48:33.484211: step 19380, loss = 0.81 (1608.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:48:34.281910: step 19390, loss = 0.85 (1604.6 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8912\n",
      "2017-05-25 12:48:35.291457: step 19400, loss = 0.90 (1267.9 examples/sec; 0.101 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:48:36.069057: step 19410, loss = 0.93 (1646.1 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:48:36.955250: step 19420, loss = 0.94 (1444.4 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:48:37.852939: step 19430, loss = 0.89 (1425.9 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:48:38.710375: step 19440, loss = 0.99 (1492.8 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:48:39.502286: step 19450, loss = 0.83 (1616.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:48:40.325696: step 19460, loss = 0.96 (1554.5 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:48:41.128792: step 19470, loss = 0.90 (1593.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:48:41.932356: step 19480, loss = 0.87 (1592.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:48:42.740429: step 19490, loss = 0.89 (1584.0 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7883\n",
      "2017-05-25 12:48:43.774385: step 19500, loss = 0.82 (1238.0 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:48:44.550882: step 19510, loss = 0.94 (1648.4 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:48:45.439025: step 19520, loss = 0.76 (1441.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:48:47.947349: step 19550, loss = 0.80 (1605.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:48:48.760860: step 19560, loss = 0.88 (1573.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:48:49.562569: step 19570, loss = 0.88 (1596.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:48:50.389120: step 19580, loss = 0.89 (1548.6 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:48:51.258110: step 19590, loss = 0.83 (1473.0 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6798\n",
      "2017-05-25 12:48:52.338424: step 19600, loss = 0.74 (1184.8 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 12:48:53.056617: step 19610, loss = 0.85 (1782.3 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:48:53.949828: step 19620, loss = 0.94 (1433.0 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:48:54.809113: step 19630, loss = 0.86 (1489.6 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:48:55.613196: step 19640, loss = 0.78 (1591.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:48:56.416032: step 19650, loss = 1.09 (1594.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:48:57.230879: step 19660, loss = 0.83 (1570.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:48:58.020706: step 19670, loss = 0.74 (1620.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:48:58.875520: step 19680, loss = 0.72 (1497.4 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:48:59.744725: step 19690, loss = 0.76 (1472.6 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7905\n",
      "2017-05-25 12:49:00.817852: step 19700, loss = 0.74 (1192.8 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:49:01.582378: step 19710, loss = 1.05 (1674.2 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 12:49:02.644259: step 19720, loss = 0.90 (1205.4 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:49:03.450725: step 19730, loss = 0.76 (1587.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:49:04.307523: step 19740, loss = 0.75 (1493.9 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:49:05.106546: step 19750, loss = 0.91 (1602.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:49:05.906126: step 19760, loss = 0.75 (1600.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:49:06.730611: step 19770, loss = 0.81 (1552.5 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:49:07.627287: step 19780, loss = 0.78 (1427.5 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:49:08.509026: step 19790, loss = 0.83 (1451.7 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.4433\n",
      "2017-05-25 12:49:09.558456: step 19800, loss = 0.90 (1219.7 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:49:10.341181: step 19810, loss = 0.91 (1635.3 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:49:11.483122: step 19820, loss = 0.93 (1120.9 examples/sec; 0.114 sec/batch)\n",
      "2017-05-25 12:49:12.711481: step 19830, loss = 0.78 (1042.0 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 12:49:13.942005: step 19840, loss = 0.88 (1040.2 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 12:49:15.078887: step 19850, loss = 0.75 (1125.9 examples/sec; 0.114 sec/batch)\n",
      "2017-05-25 12:49:16.128143: step 19860, loss = 0.80 (1219.9 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:49:17.173582: step 19870, loss = 0.85 (1224.4 examples/sec; 0.105 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.38291\n",
      "2017-05-25 12:49:20.213783: step 19900, loss = 0.88 (1227.0 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:49:20.996952: step 19910, loss = 0.94 (1634.4 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:49:21.891068: step 19920, loss = 0.73 (1431.6 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:49:22.758423: step 19930, loss = 0.87 (1475.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:49:23.575829: step 19940, loss = 0.94 (1565.9 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:49:24.388796: step 19950, loss = 0.88 (1574.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:49:25.202467: step 19960, loss = 0.84 (1573.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:49:25.996644: step 19970, loss = 0.72 (1611.7 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:49:26.843571: step 19980, loss = 0.82 (1511.3 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:49:27.729658: step 19990, loss = 0.90 (1444.6 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.645\n",
      "2017-05-25 12:49:28.803253: step 20000, loss = 0.79 (1192.3 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:49:29.579635: step 20010, loss = 0.76 (1648.7 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:49:30.489524: step 20020, loss = 0.87 (1406.8 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 12:49:31.302415: step 20030, loss = 0.76 (1574.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:49:32.117383: step 20040, loss = 0.88 (1570.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:49:32.929404: step 20050, loss = 0.94 (1576.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:49:33.733357: step 20060, loss = 0.77 (1592.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:49:34.551831: step 20070, loss = 0.92 (1563.9 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:49:35.434645: step 20080, loss = 0.72 (1449.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:49:36.325131: step 20090, loss = 0.82 (1437.4 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.631\n",
      "2017-05-25 12:49:37.401083: step 20100, loss = 0.88 (1189.6 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 12:49:38.122283: step 20110, loss = 0.78 (1774.8 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:49:38.971189: step 20120, loss = 0.84 (1507.8 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:49:39.784585: step 20130, loss = 1.04 (1573.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:49:40.608250: step 20140, loss = 1.00 (1554.0 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:49:41.413987: step 20150, loss = 0.96 (1588.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:49:42.211871: step 20160, loss = 0.85 (1604.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:49:43.058901: step 20170, loss = 0.84 (1511.2 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:49:43.945042: step 20180, loss = 0.91 (1444.5 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:49:44.841213: step 20190, loss = 0.76 (1428.3 examples/sec; 0.090 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7768\n",
      "2017-05-25 12:49:45.891729: step 20200, loss = 0.96 (1218.4 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:49:46.675837: step 20210, loss = 0.85 (1632.4 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:49:47.479182: step 20220, loss = 0.86 (1593.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:49:48.280324: step 20230, loss = 0.85 (1597.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:49:49.114139: step 20240, loss = 0.95 (1535.1 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:49:51.625735: step 20270, loss = 0.83 (1463.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:49:52.520815: step 20280, loss = 0.88 (1430.0 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:49:53.398537: step 20290, loss = 0.79 (1458.3 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6213\n",
      "2017-05-25 12:49:54.495506: step 20300, loss = 0.86 (1166.8 examples/sec; 0.110 sec/batch)\n",
      "2017-05-25 12:49:55.447881: step 20310, loss = 0.85 (1344.0 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:49:56.694520: step 20320, loss = 0.69 (1026.8 examples/sec; 0.125 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:49:57.908550: step 20330, loss = 0.83 (1054.3 examples/sec; 0.121 sec/batch)\n",
      "2017-05-25 12:49:59.079140: step 20340, loss = 0.83 (1093.5 examples/sec; 0.117 sec/batch)\n",
      "2017-05-25 12:50:00.143650: step 20350, loss = 0.84 (1202.4 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:50:01.212627: step 20360, loss = 0.78 (1197.4 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:50:02.263555: step 20370, loss = 0.70 (1218.0 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:50:03.202779: step 20380, loss = 0.77 (1362.8 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:50:04.074667: step 20390, loss = 0.78 (1468.1 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.41236\n",
      "2017-05-25 12:50:05.120932: step 20400, loss = 0.72 (1223.4 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:50:05.894921: step 20410, loss = 0.71 (1653.8 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:50:06.762666: step 20420, loss = 0.96 (1475.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:50:07.561237: step 20430, loss = 0.84 (1602.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:50:08.374751: step 20440, loss = 0.86 (1573.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:50:09.170113: step 20450, loss = 0.84 (1609.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:50:09.981673: step 20460, loss = 0.96 (1577.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:50:10.812451: step 20470, loss = 0.72 (1540.7 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:50:11.689860: step 20480, loss = 0.76 (1458.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:50:12.577475: step 20490, loss = 0.78 (1442.1 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7097\n",
      "2017-05-25 12:50:13.661252: step 20500, loss = 0.92 (1181.1 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 12:50:14.402498: step 20510, loss = 0.91 (1726.8 examples/sec; 0.074 sec/batch)\n",
      "2017-05-25 12:50:15.226323: step 20520, loss = 0.98 (1553.7 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:50:16.027706: step 20530, loss = 0.83 (1597.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:50:16.836019: step 20540, loss = 0.89 (1583.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:50:17.637560: step 20550, loss = 0.93 (1596.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:50:18.441795: step 20560, loss = 0.98 (1591.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:50:19.310195: step 20570, loss = 0.88 (1474.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:50:20.194423: step 20580, loss = 0.89 (1447.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:50:21.066456: step 20590, loss = 0.77 (1467.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:50:23.662398: step 20620, loss = 0.79 (1574.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:50:24.471309: step 20630, loss = 0.77 (1582.4 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 20640 into /home/ipython/cnn-cifar10/tb_log/test-softmax/train/model.ckpt.\n",
      "2017-05-25 12:50:25.330770: step 20640, loss = 0.93 (1489.3 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:50:26.109425: step 20650, loss = 0.75 (1643.9 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:50:26.946995: step 20660, loss = 0.86 (1528.2 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:50:27.833189: step 20670, loss = 0.89 (1444.4 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:50:28.742113: step 20680, loss = 0.85 (1408.3 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 12:50:29.633542: step 20690, loss = 0.86 (1435.9 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6104\n",
      "2017-05-25 12:50:30.732381: step 20700, loss = 1.02 (1164.9 examples/sec; 0.110 sec/batch)\n",
      "2017-05-25 12:50:31.771010: step 20710, loss = 0.84 (1232.4 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:50:32.994539: step 20720, loss = 0.84 (1046.2 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 12:50:34.227421: step 20730, loss = 1.00 (1038.2 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 12:50:35.338188: step 20740, loss = 0.70 (1152.4 examples/sec; 0.111 sec/batch)\n",
      "2017-05-25 12:50:36.411328: step 20750, loss = 0.81 (1192.8 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:50:37.450692: step 20760, loss = 0.97 (1231.5 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:50:38.500914: step 20770, loss = 0.75 (1218.8 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:50:39.405729: step 20780, loss = 0.79 (1414.7 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:50:40.312657: step 20790, loss = 0.83 (1411.4 examples/sec; 0.091 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.39144\n",
      "2017-05-25 12:50:41.376998: step 20800, loss = 0.76 (1202.6 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:50:42.134125: step 20810, loss = 0.76 (1690.6 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 12:50:43.001462: step 20820, loss = 0.84 (1475.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:50:43.816945: step 20830, loss = 0.78 (1569.6 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:50:44.611447: step 20840, loss = 0.82 (1611.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:50:45.418680: step 20850, loss = 1.07 (1585.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:50:46.233885: step 20860, loss = 0.89 (1570.2 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:50:47.069816: step 20870, loss = 0.72 (1531.2 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:50:47.967600: step 20880, loss = 0.78 (1425.7 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:50:48.845002: step 20890, loss = 0.83 (1458.9 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7565\n",
      "2017-05-25 12:50:49.882928: step 20900, loss = 0.82 (1233.2 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:50:50.667506: step 20910, loss = 0.67 (1631.5 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:50:51.471961: step 20920, loss = 0.91 (1591.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:50:52.277354: step 20930, loss = 0.96 (1589.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:50:53.075374: step 20940, loss = 0.79 (1604.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:50:55.619330: step 20970, loss = 0.94 (1431.8 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:50:56.495306: step 20980, loss = 0.74 (1461.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:50:57.379349: step 20990, loss = 0.86 (1447.9 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6388\n",
      "2017-05-25 12:50:58.475205: step 21000, loss = 0.93 (1168.0 examples/sec; 0.110 sec/batch)\n",
      "2017-05-25 12:50:59.143259: step 21010, loss = 0.73 (1916.0 examples/sec; 0.067 sec/batch)\n",
      "2017-05-25 12:50:59.942584: step 21020, loss = 0.76 (1601.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:51:00.773847: step 21030, loss = 0.76 (1539.8 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:51:01.569247: step 21040, loss = 0.92 (1609.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:51:02.376448: step 21050, loss = 0.75 (1585.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:51:03.231396: step 21060, loss = 0.87 (1497.2 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:51:04.114013: step 21070, loss = 0.72 (1450.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:51:04.991498: step 21080, loss = 0.75 (1458.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:51:05.905101: step 21090, loss = 0.76 (1401.0 examples/sec; 0.091 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8673\n",
      "2017-05-25 12:51:06.901832: step 21100, loss = 0.84 (1284.2 examples/sec; 0.100 sec/batch)\n",
      "2017-05-25 12:51:07.616578: step 21110, loss = 1.06 (1790.9 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:51:08.418454: step 21120, loss = 0.96 (1596.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:51:09.227402: step 21130, loss = 0.82 (1582.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:51:10.015879: step 21140, loss = 0.83 (1623.4 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:51:10.867951: step 21150, loss = 0.93 (1502.2 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:51:11.759175: step 21160, loss = 0.76 (1436.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:51:12.633219: step 21170, loss = 0.86 (1464.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:51:13.507581: step 21180, loss = 0.89 (1463.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:51:14.383471: step 21190, loss = 0.98 (1461.4 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8185\n",
      "2017-05-25 12:51:15.363028: step 21200, loss = 0.70 (1306.7 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 12:51:16.082681: step 21210, loss = 0.81 (1778.6 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:51:16.885607: step 21220, loss = 0.88 (1594.2 examples/sec; 0.080 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:51:17.754116: step 21230, loss = 0.81 (1473.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:51:18.562977: step 21240, loss = 0.83 (1582.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:51:19.434780: step 21250, loss = 0.83 (1468.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:51:20.330370: step 21260, loss = 0.83 (1429.2 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:51:21.207426: step 21270, loss = 1.06 (1459.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:51:22.090614: step 21280, loss = 1.09 (1449.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:51:22.941739: step 21290, loss = 0.92 (1503.9 examples/sec; 0.085 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6441\n",
      "2017-05-25 12:51:23.951573: step 21300, loss = 0.63 (1267.5 examples/sec; 0.101 sec/batch)\n",
      "2017-05-25 12:51:24.594630: step 21310, loss = 0.93 (1990.5 examples/sec; 0.064 sec/batch)\n",
      "2017-05-25 12:51:25.408220: step 21320, loss = 0.86 (1573.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:51:27.933635: step 21350, loss = 0.86 (1454.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:51:28.818490: step 21360, loss = 0.82 (1446.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:51:29.711173: step 21370, loss = 0.79 (1433.9 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:51:30.614610: step 21380, loss = 0.81 (1416.8 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:51:31.421138: step 21390, loss = 0.87 (1587.0 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8829\n",
      "2017-05-25 12:51:32.367463: step 21400, loss = 0.77 (1352.6 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:51:33.070114: step 21410, loss = 0.72 (1821.7 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:51:33.878213: step 21420, loss = 0.78 (1584.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:51:34.679417: step 21430, loss = 0.94 (1597.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:51:35.586323: step 21440, loss = 0.71 (1411.4 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 12:51:36.528019: step 21450, loss = 0.79 (1359.2 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:51:37.399466: step 21460, loss = 0.79 (1468.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:51:38.289391: step 21470, loss = 0.70 (1438.3 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:51:39.359238: step 21480, loss = 0.86 (1196.4 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:51:40.610702: step 21490, loss = 0.79 (1022.8 examples/sec; 0.125 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.3028\n",
      "2017-05-25 12:51:42.072964: step 21500, loss = 0.75 (875.4 examples/sec; 0.146 sec/batch)\n",
      "2017-05-25 12:51:43.073400: step 21510, loss = 0.93 (1279.4 examples/sec; 0.100 sec/batch)\n",
      "2017-05-25 12:51:44.129137: step 21520, loss = 0.91 (1212.4 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:51:45.172078: step 21530, loss = 0.77 (1227.3 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:51:46.244203: step 21540, loss = 0.79 (1193.9 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:51:47.202151: step 21550, loss = 0.89 (1336.2 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 12:51:48.081043: step 21560, loss = 1.03 (1456.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:51:48.961941: step 21570, loss = 0.80 (1453.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:51:49.853009: step 21580, loss = 0.89 (1436.5 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:51:50.743237: step 21590, loss = 0.86 (1437.8 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.4082\n",
      "2017-05-25 12:51:51.679822: step 21600, loss = 0.73 (1366.7 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:51:52.392444: step 21610, loss = 1.01 (1796.2 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:51:53.204331: step 21620, loss = 1.01 (1576.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:51:54.014626: step 21630, loss = 0.96 (1579.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:51:54.823051: step 21640, loss = 1.06 (1583.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:51:55.702812: step 21650, loss = 0.95 (1454.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:51:56.579598: step 21660, loss = 0.85 (1459.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:51:57.460850: step 21670, loss = 0.82 (1452.5 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8057\n",
      "2017-05-25 12:52:00.150995: step 21700, loss = 0.77 (1368.0 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:52:00.900938: step 21710, loss = 0.80 (1706.8 examples/sec; 0.075 sec/batch)\n",
      "2017-05-25 12:52:01.716464: step 21720, loss = 0.82 (1569.5 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:52:02.513519: step 21730, loss = 0.73 (1605.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:52:03.388474: step 21740, loss = 0.98 (1462.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:52:04.268412: step 21750, loss = 0.82 (1454.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:52:05.157237: step 21760, loss = 0.82 (1440.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:52:06.034422: step 21770, loss = 0.86 (1459.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:52:06.886756: step 21780, loss = 0.78 (1501.8 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:52:07.689043: step 21790, loss = 0.73 (1595.4 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7999\n",
      "2017-05-25 12:52:08.626993: step 21800, loss = 0.85 (1364.7 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:52:09.341149: step 21810, loss = 0.87 (1792.3 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:52:10.152915: step 21820, loss = 0.78 (1576.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:52:10.982496: step 21830, loss = 0.83 (1542.9 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:52:11.859822: step 21840, loss = 0.80 (1459.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:52:12.740665: step 21850, loss = 0.79 (1453.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:52:13.620670: step 21860, loss = 0.77 (1454.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:52:14.502251: step 21870, loss = 0.81 (1451.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:52:15.321055: step 21880, loss = 0.85 (1563.3 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:52:16.136218: step 21890, loss = 0.86 (1570.2 examples/sec; 0.082 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.825\n",
      "2017-05-25 12:52:17.083379: step 21900, loss = 0.78 (1351.4 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:52:17.798747: step 21910, loss = 0.96 (1789.3 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:52:18.609711: step 21920, loss = 0.98 (1578.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:52:19.468671: step 21930, loss = 0.89 (1490.2 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:52:20.371691: step 21940, loss = 0.72 (1417.5 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:52:21.257955: step 21950, loss = 0.80 (1444.3 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:52:22.126913: step 21960, loss = 0.66 (1473.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:52:22.993045: step 21970, loss = 0.78 (1477.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:52:23.793314: step 21980, loss = 0.89 (1599.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:52:24.596024: step 21990, loss = 0.81 (1594.6 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8309\n",
      "2017-05-25 12:52:25.534134: step 22000, loss = 0.79 (1364.4 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:52:26.262665: step 22010, loss = 0.84 (1757.0 examples/sec; 0.073 sec/batch)\n",
      "2017-05-25 12:52:27.097339: step 22020, loss = 0.82 (1533.5 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:52:27.973441: step 22030, loss = 0.86 (1461.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:52:28.855218: step 22040, loss = 0.85 (1451.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:52:31.806817: step 22070, loss = 0.87 (1071.8 examples/sec; 0.119 sec/batch)\n",
      "2017-05-25 12:52:33.030297: step 22080, loss = 1.01 (1046.2 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 12:52:34.250150: step 22090, loss = 0.63 (1049.3 examples/sec; 0.122 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.9275\n",
      "2017-05-25 12:52:35.607694: step 22100, loss = 0.94 (942.9 examples/sec; 0.136 sec/batch)\n",
      "2017-05-25 12:52:36.491300: step 22110, loss = 0.82 (1448.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:52:37.543208: step 22120, loss = 0.93 (1216.8 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:52:38.596682: step 22130, loss = 0.85 (1215.0 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:52:39.481011: step 22140, loss = 0.90 (1447.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:52:40.379268: step 22150, loss = 0.80 (1425.0 examples/sec; 0.090 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:52:41.262702: step 22160, loss = 0.78 (1448.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:52:42.142366: step 22170, loss = 0.85 (1455.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:52:43.006645: step 22180, loss = 0.97 (1481.0 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:52:43.816440: step 22190, loss = 0.67 (1580.6 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.8843\n",
      "2017-05-25 12:52:44.795143: step 22200, loss = 0.85 (1307.9 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 12:52:45.457594: step 22210, loss = 0.77 (1932.2 examples/sec; 0.066 sec/batch)\n",
      "2017-05-25 12:52:46.266570: step 22220, loss = 0.77 (1582.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:52:47.106634: step 22230, loss = 0.91 (1523.7 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:52:47.992397: step 22240, loss = 0.84 (1445.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:52:48.883273: step 22250, loss = 0.79 (1436.8 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:52:49.769246: step 22260, loss = 0.83 (1444.7 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:52:50.669186: step 22270, loss = 0.78 (1422.3 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:52:51.470882: step 22280, loss = 0.84 (1596.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:52:52.272095: step 22290, loss = 0.86 (1597.6 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8075\n",
      "2017-05-25 12:52:53.264247: step 22300, loss = 0.74 (1290.1 examples/sec; 0.099 sec/batch)\n",
      "2017-05-25 12:52:53.914732: step 22310, loss = 0.80 (1967.8 examples/sec; 0.065 sec/batch)\n",
      "2017-05-25 12:52:54.726392: step 22320, loss = 0.75 (1577.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:52:55.602982: step 22330, loss = 0.81 (1460.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:52:56.486104: step 22340, loss = 0.79 (1449.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:52:57.367356: step 22350, loss = 0.82 (1452.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:52:58.249648: step 22360, loss = 0.82 (1450.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:52:59.099723: step 22370, loss = 1.03 (1505.7 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:52:59.913101: step 22380, loss = 0.98 (1573.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:53:00.732944: step 22390, loss = 0.75 (1561.3 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:53:04.098596: step 22430, loss = 0.90 (1479.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:53:04.981073: step 22440, loss = 0.70 (1450.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:53:05.870428: step 22450, loss = 1.05 (1439.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:53:06.749287: step 22460, loss = 0.70 (1456.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:53:07.548202: step 22470, loss = 0.89 (1602.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:53:08.353949: step 22480, loss = 0.83 (1588.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:53:09.153555: step 22490, loss = 0.91 (1600.8 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9258\n",
      "2017-05-25 12:53:10.118933: step 22500, loss = 0.81 (1325.9 examples/sec; 0.097 sec/batch)\n",
      "2017-05-25 12:53:10.848750: step 22510, loss = 0.93 (1753.9 examples/sec; 0.073 sec/batch)\n",
      "2017-05-25 12:53:11.737960: step 22520, loss = 0.82 (1439.5 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:53:12.621300: step 22530, loss = 0.69 (1449.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:53:13.500205: step 22540, loss = 0.85 (1456.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:53:14.381843: step 22550, loss = 0.75 (1451.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:53:15.222253: step 22560, loss = 0.91 (1523.1 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:53:16.011743: step 22570, loss = 0.74 (1621.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:53:16.837821: step 22580, loss = 0.93 (1549.5 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:53:17.630382: step 22590, loss = 0.88 (1615.0 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8275\n",
      "2017-05-25 12:53:18.574210: step 22600, loss = 0.80 (1356.2 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:53:19.341283: step 22610, loss = 0.80 (1668.7 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:53:20.240302: step 22620, loss = 0.96 (1423.8 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:53:21.150563: step 22630, loss = 0.82 (1406.2 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 12:53:22.019865: step 22640, loss = 0.82 (1472.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:53:22.911814: step 22650, loss = 0.78 (1435.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:53:23.716117: step 22660, loss = 0.92 (1591.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:53:24.525015: step 22670, loss = 0.80 (1582.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:53:25.327554: step 22680, loss = 0.95 (1594.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:53:26.128819: step 22690, loss = 0.90 (1597.5 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7044\n",
      "2017-05-25 12:53:27.117638: step 22700, loss = 0.80 (1294.5 examples/sec; 0.099 sec/batch)\n",
      "2017-05-25 12:53:27.903298: step 22710, loss = 0.92 (1629.2 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:53:28.786668: step 22720, loss = 0.83 (1449.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:53:29.658488: step 22730, loss = 0.85 (1468.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:53:30.552430: step 22740, loss = 0.68 (1431.9 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:53:31.707288: step 22750, loss = 0.98 (1108.4 examples/sec; 0.115 sec/batch)\n",
      "2017-05-25 12:53:32.924424: step 22760, loss = 0.81 (1051.6 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 12:53:36.339375: step 22790, loss = 0.80 (1221.8 examples/sec; 0.105 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.55263\n",
      "2017-05-25 12:53:37.587819: step 22800, loss = 0.95 (1025.3 examples/sec; 0.125 sec/batch)\n",
      "2017-05-25 12:53:38.509044: step 22810, loss = 0.70 (1389.5 examples/sec; 0.092 sec/batch)\n",
      "2017-05-25 12:53:39.437812: step 22820, loss = 0.66 (1378.2 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 12:53:40.372237: step 22830, loss = 0.88 (1369.8 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 12:53:41.264686: step 22840, loss = 0.73 (1434.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:53:42.144279: step 22850, loss = 0.80 (1455.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:53:42.987042: step 22860, loss = 0.93 (1518.8 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:53:43.799999: step 22870, loss = 0.72 (1574.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:53:44.603231: step 22880, loss = 0.70 (1593.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:53:45.395299: step 22890, loss = 0.89 (1616.0 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.3362\n",
      "2017-05-25 12:53:46.406880: step 22900, loss = 0.82 (1265.3 examples/sec; 0.101 sec/batch)\n",
      "2017-05-25 12:53:47.092650: step 22910, loss = 0.83 (1866.5 examples/sec; 0.069 sec/batch)\n",
      "2017-05-25 12:53:47.974818: step 22920, loss = 0.90 (1451.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:53:48.847421: step 22930, loss = 0.71 (1466.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:53:49.726126: step 22940, loss = 0.85 (1456.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:53:50.620469: step 22950, loss = 0.84 (1431.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:53:51.446579: step 22960, loss = 0.97 (1549.4 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:53:52.266444: step 22970, loss = 0.85 (1561.2 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:53:53.075646: step 22980, loss = 1.10 (1581.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:53:53.897275: step 22990, loss = 0.80 (1557.9 examples/sec; 0.082 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.86\n",
      "2017-05-25 12:53:54.838688: step 23000, loss = 0.93 (1359.7 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:53:55.615526: step 23010, loss = 0.88 (1647.7 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:53:56.489267: step 23020, loss = 0.71 (1465.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:53:57.386340: step 23030, loss = 0.98 (1426.9 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:53:58.259908: step 23040, loss = 0.73 (1465.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:53:59.099049: step 23050, loss = 0.88 (1525.4 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:53:59.899429: step 23060, loss = 1.00 (1599.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:54:00.721945: step 23070, loss = 0.87 (1556.2 examples/sec; 0.082 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:54:01.530649: step 23080, loss = 0.91 (1582.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:54:02.427051: step 23090, loss = 0.83 (1427.9 examples/sec; 0.090 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.5387\n",
      "2017-05-25 12:54:03.505991: step 23100, loss = 0.73 (1186.3 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 12:54:04.243652: step 23110, loss = 0.91 (1735.2 examples/sec; 0.074 sec/batch)\n",
      "2017-05-25 12:54:05.126457: step 23120, loss = 0.98 (1449.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:54:07.681380: step 23150, loss = 0.82 (1589.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:54:08.482218: step 23160, loss = 1.02 (1598.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:54:09.286127: step 23170, loss = 0.79 (1592.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:54:10.101289: step 23180, loss = 0.79 (1570.2 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:54:10.919262: step 23190, loss = 0.85 (1564.8 examples/sec; 0.082 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7699\n",
      "2017-05-25 12:54:12.003645: step 23200, loss = 0.79 (1180.4 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 12:54:12.729733: step 23210, loss = 0.98 (1762.9 examples/sec; 0.073 sec/batch)\n",
      "2017-05-25 12:54:13.611853: step 23220, loss = 0.89 (1451.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:54:14.497953: step 23230, loss = 0.75 (1444.5 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:54:15.356165: step 23240, loss = 0.77 (1491.5 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:54:16.159204: step 23250, loss = 1.06 (1593.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:54:16.960841: step 23260, loss = 0.74 (1596.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:54:17.779562: step 23270, loss = 0.91 (1563.4 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:54:18.586879: step 23280, loss = 0.78 (1585.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:54:19.446240: step 23290, loss = 0.95 (1489.5 examples/sec; 0.086 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.681\n",
      "2017-05-25 12:54:20.562750: step 23300, loss = 0.82 (1146.4 examples/sec; 0.112 sec/batch)\n",
      "2017-05-25 12:54:21.278441: step 23310, loss = 1.05 (1788.5 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:54:22.170447: step 23320, loss = 0.87 (1435.0 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:54:23.023957: step 23330, loss = 0.69 (1499.7 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:54:23.837948: step 23340, loss = 0.75 (1572.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:54:24.648935: step 23350, loss = 0.95 (1578.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:54:25.464886: step 23360, loss = 0.90 (1568.7 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:54:26.271440: step 23370, loss = 0.68 (1587.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:54:27.096819: step 23380, loss = 0.77 (1550.8 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:54:28.004246: step 23390, loss = 0.83 (1410.6 examples/sec; 0.091 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7641\n",
      "2017-05-25 12:54:29.063154: step 23400, loss = 0.74 (1208.8 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:54:29.813944: step 23410, loss = 0.88 (1704.9 examples/sec; 0.075 sec/batch)\n",
      "2017-05-25 12:54:30.722972: step 23420, loss = 0.72 (1408.1 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 12:54:31.533068: step 23430, loss = 0.84 (1580.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:54:32.344023: step 23440, loss = 0.85 (1578.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:54:33.144124: step 23450, loss = 0.84 (1599.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:54:33.947076: step 23460, loss = 0.85 (1594.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:54:34.755676: step 23470, loss = 0.68 (1583.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:54:35.622568: step 23480, loss = 0.79 (1476.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:54:36.506013: step 23490, loss = 0.70 (1448.9 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8005\n",
      "2017-05-25 12:54:40.622776: step 23530, loss = 0.98 (1021.3 examples/sec; 0.125 sec/batch)\n",
      "2017-05-25 12:54:41.859549: step 23540, loss = 0.83 (1035.0 examples/sec; 0.124 sec/batch)\n",
      "2017-05-25 12:54:43.031642: step 23550, loss = 0.67 (1092.1 examples/sec; 0.117 sec/batch)\n",
      "2017-05-25 12:54:44.080375: step 23560, loss = 0.95 (1220.5 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:54:45.126259: step 23570, loss = 1.09 (1223.8 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:54:46.197731: step 23580, loss = 0.91 (1194.6 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:54:47.166595: step 23590, loss = 0.78 (1321.1 examples/sec; 0.097 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.35172\n",
      "2017-05-25 12:54:48.232218: step 23600, loss = 0.76 (1201.2 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:54:48.966693: step 23610, loss = 0.89 (1742.7 examples/sec; 0.073 sec/batch)\n",
      "2017-05-25 12:54:49.853995: step 23620, loss = 0.82 (1442.6 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:54:50.750005: step 23630, loss = 0.96 (1428.6 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:54:51.554187: step 23640, loss = 0.76 (1591.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:54:52.363062: step 23650, loss = 0.95 (1582.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:54:53.168925: step 23660, loss = 0.82 (1588.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:54:53.970545: step 23670, loss = 0.81 (1596.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:54:54.778797: step 23680, loss = 0.82 (1583.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:54:55.668713: step 23690, loss = 0.75 (1438.3 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6694\n",
      "2017-05-25 12:54:56.799625: step 23700, loss = 0.79 (1131.8 examples/sec; 0.113 sec/batch)\n",
      "2017-05-25 12:54:57.483618: step 23710, loss = 0.86 (1871.4 examples/sec; 0.068 sec/batch)\n",
      "2017-05-25 12:54:58.359683: step 23720, loss = 0.85 (1461.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:54:59.214464: step 23730, loss = 0.72 (1497.5 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:55:00.003823: step 23740, loss = 0.93 (1621.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:55:00.818602: step 23750, loss = 0.64 (1571.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:55:01.626179: step 23760, loss = 0.83 (1585.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:55:02.430963: step 23770, loss = 0.91 (1590.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:55:03.275788: step 23780, loss = 0.95 (1515.1 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:55:04.157288: step 23790, loss = 0.80 (1452.1 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9042\n",
      "2017-05-25 12:55:05.202038: step 23800, loss = 0.81 (1225.2 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:55:05.966161: step 23810, loss = 0.71 (1675.1 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 12:55:06.848715: step 23820, loss = 0.92 (1450.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:55:07.671418: step 23830, loss = 0.92 (1555.8 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:55:08.478233: step 23840, loss = 0.93 (1586.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:55:09.277031: step 23850, loss = 0.69 (1602.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:55:11.777745: step 23880, loss = 0.91 (1467.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:55:12.655604: step 23890, loss = 1.04 (1458.1 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7688\n",
      "2017-05-25 12:55:13.699086: step 23900, loss = 0.79 (1226.7 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:55:14.478829: step 23910, loss = 0.85 (1641.6 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:55:15.324359: step 23920, loss = 0.87 (1513.8 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:55:16.133798: step 23930, loss = 0.85 (1581.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:55:16.936711: step 23940, loss = 0.71 (1594.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:55:17.737033: step 23950, loss = 0.71 (1599.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:55:18.545214: step 23960, loss = 0.86 (1583.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:55:19.393431: step 23970, loss = 0.78 (1509.0 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:55:20.274213: step 23980, loss = 0.78 (1453.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:55:21.149514: step 23990, loss = 0.69 (1462.4 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7819\n",
      "2017-05-25 12:55:22.185415: step 24000, loss = 0.98 (1235.6 examples/sec; 0.104 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:55:22.958154: step 24010, loss = 0.84 (1656.4 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 12:55:23.762053: step 24020, loss = 0.83 (1592.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:55:24.565370: step 24030, loss = 0.89 (1593.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:55:25.377934: step 24040, loss = 1.11 (1575.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:55:26.194991: step 24050, loss = 0.75 (1566.6 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:55:27.001713: step 24060, loss = 0.84 (1586.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:55:27.894464: step 24070, loss = 0.78 (1433.8 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:55:28.767396: step 24080, loss = 0.84 (1466.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:55:29.633878: step 24090, loss = 0.81 (1477.2 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7444\n",
      "2017-05-25 12:55:30.699746: step 24100, loss = 1.03 (1200.9 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:55:31.761894: step 24110, loss = 0.81 (1205.1 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:55:32.961398: step 24120, loss = 0.90 (1067.1 examples/sec; 0.120 sec/batch)\n",
      "2017-05-25 12:55:34.189173: step 24130, loss = 0.70 (1042.5 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 12:55:35.337913: step 24140, loss = 0.80 (1114.3 examples/sec; 0.115 sec/batch)\n",
      "2017-05-25 12:55:36.387925: step 24150, loss = 0.92 (1219.0 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:55:37.444538: step 24160, loss = 0.77 (1211.4 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:55:38.483672: step 24170, loss = 0.85 (1231.8 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:55:39.444384: step 24180, loss = 0.78 (1332.3 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 12:55:40.332529: step 24190, loss = 0.73 (1441.2 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.356\n",
      "2017-05-25 12:55:41.387952: step 24200, loss = 0.82 (1212.8 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:55:43.831418: step 24230, loss = 1.13 (1579.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:55:44.637613: step 24240, loss = 0.84 (1587.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:55:45.439286: step 24250, loss = 0.85 (1596.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:55:46.250791: step 24260, loss = 0.85 (1577.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:55:47.075378: step 24270, loss = 0.71 (1552.3 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:55:47.966260: step 24280, loss = 0.92 (1436.8 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:55:48.845401: step 24290, loss = 0.67 (1455.9 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6411\n",
      "2017-05-25 12:55:49.977954: step 24300, loss = 0.69 (1130.2 examples/sec; 0.113 sec/batch)\n",
      "2017-05-25 12:55:50.669633: step 24310, loss = 0.86 (1850.6 examples/sec; 0.069 sec/batch)\n",
      "2017-05-25 12:55:51.503794: step 24320, loss = 0.84 (1534.5 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:55:52.310948: step 24330, loss = 0.89 (1585.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:55:53.112005: step 24340, loss = 0.66 (1597.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:55:53.914259: step 24350, loss = 0.76 (1595.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:55:54.718466: step 24360, loss = 0.93 (1591.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:55:55.586012: step 24370, loss = 0.90 (1475.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:55:56.466966: step 24380, loss = 0.78 (1453.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:55:57.356773: step 24390, loss = 0.82 (1438.5 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8876\n",
      "2017-05-25 12:55:58.390041: step 24400, loss = 0.78 (1238.8 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:55:59.135974: step 24410, loss = 0.78 (1716.0 examples/sec; 0.075 sec/batch)\n",
      "2017-05-25 12:55:59.939647: step 24420, loss = 0.82 (1592.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:56:00.755207: step 24430, loss = 0.78 (1569.5 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:56:01.581081: step 24440, loss = 0.96 (1549.9 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:56:02.380891: step 24450, loss = 0.77 (1600.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:56:03.221105: step 24460, loss = 0.73 (1523.4 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:56:04.094884: step 24470, loss = 1.00 (1464.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:56:04.968921: step 24480, loss = 0.77 (1464.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:56:05.847671: step 24490, loss = 0.86 (1456.6 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.783\n",
      "2017-05-25 12:56:06.877088: step 24500, loss = 1.01 (1243.4 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:56:07.600064: step 24510, loss = 0.71 (1770.5 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:56:08.399667: step 24520, loss = 0.70 (1600.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:56:09.201608: step 24530, loss = 0.80 (1596.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:56:09.996868: step 24540, loss = 0.70 (1609.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:56:10.813506: step 24550, loss = 0.82 (1567.4 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:56:11.689653: step 24560, loss = 0.82 (1460.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:56:12.568464: step 24570, loss = 0.86 (1456.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:56:13.444644: step 24580, loss = 0.73 (1460.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:56:16.013587: step 24610, loss = 0.62 (1836.5 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:56:16.824637: step 24620, loss = 0.73 (1578.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:56:17.634165: step 24630, loss = 0.95 (1581.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:56:18.446280: step 24640, loss = 0.80 (1576.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:56:19.298483: step 24650, loss = 0.65 (1502.0 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:56:20.187196: step 24660, loss = 0.81 (1440.3 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:56:21.069945: step 24670, loss = 0.80 (1450.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:56:21.942852: step 24680, loss = 0.86 (1466.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:56:22.838731: step 24690, loss = 0.96 (1428.7 examples/sec; 0.090 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.0891\n",
      "2017-05-25 12:56:24.335047: step 24700, loss = 0.85 (855.4 examples/sec; 0.150 sec/batch)\n",
      "2017-05-25 12:56:25.362362: step 24710, loss = 0.87 (1246.0 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:56:26.601231: step 24720, loss = 0.74 (1033.2 examples/sec; 0.124 sec/batch)\n",
      "2017-05-25 12:56:27.697101: step 24730, loss = 0.80 (1168.0 examples/sec; 0.110 sec/batch)\n",
      "2017-05-25 12:56:28.745845: step 24740, loss = 0.79 (1220.5 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:56:29.810692: step 24750, loss = 0.87 (1202.1 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:56:30.876724: step 24760, loss = 0.78 (1200.7 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:56:31.745740: step 24770, loss = 0.83 (1472.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:56:32.634910: step 24780, loss = 0.72 (1439.5 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:56:33.572841: step 24790, loss = 0.67 (1364.7 examples/sec; 0.094 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.71223\n",
      "2017-05-25 12:56:34.630566: step 24800, loss = 0.80 (1210.1 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:56:35.351038: step 24810, loss = 0.76 (1776.6 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:56:36.156563: step 24820, loss = 0.81 (1589.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:56:37.057628: step 24830, loss = 0.90 (1420.5 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:56:37.914410: step 24840, loss = 0.98 (1494.0 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:56:38.717104: step 24850, loss = 0.72 (1594.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:56:39.593889: step 24860, loss = 0.82 (1459.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:56:40.498919: step 24870, loss = 0.78 (1414.3 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 12:56:41.400508: step 24880, loss = 0.97 (1419.7 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:56:42.276749: step 24890, loss = 0.73 (1460.8 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.5277\n",
      "2017-05-25 12:56:43.306045: step 24900, loss = 0.76 (1243.6 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:56:43.972749: step 24910, loss = 0.87 (1919.9 examples/sec; 0.067 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:56:44.775915: step 24920, loss = 0.95 (1593.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:56:48.977333: step 24970, loss = 0.84 (1476.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:56:49.862773: step 24980, loss = 0.85 (1445.6 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:56:50.757722: step 24990, loss = 0.78 (1430.2 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8729\n",
      "2017-05-25 12:56:51.729324: step 25000, loss = 0.64 (1317.4 examples/sec; 0.097 sec/batch)\n",
      "2017-05-25 12:56:52.447545: step 25010, loss = 0.81 (1782.2 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:56:53.255961: step 25020, loss = 0.77 (1583.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:56:54.050786: step 25030, loss = 0.75 (1610.4 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:56:54.863653: step 25040, loss = 0.97 (1574.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:56:55.744289: step 25050, loss = 0.61 (1453.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:56:56.621784: step 25060, loss = 0.75 (1458.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:56:57.500242: step 25070, loss = 0.87 (1457.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:56:58.386348: step 25080, loss = 0.84 (1444.5 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:56:59.236929: step 25090, loss = 0.93 (1504.9 examples/sec; 0.085 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7604\n",
      "2017-05-25 12:57:00.231196: step 25100, loss = 0.89 (1287.4 examples/sec; 0.099 sec/batch)\n",
      "2017-05-25 12:57:00.893729: step 25110, loss = 1.06 (1932.0 examples/sec; 0.066 sec/batch)\n",
      "2017-05-25 12:57:01.707799: step 25120, loss = 0.92 (1572.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:57:02.506027: step 25130, loss = 0.80 (1603.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:57:03.357160: step 25140, loss = 0.85 (1503.9 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:57:04.218639: step 25150, loss = 0.85 (1485.8 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:57:05.097834: step 25160, loss = 0.75 (1455.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:57:05.972105: step 25170, loss = 0.74 (1464.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:57:06.848415: step 25180, loss = 0.85 (1460.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:57:08.043593: step 25190, loss = 0.87 (1071.0 examples/sec; 0.120 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.7486\n",
      "2017-05-25 12:57:09.538168: step 25200, loss = 0.84 (856.4 examples/sec; 0.149 sec/batch)\n",
      "2017-05-25 12:57:10.586955: step 25210, loss = 0.88 (1220.5 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:57:11.690311: step 25220, loss = 0.88 (1160.1 examples/sec; 0.110 sec/batch)\n",
      "2017-05-25 12:57:12.737129: step 25230, loss = 0.84 (1222.8 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:57:13.775983: step 25240, loss = 0.85 (1232.1 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:57:14.834076: step 25250, loss = 0.93 (1209.7 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 12:57:15.731243: step 25260, loss = 0.77 (1426.7 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:57:16.620039: step 25270, loss = 0.92 (1440.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:57:17.525262: step 25280, loss = 0.72 (1414.0 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 12:57:18.405433: step 25290, loss = 0.77 (1454.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:57:20.908459: step 25320, loss = 0.80 (1576.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:57:21.723774: step 25330, loss = 0.78 (1569.9 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:57:22.525334: step 25340, loss = 1.00 (1596.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:57:23.375518: step 25350, loss = 0.82 (1505.6 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:57:24.255968: step 25360, loss = 0.88 (1453.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:57:25.137464: step 25370, loss = 0.83 (1452.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:57:26.010679: step 25380, loss = 0.84 (1465.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:57:26.906989: step 25390, loss = 0.70 (1428.1 examples/sec; 0.090 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7146\n",
      "2017-05-25 12:57:27.935187: step 25400, loss = 0.71 (1244.9 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:57:28.599834: step 25410, loss = 0.74 (1925.8 examples/sec; 0.066 sec/batch)\n",
      "2017-05-25 12:57:29.421559: step 25420, loss = 0.81 (1557.7 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:57:30.245792: step 25430, loss = 0.73 (1553.0 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:57:31.060660: step 25440, loss = 0.86 (1570.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:57:31.929446: step 25450, loss = 0.79 (1473.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:57:32.802872: step 25460, loss = 0.77 (1465.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:57:33.676761: step 25470, loss = 0.71 (1464.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:57:34.557316: step 25480, loss = 0.90 (1453.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:57:35.389380: step 25490, loss = 0.81 (1538.3 examples/sec; 0.083 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9098\n",
      "2017-05-25 12:57:36.332730: step 25500, loss = 0.63 (1356.9 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 12:57:37.038248: step 25510, loss = 0.95 (1814.3 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 12:57:37.863331: step 25520, loss = 0.82 (1551.4 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:57:38.662956: step 25530, loss = 0.89 (1600.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:57:39.519385: step 25540, loss = 0.86 (1494.6 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:57:40.434965: step 25550, loss = 0.95 (1398.0 examples/sec; 0.092 sec/batch)\n",
      "2017-05-25 12:57:41.314031: step 25560, loss = 0.94 (1456.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:57:42.203015: step 25570, loss = 0.97 (1439.8 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:57:43.064331: step 25580, loss = 0.77 (1486.1 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:57:43.871811: step 25590, loss = 0.88 (1585.2 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7635\n",
      "2017-05-25 12:57:44.832028: step 25600, loss = 0.73 (1333.0 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 12:57:45.535475: step 25610, loss = 0.82 (1819.6 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 12:57:46.344386: step 25620, loss = 0.64 (1582.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:57:47.172583: step 25630, loss = 0.92 (1545.5 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:57:48.046968: step 25640, loss = 0.83 (1463.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:57:48.935295: step 25650, loss = 0.73 (1440.9 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:57:49.819465: step 25660, loss = 0.75 (1447.7 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6595\n",
      "2017-05-25 12:57:53.408270: step 25700, loss = 0.79 (1239.6 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 12:57:54.020683: step 25710, loss = 0.89 (2090.1 examples/sec; 0.061 sec/batch)\n",
      "2017-05-25 12:57:54.826281: step 25720, loss = 0.78 (1588.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:57:55.690030: step 25730, loss = 0.70 (1481.9 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:57:56.575101: step 25740, loss = 0.74 (1446.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:57:57.457749: step 25750, loss = 0.84 (1450.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:57:58.350945: step 25760, loss = 0.77 (1433.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:57:59.208547: step 25770, loss = 0.76 (1492.5 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:58:00.026532: step 25780, loss = 0.90 (1564.8 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:58:00.841313: step 25790, loss = 0.85 (1571.0 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8951\n",
      "2017-05-25 12:58:01.817455: step 25800, loss = 0.92 (1311.3 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 12:58:02.492444: step 25810, loss = 1.07 (1896.3 examples/sec; 0.067 sec/batch)\n",
      "2017-05-25 12:58:03.324954: step 25820, loss = 0.75 (1537.5 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:58:04.214458: step 25830, loss = 0.80 (1439.0 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:58:05.087991: step 25840, loss = 0.74 (1465.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:58:05.966158: step 25850, loss = 0.65 (1457.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:58:06.835976: step 25860, loss = 0.98 (1471.6 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:58:07.645312: step 25870, loss = 0.89 (1581.5 examples/sec; 0.081 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:58:08.472378: step 25880, loss = 0.76 (1547.6 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:58:09.276449: step 25890, loss = 0.90 (1591.9 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8882\n",
      "2017-05-25 12:58:10.228109: step 25900, loss = 0.95 (1345.0 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:58:10.944002: step 25910, loss = 0.82 (1788.0 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:58:11.835297: step 25920, loss = 0.92 (1436.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:58:12.715975: step 25930, loss = 0.75 (1453.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:58:13.606577: step 25940, loss = 0.95 (1437.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:58:14.492358: step 25950, loss = 1.00 (1445.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:58:15.330080: step 25960, loss = 0.93 (1528.0 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:58:16.122617: step 25970, loss = 0.99 (1615.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:58:16.923215: step 25980, loss = 0.82 (1598.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:58:17.733401: step 25990, loss = 0.88 (1579.9 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8323\n",
      "2017-05-25 12:58:18.678591: step 26000, loss = 0.91 (1354.2 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:58:19.429409: step 26010, loss = 0.77 (1704.8 examples/sec; 0.075 sec/batch)\n",
      "2017-05-25 12:58:20.351918: step 26020, loss = 0.83 (1387.5 examples/sec; 0.092 sec/batch)\n",
      "2017-05-25 12:58:21.233547: step 26030, loss = 0.73 (1451.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:58:22.104799: step 26040, loss = 0.68 (1469.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:58:25.436249: step 26070, loss = 0.89 (1039.4 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 12:58:26.660571: step 26080, loss = 0.72 (1045.5 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 12:58:27.760175: step 26090, loss = 0.86 (1164.1 examples/sec; 0.110 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.66969\n",
      "2017-05-25 12:58:29.020944: step 26100, loss = 0.79 (1015.3 examples/sec; 0.126 sec/batch)\n",
      "2017-05-25 12:58:29.947127: step 26110, loss = 0.81 (1382.0 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 12:58:31.022855: step 26120, loss = 0.75 (1189.9 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 12:58:31.900624: step 26130, loss = 0.75 (1458.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:58:32.797679: step 26140, loss = 0.83 (1426.9 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:58:33.671237: step 26150, loss = 0.85 (1465.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:58:34.538021: step 26160, loss = 0.74 (1476.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:58:35.387252: step 26170, loss = 0.87 (1507.2 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:58:36.190795: step 26180, loss = 0.79 (1592.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:58:37.013507: step 26190, loss = 0.87 (1555.8 examples/sec; 0.082 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.2135\n",
      "2017-05-25 12:58:37.939693: step 26200, loss = 0.85 (1382.0 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 12:58:38.658608: step 26210, loss = 0.96 (1780.5 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:58:39.507856: step 26220, loss = 0.68 (1507.2 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 12:58:40.396325: step 26230, loss = 0.77 (1440.7 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:58:41.273196: step 26240, loss = 0.73 (1459.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:58:42.139009: step 26250, loss = 0.81 (1478.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:58:43.021156: step 26260, loss = 0.75 (1451.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:58:43.815504: step 26270, loss = 0.83 (1611.5 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:58:44.635100: step 26280, loss = 0.74 (1561.7 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:58:45.449625: step 26290, loss = 0.75 (1571.5 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8232\n",
      "2017-05-25 12:58:46.395782: step 26300, loss = 0.81 (1352.8 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 12:58:47.117898: step 26310, loss = 0.81 (1772.6 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 12:58:48.005022: step 26320, loss = 0.75 (1442.9 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:58:48.880687: step 26330, loss = 0.81 (1461.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:58:49.782236: step 26340, loss = 0.75 (1419.8 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 12:58:50.694148: step 26350, loss = 0.85 (1403.6 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 12:58:51.524007: step 26360, loss = 0.87 (1542.4 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:58:52.327518: step 26370, loss = 0.88 (1593.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:58:53.123752: step 26380, loss = 0.86 (1607.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:58:53.945737: step 26390, loss = 0.87 (1557.2 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:58:56.563808: step 26420, loss = 0.90 (1432.9 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:58:57.441015: step 26430, loss = 1.03 (1459.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:58:58.324464: step 26440, loss = 0.83 (1448.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:58:59.184545: step 26450, loss = 0.95 (1488.2 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:58:59.982619: step 26460, loss = 0.77 (1603.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:59:00.823976: step 26470, loss = 0.79 (1521.3 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 12:59:01.645314: step 26480, loss = 0.70 (1558.4 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:59:02.586431: step 26490, loss = 0.78 (1360.1 examples/sec; 0.094 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.5795\n",
      "2017-05-25 12:59:03.580360: step 26500, loss = 0.84 (1287.8 examples/sec; 0.099 sec/batch)\n",
      "2017-05-25 12:59:04.357550: step 26510, loss = 0.81 (1647.0 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:59:05.231840: step 26520, loss = 0.83 (1464.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:59:06.103391: step 26530, loss = 0.71 (1468.6 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 12:59:07.009834: step 26540, loss = 0.80 (1412.1 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 12:59:07.820141: step 26550, loss = 0.79 (1579.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:59:08.613563: step 26560, loss = 0.72 (1613.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:59:09.433805: step 26570, loss = 0.78 (1560.5 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:59:10.246812: step 26580, loss = 0.68 (1574.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:59:11.057483: step 26590, loss = 0.84 (1578.9 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.743\n",
      "2017-05-25 12:59:12.096380: step 26600, loss = 0.90 (1232.1 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:59:12.881077: step 26610, loss = 0.86 (1631.2 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:59:13.768198: step 26620, loss = 0.85 (1442.9 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:59:14.676050: step 26630, loss = 1.05 (1409.9 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 12:59:15.505075: step 26640, loss = 1.02 (1544.0 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:59:16.314120: step 26650, loss = 0.78 (1582.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:59:17.107646: step 26660, loss = 0.82 (1613.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:59:17.921628: step 26670, loss = 0.85 (1572.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:59:18.729371: step 26680, loss = 0.73 (1584.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:59:19.660340: step 26690, loss = 0.84 (1374.9 examples/sec; 0.093 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6182\n",
      "2017-05-25 12:59:20.703447: step 26700, loss = 0.95 (1227.1 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 12:59:21.488200: step 26710, loss = 0.80 (1631.1 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 12:59:22.375856: step 26720, loss = 0.66 (1442.0 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:59:23.353440: step 26730, loss = 0.73 (1309.4 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 12:59:24.580390: step 26740, loss = 0.88 (1043.2 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 12:59:25.800349: step 26750, loss = 0.95 (1049.2 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 12:59:29.140975: step 26780, loss = 0.89 (1217.1 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 12:59:30.229169: step 26790, loss = 0.94 (1176.3 examples/sec; 0.109 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.33093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 12:59:31.421965: step 26800, loss = 0.82 (1073.1 examples/sec; 0.119 sec/batch)\n",
      "2017-05-25 12:59:32.186253: step 26810, loss = 0.76 (1674.8 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 12:59:33.063045: step 26820, loss = 0.88 (1459.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:59:33.939168: step 26830, loss = 0.90 (1461.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:59:34.826614: step 26840, loss = 0.63 (1442.3 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:59:35.657300: step 26850, loss = 0.89 (1540.9 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 12:59:36.480389: step 26860, loss = 0.83 (1555.1 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:59:37.275635: step 26870, loss = 0.70 (1609.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:59:38.096623: step 26880, loss = 0.79 (1559.1 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 12:59:38.894128: step 26890, loss = 1.04 (1605.0 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6924\n",
      "2017-05-25 12:59:39.973176: step 26900, loss = 0.92 (1186.2 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 12:59:40.709852: step 26910, loss = 0.78 (1737.5 examples/sec; 0.074 sec/batch)\n",
      "2017-05-25 12:59:41.602820: step 26920, loss = 0.82 (1433.4 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:59:42.485838: step 26930, loss = 0.64 (1449.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 12:59:43.345116: step 26940, loss = 0.61 (1489.6 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 12:59:44.150143: step 26950, loss = 0.77 (1590.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:59:44.950495: step 26960, loss = 0.84 (1599.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:59:45.753274: step 26970, loss = 0.70 (1594.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:59:46.567134: step 26980, loss = 0.88 (1572.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:59:47.417052: step 26990, loss = 0.65 (1506.0 examples/sec; 0.085 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7438\n",
      "2017-05-25 12:59:48.490808: step 27000, loss = 0.72 (1192.1 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:59:49.239037: step 27010, loss = 0.85 (1710.7 examples/sec; 0.075 sec/batch)\n",
      "2017-05-25 12:59:50.124403: step 27020, loss = 0.78 (1445.7 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:59:51.013168: step 27030, loss = 0.97 (1440.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 12:59:51.813068: step 27040, loss = 0.80 (1600.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:59:52.610394: step 27050, loss = 0.89 (1605.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:59:53.411921: step 27060, loss = 0.99 (1597.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 12:59:54.217452: step 27070, loss = 0.79 (1589.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 12:59:55.011196: step 27080, loss = 0.75 (1612.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 12:59:55.889712: step 27090, loss = 0.81 (1457.0 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7999\n",
      "2017-05-25 12:59:56.962906: step 27100, loss = 0.70 (1192.7 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 12:59:57.681751: step 27110, loss = 0.95 (1780.6 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 13:00:01.054934: step 27150, loss = 0.66 (1581.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:00:01.861671: step 27160, loss = 0.93 (1586.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:00:02.667538: step 27170, loss = 0.93 (1588.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:00:03.508672: step 27180, loss = 0.88 (1521.7 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:00:04.397177: step 27190, loss = 0.92 (1440.6 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7838\n",
      "2017-05-25 13:00:05.449352: step 27200, loss = 0.79 (1216.5 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:00:06.228833: step 27210, loss = 0.76 (1642.1 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 13:00:07.101835: step 27220, loss = 0.82 (1466.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:00:07.905497: step 27230, loss = 0.78 (1592.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:00:08.704289: step 27240, loss = 1.02 (1602.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:00:09.521944: step 27250, loss = 0.83 (1565.5 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:00:10.342723: step 27260, loss = 0.84 (1559.5 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:00:11.146079: step 27270, loss = 0.88 (1593.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:00:12.036601: step 27280, loss = 0.72 (1437.4 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:00:12.911786: step 27290, loss = 0.89 (1462.5 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7573\n",
      "2017-05-25 13:00:13.956562: step 27300, loss = 0.91 (1225.2 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 13:00:14.717405: step 27310, loss = 0.89 (1682.3 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 13:00:15.557483: step 27320, loss = 0.84 (1523.7 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:00:16.364776: step 27330, loss = 0.92 (1585.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:00:17.196240: step 27340, loss = 0.85 (1539.5 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 13:00:18.006631: step 27350, loss = 0.76 (1579.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:00:18.796401: step 27360, loss = 0.93 (1620.7 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:00:19.657036: step 27370, loss = 0.78 (1487.3 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:00:20.553004: step 27380, loss = 0.85 (1428.6 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 13:00:21.441526: step 27390, loss = 0.77 (1440.6 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.742\n",
      "2017-05-25 13:00:22.472801: step 27400, loss = 0.93 (1241.2 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 13:00:23.243919: step 27410, loss = 0.99 (1659.9 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 13:00:24.042612: step 27420, loss = 0.83 (1602.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:00:24.848636: step 27430, loss = 0.79 (1588.0 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 27436 into /home/ipython/cnn-cifar10/tb_log/test-softmax/train/model.ckpt.\n",
      "2017-05-25 13:00:25.689255: step 27440, loss = 0.89 (1522.7 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:00:26.502052: step 27450, loss = 0.83 (1574.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:00:27.342385: step 27460, loss = 0.76 (1523.2 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:00:28.220554: step 27470, loss = 0.77 (1457.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:00:29.094118: step 27480, loss = 0.84 (1465.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:00:29.973438: step 27490, loss = 0.83 (1455.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:00:33.324316: step 27520, loss = 0.78 (1026.3 examples/sec; 0.125 sec/batch)\n",
      "2017-05-25 13:00:34.541792: step 27530, loss = 0.77 (1051.4 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 13:00:35.670407: step 27540, loss = 0.77 (1134.1 examples/sec; 0.113 sec/batch)\n",
      "2017-05-25 13:00:36.713602: step 27550, loss = 0.75 (1227.0 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 13:00:37.761918: step 27560, loss = 0.81 (1221.0 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:00:38.814636: step 27570, loss = 0.96 (1215.9 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:00:39.751857: step 27580, loss = 0.98 (1365.7 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 13:00:40.648871: step 27590, loss = 0.81 (1427.0 examples/sec; 0.090 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.48537\n",
      "2017-05-25 13:00:41.683123: step 27600, loss = 0.75 (1237.6 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 13:00:42.453037: step 27610, loss = 0.98 (1662.5 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 13:00:43.314780: step 27620, loss = 0.89 (1485.4 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:00:44.127789: step 27630, loss = 0.87 (1574.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:00:44.930511: step 27640, loss = 0.76 (1594.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:00:45.742286: step 27650, loss = 0.85 (1576.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:00:46.559393: step 27660, loss = 0.78 (1566.5 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:00:47.394668: step 27670, loss = 0.92 (1532.4 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:00:48.271317: step 27680, loss = 0.83 (1460.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:00:49.157066: step 27690, loss = 0.78 (1445.1 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7454\n",
      "2017-05-25 13:00:50.195913: step 27700, loss = 0.69 (1232.1 examples/sec; 0.104 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 13:00:50.973666: step 27710, loss = 0.95 (1645.8 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 13:00:51.812335: step 27720, loss = 0.92 (1526.2 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:00:52.614152: step 27730, loss = 0.91 (1596.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:00:53.418778: step 27740, loss = 0.84 (1590.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:00:54.216442: step 27750, loss = 0.66 (1604.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:00:55.014627: step 27760, loss = 0.78 (1603.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:00:55.898096: step 27770, loss = 0.88 (1448.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:00:56.767397: step 27780, loss = 0.93 (1472.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:00:57.665103: step 27790, loss = 0.80 (1425.9 examples/sec; 0.090 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7176\n",
      "2017-05-25 13:00:58.731863: step 27800, loss = 0.77 (1199.9 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 13:00:59.432947: step 27810, loss = 0.83 (1825.7 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 13:01:00.256995: step 27820, loss = 0.74 (1553.3 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:01:01.052036: step 27830, loss = 0.81 (1610.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:01:01.873181: step 27840, loss = 0.86 (1558.8 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:01:05.303170: step 27880, loss = 0.82 (1463.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:01:06.198799: step 27890, loss = 0.74 (1429.2 examples/sec; 0.090 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6689\n",
      "2017-05-25 13:01:07.299854: step 27900, loss = 0.74 (1162.5 examples/sec; 0.110 sec/batch)\n",
      "2017-05-25 13:01:08.359706: step 27910, loss = 0.85 (1207.7 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 13:01:09.593115: step 27920, loss = 0.80 (1037.8 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 13:01:10.853262: step 27930, loss = 0.86 (1015.8 examples/sec; 0.126 sec/batch)\n",
      "2017-05-25 13:01:11.950852: step 27940, loss = 0.73 (1166.2 examples/sec; 0.110 sec/batch)\n",
      "2017-05-25 13:01:13.032188: step 27950, loss = 0.91 (1183.7 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 13:01:14.087728: step 27960, loss = 0.92 (1212.6 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 13:01:15.155851: step 27970, loss = 0.70 (1198.4 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 13:01:16.027986: step 27980, loss = 0.72 (1467.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:01:16.905904: step 27990, loss = 0.84 (1458.0 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.38187\n",
      "2017-05-25 13:01:17.960753: step 28000, loss = 1.08 (1213.4 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:01:18.721941: step 28010, loss = 0.87 (1681.6 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 13:01:19.570442: step 28020, loss = 0.87 (1508.5 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 13:01:20.385944: step 28030, loss = 0.71 (1569.6 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:01:21.183211: step 28040, loss = 1.05 (1605.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:01:21.998870: step 28050, loss = 0.97 (1569.3 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:01:22.808808: step 28060, loss = 0.80 (1580.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:01:23.663870: step 28070, loss = 0.91 (1497.0 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:01:24.552269: step 28080, loss = 0.75 (1440.8 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:01:25.435204: step 28090, loss = 0.94 (1449.7 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.709\n",
      "2017-05-25 13:01:26.499530: step 28100, loss = 0.77 (1202.6 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 13:01:27.250310: step 28110, loss = 0.94 (1704.9 examples/sec; 0.075 sec/batch)\n",
      "2017-05-25 13:01:28.058956: step 28120, loss = 0.78 (1582.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:01:28.858818: step 28130, loss = 0.81 (1600.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:01:29.673409: step 28140, loss = 0.73 (1571.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:01:30.488445: step 28150, loss = 0.73 (1570.5 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:01:31.297998: step 28160, loss = 0.91 (1581.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:01:32.190583: step 28170, loss = 0.72 (1434.0 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:01:33.069469: step 28180, loss = 0.81 (1456.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:01:33.953232: step 28190, loss = 0.92 (1448.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:01:36.509024: step 28220, loss = 0.83 (1586.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:01:37.315775: step 28230, loss = 0.74 (1586.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:01:38.142212: step 28240, loss = 0.71 (1548.8 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 13:01:38.961853: step 28250, loss = 0.76 (1561.7 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:01:39.824080: step 28260, loss = 0.79 (1484.5 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:01:40.733700: step 28270, loss = 0.83 (1407.2 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 13:01:41.616856: step 28280, loss = 0.71 (1449.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:01:42.494552: step 28290, loss = 0.79 (1458.4 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.3498\n",
      "2017-05-25 13:01:43.798942: step 28300, loss = 0.87 (981.3 examples/sec; 0.130 sec/batch)\n",
      "2017-05-25 13:01:44.781788: step 28310, loss = 0.77 (1302.3 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 13:01:46.008451: step 28320, loss = 0.92 (1043.5 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 13:01:47.229820: step 28330, loss = 0.76 (1048.0 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 13:01:48.286869: step 28340, loss = 0.77 (1210.9 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 13:01:49.339207: step 28350, loss = 0.71 (1216.3 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:01:50.408306: step 28360, loss = 0.88 (1197.3 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 13:01:51.406930: step 28370, loss = 0.78 (1281.8 examples/sec; 0.100 sec/batch)\n",
      "2017-05-25 13:01:52.284348: step 28380, loss = 0.76 (1458.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:01:53.156273: step 28390, loss = 0.76 (1468.0 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.60675\n",
      "2017-05-25 13:01:54.208068: step 28400, loss = 0.94 (1217.0 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:01:54.960869: step 28410, loss = 0.90 (1700.3 examples/sec; 0.075 sec/batch)\n",
      "2017-05-25 13:01:55.782785: step 28420, loss = 0.73 (1557.3 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:01:56.579557: step 28430, loss = 0.69 (1606.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:01:57.375145: step 28440, loss = 0.90 (1608.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:01:58.184523: step 28450, loss = 0.97 (1581.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:01:58.983077: step 28460, loss = 0.68 (1602.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:01:59.870221: step 28470, loss = 0.68 (1442.8 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:02:00.767148: step 28480, loss = 0.82 (1427.1 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 13:02:01.642135: step 28490, loss = 0.75 (1462.9 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7993\n",
      "2017-05-25 13:02:02.683665: step 28500, loss = 0.78 (1229.0 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 13:02:03.434029: step 28510, loss = 0.74 (1705.8 examples/sec; 0.075 sec/batch)\n",
      "2017-05-25 13:02:04.241499: step 28520, loss = 0.99 (1585.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:02:05.045889: step 28530, loss = 0.71 (1591.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:02:05.847121: step 28540, loss = 0.77 (1597.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:02:09.270187: step 28580, loss = 0.87 (1456.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:02:10.147221: step 28590, loss = 0.83 (1459.5 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7044\n",
      "2017-05-25 13:02:11.229227: step 28600, loss = 0.97 (1183.0 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 13:02:12.305726: step 28610, loss = 0.82 (1189.0 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 13:02:13.525530: step 28620, loss = 0.78 (1049.3 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 13:02:14.732320: step 28630, loss = 0.75 (1060.7 examples/sec; 0.121 sec/batch)\n",
      "2017-05-25 13:02:15.845952: step 28640, loss = 1.02 (1149.4 examples/sec; 0.111 sec/batch)\n",
      "2017-05-25 13:02:16.886760: step 28650, loss = 0.71 (1229.8 examples/sec; 0.104 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 13:02:17.950931: step 28660, loss = 0.73 (1202.8 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 13:02:19.010177: step 28670, loss = 0.69 (1208.4 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 13:02:19.914802: step 28680, loss = 0.98 (1414.9 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 13:02:20.798145: step 28690, loss = 0.75 (1449.0 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.42847\n",
      "2017-05-25 13:02:21.833023: step 28700, loss = 0.69 (1236.9 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 13:02:22.618177: step 28710, loss = 0.95 (1630.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:02:23.484192: step 28720, loss = 0.99 (1478.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:02:24.294256: step 28730, loss = 0.84 (1580.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:02:25.091620: step 28740, loss = 0.83 (1605.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:02:25.905416: step 28750, loss = 0.94 (1572.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:02:26.714969: step 28760, loss = 0.82 (1581.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:02:27.547861: step 28770, loss = 0.68 (1536.8 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 13:02:28.432803: step 28780, loss = 0.84 (1446.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:02:29.330977: step 28790, loss = 0.79 (1425.1 examples/sec; 0.090 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7093\n",
      "2017-05-25 13:02:30.372908: step 28800, loss = 0.85 (1228.5 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 13:02:31.152112: step 28810, loss = 0.82 (1642.7 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 13:02:31.959720: step 28820, loss = 0.81 (1584.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:02:32.770574: step 28830, loss = 0.97 (1578.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:02:33.572053: step 28840, loss = 0.74 (1597.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:02:34.378110: step 28850, loss = 0.83 (1588.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:02:35.202586: step 28860, loss = 0.84 (1552.5 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:02:36.061259: step 28870, loss = 0.71 (1490.7 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:02:36.952429: step 28880, loss = 0.75 (1436.3 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:02:37.835913: step 28890, loss = 0.72 (1448.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:02:41.256703: step 28930, loss = 0.67 (1575.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:02:42.045565: step 28940, loss = 0.69 (1622.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:02:42.864515: step 28950, loss = 0.88 (1563.0 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:02:43.709179: step 28960, loss = 0.80 (1515.4 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:02:44.597378: step 28970, loss = 0.74 (1441.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:02:45.473224: step 28980, loss = 0.91 (1461.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:02:46.370793: step 28990, loss = 0.75 (1426.1 examples/sec; 0.090 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6484\n",
      "2017-05-25 13:02:47.457705: step 29000, loss = 0.94 (1177.6 examples/sec; 0.109 sec/batch)\n",
      "2017-05-25 13:02:48.086160: step 29010, loss = 0.84 (2036.7 examples/sec; 0.063 sec/batch)\n",
      "2017-05-25 13:02:48.920792: step 29020, loss = 0.71 (1533.6 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 13:02:49.738589: step 29030, loss = 0.67 (1565.2 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:02:50.554592: step 29040, loss = 0.82 (1568.6 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:02:51.391943: step 29050, loss = 0.90 (1528.6 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:02:52.275308: step 29060, loss = 0.92 (1449.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:02:53.148012: step 29070, loss = 0.74 (1466.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:02:54.026239: step 29080, loss = 0.89 (1457.5 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:02:54.914428: step 29090, loss = 0.96 (1441.1 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8856\n",
      "2017-05-25 13:02:55.871058: step 29100, loss = 0.85 (1338.0 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 13:02:56.581682: step 29110, loss = 0.64 (1801.2 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 13:02:57.386206: step 29120, loss = 0.61 (1591.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:02:58.197373: step 29130, loss = 0.94 (1578.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:02:59.006396: step 29140, loss = 0.78 (1582.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:02:59.857047: step 29150, loss = 0.75 (1504.7 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 13:03:00.755649: step 29160, loss = 0.72 (1424.4 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 13:03:01.624813: step 29170, loss = 0.98 (1472.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:03:02.512998: step 29180, loss = 0.75 (1441.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:03:03.376615: step 29190, loss = 0.85 (1482.1 examples/sec; 0.086 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8141\n",
      "2017-05-25 13:03:04.337541: step 29200, loss = 0.97 (1332.0 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 13:03:05.029660: step 29210, loss = 0.80 (1849.4 examples/sec; 0.069 sec/batch)\n",
      "2017-05-25 13:03:05.839373: step 29220, loss = 0.81 (1580.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:03:06.653441: step 29230, loss = 0.82 (1572.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:03:07.492503: step 29240, loss = 0.90 (1525.5 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:03:08.377628: step 29250, loss = 0.85 (1446.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:03:09.261031: step 29260, loss = 0.76 (1448.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:03:10.156477: step 29270, loss = 0.78 (1429.5 examples/sec; 0.090 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.788\n",
      "2017-05-25 13:03:12.819450: step 29300, loss = 0.65 (1335.2 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 13:03:13.529666: step 29310, loss = 0.62 (1802.3 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 13:03:14.344736: step 29320, loss = 0.86 (1570.4 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:03:15.143550: step 29330, loss = 0.84 (1602.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:03:16.021354: step 29340, loss = 0.79 (1458.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:03:16.915179: step 29350, loss = 0.77 (1432.0 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:03:17.787418: step 29360, loss = 0.88 (1467.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:03:18.670221: step 29370, loss = 0.81 (1449.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:03:19.525847: step 29380, loss = 0.76 (1496.0 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:03:20.348773: step 29390, loss = 0.70 (1555.4 examples/sec; 0.082 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7939\n",
      "2017-05-25 13:03:21.298037: step 29400, loss = 0.96 (1348.4 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 13:03:22.005989: step 29410, loss = 0.98 (1808.0 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 13:03:22.818712: step 29420, loss = 0.83 (1575.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:03:23.674428: step 29430, loss = 0.67 (1495.8 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:03:24.552101: step 29440, loss = 0.89 (1458.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:03:25.430747: step 29450, loss = 0.88 (1456.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:03:26.306830: step 29460, loss = 0.81 (1461.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:03:27.190369: step 29470, loss = 0.92 (1448.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:03:28.431163: step 29480, loss = 0.76 (1031.6 examples/sec; 0.124 sec/batch)\n",
      "2017-05-25 13:03:29.626417: step 29490, loss = 0.85 (1070.9 examples/sec; 0.120 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.1781\n",
      "2017-05-25 13:03:31.127384: step 29500, loss = 0.74 (852.8 examples/sec; 0.150 sec/batch)\n",
      "2017-05-25 13:03:32.054825: step 29510, loss = 0.89 (1380.1 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 13:03:33.113569: step 29520, loss = 0.66 (1209.0 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 13:03:34.172782: step 29530, loss = 0.82 (1208.4 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 13:03:35.230803: step 29540, loss = 0.81 (1209.8 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 13:03:36.109889: step 29550, loss = 0.81 (1456.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:03:36.985416: step 29560, loss = 0.83 (1462.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:03:37.862395: step 29570, loss = 0.87 (1459.6 examples/sec; 0.088 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 13:03:38.750671: step 29580, loss = 0.81 (1441.0 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:03:39.593010: step 29590, loss = 0.97 (1519.6 examples/sec; 0.084 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.6031\n",
      "2017-05-25 13:03:40.554316: step 29600, loss = 0.86 (1331.5 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 13:03:41.269101: step 29610, loss = 0.69 (1790.8 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 13:03:42.075356: step 29620, loss = 0.67 (1587.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:03:44.612298: step 29650, loss = 0.72 (1452.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:03:45.505180: step 29660, loss = 0.71 (1433.6 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:03:46.385407: step 29670, loss = 0.77 (1454.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:03:47.269312: step 29680, loss = 0.78 (1448.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:03:48.073851: step 29690, loss = 0.63 (1591.0 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7734\n",
      "2017-05-25 13:03:49.049279: step 29700, loss = 0.96 (1312.2 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 13:03:49.731926: step 29710, loss = 0.78 (1875.1 examples/sec; 0.068 sec/batch)\n",
      "2017-05-25 13:03:50.564604: step 29720, loss = 0.72 (1537.2 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 13:03:51.386245: step 29730, loss = 0.71 (1557.9 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:03:52.270717: step 29740, loss = 0.92 (1447.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:03:53.183113: step 29750, loss = 0.81 (1402.9 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 13:03:54.091463: step 29760, loss = 0.82 (1409.1 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 13:03:54.971055: step 29770, loss = 0.76 (1455.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:03:55.795396: step 29780, loss = 0.77 (1552.8 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:03:56.607893: step 29790, loss = 0.81 (1575.4 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6856\n",
      "2017-05-25 13:03:57.605423: step 29800, loss = 0.85 (1283.2 examples/sec; 0.100 sec/batch)\n",
      "2017-05-25 13:03:58.253903: step 29810, loss = 1.02 (1973.9 examples/sec; 0.065 sec/batch)\n",
      "2017-05-25 13:03:59.049265: step 29820, loss = 0.90 (1609.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:03:59.913727: step 29830, loss = 0.88 (1480.7 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:04:00.812922: step 29840, loss = 0.83 (1423.5 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 13:04:01.704987: step 29850, loss = 0.91 (1434.9 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:04:02.706376: step 29860, loss = 0.85 (1278.2 examples/sec; 0.100 sec/batch)\n",
      "2017-05-25 13:04:03.560069: step 29870, loss = 0.73 (1499.4 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 13:04:04.364075: step 29880, loss = 0.76 (1592.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:04:05.167534: step 29890, loss = 0.83 (1593.1 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7766\n",
      "2017-05-25 13:04:06.097267: step 29900, loss = 0.95 (1376.7 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 13:04:06.821744: step 29910, loss = 0.89 (1766.8 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 13:04:07.662591: step 29920, loss = 0.80 (1522.3 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:04:08.542663: step 29930, loss = 0.72 (1454.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:04:09.420627: step 29940, loss = 0.78 (1457.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:04:10.309385: step 29950, loss = 0.75 (1440.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:04:11.198675: step 29960, loss = 0.72 (1439.4 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:04:12.002169: step 29970, loss = 0.86 (1593.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:04:12.809763: step 29980, loss = 0.72 (1585.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:04:13.605262: step 29990, loss = 0.76 (1609.1 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8242\n",
      "2017-05-25 13:04:17.057864: step 30030, loss = 0.86 (1433.6 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:04:17.953043: step 30040, loss = 0.84 (1429.9 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 13:04:18.827879: step 30050, loss = 0.77 (1463.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:04:19.668989: step 30060, loss = 1.10 (1521.8 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:04:20.491219: step 30070, loss = 0.84 (1556.7 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:04:21.291792: step 30080, loss = 0.80 (1598.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:04:22.092634: step 30090, loss = 0.77 (1598.3 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7834\n",
      "2017-05-25 13:04:23.041070: step 30100, loss = 0.75 (1349.6 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 13:04:23.799245: step 30110, loss = 0.75 (1688.3 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 13:04:24.680929: step 30120, loss = 0.93 (1451.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:04:25.567271: step 30130, loss = 0.71 (1444.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:04:26.445171: step 30140, loss = 0.75 (1458.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:04:27.322134: step 30150, loss = 0.69 (1459.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:04:28.123875: step 30160, loss = 0.74 (1596.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:04:28.925589: step 30170, loss = 0.86 (1596.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:04:29.731987: step 30180, loss = 0.80 (1587.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:04:30.571345: step 30190, loss = 0.83 (1525.0 examples/sec; 0.084 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6095\n",
      "2017-05-25 13:04:31.654182: step 30200, loss = 0.73 (1182.1 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 13:04:32.347536: step 30210, loss = 0.67 (1846.1 examples/sec; 0.069 sec/batch)\n",
      "2017-05-25 13:04:33.236268: step 30220, loss = 0.79 (1440.3 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:04:34.109593: step 30230, loss = 0.78 (1465.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:04:34.994704: step 30240, loss = 0.89 (1446.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:04:36.128439: step 30250, loss = 0.96 (1129.0 examples/sec; 0.113 sec/batch)\n",
      "2017-05-25 13:04:37.362959: step 30260, loss = 0.83 (1036.8 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 13:04:38.595324: step 30270, loss = 0.75 (1038.7 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 13:04:39.738071: step 30280, loss = 0.76 (1120.1 examples/sec; 0.114 sec/batch)\n",
      "2017-05-25 13:04:40.799278: step 30290, loss = 0.80 (1206.2 examples/sec; 0.106 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.62599\n",
      "2017-05-25 13:04:42.043686: step 30300, loss = 0.84 (1028.6 examples/sec; 0.124 sec/batch)\n",
      "2017-05-25 13:04:42.980381: step 30310, loss = 0.79 (1366.5 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 13:04:43.920940: step 30320, loss = 0.83 (1360.9 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 13:04:44.804230: step 30330, loss = 0.91 (1449.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:04:45.678334: step 30340, loss = 0.71 (1464.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:04:49.052828: step 30380, loss = 0.74 (1600.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:04:49.875917: step 30390, loss = 0.62 (1555.1 examples/sec; 0.082 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.3788\n",
      "2017-05-25 13:04:50.832228: step 30400, loss = 0.74 (1338.5 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 13:04:51.558596: step 30410, loss = 0.61 (1762.2 examples/sec; 0.073 sec/batch)\n",
      "2017-05-25 13:04:52.448681: step 30420, loss = 0.66 (1438.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:04:53.325010: step 30430, loss = 0.94 (1460.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:04:54.206722: step 30440, loss = 0.78 (1451.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:04:55.078357: step 30450, loss = 0.69 (1468.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:04:55.904034: step 30460, loss = 0.80 (1550.2 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 13:04:56.708659: step 30470, loss = 0.75 (1590.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:04:57.521885: step 30480, loss = 0.83 (1574.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:04:58.322136: step 30490, loss = 0.78 (1599.5 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8039\n",
      "2017-05-25 13:04:59.304721: step 30500, loss = 0.97 (1302.7 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 13:05:00.028543: step 30510, loss = 0.84 (1768.4 examples/sec; 0.072 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 13:05:01.125480: step 30520, loss = 0.69 (1166.9 examples/sec; 0.110 sec/batch)\n",
      "2017-05-25 13:05:02.275372: step 30530, loss = 0.90 (1113.1 examples/sec; 0.115 sec/batch)\n",
      "2017-05-25 13:05:03.149813: step 30540, loss = 0.85 (1463.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:05:03.962904: step 30550, loss = 0.81 (1574.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:05:04.770015: step 30560, loss = 0.88 (1585.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:05:05.578813: step 30570, loss = 0.77 (1582.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:05:06.388109: step 30580, loss = 0.86 (1581.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:05:07.198044: step 30590, loss = 0.78 (1580.4 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.1739\n",
      "2017-05-25 13:05:08.252494: step 30600, loss = 0.79 (1213.9 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:05:09.009413: step 30610, loss = 0.76 (1691.1 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 13:05:09.876650: step 30620, loss = 0.84 (1476.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:05:10.777881: step 30630, loss = 0.92 (1420.2 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 13:05:11.622026: step 30640, loss = 0.87 (1516.3 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:05:12.427660: step 30650, loss = 0.86 (1588.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:05:13.245244: step 30660, loss = 0.81 (1565.6 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:05:14.055257: step 30670, loss = 0.78 (1580.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:05:14.846551: step 30680, loss = 0.94 (1617.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:05:15.680873: step 30690, loss = 0.73 (1534.2 examples/sec; 0.083 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7939\n",
      "2017-05-25 13:05:16.731892: step 30700, loss = 0.81 (1217.9 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:05:17.483430: step 30710, loss = 0.71 (1703.2 examples/sec; 0.075 sec/batch)\n",
      "2017-05-25 13:05:18.365987: step 30720, loss = 0.89 (1450.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:05:20.895447: step 30750, loss = 0.80 (1528.5 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:05:21.687003: step 30760, loss = 0.90 (1617.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:05:22.484063: step 30770, loss = 0.73 (1605.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:05:23.277883: step 30780, loss = 0.72 (1612.5 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:05:24.152797: step 30790, loss = 0.84 (1463.0 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8241\n",
      "2017-05-25 13:05:25.188644: step 30800, loss = 0.80 (1235.7 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 13:05:25.971963: step 30810, loss = 0.73 (1634.1 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 13:05:26.840978: step 30820, loss = 0.83 (1472.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:05:27.901856: step 30830, loss = 0.72 (1206.5 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 13:05:29.097201: step 30840, loss = 0.86 (1070.8 examples/sec; 0.120 sec/batch)\n",
      "2017-05-25 13:05:30.334918: step 30850, loss = 0.80 (1034.2 examples/sec; 0.124 sec/batch)\n",
      "2017-05-25 13:05:31.520286: step 30860, loss = 1.08 (1079.8 examples/sec; 0.119 sec/batch)\n",
      "2017-05-25 13:05:32.548641: step 30870, loss = 0.77 (1244.7 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 13:05:33.592184: step 30880, loss = 0.81 (1226.6 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 13:05:34.623619: step 30890, loss = 0.90 (1241.0 examples/sec; 0.103 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.45325\n",
      "2017-05-25 13:05:35.767642: step 30900, loss = 0.84 (1118.9 examples/sec; 0.114 sec/batch)\n",
      "2017-05-25 13:05:36.552256: step 30910, loss = 0.91 (1631.4 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 13:05:37.432456: step 30920, loss = 0.75 (1454.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:05:38.317234: step 30930, loss = 0.64 (1446.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:05:39.198947: step 30940, loss = 0.78 (1451.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:05:40.005482: step 30950, loss = 0.94 (1587.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:05:40.803652: step 30960, loss = 0.76 (1603.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:05:41.610660: step 30970, loss = 0.89 (1586.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:05:42.404774: step 30980, loss = 0.74 (1611.9 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:05:43.196335: step 30990, loss = 0.83 (1617.1 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7531\n",
      "2017-05-25 13:05:44.277979: step 31000, loss = 0.67 (1183.4 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 13:05:44.966956: step 31010, loss = 0.66 (1857.8 examples/sec; 0.069 sec/batch)\n",
      "2017-05-25 13:05:45.865401: step 31020, loss = 0.89 (1424.7 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 13:05:46.741506: step 31030, loss = 0.96 (1461.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:05:47.599574: step 31040, loss = 0.81 (1491.7 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:05:48.394061: step 31050, loss = 0.72 (1611.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:05:49.189146: step 31060, loss = 0.87 (1609.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:05:49.977558: step 31070, loss = 0.94 (1623.5 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:05:52.659800: step 31100, loss = 0.94 (1238.9 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 13:05:53.438258: step 31110, loss = 0.76 (1644.3 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 13:05:54.306002: step 31120, loss = 0.88 (1475.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:05:55.182517: step 31130, loss = 0.75 (1460.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:05:55.990042: step 31140, loss = 0.67 (1585.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:05:56.794196: step 31150, loss = 0.74 (1591.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:05:57.588526: step 31160, loss = 0.72 (1611.4 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:05:58.383147: step 31170, loss = 0.91 (1610.8 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:05:59.191016: step 31180, loss = 0.82 (1584.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:06:00.049050: step 31190, loss = 0.76 (1491.8 examples/sec; 0.086 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8748\n",
      "2017-05-25 13:06:01.080259: step 31200, loss = 0.73 (1241.3 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 13:06:01.858969: step 31210, loss = 0.85 (1643.8 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 13:06:02.731654: step 31220, loss = 0.81 (1466.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:06:03.584341: step 31230, loss = 0.82 (1501.1 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 13:06:04.394009: step 31240, loss = 0.73 (1580.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:06:05.196703: step 31250, loss = 1.07 (1594.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:06:05.990928: step 31260, loss = 0.73 (1611.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:06:06.808485: step 31270, loss = 0.74 (1565.6 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:06:07.651776: step 31280, loss = 0.75 (1517.9 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:06:08.539360: step 31290, loss = 0.61 (1442.1 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7037\n",
      "2017-05-25 13:06:09.624885: step 31300, loss = 0.73 (1179.2 examples/sec; 0.109 sec/batch)\n",
      "2017-05-25 13:06:10.357128: step 31310, loss = 0.90 (1748.1 examples/sec; 0.073 sec/batch)\n",
      "2017-05-25 13:06:11.238280: step 31320, loss = 0.70 (1452.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:06:12.428199: step 31330, loss = 0.87 (1075.7 examples/sec; 0.119 sec/batch)\n",
      "2017-05-25 13:06:13.625226: step 31340, loss = 0.75 (1069.3 examples/sec; 0.120 sec/batch)\n",
      "2017-05-25 13:06:14.837807: step 31350, loss = 0.88 (1055.6 examples/sec; 0.121 sec/batch)\n",
      "2017-05-25 13:06:15.957282: step 31360, loss = 0.70 (1143.4 examples/sec; 0.112 sec/batch)\n",
      "2017-05-25 13:06:17.024469: step 31370, loss = 0.79 (1199.4 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 13:06:18.135927: step 31380, loss = 0.72 (1151.6 examples/sec; 0.111 sec/batch)\n",
      "2017-05-25 13:06:19.185541: step 31390, loss = 0.75 (1219.5 examples/sec; 0.105 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.40412\n",
      "2017-05-25 13:06:20.259579: step 31400, loss = 0.72 (1191.8 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 13:06:21.013684: step 31410, loss = 0.88 (1697.4 examples/sec; 0.075 sec/batch)\n",
      "2017-05-25 13:06:21.900244: step 31420, loss = 0.80 (1443.8 examples/sec; 0.089 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 13:06:25.220928: step 31460, loss = 0.83 (1610.6 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:06:26.021759: step 31470, loss = 0.80 (1598.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:06:26.845615: step 31480, loss = 0.95 (1553.7 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:06:27.685390: step 31490, loss = 0.75 (1524.3 examples/sec; 0.084 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8148\n",
      "2017-05-25 13:06:28.723787: step 31500, loss = 0.84 (1232.6 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 13:06:29.469488: step 31510, loss = 0.83 (1716.5 examples/sec; 0.075 sec/batch)\n",
      "2017-05-25 13:06:30.361070: step 31520, loss = 0.56 (1435.7 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:06:31.237621: step 31530, loss = 0.84 (1460.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:06:32.042557: step 31540, loss = 0.86 (1590.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:06:32.859786: step 31550, loss = 0.80 (1566.3 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:06:33.724630: step 31560, loss = 0.72 (1480.0 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:06:34.517191: step 31570, loss = 0.61 (1615.0 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:06:35.313998: step 31580, loss = 0.74 (1606.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:06:36.176459: step 31590, loss = 0.75 (1484.1 examples/sec; 0.086 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7569\n",
      "2017-05-25 13:06:37.227575: step 31600, loss = 0.87 (1217.7 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:06:37.983920: step 31610, loss = 0.84 (1692.4 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 13:06:38.891618: step 31620, loss = 0.86 (1410.2 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 13:06:39.755763: step 31630, loss = 0.88 (1481.2 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:06:40.569580: step 31640, loss = 0.91 (1572.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:06:41.362468: step 31650, loss = 0.97 (1614.4 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:06:42.157565: step 31660, loss = 0.81 (1609.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:06:42.952080: step 31670, loss = 0.96 (1611.0 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:06:43.798061: step 31680, loss = 0.83 (1513.0 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 13:06:44.673820: step 31690, loss = 0.73 (1461.6 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7686\n",
      "2017-05-25 13:06:45.725133: step 31700, loss = 0.88 (1217.5 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:06:46.484378: step 31710, loss = 0.88 (1685.9 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 13:06:47.365750: step 31720, loss = 0.76 (1452.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:06:48.156838: step 31730, loss = 0.88 (1618.0 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:06:48.957844: step 31740, loss = 0.85 (1598.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:06:49.753159: step 31750, loss = 0.86 (1609.4 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:06:50.565845: step 31760, loss = 0.80 (1575.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:06:51.356522: step 31770, loss = 0.72 (1618.9 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:06:52.229256: step 31780, loss = 0.76 (1466.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:06:53.106509: step 31790, loss = 0.69 (1459.1 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8634\n",
      "2017-05-25 13:06:54.154238: step 31800, loss = 0.71 (1221.7 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:06:56.635217: step 31830, loss = 0.68 (1403.1 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 13:06:57.436768: step 31840, loss = 0.84 (1596.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:06:58.245643: step 31850, loss = 0.71 (1582.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:06:59.040035: step 31860, loss = 0.81 (1611.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:06:59.887608: step 31870, loss = 0.65 (1510.2 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 13:07:00.788124: step 31880, loss = 0.77 (1421.4 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 13:07:01.669812: step 31890, loss = 1.00 (1451.8 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.6998\n",
      "2017-05-25 13:07:02.701731: step 31900, loss = 0.79 (1240.4 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 13:07:03.466301: step 31910, loss = 0.88 (1674.1 examples/sec; 0.076 sec/batch)\n",
      "2017-05-25 13:07:04.289407: step 31920, loss = 0.85 (1555.1 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:07:05.070840: step 31930, loss = 0.75 (1638.0 examples/sec; 0.078 sec/batch)\n",
      "2017-05-25 13:07:05.876476: step 31940, loss = 0.76 (1588.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:07:06.689155: step 31950, loss = 0.85 (1575.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:07:07.510455: step 31960, loss = 0.84 (1558.5 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:07:08.375332: step 31970, loss = 0.86 (1480.0 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:07:09.241795: step 31980, loss = 0.91 (1477.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:07:10.112180: step 31990, loss = 0.64 (1470.6 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8274\n",
      "2017-05-25 13:07:11.156205: step 32000, loss = 0.79 (1226.0 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 13:07:12.149729: step 32010, loss = 0.86 (1288.3 examples/sec; 0.099 sec/batch)\n",
      "2017-05-25 13:07:13.384042: step 32020, loss = 0.66 (1037.0 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 13:07:14.597339: step 32030, loss = 0.89 (1055.0 examples/sec; 0.121 sec/batch)\n",
      "2017-05-25 13:07:15.757830: step 32040, loss = 0.75 (1103.0 examples/sec; 0.116 sec/batch)\n",
      "2017-05-25 13:07:16.800108: step 32050, loss = 0.70 (1228.1 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 13:07:17.848050: step 32060, loss = 0.80 (1221.4 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:07:18.896656: step 32070, loss = 0.82 (1220.7 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:07:19.847668: step 32080, loss = 0.75 (1345.9 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 13:07:20.725870: step 32090, loss = 0.77 (1457.5 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.34481\n",
      "2017-05-25 13:07:21.857200: step 32100, loss = 0.64 (1131.4 examples/sec; 0.113 sec/batch)\n",
      "2017-05-25 13:07:22.535559: step 32110, loss = 0.84 (1886.9 examples/sec; 0.068 sec/batch)\n",
      "2017-05-25 13:07:23.434856: step 32120, loss = 0.79 (1423.3 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 13:07:24.232869: step 32130, loss = 0.88 (1604.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:07:25.047213: step 32140, loss = 0.89 (1571.8 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:07:25.869418: step 32150, loss = 0.81 (1556.8 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:07:29.219088: step 32190, loss = 0.75 (1453.6 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9096\n",
      "2017-05-25 13:07:30.255128: step 32200, loss = 0.73 (1235.5 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 13:07:31.050906: step 32210, loss = 0.83 (1608.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:07:31.874785: step 32220, loss = 0.76 (1553.6 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:07:32.673880: step 32230, loss = 0.79 (1601.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:07:33.474415: step 32240, loss = 0.81 (1598.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:07:34.264045: step 32250, loss = 0.78 (1621.0 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:07:35.063024: step 32260, loss = 0.95 (1602.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:07:35.923455: step 32270, loss = 0.80 (1487.6 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:07:36.807519: step 32280, loss = 0.89 (1447.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:07:37.690596: step 32290, loss = 0.75 (1449.5 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8408\n",
      "2017-05-25 13:07:38.701744: step 32300, loss = 0.97 (1265.9 examples/sec; 0.101 sec/batch)\n",
      "2017-05-25 13:07:39.490914: step 32310, loss = 0.72 (1622.0 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:07:40.304557: step 32320, loss = 0.86 (1573.2 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:07:41.097216: step 32330, loss = 0.76 (1614.8 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:07:41.917156: step 32340, loss = 0.86 (1561.1 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:07:42.709769: step 32350, loss = 0.68 (1614.9 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:07:43.526936: step 32360, loss = 0.85 (1566.4 examples/sec; 0.082 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 13:07:44.396539: step 32370, loss = 0.89 (1471.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:07:45.254324: step 32380, loss = 0.76 (1492.2 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:07:46.144461: step 32390, loss = 0.76 (1438.0 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7365\n",
      "2017-05-25 13:07:47.219987: step 32400, loss = 1.00 (1190.1 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 13:07:47.893143: step 32410, loss = 0.82 (1901.5 examples/sec; 0.067 sec/batch)\n",
      "2017-05-25 13:07:48.689985: step 32420, loss = 0.73 (1606.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:07:49.490656: step 32430, loss = 0.83 (1598.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:07:50.304672: step 32440, loss = 0.78 (1572.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:07:51.103392: step 32450, loss = 0.84 (1602.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:07:51.950091: step 32460, loss = 0.72 (1511.8 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 13:07:52.821742: step 32470, loss = 0.80 (1468.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:07:53.700054: step 32480, loss = 0.73 (1457.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:07:54.599781: step 32490, loss = 0.67 (1422.7 examples/sec; 0.090 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7639\n",
      "2017-05-25 13:07:55.720903: step 32500, loss = 0.79 (1141.7 examples/sec; 0.112 sec/batch)\n",
      "2017-05-25 13:07:56.774419: step 32510, loss = 0.82 (1215.0 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:07:57.994122: step 32520, loss = 0.79 (1049.4 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 13:08:01.332338: step 32550, loss = 0.82 (1244.8 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 13:08:02.368108: step 32560, loss = 0.81 (1235.8 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 13:08:03.414704: step 32570, loss = 0.69 (1223.0 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:08:04.296444: step 32580, loss = 0.78 (1451.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:08:05.164584: step 32590, loss = 0.78 (1474.4 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.52001\n",
      "2017-05-25 13:08:06.225046: step 32600, loss = 0.81 (1207.0 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 13:08:06.962610: step 32610, loss = 0.92 (1735.4 examples/sec; 0.074 sec/batch)\n",
      "2017-05-25 13:08:07.803610: step 32620, loss = 0.99 (1522.0 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:08:08.602573: step 32630, loss = 0.72 (1602.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:08:09.398586: step 32640, loss = 0.78 (1608.0 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:08:10.222783: step 32650, loss = 0.77 (1553.0 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:08:11.024382: step 32660, loss = 0.75 (1596.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:08:11.870246: step 32670, loss = 0.94 (1513.2 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 13:08:12.742041: step 32680, loss = 0.84 (1468.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:08:13.607410: step 32690, loss = 0.86 (1479.1 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9082\n",
      "2017-05-25 13:08:14.621893: step 32700, loss = 0.76 (1261.7 examples/sec; 0.101 sec/batch)\n",
      "2017-05-25 13:08:15.414262: step 32710, loss = 0.94 (1615.4 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:08:16.205204: step 32720, loss = 0.74 (1618.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:08:17.007434: step 32730, loss = 0.80 (1595.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:08:17.818037: step 32740, loss = 0.68 (1579.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:08:18.615795: step 32750, loss = 0.84 (1604.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:08:19.424218: step 32760, loss = 0.83 (1583.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:08:20.295259: step 32770, loss = 0.77 (1469.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:08:21.162239: step 32780, loss = 0.81 (1476.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:08:22.040913: step 32790, loss = 0.97 (1456.7 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7561\n",
      "2017-05-25 13:08:23.128480: step 32800, loss = 0.86 (1176.9 examples/sec; 0.109 sec/batch)\n",
      "2017-05-25 13:08:23.812851: step 32810, loss = 0.70 (1870.3 examples/sec; 0.068 sec/batch)\n",
      "2017-05-25 13:08:24.608540: step 32820, loss = 0.77 (1608.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:08:25.415450: step 32830, loss = 0.78 (1586.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:08:26.219852: step 32840, loss = 0.71 (1591.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:08:27.017998: step 32850, loss = 0.74 (1603.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:08:27.850344: step 32860, loss = 0.82 (1537.8 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 13:08:28.722623: step 32870, loss = 0.88 (1467.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:08:29.609167: step 32880, loss = 0.68 (1443.8 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:08:32.612243: step 32910, loss = 0.69 (1223.2 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:08:33.826198: step 32920, loss = 0.94 (1054.4 examples/sec; 0.121 sec/batch)\n",
      "2017-05-25 13:08:35.023914: step 32930, loss = 0.80 (1068.7 examples/sec; 0.120 sec/batch)\n",
      "2017-05-25 13:08:36.132326: step 32940, loss = 0.74 (1154.8 examples/sec; 0.111 sec/batch)\n",
      "2017-05-25 13:08:37.183090: step 32950, loss = 0.92 (1218.2 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:08:38.225176: step 32960, loss = 0.77 (1228.3 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 13:08:39.259147: step 32970, loss = 0.82 (1237.9 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 13:08:40.169125: step 32980, loss = 0.85 (1406.6 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 13:08:41.042120: step 32990, loss = 0.79 (1466.2 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.5121\n",
      "2017-05-25 13:08:42.078473: step 33000, loss = 0.80 (1235.1 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 13:08:42.849059: step 33010, loss = 0.71 (1661.1 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 13:08:43.704705: step 33020, loss = 0.97 (1495.9 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:08:44.500590: step 33030, loss = 0.75 (1608.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:08:45.303830: step 33040, loss = 0.74 (1593.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:08:46.111983: step 33050, loss = 0.91 (1583.9 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:08:46.942289: step 33060, loss = 0.75 (1541.6 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 13:08:47.769839: step 33070, loss = 0.98 (1546.7 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 13:08:48.650041: step 33080, loss = 0.74 (1454.2 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:08:49.522167: step 33090, loss = 0.84 (1467.7 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7673\n",
      "2017-05-25 13:08:50.577970: step 33100, loss = 0.82 (1212.3 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 13:08:51.345709: step 33110, loss = 0.82 (1667.2 examples/sec; 0.077 sec/batch)\n",
      "2017-05-25 13:08:52.149956: step 33120, loss = 0.86 (1591.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:08:52.960981: step 33130, loss = 0.88 (1578.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:08:53.759078: step 33140, loss = 0.68 (1603.8 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:08:54.561425: step 33150, loss = 0.77 (1595.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:08:55.359560: step 33160, loss = 0.78 (1603.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:08:56.222053: step 33170, loss = 0.76 (1484.1 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:08:57.097144: step 33180, loss = 0.66 (1462.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:08:57.962372: step 33190, loss = 0.82 (1479.4 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8308\n",
      "2017-05-25 13:08:59.031142: step 33200, loss = 0.66 (1197.6 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 13:08:59.741270: step 33210, loss = 0.85 (1802.5 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 13:09:00.554834: step 33220, loss = 0.86 (1573.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:09:01.360242: step 33230, loss = 0.77 (1589.3 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:09:02.275067: step 33240, loss = 0.80 (1399.2 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 13:09:04.879899: step 33270, loss = 0.79 (1456.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:09:05.764119: step 33280, loss = 0.77 (1447.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:09:06.645512: step 33290, loss = 0.82 (1452.2 examples/sec; 0.088 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 11.5263\n",
      "2017-05-25 13:09:07.704532: step 33300, loss = 1.00 (1208.7 examples/sec; 0.106 sec/batch)\n",
      "2017-05-25 13:09:08.358080: step 33310, loss = 0.85 (1958.5 examples/sec; 0.065 sec/batch)\n",
      "2017-05-25 13:09:09.153999: step 33320, loss = 0.65 (1608.2 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:09:09.944739: step 33330, loss = 0.84 (1618.7 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:09:10.764575: step 33340, loss = 0.71 (1561.3 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:09:11.578309: step 33350, loss = 0.73 (1573.0 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:09:12.452600: step 33360, loss = 0.73 (1464.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:09:13.326388: step 33370, loss = 0.72 (1464.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:09:14.205113: step 33380, loss = 0.72 (1456.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:09:15.082873: step 33390, loss = 0.86 (1458.3 examples/sec; 0.088 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9852\n",
      "2017-05-25 13:09:16.047956: step 33400, loss = 0.86 (1326.3 examples/sec; 0.097 sec/batch)\n",
      "2017-05-25 13:09:16.760097: step 33410, loss = 0.77 (1797.4 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 13:09:17.564373: step 33420, loss = 0.84 (1591.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:09:18.367145: step 33430, loss = 0.87 (1594.5 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:09:19.167175: step 33440, loss = 0.69 (1599.9 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:09:20.008620: step 33450, loss = 0.92 (1521.2 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:09:20.893588: step 33460, loss = 0.80 (1446.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:09:21.772207: step 33470, loss = 0.74 (1456.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:09:22.648909: step 33480, loss = 0.73 (1460.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:09:23.537951: step 33490, loss = 0.93 (1439.8 examples/sec; 0.089 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8718\n",
      "2017-05-25 13:09:24.471307: step 33500, loss = 0.88 (1371.4 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 13:09:25.188496: step 33510, loss = 0.96 (1784.8 examples/sec; 0.072 sec/batch)\n",
      "2017-05-25 13:09:25.980899: step 33520, loss = 0.88 (1615.3 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:09:26.782093: step 33530, loss = 0.68 (1597.6 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:09:27.594075: step 33540, loss = 0.73 (1576.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:09:28.493362: step 33550, loss = 0.79 (1423.3 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 13:09:29.362258: step 33560, loss = 0.90 (1473.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:09:30.250690: step 33570, loss = 0.73 (1440.7 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:09:31.115334: step 33580, loss = 0.84 (1480.4 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:09:31.938723: step 33590, loss = 0.81 (1554.5 examples/sec; 0.082 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8836\n",
      "2017-05-25 13:09:32.886700: step 33600, loss = 0.69 (1350.2 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 13:09:33.578186: step 33610, loss = 0.70 (1851.1 examples/sec; 0.069 sec/batch)\n",
      "2017-05-25 13:09:34.408597: step 33620, loss = 0.85 (1541.4 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 13:09:37.814978: step 33660, loss = 0.73 (1476.5 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:09:38.704718: step 33670, loss = 0.72 (1438.6 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:09:39.627271: step 33680, loss = 0.65 (1387.5 examples/sec; 0.092 sec/batch)\n",
      "2017-05-25 13:09:40.879388: step 33690, loss = 0.83 (1022.3 examples/sec; 0.125 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.5604\n",
      "2017-05-25 13:09:42.357770: step 33700, loss = 0.74 (865.8 examples/sec; 0.148 sec/batch)\n",
      "2017-05-25 13:09:43.408876: step 33710, loss = 0.79 (1217.8 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:09:44.455028: step 33720, loss = 0.80 (1223.5 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:09:45.507921: step 33730, loss = 0.87 (1215.7 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:09:46.559662: step 33740, loss = 0.75 (1217.0 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:09:47.605755: step 33750, loss = 0.81 (1223.6 examples/sec; 0.105 sec/batch)\n",
      "2017-05-25 13:09:48.554895: step 33760, loss = 0.78 (1348.6 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 13:09:49.418758: step 33770, loss = 0.85 (1481.7 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:09:50.307421: step 33780, loss = 0.81 (1440.4 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:09:51.178234: step 33790, loss = 0.81 (1469.9 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.1465\n",
      "2017-05-25 13:09:52.211535: step 33800, loss = 0.99 (1238.7 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 13:09:52.864352: step 33810, loss = 0.98 (1960.7 examples/sec; 0.065 sec/batch)\n",
      "2017-05-25 13:09:53.654775: step 33820, loss = 0.93 (1619.4 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:09:54.466686: step 33830, loss = 0.97 (1576.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:09:55.275591: step 33840, loss = 0.75 (1582.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:09:56.125716: step 33850, loss = 0.96 (1505.7 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 13:09:57.001909: step 33860, loss = 0.86 (1460.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:09:57.878161: step 33870, loss = 0.84 (1460.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:09:58.781883: step 33880, loss = 0.83 (1416.4 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 13:09:59.639982: step 33890, loss = 0.76 (1491.7 examples/sec; 0.086 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8167\n",
      "2017-05-25 13:10:00.674571: step 33900, loss = 0.83 (1237.2 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 13:10:01.383846: step 33910, loss = 0.84 (1804.7 examples/sec; 0.071 sec/batch)\n",
      "2017-05-25 13:10:02.190567: step 33920, loss = 0.85 (1586.7 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:10:02.982692: step 33930, loss = 0.66 (1615.9 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:10:03.817428: step 33940, loss = 0.76 (1533.4 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 13:10:04.720915: step 33950, loss = 0.81 (1416.7 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 13:10:05.581488: step 33960, loss = 0.88 (1487.4 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:10:06.450244: step 33970, loss = 0.75 (1473.4 examples/sec; 0.087 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.804\n",
      "2017-05-25 13:10:09.145980: step 34000, loss = 0.67 (1289.7 examples/sec; 0.099 sec/batch)\n",
      "2017-05-25 13:10:09.802839: step 34010, loss = 0.89 (1948.7 examples/sec; 0.066 sec/batch)\n",
      "2017-05-25 13:10:10.702687: step 34020, loss = 0.79 (1422.5 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 13:10:11.531279: step 34030, loss = 0.76 (1544.8 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 13:10:12.404978: step 34040, loss = 0.79 (1465.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:10:13.289229: step 34050, loss = 0.85 (1447.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:10:14.164730: step 34060, loss = 0.77 (1462.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:10:15.039737: step 34070, loss = 0.91 (1462.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:10:15.882362: step 34080, loss = 0.69 (1519.1 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:10:16.693856: step 34090, loss = 0.85 (1577.3 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7772\n",
      "2017-05-25 13:10:17.638399: step 34100, loss = 0.54 (1355.1 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 13:10:18.341446: step 34110, loss = 0.75 (1820.6 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 13:10:19.147798: step 34120, loss = 0.74 (1587.4 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:10:19.991447: step 34130, loss = 0.87 (1517.2 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:10:20.878568: step 34140, loss = 0.72 (1442.9 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:10:21.760917: step 34150, loss = 0.96 (1450.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:10:22.633801: step 34160, loss = 0.82 (1466.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:10:23.508696: step 34170, loss = 0.87 (1463.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:10:24.310041: step 34180, loss = 0.72 (1597.3 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:10:25.102926: step 34190, loss = 1.06 (1614.4 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 34193 into /home/ipython/cnn-cifar10/tb_log/test-softmax/train/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 11.7552\n",
      "2017-05-25 13:10:26.145405: step 34200, loss = 0.75 (1227.8 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 13:10:26.798158: step 34210, loss = 0.87 (1960.9 examples/sec; 0.065 sec/batch)\n",
      "2017-05-25 13:10:27.602330: step 34220, loss = 0.77 (1591.7 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:10:28.496061: step 34230, loss = 0.81 (1432.2 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:10:29.379339: step 34240, loss = 0.79 (1449.1 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:10:30.267263: step 34250, loss = 0.79 (1441.6 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:10:31.147833: step 34260, loss = 0.88 (1453.6 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:10:31.987212: step 34270, loss = 0.82 (1524.9 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:10:32.792216: step 34280, loss = 0.78 (1590.1 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:10:33.584240: step 34290, loss = 0.85 (1616.1 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9243\n",
      "2017-05-25 13:10:34.530222: step 34300, loss = 0.81 (1353.1 examples/sec; 0.095 sec/batch)\n",
      "2017-05-25 13:10:35.232946: step 34310, loss = 0.61 (1821.5 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 13:10:36.068749: step 34320, loss = 0.69 (1531.5 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:10:36.962974: step 34330, loss = 0.83 (1431.4 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:10:37.840673: step 34340, loss = 0.73 (1458.4 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:10:40.856711: step 34370, loss = 0.76 (1024.7 examples/sec; 0.125 sec/batch)\n",
      "2017-05-25 13:10:42.083917: step 34380, loss = 0.74 (1043.0 examples/sec; 0.123 sec/batch)\n",
      "2017-05-25 13:10:43.293869: step 34390, loss = 0.89 (1057.9 examples/sec; 0.121 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.96938\n",
      "2017-05-25 13:10:44.564591: step 34400, loss = 0.75 (1007.3 examples/sec; 0.127 sec/batch)\n",
      "2017-05-25 13:10:45.477885: step 34410, loss = 0.76 (1401.5 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 13:10:46.551317: step 34420, loss = 0.72 (1192.4 examples/sec; 0.107 sec/batch)\n",
      "2017-05-25 13:10:47.590699: step 34430, loss = 0.80 (1231.5 examples/sec; 0.104 sec/batch)\n",
      "2017-05-25 13:10:48.483339: step 34440, loss = 0.92 (1433.9 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:10:49.351886: step 34450, loss = 0.82 (1473.7 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:10:50.244441: step 34460, loss = 0.72 (1434.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:10:51.113214: step 34470, loss = 0.85 (1473.3 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:10:51.959099: step 34480, loss = 0.80 (1513.2 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 13:10:52.767212: step 34490, loss = 0.85 (1583.9 examples/sec; 0.081 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.9114\n",
      "2017-05-25 13:10:53.725384: step 34500, loss = 0.74 (1335.9 examples/sec; 0.096 sec/batch)\n",
      "2017-05-25 13:10:54.395758: step 34510, loss = 0.60 (1909.4 examples/sec; 0.067 sec/batch)\n",
      "2017-05-25 13:10:55.203088: step 34520, loss = 0.79 (1585.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:10:56.034917: step 34530, loss = 0.72 (1538.8 examples/sec; 0.083 sec/batch)\n",
      "2017-05-25 13:10:56.917199: step 34540, loss = 0.73 (1450.8 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:10:57.825684: step 34550, loss = 0.73 (1408.9 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 13:10:58.702973: step 34560, loss = 0.78 (1459.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:10:59.573058: step 34570, loss = 0.99 (1471.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:11:00.393414: step 34580, loss = 0.82 (1560.3 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:11:01.184690: step 34590, loss = 0.73 (1617.6 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.9146\n",
      "2017-05-25 13:11:02.119652: step 34600, loss = 0.71 (1369.0 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 13:11:02.821757: step 34610, loss = 0.75 (1823.1 examples/sec; 0.070 sec/batch)\n",
      "2017-05-25 13:11:03.638038: step 34620, loss = 0.63 (1568.1 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:11:04.512217: step 34630, loss = 0.86 (1464.2 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:11:05.402434: step 34640, loss = 0.85 (1437.9 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:11:06.278707: step 34650, loss = 0.70 (1460.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:11:07.141262: step 34660, loss = 0.72 (1484.0 examples/sec; 0.086 sec/batch)\n",
      "2017-05-25 13:11:07.994564: step 34670, loss = 0.96 (1500.1 examples/sec; 0.085 sec/batch)\n",
      "2017-05-25 13:11:08.804363: step 34680, loss = 0.91 (1580.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:11:09.599929: step 34690, loss = 0.76 (1608.9 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8396\n",
      "2017-05-25 13:11:12.997585: step 34730, loss = 0.72 (1457.9 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:11:13.871569: step 34740, loss = 0.74 (1464.6 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:11:14.752096: step 34750, loss = 0.91 (1453.7 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:11:15.619924: step 34760, loss = 0.92 (1474.9 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:11:16.423402: step 34770, loss = 0.88 (1593.1 examples/sec; 0.080 sec/batch)\n",
      "2017-05-25 13:11:17.246244: step 34780, loss = 0.70 (1555.6 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:11:18.038026: step 34790, loss = 0.69 (1616.6 examples/sec; 0.079 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.8946\n",
      "2017-05-25 13:11:18.971878: step 34800, loss = 0.80 (1370.7 examples/sec; 0.093 sec/batch)\n",
      "2017-05-25 13:11:19.713364: step 34810, loss = 0.77 (1726.3 examples/sec; 0.074 sec/batch)\n",
      "2017-05-25 13:11:20.601879: step 34820, loss = 0.78 (1440.6 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:11:21.473830: step 34830, loss = 0.83 (1468.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:11:22.354571: step 34840, loss = 0.98 (1453.3 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:11:23.226888: step 34850, loss = 0.70 (1467.4 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:11:24.065263: step 34860, loss = 0.78 (1526.8 examples/sec; 0.084 sec/batch)\n",
      "2017-05-25 13:11:24.855922: step 34870, loss = 0.84 (1618.9 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:11:25.649958: step 34880, loss = 1.03 (1612.0 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:11:26.445556: step 34890, loss = 0.83 (1608.9 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.7816\n",
      "2017-05-25 13:11:27.461235: step 34900, loss = 0.92 (1260.2 examples/sec; 0.102 sec/batch)\n",
      "2017-05-25 13:11:28.142697: step 34910, loss = 0.74 (1878.3 examples/sec; 0.068 sec/batch)\n",
      "2017-05-25 13:11:29.014302: step 34920, loss = 0.65 (1468.6 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:11:29.898286: step 34930, loss = 0.69 (1448.0 examples/sec; 0.088 sec/batch)\n",
      "2017-05-25 13:11:30.798381: step 34940, loss = 0.92 (1422.1 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 13:11:31.673303: step 34950, loss = 0.63 (1463.0 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:11:32.492223: step 34960, loss = 0.83 (1563.0 examples/sec; 0.082 sec/batch)\n",
      "2017-05-25 13:11:33.298965: step 34970, loss = 0.77 (1586.6 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:11:34.084175: step 34980, loss = 0.76 (1630.1 examples/sec; 0.079 sec/batch)\n",
      "2017-05-25 13:11:34.882823: step 34990, loss = 0.84 (1602.7 examples/sec; 0.080 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 11.896\n",
      "2017-05-25 13:11:35.866140: step 35000, loss = 0.96 (1301.7 examples/sec; 0.098 sec/batch)\n",
      "2017-05-25 13:11:36.615602: step 35010, loss = 0.90 (1707.9 examples/sec; 0.075 sec/batch)\n",
      "2017-05-25 13:11:37.508145: step 35020, loss = 0.71 (1434.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:11:38.402794: step 35030, loss = 0.88 (1430.7 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:11:39.275464: step 35040, loss = 0.74 (1466.8 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:11:40.449519: step 35050, loss = 0.74 (1090.2 examples/sec; 0.117 sec/batch)\n",
      "2017-05-25 13:11:41.646706: step 35060, loss = 0.88 (1069.2 examples/sec; 0.120 sec/batch)\n",
      "2017-05-25 13:11:45.104145: step 35090, loss = 0.81 (1200.9 examples/sec; 0.107 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 9.53118\n",
      "2017-05-25 13:11:46.358103: step 35100, loss = 0.83 (1020.8 examples/sec; 0.125 sec/batch)\n",
      "2017-05-25 13:11:47.261619: step 35110, loss = 0.97 (1416.7 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 13:11:48.202816: step 35120, loss = 0.78 (1360.0 examples/sec; 0.094 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 13:11:49.075862: step 35130, loss = 0.89 (1466.1 examples/sec; 0.087 sec/batch)\n",
      "2017-05-25 13:11:49.961470: step 35140, loss = 0.75 (1445.3 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:11:50.875892: step 35150, loss = 1.06 (1399.8 examples/sec; 0.091 sec/batch)\n",
      "2017-05-25 13:11:51.868658: step 35160, loss = 0.76 (1289.3 examples/sec; 0.099 sec/batch)\n",
      "2017-05-25 13:11:52.772968: step 35170, loss = 0.83 (1415.4 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 13:11:53.714752: step 35180, loss = 0.90 (1359.1 examples/sec; 0.094 sec/batch)\n",
      "2017-05-25 13:11:54.612524: step 35190, loss = 0.83 (1425.8 examples/sec; 0.090 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 10.7693\n",
      "2017-05-25 13:11:55.645431: step 35200, loss = 1.05 (1239.2 examples/sec; 0.103 sec/batch)\n",
      "2017-05-25 13:11:56.786048: step 35210, loss = 0.89 (1122.2 examples/sec; 0.114 sec/batch)\n",
      "2017-05-25 13:11:57.800871: step 35220, loss = 0.75 (1261.3 examples/sec; 0.101 sec/batch)\n",
      "2017-05-25 13:11:58.699506: step 35230, loss = 0.86 (1424.4 examples/sec; 0.090 sec/batch)\n",
      "2017-05-25 13:11:59.781182: step 35240, loss = 0.92 (1183.4 examples/sec; 0.108 sec/batch)\n",
      "2017-05-25 13:12:01.456759: step 35250, loss = 0.80 (763.9 examples/sec; 0.168 sec/batch)\n",
      "2017-05-25 13:12:02.775369: step 35260, loss = 0.93 (970.7 examples/sec; 0.132 sec/batch)\n",
      "2017-05-25 13:12:04.395566: step 35270, loss = 0.90 (790.0 examples/sec; 0.162 sec/batch)\n",
      "2017-05-25 13:12:05.754602: step 35280, loss = 0.81 (941.8 examples/sec; 0.136 sec/batch)\n",
      "2017-05-25 13:12:07.048371: step 35290, loss = 0.71 (989.4 examples/sec; 0.129 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 7.92217\n",
      "2017-05-25 13:12:08.266315: step 35300, loss = 0.79 (1050.9 examples/sec; 0.122 sec/batch)\n",
      "2017-05-25 13:12:09.076707: step 35310, loss = 0.81 (1579.5 examples/sec; 0.081 sec/batch)\n",
      "2017-05-25 13:12:09.969872: step 35320, loss = 0.91 (1433.1 examples/sec; 0.089 sec/batch)\n",
      "2017-05-25 13:12:10.977069: step 35330, loss = 0.72 (1270.9 examples/sec; 0.101 sec/batch)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e25e93c84be0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mArguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcifar10_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ipython/cnn-cifar10/cifar10/cifar10_train.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m             log_device_placement=Arguments.log_device_placement)) as mon_sess:\n\u001b[1;32m    100\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    482\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    818\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    821\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    928\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "Arguments.set_model_folder(\"test-softmax\")\n",
    "print(Arguments.train_dir)\n",
    "\n",
    "cifar10_train.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
