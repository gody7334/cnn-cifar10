{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# restart notebook when retrain model as some initial problem\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from cifar10 import cifar10_train\n",
    "from cifar10.cifar10_args import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "/home/ipython/cnn-cifar10/tb_log/res3/train\n",
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "INFO:tensorflow:Summary name conv1/weight_loss (raw) is illegal; using conv1/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res1-conv/weight_loss (raw) is illegal; using res1-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res1-res_conv/weight_loss (raw) is illegal; using res1-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res2-conv/weight_loss (raw) is illegal; using res2-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res2-res_conv/weight_loss (raw) is illegal; using res2-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res3-conv/weight_loss (raw) is illegal; using res3-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res3-res_conv/weight_loss (raw) is illegal; using res3-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res4-conv/weight_loss (raw) is illegal; using res4-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res4-res_conv/weight_loss (raw) is illegal; using res4-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res4-res_conv/res_conv_pad/weight_loss (raw) is illegal; using res4-res_conv/res_conv_pad/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res5-conv/weight_loss (raw) is illegal; using res5-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res5-res_conv/weight_loss (raw) is illegal; using res5-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res6-conv/weight_loss (raw) is illegal; using res6-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res6-res_conv/weight_loss (raw) is illegal; using res6-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res7-conv/weight_loss (raw) is illegal; using res7-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res7-res_conv/weight_loss (raw) is illegal; using res7-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res7-res_conv/res_conv_pad/weight_loss (raw) is illegal; using res7-res_conv/res_conv_pad/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res8-conv/weight_loss (raw) is illegal; using res8-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res8-res_conv/weight_loss (raw) is illegal; using res8-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res9-conv/weight_loss (raw) is illegal; using res9-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res9-res_conv/weight_loss (raw) is illegal; using res9-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res9-res_conv/res_conv_pad/weight_loss (raw) is illegal; using res9-res_conv/res_conv_pad/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res10-conv/weight_loss (raw) is illegal; using res10-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res10-res_conv/weight_loss (raw) is illegal; using res10-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res11-conv/weight_loss (raw) is illegal; using res11-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res11-res_conv/weight_loss (raw) is illegal; using res11-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res11-res_conv/res_conv_pad/weight_loss (raw) is illegal; using res11-res_conv/res_conv_pad/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res12-conv/weight_loss (raw) is illegal; using res12-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res12-res_conv/weight_loss (raw) is illegal; using res12-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res13-conv/weight_loss (raw) is illegal; using res13-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res13-res_conv/weight_loss (raw) is illegal; using res13-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local4/weight_loss (raw) is illegal; using local4/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name softmax_linear/weight_loss (raw) is illegal; using softmax_linear/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name cross_entropy (raw) is illegal; using cross_entropy__raw_ instead.\n",
      "INFO:tensorflow:Summary name total_loss (raw) is illegal; using total_loss__raw_ instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 00:38:48.234877: step 0, loss = 47.94 (69.7 examples/sec; 3.674 sec/batch)\n",
      "2017-05-29 00:38:57.768490: step 10, loss = 30.31 (268.5 examples/sec; 0.953 sec/batch)\n",
      "2017-05-29 00:39:07.555784: step 20, loss = 18.74 (261.6 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 00:39:17.249402: step 30, loss = 11.68 (264.1 examples/sec; 0.969 sec/batch)\n",
      "2017-05-29 00:39:27.202334: step 40, loss = 7.42 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 00:39:36.909563: step 50, loss = 5.01 (263.7 examples/sec; 0.971 sec/batch)\n",
      "2017-05-29 00:39:46.987237: step 60, loss = 3.61 (254.0 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 00:39:56.900795: step 70, loss = 2.96 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 00:40:07.315667: step 80, loss = 2.48 (245.8 examples/sec; 1.041 sec/batch)\n",
      "2017-05-29 00:40:17.697213: step 90, loss = 2.31 (246.6 examples/sec; 1.038 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.847441\n",
      "2017-05-29 00:40:44.650931: step 100, loss = 2.21 (95.0 examples/sec; 2.695 sec/batch)\n",
      "2017-05-29 00:40:57.680901: step 110, loss = 2.15 (196.5 examples/sec; 1.303 sec/batch)\n",
      "2017-05-29 00:41:10.387004: step 120, loss = 2.11 (201.5 examples/sec; 1.271 sec/batch)\n",
      "2017-05-29 00:41:22.196491: step 130, loss = 2.08 (216.8 examples/sec; 1.181 sec/batch)\n",
      "2017-05-29 00:41:32.698382: step 140, loss = 2.08 (243.8 examples/sec; 1.050 sec/batch)\n",
      "2017-05-29 00:41:43.274102: step 150, loss = 2.01 (242.1 examples/sec; 1.058 sec/batch)\n",
      "2017-05-29 00:41:54.793763: step 160, loss = 2.05 (222.2 examples/sec; 1.152 sec/batch)\n",
      "2017-05-29 00:42:06.475278: step 170, loss = 2.07 (219.1 examples/sec; 1.168 sec/batch)\n",
      "2017-05-29 00:42:18.578147: step 180, loss = 2.08 (211.5 examples/sec; 1.210 sec/batch)\n",
      "2017-05-29 00:42:29.864765: step 190, loss = 2.01 (226.8 examples/sec; 1.129 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.759462\n",
      "2017-05-29 00:42:56.323506: step 200, loss = 2.20 (96.8 examples/sec; 2.646 sec/batch)\n",
      "2017-05-29 00:43:06.540511: step 210, loss = 1.95 (250.6 examples/sec; 1.022 sec/batch)\n",
      "2017-05-29 00:43:17.423395: step 220, loss = 2.03 (235.2 examples/sec; 1.088 sec/batch)\n",
      "2017-05-29 00:43:28.702895: step 230, loss = 1.98 (227.0 examples/sec; 1.128 sec/batch)\n",
      "2017-05-29 00:43:39.619240: step 240, loss = 2.00 (234.5 examples/sec; 1.092 sec/batch)\n",
      "2017-05-29 00:43:51.654187: step 250, loss = 2.06 (212.7 examples/sec; 1.203 sec/batch)\n",
      "2017-05-29 00:44:02.795211: step 260, loss = 1.93 (229.8 examples/sec; 1.114 sec/batch)\n",
      "2017-05-29 00:44:13.521565: step 270, loss = 2.00 (238.7 examples/sec; 1.073 sec/batch)\n",
      "2017-05-29 00:44:24.565680: step 280, loss = 1.94 (231.8 examples/sec; 1.104 sec/batch)\n",
      "2017-05-29 00:44:34.863790: step 290, loss = 2.01 (248.6 examples/sec; 1.030 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.802173\n",
      "2017-05-29 00:45:00.980508: step 300, loss = 1.92 (98.0 examples/sec; 2.612 sec/batch)\n",
      "2017-05-29 00:45:10.676985: step 310, loss = 2.06 (264.0 examples/sec; 0.970 sec/batch)\n",
      "2017-05-29 00:45:20.919367: step 320, loss = 1.94 (249.9 examples/sec; 1.024 sec/batch)\n",
      "2017-05-29 00:45:31.656859: step 330, loss = 1.96 (238.4 examples/sec; 1.074 sec/batch)\n",
      "2017-05-29 00:45:41.856838: step 340, loss = 1.93 (251.0 examples/sec; 1.020 sec/batch)\n",
      "2017-05-29 00:45:52.679117: step 350, loss = 1.95 (236.5 examples/sec; 1.082 sec/batch)\n",
      "2017-05-29 00:46:02.994730: step 360, loss = 1.74 (248.2 examples/sec; 1.032 sec/batch)\n",
      "2017-05-29 00:46:14.208950: step 370, loss = 2.03 (228.3 examples/sec; 1.121 sec/batch)\n",
      "2017-05-29 00:46:24.167332: step 380, loss = 1.90 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 00:46:34.848412: step 390, loss = 1.91 (239.7 examples/sec; 1.068 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.841597\n",
      "2017-05-29 00:46:59.816138: step 400, loss = 1.81 (102.5 examples/sec; 2.497 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 00:47:09.851327: step 410, loss = 1.88 (255.1 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 00:47:20.121368: step 420, loss = 1.86 (249.3 examples/sec; 1.027 sec/batch)\n",
      "2017-05-29 00:47:31.121184: step 430, loss = 2.00 (232.7 examples/sec; 1.100 sec/batch)\n",
      "2017-05-29 00:47:42.441402: step 440, loss = 2.00 (226.1 examples/sec; 1.132 sec/batch)\n",
      "2017-05-29 00:47:54.031413: step 450, loss = 1.77 (220.9 examples/sec; 1.159 sec/batch)\n",
      "2017-05-29 00:48:05.380712: step 460, loss = 1.88 (225.6 examples/sec; 1.135 sec/batch)\n",
      "2017-05-29 00:48:15.562560: step 470, loss = 1.83 (251.4 examples/sec; 1.018 sec/batch)\n",
      "2017-05-29 00:48:26.582308: step 480, loss = 1.79 (232.3 examples/sec; 1.102 sec/batch)\n",
      "2017-05-29 00:48:37.268825: step 490, loss = 1.78 (239.6 examples/sec; 1.069 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 00:49:05.078229: step 500, loss = 1.69 (92.1 examples/sec; 2.781 sec/batch)\n",
      "2017-05-29 00:49:12.312279: step 510, loss = 1.90 (353.9 examples/sec; 0.723 sec/batch)\n",
      "  Num examples: 5120  Num correct: 1875  Precision @ 1 train: 0.3662\n",
      "2017-05-29 00:49:20.227274: step 520, loss = 1.87 (323.4 examples/sec; 0.791 sec/batch)\n",
      "2017-05-29 00:49:27.104723: step 530, loss = 1.82 (372.2 examples/sec; 0.688 sec/batch)\n",
      "2017-05-29 00:49:34.282779: step 540, loss = 1.90 (356.6 examples/sec; 0.718 sec/batch)\n",
      "  Num examples: 5120  Num correct: 1904  Precision @ 1 eval: 0.3719\n",
      "INFO:tensorflow:global_step/sec: 0.63547\n",
      "2017-05-29 00:49:43.534619: step 550, loss = 1.83 (276.7 examples/sec; 0.925 sec/batch)\n",
      "2017-05-29 00:49:54.708604: step 560, loss = 1.85 (229.1 examples/sec; 1.117 sec/batch)\n",
      "2017-05-29 00:50:07.065448: step 570, loss = 1.92 (207.2 examples/sec; 1.236 sec/batch)\n",
      "2017-05-29 00:50:17.925835: step 580, loss = 1.81 (235.7 examples/sec; 1.086 sec/batch)\n",
      "2017-05-29 00:50:28.695726: step 590, loss = 1.83 (237.7 examples/sec; 1.077 sec/batch)\n",
      "2017-05-29 00:50:39.777801: step 600, loss = 1.74 (231.0 examples/sec; 1.108 sec/batch)\n",
      "2017-05-29 00:50:51.341979: step 610, loss = 1.71 (221.4 examples/sec; 1.156 sec/batch)\n",
      "2017-05-29 00:51:02.440368: step 620, loss = 1.80 (230.7 examples/sec; 1.110 sec/batch)\n",
      "2017-05-29 00:51:13.683440: step 630, loss = 1.82 (227.7 examples/sec; 1.124 sec/batch)\n",
      "2017-05-29 00:51:25.431545: step 640, loss = 1.91 (217.9 examples/sec; 1.175 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.798412\n",
      "2017-05-29 00:51:47.872620: step 650, loss = 1.79 (114.1 examples/sec; 2.244 sec/batch)\n",
      "2017-05-29 00:51:58.681246: step 660, loss = 1.79 (236.8 examples/sec; 1.081 sec/batch)\n",
      "2017-05-29 00:52:09.546351: step 670, loss = 1.76 (235.6 examples/sec; 1.087 sec/batch)\n",
      "2017-05-29 00:52:20.064127: step 680, loss = 1.73 (243.4 examples/sec; 1.052 sec/batch)\n",
      "2017-05-29 00:52:30.195600: step 690, loss = 1.81 (252.7 examples/sec; 1.013 sec/batch)\n",
      "2017-05-29 00:52:40.117010: step 700, loss = 1.96 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 00:52:49.980901: step 710, loss = 1.86 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 00:52:59.810419: step 720, loss = 1.82 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 00:53:09.718846: step 730, loss = 1.76 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 00:53:20.005135: step 740, loss = 1.75 (248.9 examples/sec; 1.029 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.878835\n",
      "2017-05-29 00:53:41.560547: step 750, loss = 1.77 (118.8 examples/sec; 2.156 sec/batch)\n",
      "2017-05-29 00:53:51.602896: step 760, loss = 1.79 (254.9 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 00:54:01.424862: step 770, loss = 1.83 (260.6 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 00:54:11.372144: step 780, loss = 1.66 (257.4 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 00:54:21.251481: step 790, loss = 1.74 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 00:54:31.133321: step 800, loss = 1.71 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 00:54:41.007029: step 810, loss = 1.81 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 00:54:50.973143: step 820, loss = 1.68 (256.9 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 00:55:00.970217: step 830, loss = 1.69 (256.1 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 00:55:10.756628: step 840, loss = 1.74 (261.6 examples/sec; 0.979 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.903962\n",
      "2017-05-29 00:55:32.643176: step 850, loss = 1.84 (117.0 examples/sec; 2.189 sec/batch)\n",
      "2017-05-29 00:55:42.481386: step 860, loss = 1.83 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 00:55:52.331734: step 870, loss = 1.74 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 00:56:02.349896: step 880, loss = 1.54 (255.5 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 00:56:12.371597: step 890, loss = 1.60 (255.4 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 00:56:22.559701: step 900, loss = 1.79 (251.3 examples/sec; 1.019 sec/batch)\n",
      "2017-05-29 00:56:32.272016: step 910, loss = 1.75 (263.6 examples/sec; 0.971 sec/batch)\n",
      "2017-05-29 00:56:42.441502: step 920, loss = 1.70 (251.7 examples/sec; 1.017 sec/batch)\n",
      "2017-05-29 00:56:52.315341: step 930, loss = 1.74 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 00:57:02.151885: step 940, loss = 1.64 (260.3 examples/sec; 0.984 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.887894\n",
      "2017-05-29 00:57:24.901401: step 950, loss = 1.69 (112.5 examples/sec; 2.275 sec/batch)\n",
      "2017-05-29 00:57:34.663011: step 960, loss = 1.74 (262.3 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 00:57:44.517912: step 970, loss = 1.62 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 00:57:54.437808: step 980, loss = 1.72 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 00:58:04.337857: step 990, loss = 1.70 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 00:58:14.241759: step 1000, loss = 1.65 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 00:58:24.291794: step 1010, loss = 1.64 (254.7 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 00:58:34.578201: step 1020, loss = 1.65 (248.9 examples/sec; 1.029 sec/batch)\n",
      "2017-05-29 00:58:44.440323: step 1030, loss = 1.77 (259.6 examples/sec; 0.986 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 990 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 00:58:57.272868: step 1040, loss = 1.71 (199.5 examples/sec; 1.283 sec/batch)\n",
      "2017-05-29 00:59:17.238014: step 1050, loss = 1.71 (128.2 examples/sec; 1.997 sec/batch)\n",
      "2017-05-29 00:59:24.321012: step 1060, loss = 1.65 (361.4 examples/sec; 0.708 sec/batch)\n",
      "  Num examples: 5120  Num correct: 2459  Precision @ 1 train: 0.4803\n",
      "2017-05-29 00:59:31.222906: step 1070, loss = 1.58 (370.9 examples/sec; 0.690 sec/batch)\n",
      "2017-05-29 00:59:38.272667: step 1080, loss = 1.69 (363.1 examples/sec; 0.705 sec/batch)\n",
      "  Num examples: 5120  Num correct: 2396  Precision @ 1 eval: 0.4680\n",
      "INFO:tensorflow:global_step/sec: 0.690254\n",
      "2017-05-29 00:59:46.414508: step 1090, loss = 1.67 (314.4 examples/sec; 0.814 sec/batch)\n",
      "2017-05-29 00:59:56.425239: step 1100, loss = 1.74 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 01:00:06.369531: step 1110, loss = 1.69 (257.4 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 01:00:16.252077: step 1120, loss = 1.62 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 01:00:26.159452: step 1130, loss = 1.74 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 01:00:36.002335: step 1140, loss = 1.65 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 01:00:45.879957: step 1150, loss = 1.54 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 01:00:55.731645: step 1160, loss = 1.66 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 01:01:05.693795: step 1170, loss = 1.60 (257.0 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 01:01:15.504340: step 1180, loss = 1.58 (260.9 examples/sec; 0.981 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.898665\n",
      "2017-05-29 01:01:37.216201: step 1190, loss = 1.64 (117.9 examples/sec; 2.171 sec/batch)\n",
      "2017-05-29 01:01:46.889828: step 1200, loss = 1.65 (264.6 examples/sec; 0.967 sec/batch)\n",
      "2017-05-29 01:01:56.688176: step 1210, loss = 1.65 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 01:02:06.549680: step 1220, loss = 1.66 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 01:02:16.462089: step 1230, loss = 1.62 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 01:02:26.353555: step 1240, loss = 1.87 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 01:02:36.243333: step 1250, loss = 1.60 (258.9 examples/sec; 0.989 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 01:02:46.410554: step 1260, loss = 1.62 (251.8 examples/sec; 1.017 sec/batch)\n",
      "2017-05-29 01:02:56.330036: step 1270, loss = 1.57 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 01:03:06.148643: step 1280, loss = 1.72 (260.7 examples/sec; 0.982 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.898575\n",
      "2017-05-29 01:03:28.519604: step 1290, loss = 1.72 (114.4 examples/sec; 2.237 sec/batch)\n",
      "2017-05-29 01:03:38.075383: step 1300, loss = 1.64 (267.9 examples/sec; 0.956 sec/batch)\n",
      "2017-05-29 01:03:47.807185: step 1310, loss = 1.65 (263.1 examples/sec; 0.973 sec/batch)\n",
      "2017-05-29 01:03:57.827465: step 1320, loss = 1.54 (255.5 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 01:04:07.875529: step 1330, loss = 1.57 (254.8 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 01:04:17.744010: step 1340, loss = 1.71 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 01:04:27.643480: step 1350, loss = 1.61 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 01:04:37.907453: step 1360, loss = 1.66 (249.4 examples/sec; 1.026 sec/batch)\n",
      "2017-05-29 01:04:47.852341: step 1370, loss = 1.66 (257.4 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 01:04:57.738849: step 1380, loss = 1.69 (258.9 examples/sec; 0.989 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.898557\n",
      "2017-05-29 01:05:19.883953: step 1390, loss = 1.59 (115.6 examples/sec; 2.215 sec/batch)\n",
      "2017-05-29 01:05:29.344739: step 1400, loss = 1.56 (270.6 examples/sec; 0.946 sec/batch)\n",
      "2017-05-29 01:05:39.153705: step 1410, loss = 1.58 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 01:05:49.169366: step 1420, loss = 1.79 (255.6 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 01:05:59.088237: step 1430, loss = 1.61 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 01:06:09.119444: step 1440, loss = 1.67 (255.2 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 01:06:18.945794: step 1450, loss = 1.61 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 01:06:28.790816: step 1460, loss = 1.62 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 01:06:38.746456: step 1470, loss = 1.68 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 01:06:48.558558: step 1480, loss = 1.64 (260.9 examples/sec; 0.981 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.90578\n",
      "2017-05-29 01:07:10.232902: step 1490, loss = 1.57 (118.1 examples/sec; 2.167 sec/batch)\n",
      "2017-05-29 01:07:19.845334: step 1500, loss = 1.68 (266.3 examples/sec; 0.961 sec/batch)\n",
      "2017-05-29 01:07:29.752818: step 1510, loss = 1.68 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 01:07:40.004881: step 1520, loss = 1.60 (249.7 examples/sec; 1.025 sec/batch)\n",
      "2017-05-29 01:07:49.797944: step 1530, loss = 1.55 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 01:07:59.808244: step 1540, loss = 1.60 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 01:08:09.674606: step 1550, loss = 1.49 (259.5 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 01:08:19.686378: step 1560, loss = 1.66 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 01:08:29.465329: step 1570, loss = 1.63 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 01:08:39.310676: step 1580, loss = 1.53 (260.0 examples/sec; 0.985 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 01:09:01.702855: step 1590, loss = 1.57 (114.3 examples/sec; 2.239 sec/batch)\n",
      "2017-05-29 01:09:09.026145: step 1600, loss = 1.58 (349.6 examples/sec; 0.732 sec/batch)\n",
      "  Num examples: 5120  Num correct: 2750  Precision @ 1 train: 0.5371\n",
      "2017-05-29 01:09:15.770602: step 1610, loss = 1.53 (379.6 examples/sec; 0.674 sec/batch)\n",
      "2017-05-29 01:09:22.959907: step 1620, loss = 1.50 (356.1 examples/sec; 0.719 sec/batch)\n",
      "  Num examples: 5120  Num correct: 2687  Precision @ 1 eval: 0.5248\n",
      "2017-05-29 01:09:30.791181: step 1630, loss = 1.49 (326.9 examples/sec; 0.783 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.696349\n",
      "2017-05-29 01:09:40.024378: step 1640, loss = 1.52 (277.3 examples/sec; 0.923 sec/batch)\n",
      "2017-05-29 01:09:49.946005: step 1650, loss = 1.54 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 01:09:59.813844: step 1660, loss = 1.55 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 01:10:09.608257: step 1670, loss = 1.59 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 01:10:19.562203: step 1680, loss = 1.58 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 01:10:29.455470: step 1690, loss = 1.57 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 01:10:39.364112: step 1700, loss = 1.57 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 01:10:49.266205: step 1710, loss = 1.62 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 01:10:59.215450: step 1720, loss = 1.70 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 01:11:09.046698: step 1730, loss = 1.56 (260.4 examples/sec; 0.983 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.894326\n",
      "2017-05-29 01:11:31.287513: step 1740, loss = 1.66 (115.1 examples/sec; 2.224 sec/batch)\n",
      "2017-05-29 01:11:41.230982: step 1750, loss = 1.65 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 01:11:51.077944: step 1760, loss = 1.62 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 01:12:01.180333: step 1770, loss = 1.63 (253.4 examples/sec; 1.010 sec/batch)\n",
      "2017-05-29 01:12:11.181339: step 1780, loss = 1.46 (256.0 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 01:12:21.182087: step 1790, loss = 1.59 (256.0 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 01:12:31.506746: step 1800, loss = 1.48 (247.9 examples/sec; 1.032 sec/batch)\n",
      "2017-05-29 01:12:41.299013: step 1810, loss = 1.50 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 01:12:51.104255: step 1820, loss = 1.64 (261.1 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 01:13:01.135950: step 1830, loss = 1.55 (255.2 examples/sec; 1.003 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.908157\n",
      "2017-05-29 01:13:21.589745: step 1840, loss = 1.50 (125.2 examples/sec; 2.045 sec/batch)\n",
      "2017-05-29 01:13:31.419740: step 1850, loss = 1.70 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 01:13:41.393679: step 1860, loss = 1.52 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 01:13:51.219194: step 1870, loss = 1.61 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 01:14:01.207766: step 1880, loss = 1.57 (256.3 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 01:14:11.230684: step 1890, loss = 1.58 (255.4 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 01:14:21.040290: step 1900, loss = 1.63 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 01:14:30.971827: step 1910, loss = 1.47 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 01:14:40.884967: step 1920, loss = 1.67 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 01:14:50.825747: step 1930, loss = 1.46 (257.5 examples/sec; 0.994 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.896366\n",
      "2017-05-29 01:15:13.015572: step 1940, loss = 1.53 (115.4 examples/sec; 2.219 sec/batch)\n",
      "2017-05-29 01:15:22.883311: step 1950, loss = 1.52 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 01:15:32.654940: step 1960, loss = 1.66 (262.0 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 01:15:42.349847: step 1970, loss = 1.59 (264.1 examples/sec; 0.969 sec/batch)\n",
      "2017-05-29 01:15:52.488858: step 1980, loss = 1.48 (252.5 examples/sec; 1.014 sec/batch)\n",
      "2017-05-29 01:16:02.288458: step 1990, loss = 1.52 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 01:16:12.159157: step 2000, loss = 1.54 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 01:16:22.178815: step 2010, loss = 1.59 (255.5 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 01:16:32.055350: step 2020, loss = 1.62 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 01:16:42.039456: step 2030, loss = 1.57 (256.4 examples/sec; 0.998 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.897779\n",
      "2017-05-29 01:17:04.425929: step 2040, loss = 1.67 (114.4 examples/sec; 2.239 sec/batch)\n",
      "2017-05-29 01:17:14.449147: step 2050, loss = 1.50 (255.4 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 01:17:24.242289: step 2060, loss = 1.56 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 01:17:34.093729: step 2070, loss = 1.62 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 01:17:44.348227: step 2080, loss = 1.55 (249.6 examples/sec; 1.025 sec/batch)\n",
      "2017-05-29 01:17:54.329365: step 2090, loss = 1.56 (256.5 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 01:18:04.338473: step 2100, loss = 1.45 (255.8 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 01:18:14.260221: step 2110, loss = 1.43 (258.0 examples/sec; 0.992 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 01:18:24.108652: step 2120, loss = 1.43 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 01:18:33.921618: step 2130, loss = 1.45 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 01:18:53.674293: step 2140, loss = 1.62 (129.6 examples/sec; 1.975 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 01:19:01.677760: step 2150, loss = 1.49 (319.9 examples/sec; 0.800 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3096  Precision @ 1 train: 0.6047\n",
      "2017-05-29 01:19:09.246335: step 2160, loss = 1.49 (338.2 examples/sec; 0.757 sec/batch)\n",
      "2017-05-29 01:19:16.826148: step 2170, loss = 1.65 (337.7 examples/sec; 0.758 sec/batch)\n",
      "  Num examples: 5120  Num correct: 2972  Precision @ 1 eval: 0.5805\n",
      "INFO:tensorflow:global_step/sec: 0.69457\n",
      "2017-05-29 01:19:25.014094: step 2180, loss = 1.47 (312.7 examples/sec; 0.819 sec/batch)\n",
      "2017-05-29 01:19:34.787354: step 2190, loss = 1.56 (261.9 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 01:19:44.765167: step 2200, loss = 1.46 (256.6 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 01:19:54.706327: step 2210, loss = 1.46 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 01:20:04.533506: step 2220, loss = 1.64 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 01:20:14.773491: step 2230, loss = 1.50 (250.0 examples/sec; 1.024 sec/batch)\n",
      "2017-05-29 01:20:24.614018: step 2240, loss = 1.48 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 01:20:34.355329: step 2250, loss = 1.44 (262.8 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 01:20:44.279604: step 2260, loss = 1.58 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 01:20:53.986818: step 2270, loss = 1.50 (263.7 examples/sec; 0.971 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.909023\n",
      "2017-05-29 01:21:14.581788: step 2280, loss = 1.42 (124.3 examples/sec; 2.059 sec/batch)\n",
      "2017-05-29 01:21:24.281995: step 2290, loss = 1.68 (263.9 examples/sec; 0.970 sec/batch)\n",
      "2017-05-29 01:21:34.671184: step 2300, loss = 1.46 (246.4 examples/sec; 1.039 sec/batch)\n",
      "2017-05-29 01:21:44.562017: step 2310, loss = 1.44 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 01:21:54.416672: step 2320, loss = 1.50 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 01:22:04.258590: step 2330, loss = 1.57 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 01:22:14.175524: step 2340, loss = 1.51 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 01:22:24.019727: step 2350, loss = 1.47 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 01:22:34.155226: step 2360, loss = 1.54 (252.6 examples/sec; 1.014 sec/batch)\n",
      "2017-05-29 01:22:44.297653: step 2370, loss = 1.58 (252.4 examples/sec; 1.014 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.892014\n",
      "2017-05-29 01:23:06.676925: step 2380, loss = 1.48 (114.4 examples/sec; 2.238 sec/batch)\n",
      "2017-05-29 01:23:16.309713: step 2390, loss = 1.41 (265.8 examples/sec; 0.963 sec/batch)\n",
      "2017-05-29 01:23:26.297439: step 2400, loss = 1.67 (256.3 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 01:23:36.280069: step 2410, loss = 1.44 (256.4 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 01:23:46.175126: step 2420, loss = 1.43 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 01:23:55.959761: step 2430, loss = 1.46 (261.6 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 01:24:05.852687: step 2440, loss = 1.41 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 01:24:15.683492: step 2450, loss = 1.51 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 01:24:25.616389: step 2460, loss = 1.56 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 01:24:35.470956: step 2470, loss = 1.46 (259.8 examples/sec; 0.985 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.899423\n",
      "2017-05-29 01:24:57.810437: step 2480, loss = 1.50 (114.6 examples/sec; 2.234 sec/batch)\n",
      "2017-05-29 01:25:07.499105: step 2490, loss = 1.53 (264.2 examples/sec; 0.969 sec/batch)\n",
      "2017-05-29 01:25:17.485614: step 2500, loss = 1.43 (256.3 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 01:25:27.229401: step 2510, loss = 1.49 (262.7 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 01:25:37.098410: step 2520, loss = 1.57 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 01:25:46.983502: step 2530, loss = 1.53 (259.0 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 01:25:56.851070: step 2540, loss = 1.40 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 01:26:06.752205: step 2550, loss = 1.58 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 01:26:16.842133: step 2560, loss = 1.35 (253.7 examples/sec; 1.009 sec/batch)\n",
      "2017-05-29 01:26:27.097483: step 2570, loss = 1.49 (249.6 examples/sec; 1.026 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.907753\n",
      "2017-05-29 01:26:48.013129: step 2580, loss = 1.48 (122.4 examples/sec; 2.092 sec/batch)\n",
      "2017-05-29 01:26:57.797878: step 2590, loss = 1.58 (261.6 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 01:27:07.628700: step 2600, loss = 1.46 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 01:27:17.445412: step 2610, loss = 1.44 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 01:27:27.115391: step 2620, loss = 1.39 (264.7 examples/sec; 0.967 sec/batch)\n",
      "2017-05-29 01:27:37.086389: step 2630, loss = 1.43 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 01:27:46.913318: step 2640, loss = 1.45 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 01:27:57.157768: step 2650, loss = 1.47 (249.9 examples/sec; 1.024 sec/batch)\n",
      "2017-05-29 01:28:06.985143: step 2660, loss = 1.33 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 01:28:16.977932: step 2670, loss = 1.56 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 01:28:37.028585: step 2680, loss = 1.31 (127.7 examples/sec; 2.005 sec/batch)\n",
      "2017-05-29 01:28:44.173975: step 2690, loss = 1.47 (358.3 examples/sec; 0.715 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3212  Precision @ 1 train: 0.6273\n",
      "2017-05-29 01:28:50.992194: step 2700, loss = 1.42 (375.5 examples/sec; 0.682 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 2500 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 01:29:01.121735: step 2710, loss = 1.46 (252.7 examples/sec; 1.013 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3097  Precision @ 1 eval: 0.6049\n",
      "INFO:tensorflow:global_step/sec: 0.697673\n",
      "2017-05-29 01:29:07.822309: step 2720, loss = 1.43 (382.1 examples/sec; 0.670 sec/batch)\n",
      "2017-05-29 01:29:17.600413: step 2730, loss = 1.53 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 01:29:27.404252: step 2740, loss = 1.62 (261.1 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 01:29:37.291604: step 2750, loss = 1.44 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 01:29:47.294004: step 2760, loss = 1.48 (255.9 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 01:29:57.188285: step 2770, loss = 1.41 (258.7 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 01:30:07.086078: step 2780, loss = 1.42 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 01:30:16.927402: step 2790, loss = 1.56 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 01:30:26.770345: step 2800, loss = 1.52 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 01:30:36.554198: step 2810, loss = 1.50 (261.7 examples/sec; 0.978 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.90364\n",
      "2017-05-29 01:30:58.487658: step 2820, loss = 1.51 (116.7 examples/sec; 2.193 sec/batch)\n",
      "2017-05-29 01:31:07.918663: step 2830, loss = 1.51 (271.4 examples/sec; 0.943 sec/batch)\n",
      "2017-05-29 01:31:17.921881: step 2840, loss = 1.47 (255.9 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 01:31:28.153845: step 2850, loss = 1.48 (250.2 examples/sec; 1.023 sec/batch)\n",
      "2017-05-29 01:31:37.903644: step 2860, loss = 1.54 (262.6 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 01:31:48.042674: step 2870, loss = 1.54 (252.5 examples/sec; 1.014 sec/batch)\n",
      "2017-05-29 01:31:57.931566: step 2880, loss = 1.40 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 01:32:07.803502: step 2890, loss = 1.57 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 01:32:17.719801: step 2900, loss = 1.41 (258.2 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 01:32:27.523043: step 2910, loss = 1.48 (261.1 examples/sec; 0.980 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.911645\n",
      "2017-05-29 01:32:48.177502: step 2920, loss = 1.47 (123.9 examples/sec; 2.065 sec/batch)\n",
      "2017-05-29 01:32:57.514451: step 2930, loss = 1.38 (274.2 examples/sec; 0.934 sec/batch)\n",
      "2017-05-29 01:33:07.328858: step 2940, loss = 1.41 (260.8 examples/sec; 0.981 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 01:33:17.569016: step 2950, loss = 1.44 (250.0 examples/sec; 1.024 sec/batch)\n",
      "2017-05-29 01:33:27.534994: step 2960, loss = 1.42 (256.9 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 01:33:37.302845: step 2970, loss = 1.41 (262.1 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 01:33:47.262488: step 2980, loss = 1.58 (257.0 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 01:33:57.126663: step 2990, loss = 1.47 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 01:34:07.476922: step 3000, loss = 1.37 (247.3 examples/sec; 1.035 sec/batch)\n",
      "2017-05-29 01:34:17.357523: step 3010, loss = 1.60 (259.1 examples/sec; 0.988 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.910282\n",
      "2017-05-29 01:34:38.033549: step 3020, loss = 1.58 (123.8 examples/sec; 2.068 sec/batch)\n",
      "2017-05-29 01:34:47.349802: step 3030, loss = 1.40 (274.8 examples/sec; 0.932 sec/batch)\n",
      "2017-05-29 01:34:57.292355: step 3040, loss = 1.58 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 01:35:07.174761: step 3050, loss = 1.49 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 01:35:17.030338: step 3060, loss = 1.57 (259.8 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 01:35:27.163253: step 3070, loss = 1.45 (252.6 examples/sec; 1.013 sec/batch)\n",
      "2017-05-29 01:35:37.207593: step 3080, loss = 1.54 (254.9 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 01:35:47.095667: step 3090, loss = 1.56 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 01:35:56.978697: step 3100, loss = 1.48 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 01:36:07.110643: step 3110, loss = 1.46 (252.7 examples/sec; 1.013 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.902698\n",
      "2017-05-29 01:36:28.813669: step 3120, loss = 1.37 (118.0 examples/sec; 2.170 sec/batch)\n",
      "2017-05-29 01:36:38.248177: step 3130, loss = 1.42 (271.3 examples/sec; 0.943 sec/batch)\n",
      "2017-05-29 01:36:48.173611: step 3140, loss = 1.48 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 01:36:58.171335: step 3150, loss = 1.46 (256.1 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 01:37:08.094615: step 3160, loss = 1.45 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 01:37:17.914270: step 3170, loss = 1.40 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 01:37:27.799055: step 3180, loss = 1.42 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 01:37:37.702298: step 3190, loss = 1.38 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 01:37:47.591104: step 3200, loss = 1.40 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 01:37:57.558873: step 3210, loss = 1.44 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 01:38:18.187264: step 3220, loss = 1.40 (124.1 examples/sec; 2.063 sec/batch)\n",
      "2017-05-29 01:38:25.417254: step 3230, loss = 1.46 (354.1 examples/sec; 0.723 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3426  Precision @ 1 train: 0.6691\n",
      "2017-05-29 01:38:32.529538: step 3240, loss = 1.48 (359.9 examples/sec; 0.711 sec/batch)\n",
      "2017-05-29 01:38:39.286419: step 3250, loss = 1.51 (378.9 examples/sec; 0.676 sec/batch)\n",
      "2017-05-29 01:38:46.859567: step 3260, loss = 1.56 (338.0 examples/sec; 0.757 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3256  Precision @ 1 eval: 0.6359\n",
      "INFO:tensorflow:global_step/sec: 0.708677\n",
      "2017-05-29 01:38:55.820343: step 3270, loss = 1.49 (285.7 examples/sec; 0.896 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 3010 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 01:39:06.881644: step 3280, loss = 1.54 (231.4 examples/sec; 1.106 sec/batch)\n",
      "2017-05-29 01:39:16.896082: step 3290, loss = 1.54 (255.6 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 01:39:26.749344: step 3300, loss = 1.47 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 01:39:36.686567: step 3310, loss = 1.32 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 01:39:46.564755: step 3320, loss = 1.42 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 01:39:56.438635: step 3330, loss = 1.50 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 01:40:06.305642: step 3340, loss = 1.54 (259.5 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 01:40:16.460739: step 3350, loss = 1.48 (252.1 examples/sec; 1.016 sec/batch)\n",
      "2017-05-29 01:40:26.681230: step 3360, loss = 1.54 (250.5 examples/sec; 1.022 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.882846\n",
      "2017-05-29 01:40:48.611771: step 3370, loss = 1.58 (116.7 examples/sec; 2.193 sec/batch)\n",
      "2017-05-29 01:40:58.330105: step 3380, loss = 1.50 (263.4 examples/sec; 0.972 sec/batch)\n",
      "2017-05-29 01:41:08.353094: step 3390, loss = 1.49 (255.4 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 01:41:18.381407: step 3400, loss = 1.43 (255.3 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 01:41:28.284097: step 3410, loss = 1.40 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 01:41:38.254046: step 3420, loss = 1.43 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 01:41:48.182402: step 3430, loss = 1.35 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 01:41:58.097068: step 3440, loss = 1.25 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 01:42:08.282357: step 3450, loss = 1.54 (251.3 examples/sec; 1.019 sec/batch)\n",
      "2017-05-29 01:42:18.189618: step 3460, loss = 1.31 (258.4 examples/sec; 0.991 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.895371\n",
      "2017-05-29 01:42:40.258205: step 3470, loss = 1.39 (116.0 examples/sec; 2.207 sec/batch)\n",
      "2017-05-29 01:42:50.101546: step 3480, loss = 1.43 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 01:43:00.068702: step 3490, loss = 1.41 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 01:43:09.967575: step 3500, loss = 1.40 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 01:43:19.797894: step 3510, loss = 1.37 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 01:43:29.610563: step 3520, loss = 1.41 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 01:43:39.563138: step 3530, loss = 1.37 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 01:43:49.426601: step 3540, loss = 1.39 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 01:43:59.244655: step 3550, loss = 1.34 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 01:44:09.194538: step 3560, loss = 1.59 (257.3 examples/sec; 0.995 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.908689\n",
      "2017-05-29 01:44:30.257788: step 3570, loss = 1.26 (121.5 examples/sec; 2.106 sec/batch)\n",
      "2017-05-29 01:44:40.540193: step 3580, loss = 1.51 (249.0 examples/sec; 1.028 sec/batch)\n",
      "2017-05-29 01:44:50.586767: step 3590, loss = 1.34 (254.8 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 01:45:00.433673: step 3600, loss = 1.32 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 01:45:10.246603: step 3610, loss = 1.47 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 01:45:20.078036: step 3620, loss = 1.47 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 01:45:29.973842: step 3630, loss = 1.34 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 01:45:39.806193: step 3640, loss = 1.48 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 01:45:49.676248: step 3650, loss = 1.49 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 01:45:59.508047: step 3660, loss = 1.45 (260.4 examples/sec; 0.983 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.900218\n",
      "2017-05-29 01:46:21.732102: step 3670, loss = 1.44 (115.2 examples/sec; 2.222 sec/batch)\n",
      "2017-05-29 01:46:31.691100: step 3680, loss = 1.36 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 01:46:41.661787: step 3690, loss = 1.42 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 01:46:51.510045: step 3700, loss = 1.36 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 01:47:01.330341: step 3710, loss = 1.22 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 01:47:11.353533: step 3720, loss = 1.40 (255.4 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 01:47:21.103821: step 3730, loss = 1.54 (262.6 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 01:47:31.066921: step 3740, loss = 1.31 (256.9 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 01:47:41.662770: step 3750, loss = 1.45 (241.6 examples/sec; 1.060 sec/batch)\n",
      "2017-05-29 01:47:51.903905: step 3760, loss = 1.40 (250.0 examples/sec; 1.024 sec/batch)\n",
      "2017-05-29 01:48:11.966076: step 3770, loss = 1.46 (127.6 examples/sec; 2.006 sec/batch)\n",
      "2017-05-29 01:48:19.101612: step 3780, loss = 1.40 (358.8 examples/sec; 0.714 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3373  Precision @ 1 train: 0.6588\n",
      "2017-05-29 01:48:25.865800: step 3790, loss = 1.50 (378.5 examples/sec; 0.676 sec/batch)\n",
      "2017-05-29 01:48:33.102691: step 3800, loss = 1.34 (353.7 examples/sec; 0.724 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 5120  Num correct: 3308  Precision @ 1 eval: 0.6461\n",
      "INFO:tensorflow:global_step/sec: 0.697369\n",
      "2017-05-29 01:48:41.397614: step 3810, loss = 1.51 (308.6 examples/sec; 0.829 sec/batch)\n",
      "2017-05-29 01:48:51.362572: step 3820, loss = 1.39 (256.9 examples/sec; 0.996 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 3521 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 01:49:03.196282: step 3830, loss = 1.43 (216.3 examples/sec; 1.183 sec/batch)\n",
      "2017-05-29 01:49:12.835678: step 3840, loss = 1.41 (265.6 examples/sec; 0.964 sec/batch)\n",
      "2017-05-29 01:49:22.773203: step 3850, loss = 1.41 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 01:49:33.072382: step 3860, loss = 1.45 (248.6 examples/sec; 1.030 sec/batch)\n",
      "2017-05-29 01:49:42.892961: step 3870, loss = 1.39 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 01:49:52.766614: step 3880, loss = 1.38 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 01:50:02.723653: step 3890, loss = 1.38 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 01:50:12.612575: step 3900, loss = 1.52 (258.9 examples/sec; 0.989 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.875791\n",
      "2017-05-29 01:50:35.321768: step 3910, loss = 1.44 (112.7 examples/sec; 2.271 sec/batch)\n",
      "2017-05-29 01:50:44.824177: step 3920, loss = 1.42 (269.4 examples/sec; 0.950 sec/batch)\n",
      "2017-05-29 01:50:54.877154: step 3930, loss = 1.45 (254.7 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 01:51:04.735631: step 3940, loss = 1.32 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 01:51:14.744463: step 3950, loss = 1.40 (255.8 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 01:51:24.646258: step 3960, loss = 1.44 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 01:51:34.480045: step 3970, loss = 1.46 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 01:51:44.399035: step 3980, loss = 1.48 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 01:51:54.240585: step 3990, loss = 1.38 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 01:52:04.119096: step 4000, loss = 1.36 (259.1 examples/sec; 0.988 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.905402\n",
      "2017-05-29 01:52:25.692279: step 4010, loss = 1.27 (118.7 examples/sec; 2.157 sec/batch)\n",
      "2017-05-29 01:52:35.281713: step 4020, loss = 1.49 (267.0 examples/sec; 0.959 sec/batch)\n",
      "2017-05-29 01:52:45.222777: step 4030, loss = 1.32 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 01:52:55.153549: step 4040, loss = 1.48 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 01:53:05.037781: step 4050, loss = 1.39 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 01:53:15.308000: step 4060, loss = 1.46 (249.3 examples/sec; 1.027 sec/batch)\n",
      "2017-05-29 01:53:25.261842: step 4070, loss = 1.42 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 01:53:35.458230: step 4080, loss = 1.33 (251.1 examples/sec; 1.020 sec/batch)\n",
      "2017-05-29 01:53:45.344117: step 4090, loss = 1.42 (259.0 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 01:53:55.304617: step 4100, loss = 1.40 (257.0 examples/sec; 0.996 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.891153\n",
      "2017-05-29 01:54:17.928896: step 4110, loss = 1.37 (113.2 examples/sec; 2.262 sec/batch)\n",
      "2017-05-29 01:54:27.543085: step 4120, loss = 1.42 (266.3 examples/sec; 0.961 sec/batch)\n",
      "2017-05-29 01:54:37.224547: step 4130, loss = 1.33 (264.4 examples/sec; 0.968 sec/batch)\n",
      "2017-05-29 01:54:47.317385: step 4140, loss = 1.48 (253.6 examples/sec; 1.009 sec/batch)\n",
      "2017-05-29 01:54:57.159194: step 4150, loss = 1.40 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 01:55:06.998504: step 4160, loss = 1.50 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 01:55:16.801856: step 4170, loss = 1.57 (261.1 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 01:55:26.624826: step 4180, loss = 1.44 (260.6 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 01:55:36.530207: step 4190, loss = 1.32 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 01:55:46.336430: step 4200, loss = 1.45 (261.1 examples/sec; 0.981 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.916216\n",
      "2017-05-29 01:56:07.090083: step 4210, loss = 1.43 (123.4 examples/sec; 2.075 sec/batch)\n",
      "2017-05-29 01:56:16.649857: step 4220, loss = 1.38 (267.8 examples/sec; 0.956 sec/batch)\n",
      "2017-05-29 01:56:26.375430: step 4230, loss = 1.35 (263.2 examples/sec; 0.973 sec/batch)\n",
      "2017-05-29 01:56:36.288217: step 4240, loss = 1.46 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 01:56:46.170628: step 4250, loss = 1.41 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 01:56:56.023755: step 4260, loss = 1.27 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 01:57:05.976032: step 4270, loss = 1.31 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 01:57:15.709727: step 4280, loss = 1.46 (263.0 examples/sec; 0.973 sec/batch)\n",
      "2017-05-29 01:57:25.797589: step 4290, loss = 1.54 (253.8 examples/sec; 1.009 sec/batch)\n",
      "2017-05-29 01:57:35.661979: step 4300, loss = 1.30 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 01:57:56.474476: step 4310, loss = 1.37 (123.0 examples/sec; 2.081 sec/batch)\n",
      "2017-05-29 01:58:03.666279: step 4320, loss = 1.50 (356.0 examples/sec; 0.719 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3525  Precision @ 1 train: 0.6885\n",
      "2017-05-29 01:58:10.389119: step 4330, loss = 1.51 (380.8 examples/sec; 0.672 sec/batch)\n",
      "2017-05-29 01:58:17.780103: step 4340, loss = 1.37 (346.4 examples/sec; 0.739 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3425  Precision @ 1 eval: 0.6689\n",
      "2017-05-29 01:58:24.842423: step 4350, loss = 1.39 (362.5 examples/sec; 0.706 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.709203\n",
      "2017-05-29 01:58:34.601207: step 4360, loss = 1.37 (262.3 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 01:58:44.395586: step 4370, loss = 1.51 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 01:58:54.174125: step 4380, loss = 1.41 (261.8 examples/sec; 0.978 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 4035 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 01:59:05.478607: step 4390, loss = 1.37 (226.5 examples/sec; 1.130 sec/batch)\n",
      "2017-05-29 01:59:15.297294: step 4400, loss = 1.25 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 01:59:25.296661: step 4410, loss = 1.48 (256.0 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 01:59:35.135807: step 4420, loss = 1.50 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 01:59:44.945598: step 4430, loss = 1.43 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 01:59:54.949503: step 4440, loss = 1.31 (255.9 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 02:00:04.747645: step 4450, loss = 1.13 (261.3 examples/sec; 0.980 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.894142\n",
      "2017-05-29 02:00:25.644042: step 4460, loss = 1.41 (122.5 examples/sec; 2.090 sec/batch)\n",
      "2017-05-29 02:00:35.442482: step 4470, loss = 1.39 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 02:00:45.383196: step 4480, loss = 1.36 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 02:00:55.284029: step 4490, loss = 1.43 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 02:01:05.189470: step 4500, loss = 1.32 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 02:01:15.102253: step 4510, loss = 1.47 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 02:01:24.886951: step 4520, loss = 1.42 (261.6 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 02:01:34.940576: step 4530, loss = 1.30 (254.6 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 02:01:44.842108: step 4540, loss = 1.35 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 02:01:54.681880: step 4550, loss = 1.33 (260.2 examples/sec; 0.984 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.918811\n",
      "2017-05-29 02:02:14.317553: step 4560, loss = 1.31 (130.4 examples/sec; 1.964 sec/batch)\n",
      "2017-05-29 02:02:24.109047: step 4570, loss = 1.52 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 02:02:34.137520: step 4580, loss = 1.39 (255.3 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 02:02:44.140098: step 4590, loss = 1.41 (255.9 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 02:02:53.825927: step 4600, loss = 1.27 (264.3 examples/sec; 0.969 sec/batch)\n",
      "2017-05-29 02:03:03.919325: step 4610, loss = 1.41 (253.6 examples/sec; 1.009 sec/batch)\n",
      "2017-05-29 02:03:13.823234: step 4620, loss = 1.36 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 02:03:23.809648: step 4630, loss = 1.39 (256.3 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 02:03:33.718946: step 4640, loss = 1.31 (258.3 examples/sec; 0.991 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 02:03:43.597785: step 4650, loss = 1.42 (259.1 examples/sec; 0.988 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.89989\n",
      "2017-05-29 02:04:05.612944: step 4660, loss = 1.28 (116.3 examples/sec; 2.202 sec/batch)\n",
      "2017-05-29 02:04:15.524471: step 4670, loss = 1.28 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 02:04:25.790270: step 4680, loss = 1.48 (249.4 examples/sec; 1.027 sec/batch)\n",
      "2017-05-29 02:04:35.580233: step 4690, loss = 1.48 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 02:04:45.763562: step 4700, loss = 1.42 (251.4 examples/sec; 1.018 sec/batch)\n",
      "2017-05-29 02:04:55.746194: step 4710, loss = 1.31 (256.4 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 02:05:05.528435: step 4720, loss = 1.38 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 02:05:15.367849: step 4730, loss = 1.45 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 02:05:25.205526: step 4740, loss = 1.48 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 02:05:35.090602: step 4750, loss = 1.35 (259.0 examples/sec; 0.989 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.916629\n",
      "2017-05-29 02:05:54.621922: step 4760, loss = 1.43 (131.1 examples/sec; 1.953 sec/batch)\n",
      "2017-05-29 02:06:04.447128: step 4770, loss = 1.42 (260.6 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 02:06:14.260303: step 4780, loss = 1.33 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 02:06:23.961505: step 4790, loss = 1.56 (263.9 examples/sec; 0.970 sec/batch)\n",
      "2017-05-29 02:06:34.264289: step 4800, loss = 1.41 (248.5 examples/sec; 1.030 sec/batch)\n",
      "2017-05-29 02:06:44.210647: step 4810, loss = 1.42 (257.4 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 02:06:54.184067: step 4820, loss = 1.45 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 02:07:04.066883: step 4830, loss = 1.30 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 02:07:13.985526: step 4840, loss = 1.32 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 02:07:23.905267: step 4850, loss = 1.32 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 02:07:42.184271: step 4860, loss = 1.38 (140.1 examples/sec; 1.828 sec/batch)\n",
      "2017-05-29 02:07:49.323744: step 4870, loss = 1.15 (358.6 examples/sec; 0.714 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3629  Precision @ 1 train: 0.7088\n",
      "2017-05-29 02:07:56.957062: step 4880, loss = 1.34 (335.4 examples/sec; 0.763 sec/batch)\n",
      "2017-05-29 02:08:04.044042: step 4890, loss = 1.34 (361.2 examples/sec; 0.709 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3455  Precision @ 1 eval: 0.6748\n",
      "INFO:tensorflow:global_step/sec: 0.709258\n",
      "2017-05-29 02:08:12.155880: step 4900, loss = 1.49 (315.6 examples/sec; 0.811 sec/batch)\n",
      "2017-05-29 02:08:21.975295: step 4910, loss = 1.23 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 02:08:31.810316: step 4920, loss = 1.42 (260.3 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 02:08:41.653177: step 4930, loss = 1.31 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 02:08:51.469135: step 4940, loss = 1.43 (260.8 examples/sec; 0.982 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 4554 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 02:09:03.172812: step 4950, loss = 1.36 (218.7 examples/sec; 1.170 sec/batch)\n",
      "2017-05-29 02:09:12.531300: step 4960, loss = 1.30 (273.5 examples/sec; 0.936 sec/batch)\n",
      "2017-05-29 02:09:22.562875: step 4970, loss = 1.31 (255.2 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 02:09:32.416108: step 4980, loss = 1.41 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 02:09:42.139946: step 4990, loss = 1.37 (263.3 examples/sec; 0.972 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.901694\n",
      "2017-05-29 02:10:02.797256: step 5000, loss = 1.40 (123.9 examples/sec; 2.066 sec/batch)\n",
      "2017-05-29 02:10:12.574375: step 5010, loss = 1.31 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 02:10:22.368840: step 5020, loss = 1.41 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 02:10:32.138474: step 5030, loss = 1.23 (262.0 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 02:10:41.977242: step 5040, loss = 1.39 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 02:10:51.909708: step 5050, loss = 1.30 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 02:11:02.215902: step 5060, loss = 1.34 (248.4 examples/sec; 1.031 sec/batch)\n",
      "2017-05-29 02:11:12.167045: step 5070, loss = 1.30 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 02:11:22.004962: step 5080, loss = 1.36 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 02:11:31.848789: step 5090, loss = 1.40 (260.1 examples/sec; 0.984 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.899713\n",
      "2017-05-29 02:11:53.860752: step 5100, loss = 1.18 (116.3 examples/sec; 2.201 sec/batch)\n",
      "2017-05-29 02:12:03.506347: step 5110, loss = 1.42 (265.4 examples/sec; 0.965 sec/batch)\n",
      "2017-05-29 02:12:13.524844: step 5120, loss = 1.42 (255.5 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 02:12:23.336845: step 5130, loss = 1.33 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 02:12:33.189827: step 5140, loss = 1.18 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 02:12:43.093523: step 5150, loss = 1.29 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 02:12:52.873387: step 5160, loss = 1.26 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 02:13:02.679856: step 5170, loss = 1.30 (261.1 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 02:13:12.712423: step 5180, loss = 1.28 (255.2 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 02:13:22.624504: step 5190, loss = 1.37 (258.3 examples/sec; 0.991 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.907096\n",
      "2017-05-29 02:13:44.029724: step 5200, loss = 1.29 (119.6 examples/sec; 2.141 sec/batch)\n",
      "2017-05-29 02:13:53.831528: step 5210, loss = 1.37 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 02:14:03.760538: step 5220, loss = 1.41 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 02:14:13.671849: step 5230, loss = 1.33 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 02:14:23.462483: step 5240, loss = 1.38 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 02:14:33.341951: step 5250, loss = 1.37 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 02:14:43.197570: step 5260, loss = 1.36 (259.8 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 02:14:53.060256: step 5270, loss = 1.41 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 02:15:02.913273: step 5280, loss = 1.41 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 02:15:12.772049: step 5290, loss = 1.44 (259.7 examples/sec; 0.986 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.902787\n",
      "2017-05-29 02:15:34.841391: step 5300, loss = 1.46 (116.0 examples/sec; 2.207 sec/batch)\n",
      "2017-05-29 02:15:44.485604: step 5310, loss = 1.41 (265.4 examples/sec; 0.964 sec/batch)\n",
      "2017-05-29 02:15:54.228191: step 5320, loss = 1.42 (262.8 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 02:16:04.149150: step 5330, loss = 1.44 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 02:16:14.408384: step 5340, loss = 1.35 (249.5 examples/sec; 1.026 sec/batch)\n",
      "2017-05-29 02:16:24.354652: step 5350, loss = 1.27 (257.4 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 02:16:34.136163: step 5360, loss = 1.21 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 02:16:44.236805: step 5370, loss = 1.40 (253.4 examples/sec; 1.010 sec/batch)\n",
      "2017-05-29 02:16:54.089159: step 5380, loss = 1.36 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 02:17:04.021592: step 5390, loss = 1.35 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 02:17:24.797061: step 5400, loss = 1.37 (123.2 examples/sec; 2.078 sec/batch)\n",
      "2017-05-29 02:17:31.946309: step 5410, loss = 1.34 (358.1 examples/sec; 0.715 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3539  Precision @ 1 train: 0.6912\n",
      "2017-05-29 02:17:38.747627: step 5420, loss = 1.35 (376.4 examples/sec; 0.680 sec/batch)\n",
      "2017-05-29 02:17:45.787336: step 5430, loss = 1.41 (363.7 examples/sec; 0.704 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3489  Precision @ 1 eval: 0.6814\n",
      "INFO:tensorflow:global_step/sec: 0.702628\n",
      "2017-05-29 02:17:53.668657: step 5440, loss = 1.43 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-29 02:18:03.567029: step 5450, loss = 1.46 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 02:18:13.512563: step 5460, loss = 1.20 (257.4 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 02:18:23.405808: step 5470, loss = 1.28 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 02:18:33.228851: step 5480, loss = 1.30 (260.6 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 02:18:43.030159: step 5490, loss = 1.34 (261.2 examples/sec; 0.980 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 02:18:52.981763: step 5500, loss = 1.30 (257.2 examples/sec; 0.995 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 5069 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 02:19:05.551241: step 5510, loss = 1.23 (203.7 examples/sec; 1.257 sec/batch)\n",
      "2017-05-29 02:19:15.259650: step 5520, loss = 1.33 (263.7 examples/sec; 0.971 sec/batch)\n",
      "2017-05-29 02:19:25.331441: step 5530, loss = 1.31 (254.2 examples/sec; 1.007 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.877983\n",
      "2017-05-29 02:19:47.563700: step 5540, loss = 1.32 (115.1 examples/sec; 2.223 sec/batch)\n",
      "2017-05-29 02:19:56.927372: step 5550, loss = 1.29 (273.4 examples/sec; 0.936 sec/batch)\n",
      "2017-05-29 02:20:06.777705: step 5560, loss = 1.35 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 02:20:16.715150: step 5570, loss = 1.43 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 02:20:26.652007: step 5580, loss = 1.21 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 02:20:36.507591: step 5590, loss = 1.27 (259.8 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 02:20:46.524477: step 5600, loss = 1.26 (255.6 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 02:20:56.412924: step 5610, loss = 1.31 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 02:21:06.267358: step 5620, loss = 1.29 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 02:21:16.275844: step 5630, loss = 1.33 (255.8 examples/sec; 1.001 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.902474\n",
      "2017-05-29 02:21:38.370140: step 5640, loss = 1.27 (115.9 examples/sec; 2.209 sec/batch)\n",
      "2017-05-29 02:21:47.639856: step 5650, loss = 1.42 (276.2 examples/sec; 0.927 sec/batch)\n",
      "2017-05-29 02:21:57.511422: step 5660, loss = 1.36 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 02:22:07.436187: step 5670, loss = 1.27 (257.9 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 02:22:17.383595: step 5680, loss = 1.26 (257.4 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 02:22:27.258541: step 5690, loss = 1.25 (259.2 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 02:22:37.077787: step 5700, loss = 1.35 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 02:22:47.144012: step 5710, loss = 1.29 (254.3 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 02:22:57.021328: step 5720, loss = 1.43 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 02:23:07.056116: step 5730, loss = 1.24 (255.1 examples/sec; 1.003 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.903145\n",
      "2017-05-29 02:23:29.096502: step 5740, loss = 1.48 (116.2 examples/sec; 2.204 sec/batch)\n",
      "2017-05-29 02:23:38.421505: step 5750, loss = 1.37 (274.5 examples/sec; 0.933 sec/batch)\n",
      "2017-05-29 02:23:48.347740: step 5760, loss = 1.33 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 02:23:58.499592: step 5770, loss = 1.35 (252.2 examples/sec; 1.015 sec/batch)\n",
      "2017-05-29 02:24:08.462710: step 5780, loss = 1.33 (256.9 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 02:24:18.429018: step 5790, loss = 1.42 (256.9 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 02:24:28.336104: step 5800, loss = 1.34 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 02:24:38.327230: step 5810, loss = 1.42 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 02:24:48.247199: step 5820, loss = 1.24 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 02:24:58.191801: step 5830, loss = 1.23 (257.4 examples/sec; 0.994 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.892009\n",
      "2017-05-29 02:25:21.201274: step 5840, loss = 1.22 (111.3 examples/sec; 2.301 sec/batch)\n",
      "2017-05-29 02:25:30.662071: step 5850, loss = 1.34 (270.6 examples/sec; 0.946 sec/batch)\n",
      "2017-05-29 02:25:40.429317: step 5860, loss = 1.21 (262.1 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 02:25:50.197310: step 5870, loss = 1.31 (262.1 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 02:26:00.215827: step 5880, loss = 1.29 (255.5 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 02:26:09.970110: step 5890, loss = 1.33 (262.4 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 02:26:19.943713: step 5900, loss = 1.22 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 02:26:29.788618: step 5910, loss = 1.37 (260.0 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 02:26:39.583969: step 5920, loss = 1.39 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 02:26:49.449669: step 5930, loss = 1.43 (259.5 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 02:27:11.371084: step 5940, loss = 1.31 (116.8 examples/sec; 2.192 sec/batch)\n",
      "2017-05-29 02:27:18.077145: step 5950, loss = 1.30 (381.7 examples/sec; 0.671 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3726  Precision @ 1 train: 0.7277\n",
      "2017-05-29 02:27:25.720345: step 5960, loss = 1.28 (334.9 examples/sec; 0.764 sec/batch)\n",
      "2017-05-29 02:27:32.826092: step 5970, loss = 1.35 (360.3 examples/sec; 0.711 sec/batch)\n",
      "2017-05-29 02:27:39.862557: step 5980, loss = 1.36 (363.8 examples/sec; 0.704 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3533  Precision @ 1 eval: 0.6900\n",
      "INFO:tensorflow:global_step/sec: 0.706742\n",
      "2017-05-29 02:27:48.596949: step 5990, loss = 1.37 (293.1 examples/sec; 0.873 sec/batch)\n",
      "2017-05-29 02:27:58.455028: step 6000, loss = 1.14 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 02:28:08.287874: step 6010, loss = 1.28 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 02:28:18.175737: step 6020, loss = 1.18 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 02:28:28.013273: step 6030, loss = 1.20 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 02:28:37.812596: step 6040, loss = 1.22 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 02:28:47.534882: step 6050, loss = 1.32 (263.3 examples/sec; 0.972 sec/batch)\n",
      "2017-05-29 02:28:57.538381: step 6060, loss = 1.29 (255.9 examples/sec; 1.000 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 5581 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 02:29:08.259374: step 6070, loss = 1.26 (238.8 examples/sec; 1.072 sec/batch)\n",
      "2017-05-29 02:29:18.364257: step 6080, loss = 1.36 (253.3 examples/sec; 1.010 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.89586\n",
      "2017-05-29 02:29:39.789200: step 6090, loss = 1.16 (119.5 examples/sec; 2.142 sec/batch)\n",
      "2017-05-29 02:29:49.642749: step 6100, loss = 1.25 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 02:29:59.534656: step 6110, loss = 1.32 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 02:30:09.365690: step 6120, loss = 1.30 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 02:30:19.242524: step 6130, loss = 1.35 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 02:30:29.147056: step 6140, loss = 1.28 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 02:30:39.291527: step 6150, loss = 1.38 (252.4 examples/sec; 1.014 sec/batch)\n",
      "2017-05-29 02:30:49.319487: step 6160, loss = 1.32 (255.3 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 02:30:59.244542: step 6170, loss = 1.27 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 02:31:09.544444: step 6180, loss = 1.40 (248.5 examples/sec; 1.030 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.899948\n",
      "2017-05-29 02:31:30.820015: step 6190, loss = 1.52 (120.3 examples/sec; 2.128 sec/batch)\n",
      "2017-05-29 02:31:40.715435: step 6200, loss = 1.30 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 02:31:50.595806: step 6210, loss = 1.30 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 02:32:00.619780: step 6220, loss = 1.25 (255.4 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 02:32:10.470384: step 6230, loss = 1.28 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 02:32:20.422391: step 6240, loss = 1.31 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 02:32:30.313756: step 6250, loss = 1.50 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 02:32:40.225508: step 6260, loss = 1.46 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 02:32:50.285623: step 6270, loss = 1.31 (254.5 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 02:33:00.301832: step 6280, loss = 1.23 (255.6 examples/sec; 1.002 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.908065\n",
      "2017-05-29 02:33:20.937845: step 6290, loss = 1.28 (124.1 examples/sec; 2.064 sec/batch)\n",
      "2017-05-29 02:33:30.968226: step 6300, loss = 1.22 (255.2 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 02:33:40.802425: step 6310, loss = 1.23 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 02:33:50.645249: step 6320, loss = 1.28 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 02:34:00.909204: step 6330, loss = 1.35 (249.4 examples/sec; 1.026 sec/batch)\n",
      "2017-05-29 02:34:10.864926: step 6340, loss = 1.27 (257.1 examples/sec; 0.996 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 02:34:20.831450: step 6350, loss = 1.25 (256.9 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 02:34:30.889359: step 6360, loss = 1.36 (254.5 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 02:34:40.796534: step 6370, loss = 1.33 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 02:34:50.636677: step 6380, loss = 1.32 (260.2 examples/sec; 0.984 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.894224\n",
      "2017-05-29 02:35:12.812431: step 6390, loss = 1.31 (115.4 examples/sec; 2.218 sec/batch)\n",
      "2017-05-29 02:35:22.603800: step 6400, loss = 1.29 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 02:35:32.521512: step 6410, loss = 1.27 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 02:35:42.536014: step 6420, loss = 1.51 (255.6 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 02:35:52.354641: step 6430, loss = 1.24 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 02:36:02.564893: step 6440, loss = 1.38 (250.7 examples/sec; 1.021 sec/batch)\n",
      "2017-05-29 02:36:12.504770: step 6450, loss = 1.34 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 02:36:22.458578: step 6460, loss = 1.16 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 02:36:32.342635: step 6470, loss = 1.25 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 02:36:42.273609: step 6480, loss = 1.18 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 02:37:01.586169: step 6490, loss = 1.12 (132.6 examples/sec; 1.931 sec/batch)\n",
      "2017-05-29 02:37:08.700182: step 6500, loss = 1.35 (359.9 examples/sec; 0.711 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3764  Precision @ 1 train: 0.7352\n",
      "2017-05-29 02:37:16.110139: step 6510, loss = 1.38 (345.5 examples/sec; 0.741 sec/batch)\n",
      "2017-05-29 02:37:23.443993: step 6520, loss = 1.43 (349.1 examples/sec; 0.733 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3616  Precision @ 1 eval: 0.7063\n",
      "INFO:tensorflow:global_step/sec: 0.705937\n",
      "2017-05-29 02:37:31.013153: step 6530, loss = 1.30 (338.2 examples/sec; 0.757 sec/batch)\n",
      "2017-05-29 02:37:40.830132: step 6540, loss = 1.36 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 02:37:50.860299: step 6550, loss = 1.23 (255.2 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 02:38:00.620693: step 6560, loss = 1.24 (262.3 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 02:38:10.378534: step 6570, loss = 1.31 (262.4 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 02:38:20.367112: step 6580, loss = 1.19 (256.3 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 02:38:30.265722: step 6590, loss = 1.11 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 02:38:40.249482: step 6600, loss = 1.32 (256.4 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 02:38:50.246997: step 6610, loss = 1.28 (256.1 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 02:39:00.143602: step 6620, loss = 1.31 (258.7 examples/sec; 0.990 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 6095 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.903436\n",
      "2017-05-29 02:39:21.409553: step 6630, loss = 1.23 (120.4 examples/sec; 2.127 sec/batch)\n",
      "2017-05-29 02:39:30.924853: step 6640, loss = 1.22 (269.0 examples/sec; 0.952 sec/batch)\n",
      "2017-05-29 02:39:41.460892: step 6650, loss = 1.33 (243.0 examples/sec; 1.054 sec/batch)\n",
      "2017-05-29 02:39:53.238061: step 6660, loss = 1.26 (217.4 examples/sec; 1.178 sec/batch)\n",
      "2017-05-29 02:40:03.924316: step 6670, loss = 1.23 (239.6 examples/sec; 1.069 sec/batch)\n",
      "2017-05-29 02:40:13.765194: step 6680, loss = 1.17 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 02:40:23.637097: step 6690, loss = 1.27 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 02:40:33.499563: step 6700, loss = 1.33 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 02:40:43.271739: step 6710, loss = 1.28 (262.0 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 02:40:53.200849: step 6720, loss = 1.41 (257.8 examples/sec; 0.993 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.871451\n",
      "2017-05-29 02:41:16.179413: step 6730, loss = 1.24 (111.4 examples/sec; 2.298 sec/batch)\n",
      "2017-05-29 02:41:25.600975: step 6740, loss = 1.30 (271.7 examples/sec; 0.942 sec/batch)\n",
      "2017-05-29 02:41:35.381929: step 6750, loss = 1.32 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 02:41:45.235940: step 6760, loss = 1.34 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 02:41:55.053336: step 6770, loss = 1.25 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 02:42:04.850990: step 6780, loss = 1.18 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 02:42:14.778562: step 6790, loss = 1.31 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 02:42:24.577155: step 6800, loss = 1.27 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 02:42:34.960086: step 6810, loss = 1.34 (246.6 examples/sec; 1.038 sec/batch)\n",
      "2017-05-29 02:42:45.125393: step 6820, loss = 1.25 (251.8 examples/sec; 1.017 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.909009\n",
      "2017-05-29 02:43:06.119983: step 6830, loss = 1.28 (121.9 examples/sec; 2.099 sec/batch)\n",
      "2017-05-29 02:43:15.754007: step 6840, loss = 1.22 (265.7 examples/sec; 0.963 sec/batch)\n",
      "2017-05-29 02:43:25.611291: step 6850, loss = 1.26 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 02:43:35.467250: step 6860, loss = 1.28 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 02:43:45.332241: step 6870, loss = 1.14 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 02:43:55.144789: step 6880, loss = 1.26 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 02:44:04.943760: step 6890, loss = 1.34 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 02:44:14.710216: step 6900, loss = 1.55 (262.1 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 02:44:24.648767: step 6910, loss = 1.35 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 02:44:34.473456: step 6920, loss = 1.21 (260.6 examples/sec; 0.982 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.912225\n",
      "2017-05-29 02:44:55.939175: step 6930, loss = 1.21 (119.3 examples/sec; 2.147 sec/batch)\n",
      "2017-05-29 02:45:05.461862: step 6940, loss = 1.31 (268.8 examples/sec; 0.952 sec/batch)\n",
      "2017-05-29 02:45:15.302786: step 6950, loss = 1.18 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 02:45:25.191437: step 6960, loss = 1.29 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 02:45:35.041926: step 6970, loss = 1.35 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 02:45:44.985042: step 6980, loss = 1.27 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 02:45:54.986879: step 6990, loss = 1.37 (256.0 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 02:46:04.766769: step 7000, loss = 1.31 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 02:46:14.640253: step 7010, loss = 1.39 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 02:46:24.394530: step 7020, loss = 1.32 (262.4 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 02:46:43.955153: step 7030, loss = 1.30 (130.9 examples/sec; 1.956 sec/batch)\n",
      "2017-05-29 02:46:51.439615: step 7040, loss = 1.21 (342.0 examples/sec; 0.748 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3815  Precision @ 1 train: 0.7451\n",
      "2017-05-29 02:46:58.171187: step 7050, loss = 1.31 (380.3 examples/sec; 0.673 sec/batch)\n",
      "2017-05-29 02:47:05.252901: step 7060, loss = 1.17 (361.5 examples/sec; 0.708 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3721  Precision @ 1 eval: 0.7268\n",
      "2017-05-29 02:47:12.318516: step 7070, loss = 1.23 (362.3 examples/sec; 0.707 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.716283\n",
      "2017-05-29 02:47:21.992518: step 7080, loss = 1.23 (264.6 examples/sec; 0.967 sec/batch)\n",
      "2017-05-29 02:47:31.843441: step 7090, loss = 1.28 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 02:47:41.702973: step 7100, loss = 1.22 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 02:47:51.645227: step 7110, loss = 1.31 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 02:48:01.453206: step 7120, loss = 1.25 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 02:48:11.272278: step 7130, loss = 1.27 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 02:48:21.087715: step 7140, loss = 1.26 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 02:48:31.108082: step 7150, loss = 1.23 (255.5 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 02:48:40.943847: step 7160, loss = 1.26 (260.3 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 02:48:50.804733: step 7170, loss = 1.32 (259.6 examples/sec; 0.986 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 6600 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.868772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 02:49:16.049721: step 7180, loss = 1.28 (101.4 examples/sec; 2.524 sec/batch)\n",
      "2017-05-29 02:49:25.945376: step 7190, loss = 1.28 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 02:49:35.722314: step 7200, loss = 1.25 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 02:49:45.539433: step 7210, loss = 1.28 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 02:49:55.356715: step 7220, loss = 1.29 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 02:50:05.140371: step 7230, loss = 1.29 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 02:50:15.269766: step 7240, loss = 1.35 (252.7 examples/sec; 1.013 sec/batch)\n",
      "2017-05-29 02:50:25.175036: step 7250, loss = 1.28 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 02:50:35.136063: step 7260, loss = 1.31 (257.0 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 02:50:45.121003: step 7270, loss = 1.24 (256.4 examples/sec; 0.998 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.899612\n",
      "2017-05-29 02:51:07.302257: step 7280, loss = 1.27 (115.4 examples/sec; 2.218 sec/batch)\n",
      "2017-05-29 02:51:17.216880: step 7290, loss = 1.25 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 02:51:27.181840: step 7300, loss = 1.17 (256.9 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 02:51:37.300924: step 7310, loss = 1.26 (253.0 examples/sec; 1.012 sec/batch)\n",
      "2017-05-29 02:51:47.139038: step 7320, loss = 1.32 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 02:51:57.056749: step 7330, loss = 1.30 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 02:52:06.977480: step 7340, loss = 1.26 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 02:52:16.893987: step 7350, loss = 1.35 (258.2 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 02:52:27.073432: step 7360, loss = 1.30 (251.5 examples/sec; 1.018 sec/batch)\n",
      "2017-05-29 02:52:36.990035: step 7370, loss = 1.23 (258.2 examples/sec; 0.992 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.920507\n",
      "2017-05-29 02:52:55.996572: step 7380, loss = 1.27 (134.7 examples/sec; 1.901 sec/batch)\n",
      "2017-05-29 02:53:06.034975: step 7390, loss = 1.25 (255.0 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 02:53:15.974111: step 7400, loss = 1.22 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 02:53:25.786037: step 7410, loss = 1.17 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 02:53:35.664044: step 7420, loss = 1.20 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 02:53:45.551183: step 7430, loss = 1.24 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 02:53:55.879255: step 7440, loss = 1.28 (247.9 examples/sec; 1.033 sec/batch)\n",
      "2017-05-29 02:54:05.691075: step 7450, loss = 1.23 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 02:54:15.586885: step 7460, loss = 1.25 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 02:54:25.391025: step 7470, loss = 1.27 (261.1 examples/sec; 0.980 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.910729\n",
      "2017-05-29 02:54:45.792359: step 7480, loss = 1.44 (125.5 examples/sec; 2.040 sec/batch)\n",
      "2017-05-29 02:54:55.600905: step 7490, loss = 1.20 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 02:55:05.390461: step 7500, loss = 1.27 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 02:55:15.214544: step 7510, loss = 1.20 (260.6 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 02:55:24.957536: step 7520, loss = 1.37 (262.8 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 02:55:34.991391: step 7530, loss = 1.22 (255.1 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 02:55:44.914376: step 7540, loss = 1.30 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 02:55:54.707626: step 7550, loss = 1.30 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 02:56:04.538848: step 7560, loss = 1.23 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 02:56:14.420526: step 7570, loss = 1.21 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 02:56:33.576332: step 7580, loss = 1.14 (133.6 examples/sec; 1.916 sec/batch)\n",
      "2017-05-29 02:56:41.399991: step 7590, loss = 1.14 (327.2 examples/sec; 0.782 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3877  Precision @ 1 train: 0.7572\n",
      "2017-05-29 02:56:48.379078: step 7600, loss = 1.36 (366.8 examples/sec; 0.698 sec/batch)\n",
      "2017-05-29 02:56:55.421132: step 7610, loss = 1.13 (363.5 examples/sec; 0.704 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3711  Precision @ 1 eval: 0.7248\n",
      "INFO:tensorflow:global_step/sec: 0.708102\n",
      "2017-05-29 02:57:03.617867: step 7620, loss = 1.23 (312.3 examples/sec; 0.820 sec/batch)\n",
      "2017-05-29 02:57:13.444937: step 7630, loss = 1.11 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 02:57:23.304644: step 7640, loss = 1.23 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 02:57:33.139465: step 7650, loss = 1.37 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 02:57:43.060567: step 7660, loss = 1.26 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 02:57:53.050084: step 7670, loss = 1.24 (256.3 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 02:58:02.892859: step 7680, loss = 1.25 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 02:58:12.768273: step 7690, loss = 1.17 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 02:58:22.696311: step 7700, loss = 1.23 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 02:58:32.790242: step 7710, loss = 1.21 (253.6 examples/sec; 1.009 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.920523\n",
      "2017-05-29 02:58:51.726997: step 7720, loss = 1.33 (135.2 examples/sec; 1.894 sec/batch)\n",
      "2017-05-29 02:59:01.476091: step 7730, loss = 1.23 (262.6 examples/sec; 0.975 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 7117 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 02:59:15.255995: step 7740, loss = 1.33 (185.8 examples/sec; 1.378 sec/batch)\n",
      "2017-05-29 02:59:25.341309: step 7750, loss = 1.21 (253.8 examples/sec; 1.009 sec/batch)\n",
      "2017-05-29 02:59:35.201700: step 7760, loss = 1.26 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 02:59:45.036896: step 7770, loss = 1.37 (260.3 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 02:59:55.049458: step 7780, loss = 1.32 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 03:00:04.920727: step 7790, loss = 1.28 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 03:00:14.716547: step 7800, loss = 1.37 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 03:00:24.501436: step 7810, loss = 1.18 (261.6 examples/sec; 0.978 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.872572\n",
      "2017-05-29 03:00:46.414709: step 7820, loss = 1.29 (116.8 examples/sec; 2.191 sec/batch)\n",
      "2017-05-29 03:00:56.118783: step 7830, loss = 1.16 (263.8 examples/sec; 0.970 sec/batch)\n",
      "2017-05-29 03:01:05.967350: step 7840, loss = 1.18 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 03:01:15.891836: step 7850, loss = 1.25 (257.9 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 03:01:25.736257: step 7860, loss = 1.19 (260.0 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 03:01:35.628807: step 7870, loss = 1.26 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 03:01:45.436723: step 7880, loss = 1.34 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 03:01:55.664036: step 7890, loss = 1.23 (250.3 examples/sec; 1.023 sec/batch)\n",
      "2017-05-29 03:02:05.489371: step 7900, loss = 1.16 (260.6 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 03:02:15.423218: step 7910, loss = 1.39 (257.7 examples/sec; 0.993 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.902615\n",
      "2017-05-29 03:02:37.138645: step 7920, loss = 1.25 (117.9 examples/sec; 2.172 sec/batch)\n",
      "2017-05-29 03:02:46.753134: step 7930, loss = 1.09 (266.3 examples/sec; 0.961 sec/batch)\n",
      "2017-05-29 03:02:56.808013: step 7940, loss = 1.26 (254.6 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 03:03:06.689949: step 7950, loss = 1.28 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 03:03:16.483045: step 7960, loss = 1.27 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 03:03:26.310833: step 7970, loss = 1.27 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 03:03:36.291385: step 7980, loss = 1.17 (256.5 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 03:03:46.054687: step 7990, loss = 1.12 (262.2 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 03:03:56.056903: step 8000, loss = 1.20 (255.9 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 03:04:05.907174: step 8010, loss = 1.32 (259.9 examples/sec; 0.985 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.899406\n",
      "2017-05-29 03:04:28.344178: step 8020, loss = 1.21 (114.1 examples/sec; 2.244 sec/batch)\n",
      "2017-05-29 03:04:38.037848: step 8030, loss = 1.17 (264.1 examples/sec; 0.969 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 03:04:47.903027: step 8040, loss = 1.19 (259.5 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 03:04:57.767580: step 8050, loss = 1.23 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 03:05:07.675291: step 8060, loss = 1.20 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 03:05:17.603019: step 8070, loss = 1.40 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 03:05:27.442939: step 8080, loss = 1.39 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 03:05:37.442919: step 8090, loss = 1.30 (256.0 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 03:05:47.279467: step 8100, loss = 1.30 (260.3 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 03:05:57.053196: step 8110, loss = 1.33 (261.9 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 03:06:16.894620: step 8120, loss = 1.14 (129.0 examples/sec; 1.984 sec/batch)\n",
      "2017-05-29 03:06:24.025099: step 8130, loss = 1.30 (359.0 examples/sec; 0.713 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3877  Precision @ 1 train: 0.7572\n",
      "2017-05-29 03:06:31.582492: step 8140, loss = 1.17 (338.7 examples/sec; 0.756 sec/batch)\n",
      "2017-05-29 03:06:38.705311: step 8150, loss = 1.33 (359.4 examples/sec; 0.712 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3706  Precision @ 1 eval: 0.7238\n",
      "INFO:tensorflow:global_step/sec: 0.709627\n",
      "2017-05-29 03:06:45.784006: step 8160, loss = 1.36 (361.6 examples/sec; 0.708 sec/batch)\n",
      "2017-05-29 03:06:55.561180: step 8170, loss = 1.29 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 03:07:05.452306: step 8180, loss = 1.17 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 03:07:15.283170: step 8190, loss = 1.26 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 03:07:25.100749: step 8200, loss = 1.14 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 03:07:34.925319: step 8210, loss = 1.25 (260.6 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 03:07:44.718165: step 8220, loss = 1.23 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 03:07:55.070056: step 8230, loss = 1.12 (247.3 examples/sec; 1.035 sec/batch)\n",
      "2017-05-29 03:08:04.901081: step 8240, loss = 1.20 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 03:08:14.702068: step 8250, loss = 1.26 (261.2 examples/sec; 0.980 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.920243\n",
      "2017-05-29 03:08:34.449450: step 8260, loss = 1.14 (129.6 examples/sec; 1.975 sec/batch)\n",
      "2017-05-29 03:08:43.652686: step 8270, loss = 1.29 (278.2 examples/sec; 0.920 sec/batch)\n",
      "2017-05-29 03:08:53.426185: step 8280, loss = 1.28 (261.9 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 03:09:03.183020: step 8290, loss = 1.35 (262.4 examples/sec; 0.976 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 7632 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 03:09:16.187176: step 8300, loss = 1.22 (196.9 examples/sec; 1.300 sec/batch)\n",
      "2017-05-29 03:09:26.046199: step 8310, loss = 1.22 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 03:09:35.919533: step 8320, loss = 1.34 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 03:09:46.250281: step 8330, loss = 1.12 (247.8 examples/sec; 1.033 sec/batch)\n",
      "2017-05-29 03:09:56.267542: step 8340, loss = 1.22 (255.6 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 03:10:06.155442: step 8350, loss = 1.14 (258.9 examples/sec; 0.989 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.884182\n",
      "2017-05-29 03:10:27.548747: step 8360, loss = 1.28 (119.7 examples/sec; 2.139 sec/batch)\n",
      "2017-05-29 03:10:36.780341: step 8370, loss = 1.29 (277.3 examples/sec; 0.923 sec/batch)\n",
      "2017-05-29 03:10:46.533942: step 8380, loss = 1.17 (262.5 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 03:10:56.470595: step 8390, loss = 1.14 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 03:11:06.319723: step 8400, loss = 1.28 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 03:11:16.356232: step 8410, loss = 1.19 (255.1 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 03:11:26.238472: step 8420, loss = 1.19 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 03:11:36.087395: step 8430, loss = 1.34 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 03:11:45.911155: step 8440, loss = 1.27 (260.6 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 03:11:55.949077: step 8450, loss = 1.26 (255.0 examples/sec; 1.004 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.90258\n",
      "2017-05-29 03:12:18.344321: step 8460, loss = 1.23 (114.3 examples/sec; 2.240 sec/batch)\n",
      "2017-05-29 03:12:27.543065: step 8470, loss = 1.23 (278.3 examples/sec; 0.920 sec/batch)\n",
      "2017-05-29 03:12:37.462667: step 8480, loss = 1.19 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 03:12:47.255914: step 8490, loss = 1.27 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 03:12:57.173955: step 8500, loss = 1.29 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 03:13:07.134150: step 8510, loss = 1.25 (257.0 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 03:13:17.191572: step 8520, loss = 1.18 (254.5 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 03:13:27.182389: step 8530, loss = 1.30 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 03:13:37.256347: step 8540, loss = 1.32 (254.1 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 03:13:47.244708: step 8550, loss = 1.34 (256.3 examples/sec; 0.999 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.897221\n",
      "2017-05-29 03:14:09.798990: step 8560, loss = 1.22 (113.5 examples/sec; 2.255 sec/batch)\n",
      "2017-05-29 03:14:19.042605: step 8570, loss = 1.33 (276.9 examples/sec; 0.924 sec/batch)\n",
      "2017-05-29 03:14:29.063921: step 8580, loss = 1.24 (255.5 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 03:14:39.028715: step 8590, loss = 1.21 (256.9 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 03:14:49.022859: step 8600, loss = 1.22 (256.1 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 03:14:59.060854: step 8610, loss = 1.32 (255.0 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 03:15:08.958270: step 8620, loss = 1.32 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 03:15:18.833413: step 8630, loss = 1.20 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 03:15:28.777421: step 8640, loss = 1.26 (257.4 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 03:15:38.691968: step 8650, loss = 1.29 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 03:16:00.430554: step 8660, loss = 1.14 (117.8 examples/sec; 2.174 sec/batch)\n",
      "2017-05-29 03:16:07.177102: step 8670, loss = 1.25 (379.5 examples/sec; 0.675 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3976  Precision @ 1 train: 0.7766\n",
      "2017-05-29 03:16:14.238812: step 8680, loss = 1.22 (362.5 examples/sec; 0.706 sec/batch)\n",
      "2017-05-29 03:16:21.680410: step 8690, loss = 1.23 (344.0 examples/sec; 0.744 sec/batch)\n",
      "2017-05-29 03:16:29.080560: step 8700, loss = 1.24 (345.9 examples/sec; 0.740 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3794  Precision @ 1 eval: 0.7410\n",
      "INFO:tensorflow:global_step/sec: 0.703997\n",
      "2017-05-29 03:16:37.758331: step 8710, loss = 1.23 (295.0 examples/sec; 0.868 sec/batch)\n",
      "2017-05-29 03:16:47.619988: step 8720, loss = 1.19 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 03:16:57.498768: step 8730, loss = 1.19 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 03:17:07.674207: step 8740, loss = 1.22 (251.6 examples/sec; 1.018 sec/batch)\n",
      "2017-05-29 03:17:17.461321: step 8750, loss = 1.26 (261.6 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 03:17:27.220451: step 8760, loss = 1.16 (262.3 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 03:17:37.064848: step 8770, loss = 1.23 (260.0 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 03:17:46.875880: step 8780, loss = 1.11 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 03:17:56.800323: step 8790, loss = 1.27 (257.9 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 03:18:06.670731: step 8800, loss = 1.17 (259.4 examples/sec; 0.987 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.918169\n",
      "2017-05-29 03:18:26.105020: step 8810, loss = 1.16 (131.7 examples/sec; 1.943 sec/batch)\n",
      "2017-05-29 03:18:35.946351: step 8820, loss = 1.29 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 03:18:46.215736: step 8830, loss = 1.21 (249.3 examples/sec; 1.027 sec/batch)\n",
      "2017-05-29 03:18:56.005219: step 8840, loss = 1.30 (261.5 examples/sec; 0.979 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 8146 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 03:19:08.070373: step 8850, loss = 1.29 (212.2 examples/sec; 1.207 sec/batch)\n",
      "2017-05-29 03:19:17.496837: step 8860, loss = 1.24 (271.6 examples/sec; 0.943 sec/batch)\n",
      "2017-05-29 03:19:27.403698: step 8870, loss = 1.28 (258.4 examples/sec; 0.991 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 03:19:37.294420: step 8880, loss = 1.13 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 03:19:47.206342: step 8890, loss = 1.20 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 03:19:57.109160: step 8900, loss = 1.22 (258.5 examples/sec; 0.990 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.904347\n",
      "2017-05-29 03:20:16.872782: step 8910, loss = 1.25 (129.5 examples/sec; 1.976 sec/batch)\n",
      "2017-05-29 03:20:26.533121: step 8920, loss = 1.18 (265.0 examples/sec; 0.966 sec/batch)\n",
      "2017-05-29 03:20:36.544794: step 8930, loss = 1.18 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 03:20:46.464365: step 8940, loss = 1.17 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 03:20:56.269037: step 8950, loss = 1.34 (261.1 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 03:21:06.097696: step 8960, loss = 1.27 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 03:21:16.281897: step 8970, loss = 1.22 (251.4 examples/sec; 1.018 sec/batch)\n",
      "2017-05-29 03:21:26.164484: step 8980, loss = 1.32 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 03:21:36.168401: step 8990, loss = 1.32 (255.9 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 03:21:46.086514: step 9000, loss = 1.46 (258.1 examples/sec; 0.992 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.896764\n",
      "2017-05-29 03:22:08.119641: step 9010, loss = 1.27 (116.2 examples/sec; 2.203 sec/batch)\n",
      "2017-05-29 03:22:17.856990: step 9020, loss = 1.29 (262.9 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 03:22:27.823188: step 9030, loss = 1.17 (256.9 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 03:22:37.582985: step 9040, loss = 1.34 (262.3 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 03:22:47.462247: step 9050, loss = 1.23 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 03:22:57.291401: step 9060, loss = 1.39 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 03:23:07.197039: step 9070, loss = 1.25 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 03:23:17.047142: step 9080, loss = 1.15 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 03:23:27.127743: step 9090, loss = 1.17 (254.0 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 03:23:36.974692: step 9100, loss = 1.28 (260.0 examples/sec; 0.985 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.927818\n",
      "2017-05-29 03:23:56.217859: step 9110, loss = 1.29 (133.0 examples/sec; 1.924 sec/batch)\n",
      "2017-05-29 03:24:06.117193: step 9120, loss = 1.17 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 03:24:15.995291: step 9130, loss = 1.28 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 03:24:25.935703: step 9140, loss = 1.13 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 03:24:35.854921: step 9150, loss = 1.21 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 03:24:45.720522: step 9160, loss = 1.13 (259.5 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 03:24:55.653830: step 9170, loss = 1.16 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 03:25:05.484776: step 9180, loss = 1.14 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 03:25:15.367065: step 9190, loss = 1.22 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 03:25:25.204778: step 9200, loss = 1.29 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 03:25:43.224841: step 9210, loss = 1.04 (142.1 examples/sec; 1.802 sec/batch)\n",
      "2017-05-29 03:25:51.096053: step 9220, loss = 1.28 (325.2 examples/sec; 0.787 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3978  Precision @ 1 train: 0.7770\n",
      "2017-05-29 03:25:58.033205: step 9230, loss = 1.21 (369.0 examples/sec; 0.694 sec/batch)\n",
      "2017-05-29 03:26:05.106191: step 9240, loss = 1.21 (361.9 examples/sec; 0.707 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3814  Precision @ 1 eval: 0.7449\n",
      "INFO:tensorflow:global_step/sec: 0.713988\n",
      "2017-05-29 03:26:12.656918: step 9250, loss = 1.15 (339.0 examples/sec; 0.755 sec/batch)\n",
      "2017-05-29 03:26:22.466828: step 9260, loss = 1.21 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 03:26:32.351015: step 9270, loss = 1.18 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 03:26:42.237690: step 9280, loss = 1.17 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 03:26:52.386624: step 9290, loss = 1.23 (252.2 examples/sec; 1.015 sec/batch)\n",
      "2017-05-29 03:27:02.195651: step 9300, loss = 1.26 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 03:27:12.171961: step 9310, loss = 1.11 (256.6 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 03:27:21.902557: step 9320, loss = 1.25 (263.1 examples/sec; 0.973 sec/batch)\n",
      "2017-05-29 03:27:31.952148: step 9330, loss = 1.21 (254.7 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 03:27:41.744078: step 9340, loss = 1.20 (261.4 examples/sec; 0.979 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.917269\n",
      "2017-05-29 03:28:01.415445: step 9350, loss = 1.30 (130.1 examples/sec; 1.967 sec/batch)\n",
      "2017-05-29 03:28:11.096984: step 9360, loss = 1.18 (264.4 examples/sec; 0.968 sec/batch)\n",
      "2017-05-29 03:28:20.912680: step 9370, loss = 1.24 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 03:28:30.833815: step 9380, loss = 1.33 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 03:28:40.954991: step 9390, loss = 1.08 (252.9 examples/sec; 1.012 sec/batch)\n",
      "2017-05-29 03:28:50.898838: step 9400, loss = 1.23 (257.4 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 03:29:00.714320: step 9410, loss = 1.21 (260.8 examples/sec; 0.982 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 8668 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 03:29:12.590447: step 9420, loss = 1.29 (215.6 examples/sec; 1.188 sec/batch)\n",
      "2017-05-29 03:29:22.645818: step 9430, loss = 1.33 (254.6 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 03:29:32.504210: step 9440, loss = 1.18 (259.7 examples/sec; 0.986 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.882206\n",
      "2017-05-29 03:29:54.675999: step 9450, loss = 1.19 (115.5 examples/sec; 2.217 sec/batch)\n",
      "2017-05-29 03:30:04.204050: step 9460, loss = 1.35 (268.7 examples/sec; 0.953 sec/batch)\n",
      "2017-05-29 03:30:14.035390: step 9470, loss = 1.07 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 03:30:23.979790: step 9480, loss = 1.31 (257.4 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 03:30:33.814435: step 9490, loss = 1.14 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 03:30:43.704544: step 9500, loss = 1.39 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 03:30:53.614705: step 9510, loss = 1.08 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 03:31:03.696127: step 9520, loss = 1.44 (253.9 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 03:31:13.578608: step 9530, loss = 1.31 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 03:31:23.566554: step 9540, loss = 1.21 (256.3 examples/sec; 0.999 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.911675\n",
      "2017-05-29 03:31:44.460554: step 9550, loss = 1.27 (122.5 examples/sec; 2.089 sec/batch)\n",
      "2017-05-29 03:31:54.267423: step 9560, loss = 1.30 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 03:32:04.203497: step 9570, loss = 1.27 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 03:32:14.174496: step 9580, loss = 1.22 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 03:32:24.171223: step 9590, loss = 1.23 (256.1 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 03:32:34.234185: step 9600, loss = 1.33 (254.4 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 03:32:44.213130: step 9610, loss = 1.29 (256.5 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 03:32:54.111113: step 9620, loss = 1.24 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 03:33:04.048495: step 9630, loss = 1.31 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 03:33:13.876267: step 9640, loss = 1.26 (260.5 examples/sec; 0.983 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.89269\n",
      "2017-05-29 03:33:36.439774: step 9650, loss = 1.34 (113.5 examples/sec; 2.256 sec/batch)\n",
      "2017-05-29 03:33:45.961575: step 9660, loss = 1.19 (268.9 examples/sec; 0.952 sec/batch)\n",
      "2017-05-29 03:33:55.894290: step 9670, loss = 1.17 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 03:34:05.819337: step 9680, loss = 1.04 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 03:34:15.796811: step 9690, loss = 1.33 (256.6 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 03:34:25.652569: step 9700, loss = 1.20 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 03:34:35.357755: step 9710, loss = 1.20 (263.8 examples/sec; 0.971 sec/batch)\n",
      "2017-05-29 03:34:45.354270: step 9720, loss = 1.17 (256.1 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 03:34:55.363062: step 9730, loss = 1.13 (255.8 examples/sec; 1.001 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 03:35:05.230522: step 9740, loss = 1.28 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 03:35:25.544951: step 9750, loss = 1.11 (126.0 examples/sec; 2.031 sec/batch)\n",
      "2017-05-29 03:35:32.693464: step 9760, loss = 1.23 (358.1 examples/sec; 0.715 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3906  Precision @ 1 train: 0.7629\n",
      "2017-05-29 03:35:39.492227: step 9770, loss = 1.20 (376.5 examples/sec; 0.680 sec/batch)\n",
      "2017-05-29 03:35:46.715532: step 9780, loss = 1.26 (354.4 examples/sec; 0.722 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3730  Precision @ 1 eval: 0.7285\n",
      "2017-05-29 03:35:54.537244: step 9790, loss = 1.15 (327.3 examples/sec; 0.782 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.708332\n",
      "2017-05-29 03:36:03.819194: step 9800, loss = 1.12 (275.8 examples/sec; 0.928 sec/batch)\n",
      "2017-05-29 03:36:13.715132: step 9810, loss = 1.09 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 03:36:23.562943: step 9820, loss = 1.23 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 03:36:33.649459: step 9830, loss = 1.21 (253.8 examples/sec; 1.009 sec/batch)\n",
      "2017-05-29 03:36:43.436398: step 9840, loss = 1.29 (261.6 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 03:36:53.378463: step 9850, loss = 1.28 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 03:37:03.235856: step 9860, loss = 1.28 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 03:37:13.222877: step 9870, loss = 1.25 (256.3 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 03:37:23.002849: step 9880, loss = 1.26 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 03:37:32.736769: step 9890, loss = 1.15 (263.0 examples/sec; 0.973 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.912761\n",
      "2017-05-29 03:37:53.058246: step 9900, loss = 1.17 (126.0 examples/sec; 2.032 sec/batch)\n",
      "2017-05-29 03:38:03.172267: step 9910, loss = 1.24 (253.1 examples/sec; 1.011 sec/batch)\n",
      "2017-05-29 03:38:13.216906: step 9920, loss = 1.16 (254.9 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 03:38:23.037561: step 9930, loss = 1.23 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 03:38:32.839533: step 9940, loss = 1.19 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 03:38:42.707221: step 9950, loss = 1.32 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 03:38:52.507329: step 9960, loss = 1.33 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 03:39:02.465391: step 9970, loss = 1.14 (257.1 examples/sec; 0.996 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 9183 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 03:39:14.719919: step 9980, loss = 1.27 (208.9 examples/sec; 1.225 sec/batch)\n",
      "2017-05-29 03:39:24.647742: step 9990, loss = 1.30 (257.9 examples/sec; 0.993 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.88111\n",
      "2017-05-29 03:39:46.280193: step 10000, loss = 1.18 (118.3 examples/sec; 2.163 sec/batch)\n",
      "2017-05-29 03:39:55.856520: step 10010, loss = 1.21 (267.3 examples/sec; 0.958 sec/batch)\n",
      "2017-05-29 03:40:05.844019: step 10020, loss = 1.24 (256.3 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 03:40:15.659131: step 10030, loss = 1.13 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 03:40:25.404070: step 10040, loss = 1.21 (262.7 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 03:40:35.408352: step 10050, loss = 1.12 (255.9 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 03:40:45.353976: step 10060, loss = 1.17 (257.4 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 03:40:55.227765: step 10070, loss = 1.16 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 03:41:05.139043: step 10080, loss = 1.17 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 03:41:14.911752: step 10090, loss = 1.09 (262.0 examples/sec; 0.977 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.906223\n",
      "2017-05-29 03:41:36.576138: step 10100, loss = 1.16 (118.2 examples/sec; 2.166 sec/batch)\n",
      "2017-05-29 03:41:46.437914: step 10110, loss = 1.01 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 03:41:56.356178: step 10120, loss = 1.20 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 03:42:06.260965: step 10130, loss = 1.24 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 03:42:16.100492: step 10140, loss = 1.22 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 03:42:25.874228: step 10150, loss = 1.22 (261.9 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 03:42:35.675931: step 10160, loss = 1.18 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 03:42:45.516735: step 10170, loss = 1.15 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 03:42:55.653287: step 10180, loss = 1.24 (252.6 examples/sec; 1.014 sec/batch)\n",
      "2017-05-29 03:43:05.515623: step 10190, loss = 1.30 (259.6 examples/sec; 0.986 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.927865\n",
      "2017-05-29 03:43:24.418319: step 10200, loss = 1.24 (135.4 examples/sec; 1.890 sec/batch)\n",
      "2017-05-29 03:43:34.202555: step 10210, loss = 1.30 (261.6 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 03:43:44.034117: step 10220, loss = 1.20 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 03:43:53.797609: step 10230, loss = 1.09 (262.2 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 03:44:03.688734: step 10240, loss = 1.34 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 03:44:13.581425: step 10250, loss = 1.20 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 03:44:23.398438: step 10260, loss = 1.22 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 03:44:33.237295: step 10270, loss = 1.27 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 03:44:43.100625: step 10280, loss = 1.35 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 03:44:53.012162: step 10290, loss = 1.22 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 03:45:11.935343: step 10300, loss = 1.19 (135.3 examples/sec; 1.892 sec/batch)\n",
      "2017-05-29 03:45:19.728550: step 10310, loss = 1.25 (328.5 examples/sec; 0.779 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3962  Precision @ 1 train: 0.7738\n",
      "2017-05-29 03:45:26.708812: step 10320, loss = 1.20 (366.7 examples/sec; 0.698 sec/batch)\n",
      "2017-05-29 03:45:33.771074: step 10330, loss = 1.18 (362.5 examples/sec; 0.706 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3858  Precision @ 1 eval: 0.7535\n",
      "INFO:tensorflow:global_step/sec: 0.709816\n",
      "2017-05-29 03:45:41.982722: step 10340, loss = 1.20 (311.8 examples/sec; 0.821 sec/batch)\n",
      "2017-05-29 03:45:51.785549: step 10350, loss = 1.13 (261.1 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 03:46:01.616659: step 10360, loss = 1.22 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 03:46:11.423606: step 10370, loss = 1.35 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 03:46:21.359217: step 10380, loss = 1.29 (257.7 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 03:46:31.736679: step 10390, loss = 1.06 (246.7 examples/sec; 1.038 sec/batch)\n",
      "2017-05-29 03:46:41.606254: step 10400, loss = 1.22 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 03:46:51.343527: step 10410, loss = 1.12 (262.9 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 03:47:01.386548: step 10420, loss = 1.17 (254.9 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 03:47:11.207037: step 10430, loss = 1.25 (260.7 examples/sec; 0.982 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.914701\n",
      "2017-05-29 03:47:30.836139: step 10440, loss = 1.22 (130.4 examples/sec; 1.963 sec/batch)\n",
      "2017-05-29 03:47:40.583867: step 10450, loss = 1.17 (262.6 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 03:47:50.368970: step 10460, loss = 1.19 (261.6 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 03:48:00.203736: step 10470, loss = 1.04 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 03:48:10.171262: step 10480, loss = 1.12 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 03:48:20.062419: step 10490, loss = 1.28 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 03:48:29.871857: step 10500, loss = 1.28 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 03:48:39.939609: step 10510, loss = 1.31 (254.3 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 03:48:50.147232: step 10520, loss = 1.24 (250.8 examples/sec; 1.021 sec/batch)\n",
      "2017-05-29 03:48:59.990426: step 10530, loss = 1.12 (260.1 examples/sec; 0.984 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 9700 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.903834\n",
      "2017-05-29 03:49:21.400178: step 10540, loss = 1.20 (119.6 examples/sec; 2.141 sec/batch)\n",
      "2017-05-29 03:49:31.055950: step 10550, loss = 1.20 (265.1 examples/sec; 0.966 sec/batch)\n",
      "2017-05-29 03:49:41.196280: step 10560, loss = 1.11 (252.5 examples/sec; 1.014 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 03:49:51.055858: step 10570, loss = 1.15 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 03:50:00.938892: step 10580, loss = 0.98 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 03:50:10.847004: step 10590, loss = 1.15 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 03:50:20.615037: step 10600, loss = 1.22 (262.1 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 03:50:30.467851: step 10610, loss = 1.24 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 03:50:40.410238: step 10620, loss = 1.13 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 03:50:50.352044: step 10630, loss = 1.15 (257.5 examples/sec; 0.994 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.915511\n",
      "2017-05-29 03:51:10.685922: step 10640, loss = 1.12 (125.9 examples/sec; 2.033 sec/batch)\n",
      "2017-05-29 03:51:20.488466: step 10650, loss = 1.17 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 03:51:30.373067: step 10660, loss = 1.14 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 03:51:40.292751: step 10670, loss = 1.12 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 03:51:50.285456: step 10680, loss = 1.22 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 03:52:00.184412: step 10690, loss = 1.12 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 03:52:10.151001: step 10700, loss = 1.32 (256.9 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 03:52:20.163469: step 10710, loss = 1.18 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 03:52:30.063958: step 10720, loss = 1.29 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 03:52:39.905742: step 10730, loss = 1.14 (260.1 examples/sec; 0.984 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.912659\n",
      "2017-05-29 03:53:00.344360: step 10740, loss = 1.17 (125.3 examples/sec; 2.044 sec/batch)\n",
      "2017-05-29 03:53:10.083586: step 10750, loss = 1.21 (262.9 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 03:53:20.103055: step 10760, loss = 1.28 (255.5 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 03:53:29.933468: step 10770, loss = 1.31 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 03:53:39.839971: step 10780, loss = 1.30 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 03:53:49.763331: step 10790, loss = 1.35 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 03:53:59.626318: step 10800, loss = 1.15 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 03:54:09.551244: step 10810, loss = 1.04 (257.9 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 03:54:19.492039: step 10820, loss = 1.23 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 03:54:29.407579: step 10830, loss = 1.13 (258.2 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 03:54:49.645211: step 10840, loss = 1.18 (126.5 examples/sec; 2.024 sec/batch)\n",
      "2017-05-29 03:54:57.232186: step 10850, loss = 1.33 (337.4 examples/sec; 0.759 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4049  Precision @ 1 train: 0.7908\n",
      "2017-05-29 03:55:04.059700: step 10860, loss = 1.19 (375.0 examples/sec; 0.683 sec/batch)\n",
      "2017-05-29 03:55:11.396150: step 10870, loss = 1.21 (348.9 examples/sec; 0.734 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3880  Precision @ 1 eval: 0.7578\n",
      "INFO:tensorflow:global_step/sec: 0.705688\n",
      "2017-05-29 03:55:18.464441: step 10880, loss = 1.29 (362.2 examples/sec; 0.707 sec/batch)\n",
      "2017-05-29 03:55:28.355178: step 10890, loss = 1.19 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 03:55:38.312836: step 10900, loss = 1.23 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 03:55:48.303685: step 10910, loss = 1.09 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 03:55:58.306812: step 10920, loss = 1.17 (255.9 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 03:56:08.167627: step 10930, loss = 1.10 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 03:56:18.234381: step 10940, loss = 1.22 (254.3 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 03:56:27.960947: step 10950, loss = 1.35 (263.2 examples/sec; 0.973 sec/batch)\n",
      "2017-05-29 03:56:37.831935: step 10960, loss = 1.31 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 03:56:47.843365: step 10970, loss = 1.26 (255.7 examples/sec; 1.001 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.89736\n",
      "2017-05-29 03:57:09.901735: step 10980, loss = 1.19 (116.1 examples/sec; 2.206 sec/batch)\n",
      "2017-05-29 03:57:19.157530: step 10990, loss = 1.16 (276.6 examples/sec; 0.926 sec/batch)\n",
      "2017-05-29 03:57:28.969624: step 11000, loss = 1.08 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 03:57:38.878599: step 11010, loss = 1.12 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 03:57:48.900589: step 11020, loss = 1.11 (255.4 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 03:57:58.752256: step 11030, loss = 1.09 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 03:58:08.696717: step 11040, loss = 1.26 (257.4 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 03:58:18.706210: step 11050, loss = 1.21 (255.8 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 03:58:28.563192: step 11060, loss = 1.15 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 03:58:38.344126: step 11070, loss = 1.07 (261.7 examples/sec; 0.978 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.906159\n",
      "2017-05-29 03:59:00.258260: step 11080, loss = 1.28 (116.8 examples/sec; 2.191 sec/batch)\n",
      "2017-05-29 03:59:09.470181: step 11090, loss = 1.29 (277.9 examples/sec; 0.921 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 10217 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 03:59:22.761563: step 11100, loss = 1.17 (192.6 examples/sec; 1.329 sec/batch)\n",
      "2017-05-29 03:59:32.814881: step 11110, loss = 1.20 (254.6 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 03:59:42.703565: step 11120, loss = 1.22 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 03:59:52.677190: step 11130, loss = 1.15 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 04:00:02.476180: step 11140, loss = 1.18 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 04:00:12.464081: step 11150, loss = 1.15 (256.3 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 04:00:22.288314: step 11160, loss = 1.16 (260.6 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 04:00:32.217703: step 11170, loss = 1.21 (257.8 examples/sec; 0.993 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.883889\n",
      "2017-05-29 04:00:53.394726: step 11180, loss = 1.12 (120.9 examples/sec; 2.118 sec/batch)\n",
      "2017-05-29 04:01:02.633456: step 11190, loss = 1.11 (277.1 examples/sec; 0.924 sec/batch)\n",
      "2017-05-29 04:01:12.458694: step 11200, loss = 1.26 (260.6 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 04:01:22.581860: step 11210, loss = 1.19 (252.9 examples/sec; 1.012 sec/batch)\n",
      "2017-05-29 04:01:32.439336: step 11220, loss = 1.25 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 04:01:42.356381: step 11230, loss = 0.96 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 04:01:52.372722: step 11240, loss = 1.22 (255.6 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 04:02:02.181983: step 11250, loss = 1.15 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 04:02:12.028508: step 11260, loss = 1.18 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 04:02:21.852199: step 11270, loss = 1.31 (260.6 examples/sec; 0.982 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.902658\n",
      "2017-05-29 04:02:44.179504: step 11280, loss = 1.14 (114.7 examples/sec; 2.233 sec/batch)\n",
      "2017-05-29 04:02:53.334155: step 11290, loss = 1.29 (279.6 examples/sec; 0.915 sec/batch)\n",
      "2017-05-29 04:03:03.420166: step 11300, loss = 1.20 (253.8 examples/sec; 1.009 sec/batch)\n",
      "2017-05-29 04:03:13.177985: step 11310, loss = 1.14 (262.4 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 04:03:23.192324: step 11320, loss = 1.14 (255.6 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 04:03:32.912297: step 11330, loss = 1.10 (263.4 examples/sec; 0.972 sec/batch)\n",
      "2017-05-29 04:03:43.039631: step 11340, loss = 1.26 (252.8 examples/sec; 1.013 sec/batch)\n",
      "2017-05-29 04:03:52.904817: step 11350, loss = 1.17 (259.5 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 04:04:02.867266: step 11360, loss = 1.09 (257.0 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 04:04:12.854211: step 11370, loss = 1.16 (256.3 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 04:04:34.588875: step 11380, loss = 1.18 (117.8 examples/sec; 2.173 sec/batch)\n",
      "2017-05-29 04:04:41.338147: step 11390, loss = 1.17 (379.3 examples/sec; 0.675 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3832  Precision @ 1 train: 0.7484\n",
      "2017-05-29 04:04:48.408058: step 11400, loss = 1.03 (362.1 examples/sec; 0.707 sec/batch)\n",
      "2017-05-29 04:04:55.228405: step 11410, loss = 1.25 (375.3 examples/sec; 0.682 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 04:05:02.339489: step 11420, loss = 1.14 (360.0 examples/sec; 0.711 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3689  Precision @ 1 eval: 0.7205\n",
      "INFO:tensorflow:global_step/sec: 0.709298\n",
      "2017-05-29 04:05:11.095375: step 11430, loss = 1.26 (292.4 examples/sec; 0.876 sec/batch)\n",
      "2017-05-29 04:05:20.924641: step 11440, loss = 1.12 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 04:05:30.808894: step 11450, loss = 1.12 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 04:05:40.726908: step 11460, loss = 1.25 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 04:05:50.988987: step 11470, loss = 1.40 (249.5 examples/sec; 1.026 sec/batch)\n",
      "2017-05-29 04:06:00.753247: step 11480, loss = 1.15 (262.2 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 04:06:10.635208: step 11490, loss = 1.09 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 04:06:20.897988: step 11500, loss = 1.15 (249.4 examples/sec; 1.026 sec/batch)\n",
      "2017-05-29 04:06:30.892124: step 11510, loss = 1.22 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 04:06:40.790418: step 11520, loss = 1.15 (258.6 examples/sec; 0.990 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.911231\n",
      "2017-05-29 04:07:00.420755: step 11530, loss = 1.18 (130.4 examples/sec; 1.963 sec/batch)\n",
      "2017-05-29 04:07:10.151535: step 11540, loss = 1.19 (263.1 examples/sec; 0.973 sec/batch)\n",
      "2017-05-29 04:07:20.203087: step 11550, loss = 1.08 (254.7 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 04:07:30.112093: step 11560, loss = 1.05 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 04:07:39.948503: step 11570, loss = 1.18 (260.3 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 04:07:49.764619: step 11580, loss = 1.21 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 04:07:59.592713: step 11590, loss = 1.17 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 04:08:09.504135: step 11600, loss = 1.21 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 04:08:19.472201: step 11610, loss = 1.37 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 04:08:29.407904: step 11620, loss = 1.01 (257.7 examples/sec; 0.994 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.91274\n",
      "2017-05-29 04:08:49.847251: step 11630, loss = 1.27 (125.2 examples/sec; 2.044 sec/batch)\n",
      "2017-05-29 04:08:59.888580: step 11640, loss = 1.10 (254.9 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 04:09:09.690003: step 11650, loss = 1.21 (261.2 examples/sec; 0.980 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 10733 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 04:09:20.566881: step 11660, loss = 1.14 (235.4 examples/sec; 1.088 sec/batch)\n",
      "2017-05-29 04:09:30.543601: step 11670, loss = 1.16 (256.6 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 04:09:40.420560: step 11680, loss = 1.14 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 04:09:50.249603: step 11690, loss = 1.27 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 04:10:00.182572: step 11700, loss = 1.16 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 04:10:10.173434: step 11710, loss = 1.08 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 04:10:20.181911: step 11720, loss = 1.17 (255.8 examples/sec; 1.001 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.897494\n",
      "2017-05-29 04:10:41.272350: step 11730, loss = 1.22 (121.4 examples/sec; 2.109 sec/batch)\n",
      "2017-05-29 04:10:51.095726: step 11740, loss = 1.23 (260.6 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 04:11:00.945915: step 11750, loss = 1.04 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 04:11:10.956558: step 11760, loss = 1.09 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 04:11:20.832724: step 11770, loss = 1.13 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 04:11:30.627804: step 11780, loss = 1.19 (261.4 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 04:11:40.657226: step 11790, loss = 1.21 (255.2 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 04:11:50.487326: step 11800, loss = 1.09 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 04:12:00.534137: step 11810, loss = 1.12 (254.8 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 04:12:10.365571: step 11820, loss = 1.18 (260.4 examples/sec; 0.983 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.914547\n",
      "2017-05-29 04:12:30.666085: step 11830, loss = 1.13 (126.1 examples/sec; 2.030 sec/batch)\n",
      "2017-05-29 04:12:40.355417: step 11840, loss = 1.27 (264.2 examples/sec; 0.969 sec/batch)\n",
      "2017-05-29 04:12:50.343247: step 11850, loss = 1.14 (256.3 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 04:13:00.234982: step 11860, loss = 1.22 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 04:13:10.136749: step 11870, loss = 1.19 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 04:13:20.037379: step 11880, loss = 1.03 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 04:13:29.979213: step 11890, loss = 1.20 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 04:13:39.954069: step 11900, loss = 1.25 (256.6 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 04:13:49.988145: step 11910, loss = 1.11 (255.1 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 04:13:59.961858: step 11920, loss = 1.12 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 04:14:19.078394: step 11930, loss = 1.03 (133.9 examples/sec; 1.912 sec/batch)\n",
      "2017-05-29 04:14:26.157438: step 11940, loss = 1.35 (361.6 examples/sec; 0.708 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4061  Precision @ 1 train: 0.7932\n",
      "2017-05-29 04:14:33.673605: step 11950, loss = 1.29 (340.6 examples/sec; 0.752 sec/batch)\n",
      "2017-05-29 04:14:40.910341: step 11960, loss = 1.03 (353.8 examples/sec; 0.724 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3935  Precision @ 1 eval: 0.7686\n",
      "INFO:tensorflow:global_step/sec: 0.708112\n",
      "2017-05-29 04:14:48.430980: step 11970, loss = 1.22 (340.4 examples/sec; 0.752 sec/batch)\n",
      "2017-05-29 04:14:58.482698: step 11980, loss = 1.19 (254.7 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 04:15:08.455224: step 11990, loss = 1.06 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 04:15:18.201807: step 12000, loss = 1.17 (262.7 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 04:15:28.256936: step 12010, loss = 1.12 (254.6 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 04:15:38.207942: step 12020, loss = 1.13 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 04:15:48.171922: step 12030, loss = 1.23 (256.9 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 04:15:58.446432: step 12040, loss = 1.24 (249.2 examples/sec; 1.027 sec/batch)\n",
      "2017-05-29 04:16:08.456540: step 12050, loss = 1.19 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 04:16:18.373252: step 12060, loss = 1.21 (258.2 examples/sec; 0.992 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.917174\n",
      "2017-05-29 04:16:37.199827: step 12070, loss = 1.15 (136.0 examples/sec; 1.883 sec/batch)\n",
      "2017-05-29 04:16:46.780286: step 12080, loss = 1.27 (267.2 examples/sec; 0.958 sec/batch)\n",
      "2017-05-29 04:16:56.645042: step 12090, loss = 1.32 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 04:17:06.476514: step 12100, loss = 1.23 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 04:17:16.445230: step 12110, loss = 1.20 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 04:17:26.401707: step 12120, loss = 1.23 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 04:17:36.319367: step 12130, loss = 1.21 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 04:17:46.151028: step 12140, loss = 1.15 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 04:17:56.049086: step 12150, loss = 1.16 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 04:18:06.011962: step 12160, loss = 1.13 (257.0 examples/sec; 0.996 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.908932\n",
      "2017-05-29 04:18:27.141402: step 12170, loss = 1.17 (121.2 examples/sec; 2.113 sec/batch)\n",
      "2017-05-29 04:18:36.701009: step 12180, loss = 1.21 (267.8 examples/sec; 0.956 sec/batch)\n",
      "2017-05-29 04:18:46.623998: step 12190, loss = 1.25 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 04:18:56.519980: step 12200, loss = 1.11 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 04:19:06.413667: step 12210, loss = 1.21 (258.8 examples/sec; 0.989 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 11253 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 04:19:18.688202: step 12220, loss = 1.04 (208.6 examples/sec; 1.227 sec/batch)\n",
      "2017-05-29 04:19:28.062518: step 12230, loss = 1.22 (273.1 examples/sec; 0.937 sec/batch)\n",
      "2017-05-29 04:19:38.074795: step 12240, loss = 1.25 (255.7 examples/sec; 1.001 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 04:19:47.971221: step 12250, loss = 1.05 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 04:19:57.946971: step 12260, loss = 1.11 (256.6 examples/sec; 0.998 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.898776\n",
      "2017-05-29 04:20:18.469727: step 12270, loss = 1.12 (124.7 examples/sec; 2.052 sec/batch)\n",
      "2017-05-29 04:20:28.146370: step 12280, loss = 1.09 (264.6 examples/sec; 0.968 sec/batch)\n",
      "2017-05-29 04:20:38.028600: step 12290, loss = 1.27 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 04:20:47.898230: step 12300, loss = 1.19 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 04:20:57.742500: step 12310, loss = 1.13 (260.0 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 04:21:07.633897: step 12320, loss = 1.18 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 04:21:17.485453: step 12330, loss = 1.10 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 04:21:27.365144: step 12340, loss = 1.32 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 04:21:37.310775: step 12350, loss = 1.19 (257.4 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 04:21:47.230075: step 12360, loss = 1.20 (258.1 examples/sec; 0.992 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.905052\n",
      "2017-05-29 04:22:08.897374: step 12370, loss = 1.15 (118.2 examples/sec; 2.167 sec/batch)\n",
      "2017-05-29 04:22:18.531017: step 12380, loss = 1.26 (265.7 examples/sec; 0.963 sec/batch)\n",
      "2017-05-29 04:22:28.432174: step 12390, loss = 1.20 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 04:22:38.230832: step 12400, loss = 1.19 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 04:22:48.080043: step 12410, loss = 1.09 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 04:22:58.203042: step 12420, loss = 1.15 (252.9 examples/sec; 1.012 sec/batch)\n",
      "2017-05-29 04:23:08.212173: step 12430, loss = 1.18 (255.8 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 04:23:18.042388: step 12440, loss = 1.22 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 04:23:27.957650: step 12450, loss = 1.14 (258.2 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 04:23:37.819847: step 12460, loss = 1.20 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 04:23:58.728327: step 12470, loss = 1.19 (122.4 examples/sec; 2.091 sec/batch)\n",
      "2017-05-29 04:24:05.888068: step 12480, loss = 1.17 (357.6 examples/sec; 0.716 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4097  Precision @ 1 train: 0.8002\n",
      "2017-05-29 04:24:12.627909: step 12490, loss = 1.23 (379.8 examples/sec; 0.674 sec/batch)\n",
      "2017-05-29 04:24:19.705322: step 12500, loss = 1.30 (361.7 examples/sec; 0.708 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3881  Precision @ 1 eval: 0.7580\n",
      "2017-05-29 04:24:26.811748: step 12510, loss = 1.13 (360.2 examples/sec; 0.711 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.709492\n",
      "2017-05-29 04:24:36.144350: step 12520, loss = 1.16 (274.3 examples/sec; 0.933 sec/batch)\n",
      "2017-05-29 04:24:45.975649: step 12530, loss = 1.08 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 04:24:56.283149: step 12540, loss = 1.03 (248.4 examples/sec; 1.031 sec/batch)\n",
      "2017-05-29 04:25:06.187204: step 12550, loss = 1.10 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 04:25:16.221494: step 12560, loss = 1.14 (255.1 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 04:25:26.143838: step 12570, loss = 1.16 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 04:25:36.021158: step 12580, loss = 1.10 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 04:25:45.859457: step 12590, loss = 1.06 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 04:25:56.154023: step 12600, loss = 1.26 (248.7 examples/sec; 1.029 sec/batch)\n",
      "2017-05-29 04:26:06.025775: step 12610, loss = 1.38 (259.3 examples/sec; 0.987 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.914132\n",
      "2017-05-29 04:26:24.839662: step 12620, loss = 1.19 (136.1 examples/sec; 1.881 sec/batch)\n",
      "2017-05-29 04:26:34.802609: step 12630, loss = 1.20 (257.0 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 04:26:44.604916: step 12640, loss = 1.09 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 04:26:54.623272: step 12650, loss = 1.29 (255.5 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 04:27:04.570010: step 12660, loss = 1.21 (257.4 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 04:27:14.307507: step 12670, loss = 1.21 (262.9 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 04:27:24.140332: step 12680, loss = 1.35 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 04:27:34.265634: step 12690, loss = 1.09 (252.8 examples/sec; 1.013 sec/batch)\n",
      "2017-05-29 04:27:44.068880: step 12700, loss = 1.04 (261.1 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 04:27:54.048340: step 12710, loss = 1.19 (256.5 examples/sec; 0.998 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.904144\n",
      "2017-05-29 04:28:15.466279: step 12720, loss = 1.17 (119.5 examples/sec; 2.142 sec/batch)\n",
      "2017-05-29 04:28:25.190696: step 12730, loss = 1.30 (263.3 examples/sec; 0.972 sec/batch)\n",
      "2017-05-29 04:28:35.019245: step 12740, loss = 1.30 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 04:28:44.890421: step 12750, loss = 1.19 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 04:28:54.664156: step 12760, loss = 1.14 (261.9 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 04:29:04.587291: step 12770, loss = 1.42 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 04:29:14.399666: step 12780, loss = 1.22 (260.9 examples/sec; 0.981 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 11771 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 04:29:26.366636: step 12790, loss = 1.33 (213.9 examples/sec; 1.197 sec/batch)\n",
      "2017-05-29 04:29:36.384746: step 12800, loss = 1.30 (255.5 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 04:29:46.189882: step 12810, loss = 1.00 (261.1 examples/sec; 0.981 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.905045\n",
      "2017-05-29 04:30:05.963160: step 12820, loss = 1.18 (129.5 examples/sec; 1.977 sec/batch)\n",
      "2017-05-29 04:30:15.726146: step 12830, loss = 1.09 (262.2 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 04:30:25.554778: step 12840, loss = 1.09 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 04:30:35.484759: step 12850, loss = 1.26 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 04:30:45.344463: step 12860, loss = 1.07 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 04:30:55.229948: step 12870, loss = 1.08 (259.0 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 04:31:05.092773: step 12880, loss = 1.32 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 04:31:14.898784: step 12890, loss = 1.19 (261.1 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 04:31:24.745641: step 12900, loss = 1.18 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 04:31:34.535309: step 12910, loss = 1.21 (261.5 examples/sec; 0.979 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.921132\n",
      "2017-05-29 04:31:54.582441: step 12920, loss = 1.21 (127.7 examples/sec; 2.005 sec/batch)\n",
      "2017-05-29 04:32:04.461780: step 12930, loss = 1.28 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 04:32:14.309301: step 12940, loss = 1.09 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 04:32:24.155845: step 12950, loss = 1.22 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 04:32:34.089595: step 12960, loss = 1.12 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 04:32:43.890574: step 12970, loss = 1.19 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 04:32:53.704466: step 12980, loss = 1.15 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 04:33:03.539125: step 12990, loss = 1.18 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 04:33:13.373969: step 13000, loss = 1.19 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 04:33:23.216527: step 13010, loss = 1.11 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 04:33:42.021456: step 13020, loss = 1.24 (136.1 examples/sec; 1.880 sec/batch)\n",
      "2017-05-29 04:33:49.161846: step 13030, loss = 1.13 (358.5 examples/sec; 0.714 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4102  Precision @ 1 train: 0.8012\n",
      "2017-05-29 04:33:55.887548: step 13040, loss = 1.24 (380.6 examples/sec; 0.673 sec/batch)\n",
      "2017-05-29 04:34:03.832027: step 13050, loss = 1.22 (322.2 examples/sec; 0.794 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3927  Precision @ 1 eval: 0.7670\n",
      "INFO:tensorflow:global_step/sec: 0.709676\n",
      "2017-05-29 04:34:12.097161: step 13060, loss = 1.17 (309.7 examples/sec; 0.827 sec/batch)\n",
      "2017-05-29 04:34:21.805003: step 13070, loss = 1.22 (263.7 examples/sec; 0.971 sec/batch)\n",
      "2017-05-29 04:34:31.725380: step 13080, loss = 1.14 (258.1 examples/sec; 0.992 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 04:34:41.807886: step 13090, loss = 1.08 (253.9 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 04:34:51.678365: step 13100, loss = 1.25 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 04:35:01.561120: step 13110, loss = 1.25 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 04:35:11.410738: step 13120, loss = 1.27 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 04:35:21.262345: step 13130, loss = 1.19 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 04:35:31.130234: step 13140, loss = 1.19 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 04:35:40.955893: step 13150, loss = 1.16 (260.5 examples/sec; 0.983 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.913058\n",
      "2017-05-29 04:36:01.157847: step 13160, loss = 1.21 (126.7 examples/sec; 2.020 sec/batch)\n",
      "2017-05-29 04:36:10.838353: step 13170, loss = 1.07 (264.4 examples/sec; 0.968 sec/batch)\n",
      "2017-05-29 04:36:20.730350: step 13180, loss = 1.23 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 04:36:30.621839: step 13190, loss = 1.23 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 04:36:40.628477: step 13200, loss = 1.04 (255.8 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 04:36:50.453961: step 13210, loss = 1.20 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 04:37:00.373530: step 13220, loss = 1.31 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 04:37:10.270738: step 13230, loss = 1.19 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 04:37:20.096104: step 13240, loss = 1.23 (260.6 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 04:37:29.883982: step 13250, loss = 1.17 (261.5 examples/sec; 0.979 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.916924\n",
      "2017-05-29 04:37:50.229535: step 13260, loss = 1.24 (125.8 examples/sec; 2.035 sec/batch)\n",
      "2017-05-29 04:37:59.962159: step 13270, loss = 1.28 (263.0 examples/sec; 0.973 sec/batch)\n",
      "2017-05-29 04:38:09.727938: step 13280, loss = 1.14 (262.1 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 04:38:19.812307: step 13290, loss = 1.14 (253.9 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 04:38:29.592557: step 13300, loss = 1.19 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 04:38:39.412644: step 13310, loss = 1.17 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 04:38:49.328433: step 13320, loss = 1.19 (258.2 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 04:38:59.676261: step 13330, loss = 1.14 (247.4 examples/sec; 1.035 sec/batch)\n",
      "2017-05-29 04:39:09.596097: step 13340, loss = 1.10 (258.1 examples/sec; 0.992 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 12292 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 04:39:21.240544: step 13350, loss = 1.12 (219.8 examples/sec; 1.164 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.901153\n",
      "2017-05-29 04:39:41.324130: step 13360, loss = 1.17 (127.5 examples/sec; 2.008 sec/batch)\n",
      "2017-05-29 04:39:51.237343: step 13370, loss = 1.17 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 04:40:01.244387: step 13380, loss = 1.11 (255.8 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 04:40:11.108820: step 13390, loss = 1.06 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 04:40:20.915175: step 13400, loss = 1.28 (261.1 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 04:40:31.002729: step 13410, loss = 1.19 (253.8 examples/sec; 1.009 sec/batch)\n",
      "2017-05-29 04:40:40.855768: step 13420, loss = 1.04 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 04:40:50.832108: step 13430, loss = 1.06 (256.6 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 04:41:00.792429: step 13440, loss = 1.13 (257.0 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 04:41:10.716603: step 13450, loss = 1.15 (258.0 examples/sec; 0.992 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.903251\n",
      "2017-05-29 04:41:31.855309: step 13460, loss = 1.16 (121.1 examples/sec; 2.114 sec/batch)\n",
      "2017-05-29 04:41:41.567302: step 13470, loss = 1.15 (263.6 examples/sec; 0.971 sec/batch)\n",
      "2017-05-29 04:41:51.591509: step 13480, loss = 1.16 (255.4 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 04:42:01.333729: step 13490, loss = 1.27 (262.8 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 04:42:11.282639: step 13500, loss = 1.15 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 04:42:21.324142: step 13510, loss = 1.16 (254.9 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 04:42:31.059710: step 13520, loss = 1.09 (263.0 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 04:42:41.163144: step 13530, loss = 1.09 (253.4 examples/sec; 1.010 sec/batch)\n",
      "2017-05-29 04:42:51.000152: step 13540, loss = 1.07 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 04:43:00.955409: step 13550, loss = 1.06 (257.2 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 04:43:19.700813: step 13560, loss = 1.31 (136.6 examples/sec; 1.875 sec/batch)\n",
      "2017-05-29 04:43:27.024620: step 13570, loss = 1.33 (349.5 examples/sec; 0.732 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4133  Precision @ 1 train: 0.8072\n",
      "2017-05-29 04:43:33.943407: step 13580, loss = 1.12 (370.0 examples/sec; 0.692 sec/batch)\n",
      "2017-05-29 04:43:41.774704: step 13590, loss = 1.05 (326.9 examples/sec; 0.783 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3954  Precision @ 1 eval: 0.7723\n",
      "INFO:tensorflow:global_step/sec: 0.712551\n",
      "2017-05-29 04:43:48.761271: step 13600, loss = 1.18 (366.4 examples/sec; 0.699 sec/batch)\n",
      "2017-05-29 04:43:58.701701: step 13610, loss = 1.27 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 04:44:08.650067: step 13620, loss = 1.08 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 04:44:18.687948: step 13630, loss = 1.24 (255.0 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 04:44:28.573562: step 13640, loss = 1.13 (259.0 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 04:44:38.633976: step 13650, loss = 1.08 (254.5 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 04:44:48.908040: step 13660, loss = 1.07 (249.2 examples/sec; 1.027 sec/batch)\n",
      "2017-05-29 04:44:58.803136: step 13670, loss = 1.12 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 04:45:08.596032: step 13680, loss = 1.25 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 04:45:18.305787: step 13690, loss = 1.10 (263.7 examples/sec; 0.971 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.904989\n",
      "2017-05-29 04:45:39.258786: step 13700, loss = 1.25 (122.2 examples/sec; 2.095 sec/batch)\n",
      "2017-05-29 04:45:48.466245: step 13710, loss = 1.17 (278.0 examples/sec; 0.921 sec/batch)\n",
      "2017-05-29 04:45:58.170935: step 13720, loss = 1.17 (263.8 examples/sec; 0.970 sec/batch)\n",
      "2017-05-29 04:46:08.170450: step 13730, loss = 1.19 (256.0 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 04:46:18.118097: step 13740, loss = 1.15 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 04:46:28.029085: step 13750, loss = 1.21 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 04:46:37.878051: step 13760, loss = 1.31 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 04:46:48.235858: step 13770, loss = 1.11 (247.2 examples/sec; 1.036 sec/batch)\n",
      "2017-05-29 04:46:58.121051: step 13780, loss = 1.14 (259.0 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 04:47:08.037715: step 13790, loss = 1.20 (258.2 examples/sec; 0.992 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.906802\n",
      "2017-05-29 04:47:29.539437: step 13800, loss = 1.17 (119.1 examples/sec; 2.150 sec/batch)\n",
      "2017-05-29 04:47:38.669186: step 13810, loss = 1.21 (280.4 examples/sec; 0.913 sec/batch)\n",
      "2017-05-29 04:47:48.393771: step 13820, loss = 1.14 (263.3 examples/sec; 0.972 sec/batch)\n",
      "2017-05-29 04:47:58.369394: step 13830, loss = 1.12 (256.6 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 04:48:08.249471: step 13840, loss = 1.07 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 04:48:18.181041: step 13850, loss = 1.18 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 04:48:28.030201: step 13860, loss = 1.13 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 04:48:37.788230: step 13870, loss = 1.06 (262.3 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 04:48:47.681821: step 13880, loss = 1.12 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 04:48:57.461545: step 13890, loss = 1.23 (261.8 examples/sec; 0.978 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 12800 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.894103\n",
      "2017-05-29 04:49:21.381066: step 13900, loss = 1.19 (107.0 examples/sec; 2.392 sec/batch)\n",
      "2017-05-29 04:49:30.723558: step 13910, loss = 1.10 (274.0 examples/sec; 0.934 sec/batch)\n",
      "2017-05-29 04:49:40.679025: step 13920, loss = 1.03 (257.1 examples/sec; 0.996 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 04:49:50.523518: step 13930, loss = 1.29 (260.0 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 04:50:00.384806: step 13940, loss = 1.13 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 04:50:10.355697: step 13950, loss = 1.11 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 04:50:20.167492: step 13960, loss = 1.17 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 04:50:30.054679: step 13970, loss = 1.19 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 04:50:40.172142: step 13980, loss = 1.05 (253.0 examples/sec; 1.012 sec/batch)\n",
      "2017-05-29 04:50:50.252092: step 13990, loss = 1.23 (254.0 examples/sec; 1.008 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.909742\n",
      "2017-05-29 04:51:11.304003: step 14000, loss = 1.25 (121.6 examples/sec; 2.105 sec/batch)\n",
      "2017-05-29 04:51:20.592251: step 14010, loss = 1.10 (275.6 examples/sec; 0.929 sec/batch)\n",
      "2017-05-29 04:51:30.517927: step 14020, loss = 1.05 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 04:51:40.462931: step 14030, loss = 1.22 (257.4 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 04:51:50.360882: step 14040, loss = 1.27 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 04:52:00.322281: step 14050, loss = 1.04 (257.0 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 04:52:10.236353: step 14060, loss = 1.15 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 04:52:20.519410: step 14070, loss = 1.19 (249.0 examples/sec; 1.028 sec/batch)\n",
      "2017-05-29 04:52:30.429040: step 14080, loss = 1.17 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 04:52:40.256111: step 14090, loss = 1.24 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 04:52:59.562841: step 14100, loss = 1.29 (132.6 examples/sec; 1.931 sec/batch)\n",
      "2017-05-29 04:53:06.856495: step 14110, loss = 1.09 (351.0 examples/sec; 0.729 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4138  Precision @ 1 train: 0.8082\n",
      "2017-05-29 04:53:13.980281: step 14120, loss = 1.11 (359.4 examples/sec; 0.712 sec/batch)\n",
      "2017-05-29 04:53:20.791114: step 14130, loss = 1.22 (375.9 examples/sec; 0.681 sec/batch)\n",
      "2017-05-29 04:53:27.813880: step 14140, loss = 1.10 (364.5 examples/sec; 0.702 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3935  Precision @ 1 eval: 0.7686\n",
      "INFO:tensorflow:global_step/sec: 0.717451\n",
      "2017-05-29 04:53:36.548140: step 14150, loss = 1.14 (293.1 examples/sec; 0.873 sec/batch)\n",
      "2017-05-29 04:53:46.392068: step 14160, loss = 1.16 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 04:53:56.238402: step 14170, loss = 1.18 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 04:54:06.366788: step 14180, loss = 1.21 (252.8 examples/sec; 1.013 sec/batch)\n",
      "2017-05-29 04:54:16.266406: step 14190, loss = 1.27 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 04:54:26.115578: step 14200, loss = 1.10 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 04:54:36.020770: step 14210, loss = 1.24 (258.5 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 04:54:46.035790: step 14220, loss = 1.19 (255.6 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 04:54:55.943824: step 14230, loss = 1.16 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 04:55:05.803883: step 14240, loss = 1.24 (259.6 examples/sec; 0.986 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.915354\n",
      "2017-05-29 04:55:25.235525: step 14250, loss = 1.13 (131.7 examples/sec; 1.943 sec/batch)\n",
      "2017-05-29 04:55:35.094585: step 14260, loss = 1.20 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 04:55:44.943590: step 14270, loss = 1.00 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 04:55:54.932240: step 14280, loss = 1.03 (256.3 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 04:56:04.858676: step 14290, loss = 1.18 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 04:56:14.737409: step 14300, loss = 1.09 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 04:56:24.576385: step 14310, loss = 1.18 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 04:56:34.385187: step 14320, loss = 1.17 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 04:56:44.157222: step 14330, loss = 1.13 (262.0 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 04:56:54.151475: step 14340, loss = 1.07 (256.1 examples/sec; 0.999 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.915454\n",
      "2017-05-29 04:57:14.653449: step 14350, loss = 1.15 (124.9 examples/sec; 2.050 sec/batch)\n",
      "2017-05-29 04:57:24.494552: step 14360, loss = 1.08 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 04:57:34.341285: step 14370, loss = 1.10 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 04:57:44.311594: step 14380, loss = 1.14 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 04:57:54.238189: step 14390, loss = 1.16 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 04:58:04.150328: step 14400, loss = 1.25 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 04:58:14.097401: step 14410, loss = 1.08 (257.4 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 04:58:23.986529: step 14420, loss = 1.07 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 04:58:33.858806: step 14430, loss = 1.24 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 04:58:43.817304: step 14440, loss = 1.08 (257.1 examples/sec; 0.996 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.904614\n",
      "2017-05-29 04:59:05.137743: step 14450, loss = 1.13 (120.1 examples/sec; 2.132 sec/batch)\n",
      "2017-05-29 04:59:15.060151: step 14460, loss = 1.00 (258.0 examples/sec; 0.992 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 13319 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 04:59:27.363183: step 14470, loss = 1.09 (208.1 examples/sec; 1.230 sec/batch)\n",
      "2017-05-29 04:59:37.337036: step 14480, loss = 1.06 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 04:59:47.194305: step 14490, loss = 1.11 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 04:59:57.358700: step 14500, loss = 1.21 (251.9 examples/sec; 1.016 sec/batch)\n",
      "2017-05-29 05:00:07.262379: step 14510, loss = 1.11 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 05:00:17.123253: step 14520, loss = 1.10 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 05:00:26.981055: step 14530, loss = 1.09 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 05:00:36.742257: step 14540, loss = 1.10 (262.3 examples/sec; 0.976 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.88335\n",
      "2017-05-29 05:00:58.391230: step 14550, loss = 1.13 (118.3 examples/sec; 2.165 sec/batch)\n",
      "2017-05-29 05:01:08.194385: step 14560, loss = 1.14 (261.1 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 05:01:18.233735: step 14570, loss = 1.19 (255.0 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 05:01:28.006411: step 14580, loss = 1.00 (262.0 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 05:01:38.001824: step 14590, loss = 1.13 (256.1 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 05:01:48.030340: step 14600, loss = 1.01 (255.3 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 05:01:57.857311: step 14610, loss = 0.99 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 05:02:07.684093: step 14620, loss = 1.11 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 05:02:17.426347: step 14630, loss = 1.11 (262.8 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 05:02:27.242855: step 14640, loss = 1.17 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 05:02:44.573429: step 14650, loss = 1.17 (147.7 examples/sec; 1.733 sec/batch)\n",
      "2017-05-29 05:02:51.998355: step 14660, loss = 1.10 (344.8 examples/sec; 0.742 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4048  Precision @ 1 train: 0.7906\n",
      "2017-05-29 05:02:59.459689: step 14670, loss = 1.12 (343.1 examples/sec; 0.746 sec/batch)\n",
      "2017-05-29 05:03:06.487039: step 14680, loss = 1.12 (364.3 examples/sec; 0.703 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3863  Precision @ 1 eval: 0.7545\n",
      "INFO:tensorflow:global_step/sec: 0.717912\n",
      "2017-05-29 05:03:14.153805: step 14690, loss = 1.03 (333.9 examples/sec; 0.767 sec/batch)\n",
      "2017-05-29 05:03:23.957948: step 14700, loss = 1.08 (261.1 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 05:03:33.961809: step 14710, loss = 1.04 (255.9 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 05:03:43.682195: step 14720, loss = 1.15 (263.4 examples/sec; 0.972 sec/batch)\n",
      "2017-05-29 05:03:53.653677: step 14730, loss = 1.19 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 05:04:03.409855: step 14740, loss = 1.29 (262.4 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 05:04:13.284304: step 14750, loss = 1.25 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 05:04:23.103949: step 14760, loss = 1.13 (260.7 examples/sec; 0.982 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 05:04:32.903224: step 14770, loss = 1.13 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 05:04:42.668520: step 14780, loss = 1.16 (262.2 examples/sec; 0.977 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.908681\n",
      "2017-05-29 05:05:03.909890: step 14790, loss = 1.21 (120.5 examples/sec; 2.124 sec/batch)\n",
      "2017-05-29 05:05:13.483192: step 14800, loss = 1.13 (267.4 examples/sec; 0.957 sec/batch)\n",
      "2017-05-29 05:05:23.304672: step 14810, loss = 1.15 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 05:05:33.113083: step 14820, loss = 1.25 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 05:05:43.029334: step 14830, loss = 1.01 (258.2 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 05:05:52.940163: step 14840, loss = 1.15 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 05:06:02.748751: step 14850, loss = 1.17 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 05:06:12.508747: step 14860, loss = 0.96 (262.3 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 05:06:22.323765: step 14870, loss = 1.13 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 05:06:32.098200: step 14880, loss = 1.11 (261.9 examples/sec; 0.977 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.919201\n",
      "2017-05-29 05:06:52.695563: step 14890, loss = 1.03 (124.3 examples/sec; 2.060 sec/batch)\n",
      "2017-05-29 05:07:02.375751: step 14900, loss = 1.19 (264.5 examples/sec; 0.968 sec/batch)\n",
      "2017-05-29 05:07:12.231569: step 14910, loss = 1.15 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 05:07:22.109035: step 14920, loss = 1.13 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 05:07:32.064706: step 14930, loss = 1.27 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 05:07:41.839554: step 14940, loss = 1.02 (261.9 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 05:07:51.678705: step 14950, loss = 1.21 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 05:08:01.516409: step 14960, loss = 1.18 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 05:08:11.473354: step 14970, loss = 1.23 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 05:08:21.286890: step 14980, loss = 1.06 (260.9 examples/sec; 0.981 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.908658\n",
      "2017-05-29 05:08:42.783378: step 14990, loss = 1.22 (119.1 examples/sec; 2.150 sec/batch)\n",
      "2017-05-29 05:08:52.150415: step 15000, loss = 1.24 (273.3 examples/sec; 0.937 sec/batch)\n",
      "2017-05-29 05:09:02.106506: step 15010, loss = 1.16 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 05:09:12.028591: step 15020, loss = 1.13 (258.0 examples/sec; 0.992 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 13839 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 05:09:23.744334: step 15030, loss = 1.14 (218.5 examples/sec; 1.172 sec/batch)\n",
      "2017-05-29 05:09:33.804795: step 15040, loss = 1.11 (254.5 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 05:09:43.755301: step 15050, loss = 1.15 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 05:09:53.489567: step 15060, loss = 1.08 (263.0 examples/sec; 0.973 sec/batch)\n",
      "2017-05-29 05:10:03.524919: step 15070, loss = 0.98 (255.1 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 05:10:13.458401: step 15080, loss = 1.08 (257.7 examples/sec; 0.993 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.8983\n",
      "2017-05-29 05:10:34.127368: step 15090, loss = 1.14 (123.9 examples/sec; 2.067 sec/batch)\n",
      "2017-05-29 05:10:43.679485: step 15100, loss = 1.17 (268.0 examples/sec; 0.955 sec/batch)\n",
      "2017-05-29 05:10:53.501123: step 15110, loss = 1.20 (260.6 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 05:11:03.444109: step 15120, loss = 1.08 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 05:11:13.282650: step 15130, loss = 1.15 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 05:11:23.263354: step 15140, loss = 1.04 (256.5 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 05:11:33.128620: step 15150, loss = 0.97 (259.5 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 05:11:43.208856: step 15160, loss = 1.16 (254.0 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 05:11:53.174658: step 15170, loss = 1.06 (256.9 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 05:12:03.104784: step 15180, loss = 1.23 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 05:12:23.800052: step 15190, loss = 1.29 (123.7 examples/sec; 2.070 sec/batch)\n",
      "2017-05-29 05:12:30.976481: step 15200, loss = 1.10 (356.7 examples/sec; 0.718 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4179  Precision @ 1 train: 0.8162\n",
      "2017-05-29 05:12:37.699474: step 15210, loss = 1.28 (380.8 examples/sec; 0.672 sec/batch)\n",
      "2017-05-29 05:12:44.765718: step 15220, loss = 1.01 (362.3 examples/sec; 0.707 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4055  Precision @ 1 eval: 0.7920\n",
      "2017-05-29 05:12:52.578606: step 15230, loss = 1.01 (327.7 examples/sec; 0.781 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.705854\n",
      "2017-05-29 05:13:02.048925: step 15240, loss = 1.14 (270.3 examples/sec; 0.947 sec/batch)\n",
      "2017-05-29 05:13:11.838395: step 15250, loss = 1.11 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 05:13:21.689311: step 15260, loss = 1.13 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 05:13:31.683993: step 15270, loss = 1.00 (256.1 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 05:13:41.536561: step 15280, loss = 1.08 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 05:13:51.481150: step 15290, loss = 1.15 (257.4 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 05:14:01.397181: step 15300, loss = 1.15 (258.2 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 05:14:11.368325: step 15310, loss = 1.21 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 05:14:21.472946: step 15320, loss = 1.08 (253.3 examples/sec; 1.010 sec/batch)\n",
      "2017-05-29 05:14:31.637435: step 15330, loss = 1.17 (251.9 examples/sec; 1.016 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.906054\n",
      "2017-05-29 05:14:51.733204: step 15340, loss = 1.18 (127.4 examples/sec; 2.010 sec/batch)\n",
      "2017-05-29 05:15:01.483841: step 15350, loss = 1.10 (262.5 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 05:15:11.173635: step 15360, loss = 1.06 (264.2 examples/sec; 0.969 sec/batch)\n",
      "2017-05-29 05:15:20.949955: step 15370, loss = 1.22 (261.9 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 05:15:30.873424: step 15380, loss = 1.10 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 05:15:40.887432: step 15390, loss = 1.29 (255.6 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 05:15:50.792334: step 15400, loss = 1.25 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 05:16:00.635828: step 15410, loss = 1.15 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 05:16:10.702379: step 15420, loss = 1.11 (254.3 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 05:16:20.549318: step 15430, loss = 1.07 (260.0 examples/sec; 0.985 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.91324\n",
      "2017-05-29 05:16:41.268344: step 15440, loss = 1.15 (123.6 examples/sec; 2.072 sec/batch)\n",
      "2017-05-29 05:16:51.070914: step 15450, loss = 1.06 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 05:17:00.929155: step 15460, loss = 1.32 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 05:17:10.871993: step 15470, loss = 1.18 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 05:17:20.864469: step 15480, loss = 1.16 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 05:17:30.787049: step 15490, loss = 1.11 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 05:17:40.782017: step 15500, loss = 1.00 (256.1 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 05:17:50.828106: step 15510, loss = 1.19 (254.8 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 05:18:00.644785: step 15520, loss = 1.13 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 05:18:10.560932: step 15530, loss = 1.06 (258.2 examples/sec; 0.992 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.898035\n",
      "2017-05-29 05:18:32.553539: step 15540, loss = 1.27 (116.4 examples/sec; 2.199 sec/batch)\n",
      "2017-05-29 05:18:42.490211: step 15550, loss = 1.23 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 05:18:52.297725: step 15560, loss = 1.08 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 05:19:02.162023: step 15570, loss = 1.14 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 05:19:12.235849: step 15580, loss = 1.01 (254.1 examples/sec; 1.007 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 14355 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 05:19:23.304681: step 15590, loss = 1.08 (231.3 examples/sec; 1.107 sec/batch)\n",
      "2017-05-29 05:19:33.354099: step 15600, loss = 1.19 (254.7 examples/sec; 1.005 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 05:19:43.299897: step 15610, loss = 1.17 (257.4 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 05:19:53.162336: step 15620, loss = 1.17 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 05:20:03.222419: step 15630, loss = 1.11 (254.5 examples/sec; 1.006 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.90547\n",
      "2017-05-29 05:20:23.051820: step 15640, loss = 1.10 (129.1 examples/sec; 1.983 sec/batch)\n",
      "2017-05-29 05:20:33.057695: step 15650, loss = 1.35 (255.8 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 05:20:43.017426: step 15660, loss = 1.12 (257.0 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 05:20:52.924183: step 15670, loss = 1.15 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 05:21:02.744149: step 15680, loss = 1.17 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 05:21:12.590363: step 15690, loss = 1.25 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 05:21:22.631877: step 15700, loss = 1.06 (254.9 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 05:21:32.480608: step 15710, loss = 1.14 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 05:21:42.252503: step 15720, loss = 1.13 (262.0 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 05:21:52.328234: step 15730, loss = 1.17 (254.1 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 05:22:10.472062: step 15740, loss = 1.01 (141.1 examples/sec; 1.814 sec/batch)\n",
      "2017-05-29 05:22:17.625923: step 15750, loss = 1.15 (357.8 examples/sec; 0.715 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4186  Precision @ 1 train: 0.8176\n",
      "2017-05-29 05:22:24.401168: step 15760, loss = 1.15 (377.8 examples/sec; 0.678 sec/batch)\n",
      "2017-05-29 05:22:32.151152: step 15770, loss = 1.18 (330.3 examples/sec; 0.775 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4007  Precision @ 1 eval: 0.7826\n",
      "INFO:tensorflow:global_step/sec: 0.70979\n",
      "2017-05-29 05:22:40.593976: step 15780, loss = 1.09 (303.2 examples/sec; 0.844 sec/batch)\n",
      "2017-05-29 05:22:50.357502: step 15790, loss = 1.07 (262.2 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 05:23:00.440361: step 15800, loss = 1.02 (253.9 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 05:23:10.329309: step 15810, loss = 1.08 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 05:23:20.158001: step 15820, loss = 1.13 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 05:23:30.215512: step 15830, loss = 1.20 (254.5 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 05:23:40.039209: step 15840, loss = 1.14 (260.6 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 05:23:50.187786: step 15850, loss = 1.03 (252.3 examples/sec; 1.015 sec/batch)\n",
      "2017-05-29 05:24:00.135052: step 15860, loss = 1.11 (257.4 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 05:24:10.068465: step 15870, loss = 1.02 (257.7 examples/sec; 0.993 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.90205\n",
      "2017-05-29 05:24:31.084274: step 15880, loss = 1.05 (121.8 examples/sec; 2.102 sec/batch)\n",
      "2017-05-29 05:24:40.795390: step 15890, loss = 1.20 (263.6 examples/sec; 0.971 sec/batch)\n",
      "2017-05-29 05:24:50.824707: step 15900, loss = 1.09 (255.3 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 05:25:00.708937: step 15910, loss = 1.14 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 05:25:10.559616: step 15920, loss = 1.08 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 05:25:20.361173: step 15930, loss = 1.11 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 05:25:30.316624: step 15940, loss = 1.32 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 05:25:40.250861: step 15950, loss = 1.07 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 05:25:50.106955: step 15960, loss = 1.10 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 05:26:00.138632: step 15970, loss = 1.03 (255.2 examples/sec; 1.003 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.915311\n",
      "2017-05-29 05:26:20.280471: step 15980, loss = 1.17 (127.1 examples/sec; 2.014 sec/batch)\n",
      "2017-05-29 05:26:30.089995: step 15990, loss = 1.07 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 05:26:40.165762: step 16000, loss = 1.13 (254.1 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 05:26:50.116479: step 16010, loss = 1.29 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 05:27:00.090428: step 16020, loss = 1.23 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 05:27:09.990549: step 16030, loss = 1.12 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 05:27:20.015413: step 16040, loss = 1.05 (255.4 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 05:27:30.116629: step 16050, loss = 1.09 (253.4 examples/sec; 1.010 sec/batch)\n",
      "2017-05-29 05:27:40.351579: step 16060, loss = 1.17 (250.1 examples/sec; 1.023 sec/batch)\n",
      "2017-05-29 05:27:50.193457: step 16070, loss = 1.05 (260.1 examples/sec; 0.984 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.915462\n",
      "2017-05-29 05:28:09.599583: step 16080, loss = 1.02 (131.9 examples/sec; 1.941 sec/batch)\n",
      "2017-05-29 05:28:19.433143: step 16090, loss = 1.17 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 05:28:29.353421: step 16100, loss = 1.06 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 05:28:39.297223: step 16110, loss = 1.08 (257.4 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 05:28:49.190513: step 16120, loss = 1.22 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 05:28:59.055547: step 16130, loss = 1.15 (259.5 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 05:29:08.959859: step 16140, loss = 1.20 (258.5 examples/sec; 0.990 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 14875 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 05:29:22.090980: step 16150, loss = 1.04 (195.0 examples/sec; 1.313 sec/batch)\n",
      "2017-05-29 05:29:31.439047: step 16160, loss = 1.23 (273.9 examples/sec; 0.935 sec/batch)\n",
      "2017-05-29 05:29:41.382931: step 16170, loss = 1.12 (257.4 examples/sec; 0.994 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.889269\n",
      "2017-05-29 05:30:01.907522: step 16180, loss = 1.03 (124.7 examples/sec; 2.052 sec/batch)\n",
      "2017-05-29 05:30:11.541738: step 16190, loss = 1.03 (265.7 examples/sec; 0.963 sec/batch)\n",
      "2017-05-29 05:30:21.300285: step 16200, loss = 1.05 (262.3 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 05:30:31.121965: step 16210, loss = 1.29 (260.6 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 05:30:41.051652: step 16220, loss = 1.21 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 05:30:50.861254: step 16230, loss = 1.15 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 05:31:00.838509: step 16240, loss = 1.16 (256.6 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 05:31:10.729330: step 16250, loss = 1.13 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 05:31:20.544581: step 16260, loss = 1.06 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 05:31:30.374782: step 16270, loss = 1.22 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 05:31:48.440806: step 16280, loss = 1.17 (141.7 examples/sec; 1.807 sec/batch)\n",
      "2017-05-29 05:31:55.961594: step 16290, loss = 1.25 (340.4 examples/sec; 0.752 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4182  Precision @ 1 train: 0.8168\n",
      "2017-05-29 05:32:02.729164: step 16300, loss = 1.08 (378.3 examples/sec; 0.677 sec/batch)\n",
      "2017-05-29 05:32:09.780215: step 16310, loss = 1.02 (363.1 examples/sec; 0.705 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3933  Precision @ 1 eval: 0.7682\n",
      "INFO:tensorflow:global_step/sec: 0.718902\n",
      "2017-05-29 05:32:17.544461: step 16320, loss = 1.05 (329.7 examples/sec; 0.776 sec/batch)\n",
      "2017-05-29 05:32:27.585921: step 16330, loss = 1.19 (254.9 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 05:32:37.306591: step 16340, loss = 1.26 (263.4 examples/sec; 0.972 sec/batch)\n",
      "2017-05-29 05:32:47.296905: step 16350, loss = 1.19 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 05:32:57.181303: step 16360, loss = 1.09 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 05:33:07.014719: step 16370, loss = 1.22 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 05:33:16.785046: step 16380, loss = 1.21 (262.0 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 05:33:26.854506: step 16390, loss = 1.15 (254.2 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 05:33:36.741179: step 16400, loss = 1.22 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 05:33:46.516304: step 16410, loss = 1.18 (261.9 examples/sec; 0.978 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.911128\n",
      "2017-05-29 05:34:07.299047: step 16420, loss = 1.23 (123.2 examples/sec; 2.078 sec/batch)\n",
      "2017-05-29 05:34:16.484318: step 16430, loss = 1.15 (278.7 examples/sec; 0.919 sec/batch)\n",
      "2017-05-29 05:34:26.450944: step 16440, loss = 1.09 (256.9 examples/sec; 0.997 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 05:34:36.205161: step 16450, loss = 1.10 (262.5 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 05:34:46.174261: step 16460, loss = 1.07 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 05:34:56.015555: step 16470, loss = 1.28 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 05:35:05.784858: step 16480, loss = 1.20 (262.0 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 05:35:15.580402: step 16490, loss = 1.01 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 05:35:25.386384: step 16500, loss = 1.06 (261.1 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 05:35:35.169472: step 16510, loss = 1.04 (261.7 examples/sec; 0.978 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.925103\n",
      "2017-05-29 05:35:55.395573: step 16520, loss = 1.12 (126.6 examples/sec; 2.023 sec/batch)\n",
      "2017-05-29 05:36:04.694746: step 16530, loss = 1.06 (275.3 examples/sec; 0.930 sec/batch)\n",
      "2017-05-29 05:36:14.415349: step 16540, loss = 1.10 (263.4 examples/sec; 0.972 sec/batch)\n",
      "2017-05-29 05:36:24.427523: step 16550, loss = 1.11 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 05:36:34.257533: step 16560, loss = 1.17 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 05:36:44.078835: step 16570, loss = 1.18 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 05:36:53.971610: step 16580, loss = 1.24 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 05:37:03.714608: step 16590, loss = 1.19 (262.8 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 05:37:13.714805: step 16600, loss = 0.94 (256.0 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 05:37:23.557648: step 16610, loss = 1.10 (260.1 examples/sec; 0.984 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.922084\n",
      "2017-05-29 05:37:43.845234: step 16620, loss = 1.22 (126.2 examples/sec; 2.029 sec/batch)\n",
      "2017-05-29 05:37:53.035573: step 16630, loss = 1.26 (278.6 examples/sec; 0.919 sec/batch)\n",
      "2017-05-29 05:38:02.977201: step 16640, loss = 1.12 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 05:38:12.776515: step 16650, loss = 1.07 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 05:38:22.834674: step 16660, loss = 1.15 (254.5 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 05:38:32.622184: step 16670, loss = 1.08 (261.6 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 05:38:42.408382: step 16680, loss = 1.22 (261.6 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 05:38:52.264872: step 16690, loss = 1.19 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 05:39:02.122337: step 16700, loss = 1.10 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 05:39:12.232830: step 16710, loss = 1.16 (253.2 examples/sec; 1.011 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 15398 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.885096\n",
      "2017-05-29 05:39:36.828213: step 16720, loss = 1.06 (104.1 examples/sec; 2.460 sec/batch)\n",
      "2017-05-29 05:39:46.106682: step 16730, loss = 1.07 (275.9 examples/sec; 0.928 sec/batch)\n",
      "2017-05-29 05:39:55.981300: step 16740, loss = 1.14 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 05:40:05.837457: step 16750, loss = 1.14 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 05:40:15.759814: step 16760, loss = 0.96 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 05:40:25.636783: step 16770, loss = 1.08 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 05:40:35.368151: step 16780, loss = 1.20 (263.1 examples/sec; 0.973 sec/batch)\n",
      "2017-05-29 05:40:45.515880: step 16790, loss = 1.26 (252.3 examples/sec; 1.015 sec/batch)\n",
      "2017-05-29 05:40:55.460216: step 16800, loss = 1.10 (257.4 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 05:41:05.446016: step 16810, loss = 1.24 (256.4 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 05:41:25.086436: step 16820, loss = 0.99 (130.3 examples/sec; 1.964 sec/batch)\n",
      "2017-05-29 05:41:31.894362: step 16830, loss = 1.09 (376.0 examples/sec; 0.681 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4228  Precision @ 1 train: 0.8258\n",
      "2017-05-29 05:41:39.010644: step 16840, loss = 1.09 (359.7 examples/sec; 0.712 sec/batch)\n",
      "2017-05-29 05:41:46.531262: step 16850, loss = 1.09 (340.4 examples/sec; 0.752 sec/batch)\n",
      "2017-05-29 05:41:53.779610: step 16860, loss = 1.09 (353.2 examples/sec; 0.725 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4078  Precision @ 1 eval: 0.7965\n",
      "INFO:tensorflow:global_step/sec: 0.715726\n",
      "2017-05-29 05:42:02.404530: step 16870, loss = 1.00 (296.8 examples/sec; 0.862 sec/batch)\n",
      "2017-05-29 05:42:12.119545: step 16880, loss = 1.16 (263.5 examples/sec; 0.972 sec/batch)\n",
      "2017-05-29 05:42:22.344077: step 16890, loss = 1.12 (250.4 examples/sec; 1.022 sec/batch)\n",
      "2017-05-29 05:42:32.162853: step 16900, loss = 1.23 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 05:42:42.277199: step 16910, loss = 1.20 (253.1 examples/sec; 1.011 sec/batch)\n",
      "2017-05-29 05:42:52.299291: step 16920, loss = 1.24 (255.4 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 05:43:02.170179: step 16930, loss = 1.05 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 05:43:12.111405: step 16940, loss = 1.02 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 05:43:21.888647: step 16950, loss = 1.23 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 05:43:31.994705: step 16960, loss = 1.12 (253.3 examples/sec; 1.011 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.901764\n",
      "2017-05-29 05:43:52.796494: step 16970, loss = 1.23 (123.1 examples/sec; 2.080 sec/batch)\n",
      "2017-05-29 05:44:02.625333: step 16980, loss = 1.06 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 05:44:12.523896: step 16990, loss = 1.05 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 05:44:22.424378: step 17000, loss = 1.10 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 05:44:32.227463: step 17010, loss = 1.10 (261.1 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 05:44:42.238477: step 17020, loss = 1.24 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 05:44:52.192060: step 17030, loss = 1.12 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 05:45:02.116109: step 17040, loss = 1.22 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 05:45:12.107221: step 17050, loss = 1.28 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 05:45:22.010509: step 17060, loss = 1.15 (258.5 examples/sec; 0.990 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.919884\n",
      "2017-05-29 05:45:41.483470: step 17070, loss = 1.02 (131.5 examples/sec; 1.947 sec/batch)\n",
      "2017-05-29 05:45:51.290659: step 17080, loss = 1.07 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 05:46:01.203670: step 17090, loss = 1.10 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 05:46:11.080355: step 17100, loss = 1.15 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 05:46:21.015025: step 17110, loss = 1.09 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 05:46:30.811481: step 17120, loss = 1.02 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 05:46:40.862069: step 17130, loss = 1.09 (254.7 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 05:46:50.605461: step 17140, loss = 1.15 (262.7 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 05:47:00.676806: step 17150, loss = 1.12 (254.2 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 05:47:10.579599: step 17160, loss = 1.04 (258.5 examples/sec; 0.990 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.906682\n",
      "2017-05-29 05:47:31.802705: step 17170, loss = 1.16 (120.6 examples/sec; 2.122 sec/batch)\n",
      "2017-05-29 05:47:41.420765: step 17180, loss = 1.06 (266.2 examples/sec; 0.962 sec/batch)\n",
      "2017-05-29 05:47:51.324805: step 17190, loss = 1.05 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 05:48:01.215204: step 17200, loss = 1.04 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 05:48:11.104893: step 17210, loss = 1.14 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 05:48:20.959705: step 17220, loss = 1.04 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 05:48:30.738507: step 17230, loss = 0.97 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 05:48:40.781295: step 17240, loss = 1.08 (254.9 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 05:48:50.608874: step 17250, loss = 1.08 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 05:49:00.462134: step 17260, loss = 1.17 (259.8 examples/sec; 0.985 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.919917\n",
      "INFO:tensorflow:Saving checkpoints for 15906 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 05:49:22.363733: step 17270, loss = 1.18 (116.9 examples/sec; 2.190 sec/batch)\n",
      "2017-05-29 05:49:31.721613: step 17280, loss = 1.14 (273.6 examples/sec; 0.936 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 05:49:41.754117: step 17290, loss = 1.09 (255.2 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 05:49:51.593878: step 17300, loss = 1.22 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 05:50:01.487494: step 17310, loss = 1.14 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 05:50:11.723030: step 17320, loss = 1.07 (250.1 examples/sec; 1.024 sec/batch)\n",
      "2017-05-29 05:50:21.617406: step 17330, loss = 1.07 (258.7 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 05:50:31.430488: step 17340, loss = 1.01 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 05:50:41.430706: step 17350, loss = 1.01 (256.0 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 05:50:51.289347: step 17360, loss = 1.24 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 05:51:09.772070: step 17370, loss = 1.22 (138.5 examples/sec; 1.848 sec/batch)\n",
      "2017-05-29 05:51:16.822471: step 17380, loss = 1.06 (363.1 examples/sec; 0.705 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4195  Precision @ 1 train: 0.8193\n",
      "2017-05-29 05:51:23.592727: step 17390, loss = 1.10 (378.1 examples/sec; 0.677 sec/batch)\n",
      "2017-05-29 05:51:30.649737: step 17400, loss = 1.08 (362.8 examples/sec; 0.706 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3969  Precision @ 1 eval: 0.7752\n",
      "INFO:tensorflow:global_step/sec: 0.708518\n",
      "2017-05-29 05:51:38.295642: step 17410, loss = 1.09 (334.8 examples/sec; 0.765 sec/batch)\n",
      "2017-05-29 05:51:48.227519: step 17420, loss = 1.06 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 05:51:58.179101: step 17430, loss = 1.11 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 05:52:08.083987: step 17440, loss = 1.07 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 05:52:17.943893: step 17450, loss = 1.10 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 05:52:27.768970: step 17460, loss = 1.13 (260.6 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 05:52:37.693784: step 17470, loss = 1.04 (257.9 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 05:52:47.548298: step 17480, loss = 1.15 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 05:52:57.527689: step 17490, loss = 1.18 (256.5 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 05:53:07.524066: step 17500, loss = 1.24 (256.1 examples/sec; 1.000 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.920146\n",
      "2017-05-29 05:53:26.598904: step 17510, loss = 1.16 (134.2 examples/sec; 1.907 sec/batch)\n",
      "2017-05-29 05:53:36.249851: step 17520, loss = 1.01 (265.3 examples/sec; 0.965 sec/batch)\n",
      "2017-05-29 05:53:46.255127: step 17530, loss = 1.12 (255.9 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 05:53:56.198235: step 17540, loss = 1.12 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 05:54:06.244799: step 17550, loss = 1.26 (254.8 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 05:54:16.169753: step 17560, loss = 1.06 (257.9 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 05:54:26.018850: step 17570, loss = 1.02 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 05:54:35.930655: step 17580, loss = 1.08 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 05:54:45.819670: step 17590, loss = 1.04 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 05:54:55.634167: step 17600, loss = 1.03 (260.8 examples/sec; 0.981 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.902647\n",
      "2017-05-29 05:55:17.370139: step 17610, loss = 1.02 (117.8 examples/sec; 2.174 sec/batch)\n",
      "2017-05-29 05:55:26.817660: step 17620, loss = 1.20 (271.0 examples/sec; 0.945 sec/batch)\n",
      "2017-05-29 05:55:36.644991: step 17630, loss = 1.12 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 05:55:46.455274: step 17640, loss = 1.03 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 05:55:56.394010: step 17650, loss = 1.05 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 05:56:06.195777: step 17660, loss = 1.05 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 05:56:16.152942: step 17670, loss = 1.08 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 05:56:25.915096: step 17680, loss = 1.03 (262.2 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 05:56:35.901156: step 17690, loss = 1.16 (256.4 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 05:56:45.780437: step 17700, loss = 1.27 (259.1 examples/sec; 0.988 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.910642\n",
      "2017-05-29 05:57:07.257800: step 17710, loss = 1.33 (119.2 examples/sec; 2.148 sec/batch)\n",
      "2017-05-29 05:57:16.613030: step 17720, loss = 1.10 (273.6 examples/sec; 0.936 sec/batch)\n",
      "2017-05-29 05:57:26.579974: step 17730, loss = 1.15 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 05:57:36.392818: step 17740, loss = 1.16 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 05:57:46.351183: step 17750, loss = 1.13 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 05:57:56.250064: step 17760, loss = 1.04 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 05:58:06.083006: step 17770, loss = 1.13 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 05:58:15.968123: step 17780, loss = 1.09 (259.0 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 05:58:25.868878: step 17790, loss = 1.01 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 05:58:35.750674: step 17800, loss = 0.99 (259.1 examples/sec; 0.988 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.917856\n",
      "2017-05-29 05:58:56.151647: step 17810, loss = 1.17 (125.5 examples/sec; 2.040 sec/batch)\n",
      "2017-05-29 05:59:06.069606: step 17820, loss = 1.02 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 05:59:15.972818: step 17830, loss = 1.15 (258.5 examples/sec; 0.990 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 16427 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 05:59:26.968385: step 17840, loss = 1.05 (232.8 examples/sec; 1.100 sec/batch)\n",
      "2017-05-29 05:59:37.017524: step 17850, loss = 0.99 (254.7 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 05:59:46.852287: step 17860, loss = 1.08 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 05:59:56.861929: step 17870, loss = 1.13 (255.8 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 06:00:06.781350: step 17880, loss = 1.24 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 06:00:16.657853: step 17890, loss = 1.18 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 06:00:26.485132: step 17900, loss = 1.20 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 06:00:45.308007: step 17910, loss = 1.29 (136.0 examples/sec; 1.882 sec/batch)\n",
      "2017-05-29 06:00:52.866571: step 17920, loss = 1.05 (338.7 examples/sec; 0.756 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4276  Precision @ 1 train: 0.8352\n",
      "2017-05-29 06:00:59.630545: step 17930, loss = 1.04 (378.5 examples/sec; 0.676 sec/batch)\n",
      "2017-05-29 06:01:06.673638: step 17940, loss = 1.02 (363.5 examples/sec; 0.704 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4056  Precision @ 1 eval: 0.7922\n",
      "2017-05-29 06:01:13.702912: step 17950, loss = 1.16 (364.2 examples/sec; 0.703 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.711216\n",
      "2017-05-29 06:01:22.972553: step 17960, loss = 1.09 (276.2 examples/sec; 0.927 sec/batch)\n",
      "2017-05-29 06:01:32.754650: step 17970, loss = 1.00 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 06:01:42.766573: step 17980, loss = 1.16 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 06:01:52.705114: step 17990, loss = 1.01 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 06:02:02.520123: step 18000, loss = 1.13 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 06:02:12.492430: step 18010, loss = 1.06 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 06:02:22.327266: step 18020, loss = 1.04 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 06:02:32.215677: step 18030, loss = 1.07 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 06:02:42.098814: step 18040, loss = 1.14 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 06:02:51.971268: step 18050, loss = 1.09 (259.3 examples/sec; 0.987 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.903865\n",
      "2017-05-29 06:03:13.111918: step 18060, loss = 1.08 (121.1 examples/sec; 2.114 sec/batch)\n",
      "2017-05-29 06:03:22.861448: step 18070, loss = 1.12 (262.6 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 06:03:32.716679: step 18080, loss = 0.99 (259.8 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 06:03:42.562143: step 18090, loss = 1.25 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 06:03:52.528246: step 18100, loss = 1.21 (256.9 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 06:04:02.352406: step 18110, loss = 1.09 (260.6 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 06:04:12.243676: step 18120, loss = 1.14 (258.8 examples/sec; 0.989 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 06:04:22.214444: step 18130, loss = 1.15 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 06:04:32.241490: step 18140, loss = 1.20 (255.3 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 06:04:42.234662: step 18150, loss = 1.11 (256.2 examples/sec; 0.999 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.912624\n",
      "2017-05-29 06:05:02.595484: step 18160, loss = 1.10 (125.7 examples/sec; 2.036 sec/batch)\n",
      "2017-05-29 06:05:12.438887: step 18170, loss = 1.13 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 06:05:22.384842: step 18180, loss = 1.11 (257.4 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 06:05:32.325238: step 18190, loss = 1.22 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 06:05:42.186207: step 18200, loss = 1.09 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 06:05:52.088856: step 18210, loss = 1.01 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 06:06:02.061094: step 18220, loss = 0.99 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 06:06:11.936883: step 18230, loss = 1.06 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 06:06:21.622940: step 18240, loss = 1.08 (264.3 examples/sec; 0.969 sec/batch)\n",
      "2017-05-29 06:06:31.551811: step 18250, loss = 1.09 (257.8 examples/sec; 0.993 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.929239\n",
      "2017-05-29 06:06:50.532091: step 18260, loss = 1.13 (134.9 examples/sec; 1.898 sec/batch)\n",
      "2017-05-29 06:07:00.382488: step 18270, loss = 1.04 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 06:07:10.393587: step 18280, loss = 1.15 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 06:07:20.261570: step 18290, loss = 0.99 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 06:07:30.165471: step 18300, loss = 1.10 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 06:07:40.060762: step 18310, loss = 1.07 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 06:07:49.922460: step 18320, loss = 1.17 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 06:07:59.787984: step 18330, loss = 1.08 (259.5 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 06:08:09.548616: step 18340, loss = 1.22 (262.3 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 06:08:19.521169: step 18350, loss = 1.05 (256.7 examples/sec; 0.997 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.929255\n",
      "2017-05-29 06:08:37.910455: step 18360, loss = 1.12 (139.2 examples/sec; 1.839 sec/batch)\n",
      "2017-05-29 06:08:47.711587: step 18370, loss = 1.12 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 06:08:57.486912: step 18380, loss = 1.03 (261.9 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 06:09:07.651682: step 18390, loss = 1.12 (251.9 examples/sec; 1.016 sec/batch)\n",
      "2017-05-29 06:09:17.506384: step 18400, loss = 1.03 (259.8 examples/sec; 0.985 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 16952 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 06:09:28.381112: step 18410, loss = 1.21 (235.4 examples/sec; 1.087 sec/batch)\n",
      "2017-05-29 06:09:38.236865: step 18420, loss = 1.09 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 06:09:48.179534: step 18430, loss = 1.15 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 06:09:58.124532: step 18440, loss = 1.06 (257.4 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 06:10:07.966091: step 18450, loss = 1.20 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 06:10:26.697452: step 18460, loss = 1.14 (136.7 examples/sec; 1.873 sec/batch)\n",
      "2017-05-29 06:10:33.751646: step 18470, loss = 1.09 (362.9 examples/sec; 0.705 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4292  Precision @ 1 train: 0.8383\n",
      "2017-05-29 06:10:40.510260: step 18480, loss = 1.06 (378.8 examples/sec; 0.676 sec/batch)\n",
      "2017-05-29 06:10:47.575240: step 18490, loss = 1.13 (362.4 examples/sec; 0.706 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4063  Precision @ 1 eval: 0.7936\n",
      "INFO:tensorflow:global_step/sec: 0.708195\n",
      "2017-05-29 06:10:55.721191: step 18500, loss = 1.07 (314.3 examples/sec; 0.815 sec/batch)\n",
      "2017-05-29 06:11:05.574146: step 18510, loss = 1.05 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 06:11:15.441443: step 18520, loss = 0.98 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 06:11:25.340268: step 18530, loss = 1.11 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 06:11:35.235579: step 18540, loss = 1.17 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 06:11:44.997746: step 18550, loss = 0.98 (262.2 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 06:11:54.972200: step 18560, loss = 1.24 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 06:12:04.785851: step 18570, loss = 1.13 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 06:12:14.725673: step 18580, loss = 1.07 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 06:12:24.601978: step 18590, loss = 1.17 (259.2 examples/sec; 0.988 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.904386\n",
      "2017-05-29 06:12:45.788493: step 18600, loss = 1.10 (120.8 examples/sec; 2.119 sec/batch)\n",
      "2017-05-29 06:12:55.436482: step 18610, loss = 1.20 (265.3 examples/sec; 0.965 sec/batch)\n",
      "2017-05-29 06:13:05.378133: step 18620, loss = 1.08 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 06:13:15.307060: step 18630, loss = 1.00 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 06:13:25.228528: step 18640, loss = 1.17 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 06:13:35.376919: step 18650, loss = 1.22 (252.3 examples/sec; 1.015 sec/batch)\n",
      "2017-05-29 06:13:45.230624: step 18660, loss = 1.11 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 06:13:55.040951: step 18670, loss = 1.01 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 06:14:05.161322: step 18680, loss = 1.13 (253.0 examples/sec; 1.012 sec/batch)\n",
      "2017-05-29 06:14:14.978402: step 18690, loss = 1.15 (260.8 examples/sec; 0.982 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.923881\n",
      "2017-05-29 06:14:34.046390: step 18700, loss = 1.04 (134.3 examples/sec; 1.907 sec/batch)\n",
      "2017-05-29 06:14:43.799247: step 18710, loss = 1.15 (262.5 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 06:14:53.718422: step 18720, loss = 1.21 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 06:15:03.793769: step 18730, loss = 1.01 (254.1 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 06:15:13.756948: step 18740, loss = 1.05 (256.9 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 06:15:23.622462: step 18750, loss = 1.17 (259.5 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 06:15:33.455427: step 18760, loss = 1.32 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 06:15:43.269401: step 18770, loss = 1.10 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 06:15:53.349054: step 18780, loss = 1.09 (254.0 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 06:16:03.106711: step 18790, loss = 1.17 (262.4 examples/sec; 0.976 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.920671\n",
      "2017-05-29 06:16:22.670316: step 18800, loss = 1.09 (130.9 examples/sec; 1.956 sec/batch)\n",
      "2017-05-29 06:16:32.345115: step 18810, loss = 1.06 (264.6 examples/sec; 0.967 sec/batch)\n",
      "2017-05-29 06:16:42.297581: step 18820, loss = 1.18 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 06:16:52.202271: step 18830, loss = 1.10 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 06:17:02.013819: step 18840, loss = 1.13 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 06:17:11.869717: step 18850, loss = 1.20 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 06:17:21.835333: step 18860, loss = 1.13 (256.9 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 06:17:31.772377: step 18870, loss = 0.96 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 06:17:41.661971: step 18880, loss = 1.08 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 06:17:51.533549: step 18890, loss = 1.04 (259.3 examples/sec; 0.987 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.922396\n",
      "2017-05-29 06:18:11.103142: step 18900, loss = 1.16 (130.8 examples/sec; 1.957 sec/batch)\n",
      "2017-05-29 06:18:20.899958: step 18910, loss = 1.22 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 06:18:30.736434: step 18920, loss = 1.00 (260.3 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 06:18:40.603529: step 18930, loss = 1.14 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 06:18:50.432892: step 18940, loss = 1.14 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 06:19:00.317989: step 18950, loss = 1.02 (259.0 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 06:19:10.331602: step 18960, loss = 1.12 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 06:19:20.402431: step 18970, loss = 1.15 (254.2 examples/sec; 1.007 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 17476 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 06:19:33.241628: step 18980, loss = 1.26 (199.4 examples/sec; 1.284 sec/batch)\n",
      "2017-05-29 06:19:43.242065: step 18990, loss = 1.27 (256.0 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 06:20:02.330509: step 19000, loss = 1.11 (134.1 examples/sec; 1.909 sec/batch)\n",
      "2017-05-29 06:20:09.488206: step 19010, loss = 0.94 (357.7 examples/sec; 0.716 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4133  Precision @ 1 train: 0.8072\n",
      "2017-05-29 06:20:16.226564: step 19020, loss = 1.04 (379.9 examples/sec; 0.674 sec/batch)\n",
      "2017-05-29 06:20:23.282834: step 19030, loss = 1.13 (362.8 examples/sec; 0.706 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3937  Precision @ 1 eval: 0.7689\n",
      "INFO:tensorflow:global_step/sec: 0.7007\n",
      "2017-05-29 06:20:30.313221: step 19040, loss = 1.09 (364.1 examples/sec; 0.703 sec/batch)\n",
      "2017-05-29 06:20:40.144007: step 19050, loss = 1.03 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 06:20:49.944804: step 19060, loss = 1.10 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 06:20:59.862011: step 19070, loss = 1.25 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 06:21:09.767109: step 19080, loss = 1.04 (258.5 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 06:21:19.688765: step 19090, loss = 1.23 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 06:21:29.578814: step 19100, loss = 1.15 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 06:21:39.489301: step 19110, loss = 1.00 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 06:21:49.388031: step 19120, loss = 1.25 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 06:21:59.304351: step 19130, loss = 1.05 (258.2 examples/sec; 0.992 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.914686\n",
      "2017-05-29 06:22:19.640842: step 19140, loss = 1.22 (125.9 examples/sec; 2.034 sec/batch)\n",
      "2017-05-29 06:22:28.959073: step 19150, loss = 1.21 (274.7 examples/sec; 0.932 sec/batch)\n",
      "2017-05-29 06:22:38.860074: step 19160, loss = 1.15 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 06:22:48.725909: step 19170, loss = 1.07 (259.5 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 06:22:58.578970: step 19180, loss = 1.08 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 06:23:08.419139: step 19190, loss = 1.13 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 06:23:18.208803: step 19200, loss = 1.16 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 06:23:28.307975: step 19210, loss = 1.19 (253.5 examples/sec; 1.010 sec/batch)\n",
      "2017-05-29 06:23:38.175205: step 19220, loss = 1.21 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 06:23:48.100444: step 19230, loss = 1.08 (257.9 examples/sec; 0.993 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.908884\n",
      "2017-05-29 06:24:09.666195: step 19240, loss = 1.05 (118.7 examples/sec; 2.157 sec/batch)\n",
      "2017-05-29 06:24:18.837964: step 19250, loss = 1.03 (279.1 examples/sec; 0.917 sec/batch)\n",
      "2017-05-29 06:24:29.228617: step 19260, loss = 1.08 (246.4 examples/sec; 1.039 sec/batch)\n",
      "2017-05-29 06:24:39.042069: step 19270, loss = 1.03 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 06:24:49.005619: step 19280, loss = 1.10 (256.9 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 06:24:58.871699: step 19290, loss = 1.16 (259.5 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 06:25:08.720035: step 19300, loss = 1.05 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 06:25:18.556745: step 19310, loss = 0.93 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 06:25:28.389570: step 19320, loss = 1.13 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 06:25:38.433538: step 19330, loss = 1.09 (254.9 examples/sec; 1.004 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.902983\n",
      "2017-05-29 06:26:00.408538: step 19340, loss = 0.99 (116.5 examples/sec; 2.198 sec/batch)\n",
      "2017-05-29 06:26:09.702197: step 19350, loss = 0.88 (275.5 examples/sec; 0.929 sec/batch)\n",
      "2017-05-29 06:26:19.498380: step 19360, loss = 1.05 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 06:26:29.328232: step 19370, loss = 1.16 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 06:26:39.435870: step 19380, loss = 1.08 (253.3 examples/sec; 1.011 sec/batch)\n",
      "2017-05-29 06:26:49.282249: step 19390, loss = 1.01 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 06:26:59.163249: step 19400, loss = 1.05 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 06:27:09.056483: step 19410, loss = 1.08 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 06:27:18.951900: step 19420, loss = 1.01 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 06:27:28.797397: step 19430, loss = 1.29 (260.0 examples/sec; 0.985 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.908828\n",
      "2017-05-29 06:27:50.441346: step 19440, loss = 1.11 (118.3 examples/sec; 2.164 sec/batch)\n",
      "2017-05-29 06:27:59.718820: step 19450, loss = 1.00 (275.9 examples/sec; 0.928 sec/batch)\n",
      "2017-05-29 06:28:09.526744: step 19460, loss = 1.16 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 06:28:19.588336: step 19470, loss = 1.09 (254.4 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 06:28:29.537640: step 19480, loss = 1.01 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 06:28:39.456210: step 19490, loss = 1.10 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 06:28:49.212857: step 19500, loss = 1.17 (262.4 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 06:28:59.352594: step 19510, loss = 1.08 (252.5 examples/sec; 1.014 sec/batch)\n",
      "2017-05-29 06:29:09.273064: step 19520, loss = 1.00 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 06:29:19.138921: step 19530, loss = 1.10 (259.5 examples/sec; 0.987 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 17994 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 06:29:40.985725: step 19540, loss = 1.11 (117.2 examples/sec; 2.185 sec/batch)\n",
      "2017-05-29 06:29:47.647623: step 19550, loss = 1.09 (384.3 examples/sec; 0.666 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4240  Precision @ 1 train: 0.8281\n",
      "2017-05-29 06:29:54.719294: step 19560, loss = 0.93 (362.0 examples/sec; 0.707 sec/batch)\n",
      "2017-05-29 06:30:01.943798: step 19570, loss = 1.13 (354.3 examples/sec; 0.722 sec/batch)\n",
      "2017-05-29 06:30:09.463614: step 19580, loss = 1.02 (340.4 examples/sec; 0.752 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4007  Precision @ 1 eval: 0.7826\n",
      "INFO:tensorflow:global_step/sec: 0.705\n",
      "2017-05-29 06:30:18.201477: step 19590, loss = 1.16 (293.0 examples/sec; 0.874 sec/batch)\n",
      "2017-05-29 06:30:28.109734: step 19600, loss = 1.12 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 06:30:38.189002: step 19610, loss = 1.29 (254.0 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 06:30:47.971758: step 19620, loss = 1.24 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 06:30:57.869087: step 19630, loss = 1.07 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 06:31:07.853487: step 19640, loss = 0.93 (256.4 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 06:31:17.712634: step 19650, loss = 0.98 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 06:31:27.800695: step 19660, loss = 1.11 (253.8 examples/sec; 1.009 sec/batch)\n",
      "2017-05-29 06:31:37.685310: step 19670, loss = 1.16 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 06:31:47.549488: step 19680, loss = 1.04 (259.5 examples/sec; 0.986 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.898898\n",
      "2017-05-29 06:32:08.945902: step 19690, loss = 1.08 (119.6 examples/sec; 2.140 sec/batch)\n",
      "2017-05-29 06:32:18.727873: step 19700, loss = 1.08 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 06:32:28.562271: step 19710, loss = 1.06 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 06:32:38.485313: step 19720, loss = 1.12 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 06:32:48.415369: step 19730, loss = 1.10 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 06:32:58.313849: step 19740, loss = 1.10 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 06:33:08.192315: step 19750, loss = 1.03 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 06:33:18.111534: step 19760, loss = 1.21 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 06:33:27.951811: step 19770, loss = 1.24 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 06:33:38.003316: step 19780, loss = 1.15 (254.7 examples/sec; 1.005 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.906608\n",
      "2017-05-29 06:33:59.158077: step 19790, loss = 1.17 (121.0 examples/sec; 2.115 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 06:34:08.863615: step 19800, loss = 1.06 (263.8 examples/sec; 0.971 sec/batch)\n",
      "2017-05-29 06:34:18.933873: step 19810, loss = 1.15 (254.2 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 06:34:28.842684: step 19820, loss = 1.02 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 06:34:38.735088: step 19830, loss = 0.96 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 06:34:48.602521: step 19840, loss = 1.06 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 06:34:58.489644: step 19850, loss = 1.21 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 06:35:08.517130: step 19860, loss = 0.99 (255.3 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 06:35:18.404823: step 19870, loss = 1.04 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 06:35:28.277268: step 19880, loss = 1.15 (259.3 examples/sec; 0.987 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.927374\n",
      "2017-05-29 06:35:47.676403: step 19890, loss = 1.14 (132.0 examples/sec; 1.940 sec/batch)\n",
      "2017-05-29 06:35:57.457503: step 19900, loss = 1.01 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 06:36:07.406227: step 19910, loss = 1.11 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 06:36:17.283732: step 19920, loss = 1.09 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 06:36:27.285077: step 19930, loss = 1.07 (256.0 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 06:36:37.145136: step 19940, loss = 1.09 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 06:36:46.944392: step 19950, loss = 1.12 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 06:36:56.964407: step 19960, loss = 1.06 (255.5 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 06:37:06.811639: step 19970, loss = 1.11 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 06:37:16.922257: step 19980, loss = 1.19 (253.2 examples/sec; 1.011 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.921366\n",
      "2017-05-29 06:37:35.545363: step 19990, loss = 0.95 (137.5 examples/sec; 1.862 sec/batch)\n",
      "2017-05-29 06:37:45.308532: step 20000, loss = 1.03 (262.2 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 06:37:55.123492: step 20010, loss = 1.16 (260.8 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 06:38:05.194331: step 20020, loss = 1.07 (254.2 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 06:38:15.078688: step 20030, loss = 1.16 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 06:38:24.896856: step 20040, loss = 1.06 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 06:38:34.775237: step 20050, loss = 0.99 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 06:38:44.607661: step 20060, loss = 1.12 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 06:38:54.426361: step 20070, loss = 1.14 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 06:39:04.377130: step 20080, loss = 1.08 (257.3 examples/sec; 0.995 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 18500 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 06:39:25.526305: step 20090, loss = 1.19 (121.0 examples/sec; 2.115 sec/batch)\n",
      "2017-05-29 06:39:32.334407: step 20100, loss = 1.05 (376.0 examples/sec; 0.681 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4366  Precision @ 1 train: 0.8527\n",
      "2017-05-29 06:39:39.589450: step 20110, loss = 1.21 (352.9 examples/sec; 0.726 sec/batch)\n",
      "2017-05-29 06:39:47.868544: step 20120, loss = 0.98 (309.2 examples/sec; 0.828 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4125  Precision @ 1 eval: 0.8057\n",
      "INFO:tensorflow:global_step/sec: 0.694278\n",
      "2017-05-29 06:39:56.170447: step 20130, loss = 1.07 (308.4 examples/sec; 0.830 sec/batch)\n",
      "2017-05-29 06:40:06.034520: step 20140, loss = 1.08 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 06:40:15.814297: step 20150, loss = 1.07 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 06:40:25.910656: step 20160, loss = 1.10 (253.6 examples/sec; 1.010 sec/batch)\n",
      "2017-05-29 06:40:35.843287: step 20170, loss = 1.07 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 06:40:45.622544: step 20180, loss = 0.96 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 06:40:55.415434: step 20190, loss = 1.07 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 06:41:05.552042: step 20200, loss = 0.99 (252.5 examples/sec; 1.014 sec/batch)\n",
      "2017-05-29 06:41:15.488201: step 20210, loss = 0.91 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 06:41:25.272832: step 20220, loss = 0.96 (261.6 examples/sec; 0.978 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.900172\n",
      "2017-05-29 06:41:47.012848: step 20230, loss = 1.01 (117.8 examples/sec; 2.174 sec/batch)\n",
      "2017-05-29 06:41:56.402246: step 20240, loss = 1.17 (272.6 examples/sec; 0.939 sec/batch)\n",
      "2017-05-29 06:42:06.143615: step 20250, loss = 1.13 (262.8 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 06:42:16.160776: step 20260, loss = 1.15 (255.6 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 06:42:26.035900: step 20270, loss = 1.16 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 06:42:35.682013: step 20280, loss = 1.09 (265.4 examples/sec; 0.965 sec/batch)\n",
      "2017-05-29 06:42:45.855803: step 20290, loss = 1.05 (251.6 examples/sec; 1.017 sec/batch)\n",
      "2017-05-29 06:42:55.753092: step 20300, loss = 1.06 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 06:43:05.583591: step 20310, loss = 1.13 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 06:43:15.363900: step 20320, loss = 1.00 (261.8 examples/sec; 0.978 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.89949\n",
      "2017-05-29 06:43:38.106578: step 20330, loss = 1.11 (112.6 examples/sec; 2.274 sec/batch)\n",
      "2017-05-29 06:43:47.483033: step 20340, loss = 1.02 (273.0 examples/sec; 0.938 sec/batch)\n",
      "2017-05-29 06:43:57.412188: step 20350, loss = 1.00 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 06:44:07.181621: step 20360, loss = 1.10 (262.0 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 06:44:17.063419: step 20370, loss = 1.09 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 06:44:26.876335: step 20380, loss = 1.05 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 06:44:36.707011: step 20390, loss = 1.17 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 06:44:46.414240: step 20400, loss = 1.08 (263.7 examples/sec; 0.971 sec/batch)\n",
      "2017-05-29 06:44:56.407569: step 20410, loss = 1.08 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 06:45:06.200115: step 20420, loss = 1.02 (261.4 examples/sec; 0.979 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.922103\n",
      "2017-05-29 06:45:26.597173: step 20430, loss = 1.04 (125.5 examples/sec; 2.040 sec/batch)\n",
      "2017-05-29 06:45:36.319724: step 20440, loss = 1.12 (263.3 examples/sec; 0.972 sec/batch)\n",
      "2017-05-29 06:45:46.153874: step 20450, loss = 1.12 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 06:45:55.960094: step 20460, loss = 1.13 (261.1 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 06:46:05.760100: step 20470, loss = 1.06 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 06:46:15.577677: step 20480, loss = 1.00 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 06:46:25.536750: step 20490, loss = 1.02 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 06:46:35.334209: step 20500, loss = 1.14 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 06:46:45.186821: step 20510, loss = 1.07 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 06:46:55.091453: step 20520, loss = 1.12 (258.5 examples/sec; 0.990 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.909282\n",
      "2017-05-29 06:47:16.542008: step 20530, loss = 1.12 (119.3 examples/sec; 2.145 sec/batch)\n",
      "2017-05-29 06:47:26.062399: step 20540, loss = 0.95 (268.9 examples/sec; 0.952 sec/batch)\n",
      "2017-05-29 06:47:35.899077: step 20550, loss = 1.07 (260.3 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 06:47:45.657083: step 20560, loss = 0.98 (262.3 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 06:47:55.482776: step 20570, loss = 1.12 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 06:48:05.344354: step 20580, loss = 1.10 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 06:48:15.112861: step 20590, loss = 0.96 (262.1 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 06:48:25.239600: step 20600, loss = 1.08 (252.8 examples/sec; 1.013 sec/batch)\n",
      "2017-05-29 06:48:35.271879: step 20610, loss = 1.20 (255.2 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 06:48:45.069876: step 20620, loss = 1.06 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 06:49:03.648429: step 20630, loss = 1.15 (137.8 examples/sec; 1.858 sec/batch)\n",
      "2017-05-29 06:49:10.836867: step 20640, loss = 0.93 (356.1 examples/sec; 0.719 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4276  Precision @ 1 train: 0.8352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 06:49:18.404879: step 20650, loss = 1.06 (338.3 examples/sec; 0.757 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 19000 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 06:49:28.685342: step 20660, loss = 1.12 (249.0 examples/sec; 1.028 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4045  Precision @ 1 eval: 0.7900\n",
      "2017-05-29 06:49:35.859173: step 20670, loss = 1.07 (356.9 examples/sec; 0.717 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.702339\n",
      "2017-05-29 06:49:45.530948: step 20680, loss = 1.10 (264.7 examples/sec; 0.967 sec/batch)\n",
      "2017-05-29 06:49:55.416651: step 20690, loss = 1.18 (259.0 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 06:50:05.272667: step 20700, loss = 0.94 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 06:50:15.100044: step 20710, loss = 1.15 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 06:50:25.066670: step 20720, loss = 1.15 (256.9 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 06:50:34.963097: step 20730, loss = 1.04 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 06:50:45.137313: step 20740, loss = 1.16 (251.6 examples/sec; 1.017 sec/batch)\n",
      "2017-05-29 06:50:54.967453: step 20750, loss = 1.01 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 06:51:05.105249: step 20760, loss = 1.06 (252.5 examples/sec; 1.014 sec/batch)\n",
      "2017-05-29 06:51:15.019768: step 20770, loss = 1.13 (258.2 examples/sec; 0.991 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.898504\n",
      "2017-05-29 06:51:35.799534: step 20780, loss = 1.07 (123.2 examples/sec; 2.078 sec/batch)\n",
      "2017-05-29 06:51:45.527243: step 20790, loss = 0.96 (263.2 examples/sec; 0.973 sec/batch)\n",
      "2017-05-29 06:51:55.244254: step 20800, loss = 1.10 (263.5 examples/sec; 0.972 sec/batch)\n",
      "2017-05-29 06:52:05.216377: step 20810, loss = 1.08 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 06:52:15.210683: step 20820, loss = 1.13 (256.1 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 06:52:25.102408: step 20830, loss = 1.16 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 06:52:34.859239: step 20840, loss = 1.11 (262.4 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 06:52:44.839986: step 20850, loss = 1.11 (256.5 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 06:52:54.683647: step 20860, loss = 1.15 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 06:53:04.573003: step 20870, loss = 1.20 (258.9 examples/sec; 0.989 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.906213\n",
      "2017-05-29 06:53:26.169920: step 20880, loss = 1.16 (118.5 examples/sec; 2.160 sec/batch)\n",
      "2017-05-29 06:53:36.052516: step 20890, loss = 1.09 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 06:53:45.841125: step 20900, loss = 1.05 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 06:53:55.743207: step 20910, loss = 1.14 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 06:54:05.442038: step 20920, loss = 1.05 (263.9 examples/sec; 0.970 sec/batch)\n",
      "2017-05-29 06:54:15.486074: step 20930, loss = 1.16 (254.9 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 06:54:25.305260: step 20940, loss = 1.11 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 06:54:35.330361: step 20950, loss = 0.97 (255.4 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 06:54:45.239280: step 20960, loss = 1.06 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 06:54:55.075184: step 20970, loss = 1.12 (260.3 examples/sec; 0.984 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.924517\n",
      "2017-05-29 06:55:14.387582: step 20980, loss = 1.12 (132.6 examples/sec; 1.931 sec/batch)\n",
      "2017-05-29 06:55:24.170534: step 20990, loss = 1.09 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 06:55:33.986057: step 21000, loss = 1.01 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 06:55:43.894942: step 21010, loss = 1.12 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 06:55:53.651818: step 21020, loss = 1.14 (262.4 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 06:56:03.579165: step 21030, loss = 1.16 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 06:56:13.403186: step 21040, loss = 0.94 (260.6 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 06:56:23.284766: step 21050, loss = 0.97 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 06:56:33.115953: step 21060, loss = 1.06 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 06:56:43.131639: step 21070, loss = 1.16 (255.6 examples/sec; 1.002 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.928887\n",
      "2017-05-29 06:57:02.166099: step 21080, loss = 1.14 (134.5 examples/sec; 1.903 sec/batch)\n",
      "2017-05-29 06:57:12.089584: step 21090, loss = 1.07 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 06:57:21.912410: step 21100, loss = 1.12 (260.6 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 06:57:31.864070: step 21110, loss = 1.06 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 06:57:41.778325: step 21120, loss = 1.27 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 06:57:51.750064: step 21130, loss = 1.00 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 06:58:01.564709: step 21140, loss = 1.11 (260.8 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 06:58:11.382459: step 21150, loss = 1.07 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 06:58:21.074091: step 21160, loss = 1.15 (264.1 examples/sec; 0.969 sec/batch)\n",
      "2017-05-29 06:58:30.907644: step 21170, loss = 1.23 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 06:58:47.945523: step 21180, loss = 1.12 (150.3 examples/sec; 1.704 sec/batch)\n",
      "2017-05-29 06:58:55.546556: step 21190, loss = 0.99 (336.8 examples/sec; 0.760 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4275  Precision @ 1 train: 0.8350\n",
      "2017-05-29 06:59:02.321314: step 21200, loss = 1.07 (377.9 examples/sec; 0.677 sec/batch)\n",
      "2017-05-29 06:59:09.391071: step 21210, loss = 1.11 (362.1 examples/sec; 0.707 sec/batch)\n",
      "  Num examples: 5120  Num correct: 3990  Precision @ 1 eval: 0.7793\n",
      "INFO:tensorflow:global_step/sec: 0.720021\n",
      "2017-05-29 06:59:17.553215: step 21220, loss = 1.08 (313.6 examples/sec; 0.816 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 19511 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 06:59:28.696961: step 21230, loss = 1.04 (229.7 examples/sec; 1.114 sec/batch)\n",
      "2017-05-29 06:59:38.666036: step 21240, loss = 1.19 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 06:59:48.401091: step 21250, loss = 1.15 (263.0 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 06:59:58.418197: step 21260, loss = 1.02 (255.6 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 07:00:08.331719: step 21270, loss = 1.07 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 07:00:18.296074: step 21280, loss = 1.06 (256.9 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 07:00:28.831766: step 21290, loss = 1.00 (243.0 examples/sec; 1.054 sec/batch)\n",
      "2017-05-29 07:00:38.892913: step 21300, loss = 1.06 (254.4 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 07:00:48.754820: step 21310, loss = 1.00 (259.6 examples/sec; 0.986 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.89894\n",
      "2017-05-29 07:01:08.382319: step 21320, loss = 1.08 (130.4 examples/sec; 1.963 sec/batch)\n",
      "2017-05-29 07:01:18.111705: step 21330, loss = 1.11 (263.1 examples/sec; 0.973 sec/batch)\n",
      "2017-05-29 07:01:28.189551: step 21340, loss = 1.06 (254.0 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 07:01:38.059466: step 21350, loss = 1.10 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 07:01:47.933663: step 21360, loss = 1.01 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 07:01:57.966710: step 21370, loss = 1.05 (255.2 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 07:02:07.846835: step 21380, loss = 1.09 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 07:02:17.692734: step 21390, loss = 1.02 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 07:02:27.681283: step 21400, loss = 1.23 (256.3 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 07:02:37.573283: step 21410, loss = 1.01 (258.8 examples/sec; 0.989 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.927874\n",
      "2017-05-29 07:02:56.088627: step 21420, loss = 1.03 (138.3 examples/sec; 1.852 sec/batch)\n",
      "2017-05-29 07:03:05.780569: step 21430, loss = 1.25 (264.1 examples/sec; 0.969 sec/batch)\n",
      "2017-05-29 07:03:15.624888: step 21440, loss = 1.07 (260.0 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 07:03:25.394337: step 21450, loss = 1.24 (262.0 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 07:03:35.366597: step 21460, loss = 1.00 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 07:03:45.264649: step 21470, loss = 0.98 (258.6 examples/sec; 0.990 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 07:03:55.191616: step 21480, loss = 1.13 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 07:04:05.205923: step 21490, loss = 1.09 (255.6 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 07:04:15.194195: step 21500, loss = 1.15 (256.3 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 07:04:25.192116: step 21510, loss = 1.10 (256.1 examples/sec; 1.000 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.907615\n",
      "2017-05-29 07:04:46.239846: step 21520, loss = 1.00 (121.6 examples/sec; 2.105 sec/batch)\n",
      "2017-05-29 07:04:55.751359: step 21530, loss = 1.07 (269.1 examples/sec; 0.951 sec/batch)\n",
      "2017-05-29 07:05:05.789238: step 21540, loss = 0.99 (255.0 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 07:05:15.770974: step 21550, loss = 1.15 (256.5 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 07:05:25.719930: step 21560, loss = 1.29 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 07:05:35.510357: step 21570, loss = 1.15 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 07:05:45.596854: step 21580, loss = 0.95 (253.8 examples/sec; 1.009 sec/batch)\n",
      "2017-05-29 07:05:55.482367: step 21590, loss = 1.08 (259.0 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 07:06:05.373015: step 21600, loss = 1.10 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 07:06:15.264237: step 21610, loss = 1.05 (258.8 examples/sec; 0.989 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.921052\n",
      "2017-05-29 07:06:34.892713: step 21620, loss = 1.13 (130.4 examples/sec; 1.963 sec/batch)\n",
      "2017-05-29 07:06:44.794884: step 21630, loss = 1.21 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 07:06:54.593680: step 21640, loss = 1.07 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 07:07:04.386860: step 21650, loss = 0.96 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 07:07:14.200263: step 21660, loss = 1.00 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 07:07:24.044510: step 21670, loss = 0.98 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 07:07:34.115370: step 21680, loss = 1.05 (254.2 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 07:07:44.027163: step 21690, loss = 1.02 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 07:07:53.841820: step 21700, loss = 0.94 (260.8 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 07:08:03.823015: step 21710, loss = 1.07 (256.5 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 07:08:21.318755: step 21720, loss = 1.13 (146.3 examples/sec; 1.750 sec/batch)\n",
      "2017-05-29 07:08:28.455626: step 21730, loss = 1.02 (358.7 examples/sec; 0.714 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4352  Precision @ 1 train: 0.8500\n",
      "2017-05-29 07:08:35.214464: step 21740, loss = 1.00 (378.8 examples/sec; 0.676 sec/batch)\n",
      "2017-05-29 07:08:43.100458: step 21750, loss = 1.06 (324.6 examples/sec; 0.789 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4132  Precision @ 1 eval: 0.8070\n",
      "INFO:tensorflow:global_step/sec: 0.719813\n",
      "2017-05-29 07:08:50.344857: step 21760, loss = 1.13 (353.4 examples/sec; 0.724 sec/batch)\n",
      "2017-05-29 07:09:00.307873: step 21770, loss = 0.95 (257.0 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 07:09:10.153564: step 21780, loss = 1.27 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 07:09:19.920363: step 21790, loss = 1.12 (262.1 examples/sec; 0.977 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 20035 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 07:09:31.373819: step 21800, loss = 1.15 (223.5 examples/sec; 1.145 sec/batch)\n",
      "2017-05-29 07:09:41.409644: step 21810, loss = 0.95 (255.1 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 07:09:51.252359: step 21820, loss = 1.06 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 07:10:01.141287: step 21830, loss = 1.08 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 07:10:11.006335: step 21840, loss = 1.09 (259.5 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 07:10:20.749204: step 21850, loss = 1.12 (262.8 examples/sec; 0.974 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.914706\n",
      "2017-05-29 07:10:39.671165: step 21860, loss = 1.10 (135.3 examples/sec; 1.892 sec/batch)\n",
      "2017-05-29 07:10:48.956653: step 21870, loss = 1.10 (275.7 examples/sec; 0.929 sec/batch)\n",
      "2017-05-29 07:10:58.844537: step 21880, loss = 1.04 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 07:11:08.740437: step 21890, loss = 1.19 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 07:11:18.543015: step 21900, loss = 1.09 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 07:11:28.459298: step 21910, loss = 1.16 (258.2 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 07:11:38.311686: step 21920, loss = 1.14 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 07:11:48.194912: step 21930, loss = 1.06 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 07:11:58.068147: step 21940, loss = 1.14 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 07:12:08.331548: step 21950, loss = 1.17 (249.4 examples/sec; 1.026 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.903729\n",
      "2017-05-29 07:12:30.321988: step 21960, loss = 1.09 (116.4 examples/sec; 2.199 sec/batch)\n",
      "2017-05-29 07:12:39.554115: step 21970, loss = 1.07 (277.3 examples/sec; 0.923 sec/batch)\n",
      "2017-05-29 07:12:49.418705: step 21980, loss = 1.08 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 07:12:59.281240: step 21990, loss = 1.13 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 07:13:09.201489: step 22000, loss = 1.16 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 07:13:19.333293: step 22010, loss = 1.19 (252.7 examples/sec; 1.013 sec/batch)\n",
      "2017-05-29 07:13:29.356104: step 22020, loss = 1.16 (255.4 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 07:13:39.169729: step 22030, loss = 1.19 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 07:13:49.010323: step 22040, loss = 1.18 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 07:13:59.009643: step 22050, loss = 1.03 (256.0 examples/sec; 1.000 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.909501\n",
      "2017-05-29 07:14:20.273785: step 22060, loss = 1.08 (120.4 examples/sec; 2.126 sec/batch)\n",
      "2017-05-29 07:14:29.459597: step 22070, loss = 1.04 (278.7 examples/sec; 0.919 sec/batch)\n",
      "2017-05-29 07:14:39.384343: step 22080, loss = 1.10 (257.9 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 07:14:49.271509: step 22090, loss = 1.14 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 07:14:59.037710: step 22100, loss = 1.02 (262.1 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 07:15:09.032945: step 22110, loss = 1.16 (256.1 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 07:15:18.839518: step 22120, loss = 1.12 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 07:15:28.707338: step 22130, loss = 1.11 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 07:15:38.893278: step 22140, loss = 1.10 (251.3 examples/sec; 1.019 sec/batch)\n",
      "2017-05-29 07:15:48.801722: step 22150, loss = 1.18 (258.4 examples/sec; 0.991 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.910559\n",
      "2017-05-29 07:16:10.095444: step 22160, loss = 1.10 (120.2 examples/sec; 2.129 sec/batch)\n",
      "2017-05-29 07:16:19.388474: step 22170, loss = 1.11 (275.5 examples/sec; 0.929 sec/batch)\n",
      "2017-05-29 07:16:29.334436: step 22180, loss = 1.05 (257.4 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 07:16:39.219522: step 22190, loss = 0.91 (259.0 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 07:16:49.245371: step 22200, loss = 1.01 (255.3 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 07:16:59.153866: step 22210, loss = 1.01 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 07:17:08.904957: step 22220, loss = 1.08 (262.5 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 07:17:18.871502: step 22230, loss = 0.93 (256.9 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 07:17:28.716687: step 22240, loss = 0.90 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 07:17:38.541732: step 22250, loss = 1.16 (260.6 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 07:17:58.938354: step 22260, loss = 1.21 (125.5 examples/sec; 2.040 sec/batch)\n",
      "2017-05-29 07:18:05.902898: step 22270, loss = 0.96 (367.6 examples/sec; 0.696 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4254  Precision @ 1 train: 0.8309\n",
      "2017-05-29 07:18:12.994061: step 22280, loss = 0.98 (361.0 examples/sec; 0.709 sec/batch)\n",
      "2017-05-29 07:18:19.714067: step 22290, loss = 1.12 (381.0 examples/sec; 0.672 sec/batch)\n",
      "2017-05-29 07:18:26.809798: step 22300, loss = 1.07 (360.8 examples/sec; 0.710 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4026  Precision @ 1 eval: 0.7863\n",
      "INFO:tensorflow:global_step/sec: 0.716579\n",
      "2017-05-29 07:18:35.524528: step 22310, loss = 1.08 (293.8 examples/sec; 0.871 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 07:18:45.572251: step 22320, loss = 1.07 (254.8 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 07:18:55.405861: step 22330, loss = 1.05 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 07:19:05.347125: step 22340, loss = 1.12 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 07:19:15.242087: step 22350, loss = 1.07 (258.7 examples/sec; 0.989 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 20556 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 07:19:29.705493: step 22360, loss = 1.05 (177.0 examples/sec; 1.446 sec/batch)\n",
      "2017-05-29 07:19:39.051901: step 22370, loss = 1.11 (273.9 examples/sec; 0.935 sec/batch)\n",
      "2017-05-29 07:19:49.090714: step 22380, loss = 1.12 (255.0 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 07:19:58.940523: step 22390, loss = 1.16 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 07:20:09.150782: step 22400, loss = 1.12 (250.7 examples/sec; 1.021 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.886098\n",
      "2017-05-29 07:20:27.995468: step 22410, loss = 1.22 (135.8 examples/sec; 1.884 sec/batch)\n",
      "2017-05-29 07:20:37.738884: step 22420, loss = 1.19 (262.7 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 07:20:47.570051: step 22430, loss = 1.06 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 07:20:57.429249: step 22440, loss = 1.16 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 07:21:07.306178: step 22450, loss = 1.16 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 07:21:17.314494: step 22460, loss = 1.18 (255.8 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 07:21:27.179031: step 22470, loss = 1.06 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 07:21:37.029998: step 22480, loss = 1.04 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 07:21:47.043331: step 22490, loss = 1.02 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 07:21:56.926739: step 22500, loss = 1.06 (259.0 examples/sec; 0.988 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.917697\n",
      "2017-05-29 07:22:16.828921: step 22510, loss = 1.20 (128.6 examples/sec; 1.990 sec/batch)\n",
      "2017-05-29 07:22:26.667796: step 22520, loss = 1.06 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 07:22:36.457312: step 22530, loss = 1.07 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 07:22:46.250109: step 22540, loss = 1.11 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 07:22:56.270687: step 22550, loss = 1.05 (255.5 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 07:23:06.240543: step 22560, loss = 1.05 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 07:23:15.986300: step 22570, loss = 1.00 (262.7 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 07:23:26.169566: step 22580, loss = 1.16 (251.4 examples/sec; 1.018 sec/batch)\n",
      "2017-05-29 07:23:36.163454: step 22590, loss = 1.22 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 07:23:45.972715: step 22600, loss = 1.19 (261.0 examples/sec; 0.981 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.90793\n",
      "2017-05-29 07:24:06.992719: step 22610, loss = 1.06 (121.8 examples/sec; 2.102 sec/batch)\n",
      "2017-05-29 07:24:16.669246: step 22620, loss = 1.14 (264.6 examples/sec; 0.968 sec/batch)\n",
      "2017-05-29 07:24:26.457940: step 22630, loss = 1.12 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 07:24:36.383886: step 22640, loss = 1.00 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 07:24:46.196805: step 22650, loss = 0.84 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 07:24:56.100604: step 22660, loss = 1.21 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 07:25:05.983514: step 22670, loss = 0.97 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 07:25:15.949949: step 22680, loss = 1.29 (256.9 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 07:25:25.817045: step 22690, loss = 1.07 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 07:25:35.822457: step 22700, loss = 1.17 (255.9 examples/sec; 1.001 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.923367\n",
      "2017-05-29 07:25:55.367635: step 22710, loss = 1.14 (131.0 examples/sec; 1.955 sec/batch)\n",
      "2017-05-29 07:26:05.209751: step 22720, loss = 0.98 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 07:26:15.164526: step 22730, loss = 1.07 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 07:26:24.914313: step 22740, loss = 0.97 (262.6 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 07:26:35.011879: step 22750, loss = 1.08 (253.5 examples/sec; 1.010 sec/batch)\n",
      "2017-05-29 07:26:44.830664: step 22760, loss = 1.12 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 07:26:54.558939: step 22770, loss = 1.07 (263.2 examples/sec; 0.973 sec/batch)\n",
      "2017-05-29 07:27:04.700179: step 22780, loss = 1.05 (252.4 examples/sec; 1.014 sec/batch)\n",
      "2017-05-29 07:27:14.675238: step 22790, loss = 0.95 (256.6 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 07:27:24.568246: step 22800, loss = 1.11 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 07:27:42.713866: step 22810, loss = 1.05 (141.1 examples/sec; 1.815 sec/batch)\n",
      "2017-05-29 07:27:49.790251: step 22820, loss = 1.00 (361.8 examples/sec; 0.708 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4282  Precision @ 1 train: 0.8363\n",
      "2017-05-29 07:27:56.577683: step 22830, loss = 1.01 (377.2 examples/sec; 0.679 sec/batch)\n",
      "2017-05-29 07:28:03.664906: step 22840, loss = 1.06 (361.2 examples/sec; 0.709 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4034  Precision @ 1 eval: 0.7879\n",
      "INFO:tensorflow:global_step/sec: 0.717507\n",
      "2017-05-29 07:28:11.243495: step 22850, loss = 1.02 (337.8 examples/sec; 0.758 sec/batch)\n",
      "2017-05-29 07:28:21.103394: step 22860, loss = 1.03 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 07:28:30.993804: step 22870, loss = 1.02 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 07:28:40.789209: step 22880, loss = 1.21 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 07:28:50.743315: step 22890, loss = 1.03 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 07:29:00.578464: step 22900, loss = 1.14 (260.3 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 07:29:10.360230: step 22910, loss = 1.19 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 07:29:20.356076: step 22920, loss = 1.00 (256.1 examples/sec; 1.000 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 21077 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 07:29:35.447201: step 22930, loss = 1.03 (169.6 examples/sec; 1.509 sec/batch)\n",
      "2017-05-29 07:29:45.874230: step 22940, loss = 1.09 (245.5 examples/sec; 1.043 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.880014\n",
      "2017-05-29 07:30:04.559661: step 22950, loss = 1.06 (137.0 examples/sec; 1.869 sec/batch)\n",
      "2017-05-29 07:30:14.006689: step 22960, loss = 1.11 (271.0 examples/sec; 0.945 sec/batch)\n",
      "2017-05-29 07:30:23.835062: step 22970, loss = 1.10 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 07:30:33.660505: step 22980, loss = 1.06 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 07:30:43.401047: step 22990, loss = 1.00 (262.8 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 07:30:53.272803: step 23000, loss = 1.11 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 07:31:03.225315: step 23010, loss = 1.17 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 07:31:13.121821: step 23020, loss = 1.07 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 07:31:22.924607: step 23030, loss = 1.10 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 07:31:32.804768: step 23040, loss = 1.15 (259.1 examples/sec; 0.988 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.936803\n",
      "2017-05-29 07:31:51.355077: step 23050, loss = 0.99 (138.0 examples/sec; 1.855 sec/batch)\n",
      "2017-05-29 07:32:00.933290: step 23060, loss = 1.08 (267.3 examples/sec; 0.958 sec/batch)\n",
      "2017-05-29 07:32:10.693612: step 23070, loss = 1.03 (262.3 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 07:32:20.666002: step 23080, loss = 1.07 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 07:32:30.551172: step 23090, loss = 1.10 (259.0 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 07:32:40.367244: step 23100, loss = 0.99 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 07:32:50.147259: step 23110, loss = 1.05 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 07:33:00.207097: step 23120, loss = 1.10 (254.5 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 07:33:10.039588: step 23130, loss = 1.11 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 07:33:19.970182: step 23140, loss = 1.00 (257.8 examples/sec; 0.993 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.910563\n",
      "2017-05-29 07:33:41.139545: step 23150, loss = 1.04 (120.9 examples/sec; 2.117 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 07:33:50.573953: step 23160, loss = 1.00 (271.3 examples/sec; 0.943 sec/batch)\n",
      "2017-05-29 07:34:00.344585: step 23170, loss = 1.04 (262.0 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 07:34:10.165404: step 23180, loss = 1.17 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 07:34:20.199503: step 23190, loss = 1.11 (255.1 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 07:34:29.947917: step 23200, loss = 1.13 (262.6 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 07:34:40.026628: step 23210, loss = 1.11 (254.0 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 07:34:49.796591: step 23220, loss = 0.82 (262.0 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 07:34:59.641122: step 23230, loss = 0.97 (260.0 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 07:35:09.516378: step 23240, loss = 1.00 (259.2 examples/sec; 0.988 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.913854\n",
      "2017-05-29 07:35:30.769621: step 23250, loss = 1.01 (120.5 examples/sec; 2.125 sec/batch)\n",
      "2017-05-29 07:35:40.373673: step 23260, loss = 1.15 (266.6 examples/sec; 0.960 sec/batch)\n",
      "2017-05-29 07:35:50.130848: step 23270, loss = 1.03 (262.4 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 07:36:00.220618: step 23280, loss = 1.09 (253.7 examples/sec; 1.009 sec/batch)\n",
      "2017-05-29 07:36:10.173832: step 23290, loss = 1.06 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 07:36:20.101506: step 23300, loss = 0.93 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 07:36:29.910462: step 23310, loss = 1.13 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 07:36:39.765126: step 23320, loss = 1.03 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 07:36:49.619515: step 23330, loss = 0.95 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 07:36:59.394815: step 23340, loss = 1.03 (261.9 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 07:37:19.649855: step 23350, loss = 1.03 (126.4 examples/sec; 2.026 sec/batch)\n",
      "2017-05-29 07:37:26.747270: step 23360, loss = 1.12 (360.7 examples/sec; 0.710 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4322  Precision @ 1 train: 0.8441\n",
      "2017-05-29 07:37:33.457547: step 23370, loss = 1.11 (381.5 examples/sec; 0.671 sec/batch)\n",
      "2017-05-29 07:37:40.518458: step 23380, loss = 1.00 (362.6 examples/sec; 0.706 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4114  Precision @ 1 eval: 0.8035\n",
      "2017-05-29 07:37:47.546322: step 23390, loss = 1.06 (364.3 examples/sec; 0.703 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.714334\n",
      "2017-05-29 07:37:56.751616: step 23400, loss = 1.17 (278.1 examples/sec; 0.921 sec/batch)\n",
      "2017-05-29 07:38:06.532705: step 23410, loss = 1.07 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 07:38:16.359700: step 23420, loss = 1.10 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 07:38:26.315357: step 23430, loss = 1.10 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 07:38:36.192634: step 23440, loss = 0.96 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 07:38:46.130071: step 23450, loss = 1.05 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 07:38:56.043584: step 23460, loss = 1.01 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 07:39:05.809714: step 23470, loss = 1.03 (262.1 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 07:39:15.665893: step 23480, loss = 1.01 (259.7 examples/sec; 0.986 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 21598 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 07:39:27.821166: step 23490, loss = 0.92 (210.6 examples/sec; 1.216 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.911075\n",
      "2017-05-29 07:39:46.031022: step 23500, loss = 0.90 (140.6 examples/sec; 1.821 sec/batch)\n",
      "2017-05-29 07:39:55.851398: step 23510, loss = 1.00 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 07:40:05.673919: step 23520, loss = 0.97 (260.6 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 07:40:15.684797: step 23530, loss = 1.12 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 07:40:25.573934: step 23540, loss = 1.11 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 07:40:35.393468: step 23550, loss = 1.18 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 07:40:45.473381: step 23560, loss = 1.10 (254.0 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 07:40:55.337986: step 23570, loss = 1.08 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 07:41:05.312130: step 23580, loss = 1.03 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 07:41:15.117094: step 23590, loss = 1.00 (261.1 examples/sec; 0.980 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.907969\n",
      "2017-05-29 07:41:36.058824: step 23600, loss = 0.99 (122.2 examples/sec; 2.094 sec/batch)\n",
      "2017-05-29 07:41:45.854893: step 23610, loss = 1.08 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 07:41:55.737292: step 23620, loss = 1.11 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 07:42:05.536192: step 23630, loss = 0.91 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 07:42:15.525200: step 23640, loss = 1.14 (256.3 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 07:42:25.475839: step 23650, loss = 1.19 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 07:42:35.607860: step 23660, loss = 1.02 (252.7 examples/sec; 1.013 sec/batch)\n",
      "2017-05-29 07:42:45.652181: step 23670, loss = 1.15 (254.9 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 07:42:55.524476: step 23680, loss = 1.17 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 07:43:05.383080: step 23690, loss = 1.00 (259.7 examples/sec; 0.986 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.926483\n",
      "2017-05-29 07:43:24.100091: step 23700, loss = 1.10 (136.8 examples/sec; 1.872 sec/batch)\n",
      "2017-05-29 07:43:34.174624: step 23710, loss = 0.98 (254.1 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 07:43:44.049734: step 23720, loss = 0.99 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 07:43:53.893905: step 23730, loss = 1.16 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 07:44:03.762554: step 23740, loss = 1.06 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 07:44:13.690438: step 23750, loss = 1.14 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 07:44:23.663463: step 23760, loss = 1.00 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 07:44:33.521098: step 23770, loss = 0.98 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 07:44:43.374254: step 23780, loss = 1.07 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 07:44:53.358898: step 23790, loss = 1.16 (256.4 examples/sec; 0.998 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.904502\n",
      "2017-05-29 07:45:14.548896: step 23800, loss = 1.09 (120.8 examples/sec; 2.119 sec/batch)\n",
      "2017-05-29 07:45:24.329071: step 23810, loss = 1.11 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 07:45:34.300199: step 23820, loss = 0.93 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 07:45:44.145816: step 23830, loss = 1.03 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 07:45:54.141841: step 23840, loss = 0.90 (256.1 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 07:46:04.123571: step 23850, loss = 1.08 (256.5 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 07:46:14.092524: step 23860, loss = 0.96 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 07:46:23.981243: step 23870, loss = 1.06 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 07:46:33.839895: step 23880, loss = 1.16 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 07:46:43.722979: step 23890, loss = 1.24 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 07:47:02.310051: step 23900, loss = 1.03 (137.7 examples/sec; 1.859 sec/batch)\n",
      "2017-05-29 07:47:09.395139: step 23910, loss = 1.11 (361.3 examples/sec; 0.709 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4333  Precision @ 1 train: 0.8463\n",
      "2017-05-29 07:47:16.165622: step 23920, loss = 1.20 (378.1 examples/sec; 0.677 sec/batch)\n",
      "2017-05-29 07:47:23.260691: step 23930, loss = 1.17 (360.8 examples/sec; 0.710 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4153  Precision @ 1 eval: 0.8111\n",
      "INFO:tensorflow:global_step/sec: 0.71369\n",
      "2017-05-29 07:47:31.468194: step 23940, loss = 1.15 (311.9 examples/sec; 0.821 sec/batch)\n",
      "2017-05-29 07:47:41.256361: step 23950, loss = 1.07 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 07:47:51.169580: step 23960, loss = 1.02 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 07:48:01.190335: step 23970, loss = 0.97 (255.5 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 07:48:11.156931: step 23980, loss = 0.93 (256.9 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 07:48:21.182115: step 23990, loss = 0.97 (255.4 examples/sec; 1.003 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 07:48:31.029620: step 24000, loss = 1.24 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 07:48:40.993518: step 24010, loss = 0.98 (256.9 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 07:48:50.940964: step 24020, loss = 1.17 (257.4 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 07:49:00.861308: step 24030, loss = 0.99 (258.1 examples/sec; 0.992 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.897977\n",
      "2017-05-29 07:49:22.222093: step 24040, loss = 1.19 (119.8 examples/sec; 2.136 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 22108 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 07:49:33.771831: step 24050, loss = 1.11 (221.7 examples/sec; 1.155 sec/batch)\n",
      "2017-05-29 07:49:43.676790: step 24060, loss = 0.92 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 07:49:53.602816: step 24070, loss = 1.00 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 07:50:03.495725: step 24080, loss = 0.98 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 07:50:13.425017: step 24090, loss = 1.09 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 07:50:23.241187: step 24100, loss = 1.08 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 07:50:33.196922: step 24110, loss = 1.10 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 07:50:43.125473: step 24120, loss = 1.01 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 07:50:53.021840: step 24130, loss = 1.02 (258.7 examples/sec; 0.990 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.89186\n",
      "2017-05-29 07:51:14.386001: step 24140, loss = 0.99 (119.8 examples/sec; 2.136 sec/batch)\n",
      "2017-05-29 07:51:24.084502: step 24150, loss = 1.13 (264.0 examples/sec; 0.970 sec/batch)\n",
      "2017-05-29 07:51:34.025380: step 24160, loss = 1.11 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 07:51:43.919973: step 24170, loss = 1.15 (258.7 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 07:51:53.924545: step 24180, loss = 1.06 (255.9 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 07:52:03.777109: step 24190, loss = 1.04 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 07:52:13.910860: step 24200, loss = 1.09 (252.6 examples/sec; 1.013 sec/batch)\n",
      "2017-05-29 07:52:23.845522: step 24210, loss = 1.01 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 07:52:33.701914: step 24220, loss = 1.11 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 07:52:43.615129: step 24230, loss = 0.98 (258.2 examples/sec; 0.991 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.913727\n",
      "2017-05-29 07:53:03.811613: step 24240, loss = 0.97 (126.8 examples/sec; 2.020 sec/batch)\n",
      "2017-05-29 07:53:13.646779: step 24250, loss = 1.12 (260.3 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 07:53:23.587649: step 24260, loss = 1.14 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 07:53:33.354627: step 24270, loss = 1.15 (262.1 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 07:53:43.396574: step 24280, loss = 0.95 (254.9 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 07:53:53.374378: step 24290, loss = 1.07 (256.6 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 07:54:03.353939: step 24300, loss = 1.10 (256.5 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 07:54:13.456264: step 24310, loss = 1.11 (253.4 examples/sec; 1.010 sec/batch)\n",
      "2017-05-29 07:54:23.363807: step 24320, loss = 1.13 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 07:54:33.239994: step 24330, loss = 1.07 (259.2 examples/sec; 0.988 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.908842\n",
      "2017-05-29 07:54:53.831323: step 24340, loss = 1.05 (124.3 examples/sec; 2.059 sec/batch)\n",
      "2017-05-29 07:55:03.602481: step 24350, loss = 0.99 (262.0 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 07:55:13.352699: step 24360, loss = 1.08 (262.6 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 07:55:23.164815: step 24370, loss = 1.04 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 07:55:33.268497: step 24380, loss = 1.13 (253.4 examples/sec; 1.010 sec/batch)\n",
      "2017-05-29 07:55:43.136183: step 24390, loss = 0.94 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 07:55:52.951115: step 24400, loss = 1.11 (260.8 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 07:56:03.021464: step 24410, loss = 1.03 (254.2 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 07:56:12.829781: step 24420, loss = 0.98 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 07:56:22.722834: step 24430, loss = 1.12 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 07:56:43.201607: step 24440, loss = 1.00 (125.0 examples/sec; 2.048 sec/batch)\n",
      "2017-05-29 07:56:50.216635: step 24450, loss = 0.82 (364.9 examples/sec; 0.702 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4378  Precision @ 1 train: 0.8551\n",
      "2017-05-29 07:56:56.916740: step 24460, loss = 1.13 (382.1 examples/sec; 0.670 sec/batch)\n",
      "2017-05-29 07:57:03.950773: step 24470, loss = 0.98 (363.9 examples/sec; 0.703 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4099  Precision @ 1 eval: 0.8006\n",
      "INFO:tensorflow:global_step/sec: 0.711254\n",
      "2017-05-29 07:57:10.962776: step 24480, loss = 1.10 (365.1 examples/sec; 0.701 sec/batch)\n",
      "2017-05-29 07:57:20.847033: step 24490, loss = 0.96 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 07:57:30.665242: step 24500, loss = 1.04 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 07:57:40.472981: step 24510, loss = 1.13 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 07:57:50.391925: step 24520, loss = 1.22 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 07:58:00.173021: step 24530, loss = 1.19 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 07:58:10.093654: step 24540, loss = 1.14 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 07:58:19.952417: step 24550, loss = 1.05 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 07:58:29.807163: step 24560, loss = 1.11 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 07:58:39.720497: step 24570, loss = 1.13 (258.2 examples/sec; 0.991 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.920709\n",
      "2017-05-29 07:58:59.578812: step 24580, loss = 0.99 (128.9 examples/sec; 1.986 sec/batch)\n",
      "2017-05-29 07:59:09.016480: step 24590, loss = 1.05 (271.3 examples/sec; 0.944 sec/batch)\n",
      "2017-05-29 07:59:18.767459: step 24600, loss = 1.02 (262.5 examples/sec; 0.975 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 22628 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 07:59:30.001269: step 24610, loss = 1.03 (227.9 examples/sec; 1.123 sec/batch)\n",
      "2017-05-29 07:59:39.795654: step 24620, loss = 1.08 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 07:59:49.684052: step 24630, loss = 1.05 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 07:59:59.473155: step 24640, loss = 0.97 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 08:00:09.518738: step 24650, loss = 1.12 (254.8 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 08:00:19.291756: step 24660, loss = 1.03 (261.9 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 08:00:29.367606: step 24670, loss = 1.03 (254.1 examples/sec; 1.008 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.918444\n",
      "2017-05-29 08:00:48.454800: step 24680, loss = 1.04 (134.1 examples/sec; 1.909 sec/batch)\n",
      "2017-05-29 08:00:57.631729: step 24690, loss = 1.09 (279.0 examples/sec; 0.918 sec/batch)\n",
      "2017-05-29 08:01:07.572877: step 24700, loss = 1.01 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 08:01:17.453663: step 24710, loss = 1.06 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 08:01:27.339094: step 24720, loss = 0.97 (259.0 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 08:01:37.264068: step 24730, loss = 1.08 (257.9 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 08:01:47.155999: step 24740, loss = 1.12 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 08:01:56.959875: step 24750, loss = 1.18 (261.1 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 08:02:06.801722: step 24760, loss = 1.08 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 08:02:16.568070: step 24770, loss = 1.23 (262.1 examples/sec; 0.977 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.932116\n",
      "2017-05-29 08:02:35.737321: step 24780, loss = 0.91 (133.5 examples/sec; 1.917 sec/batch)\n",
      "2017-05-29 08:02:44.945175: step 24790, loss = 1.12 (278.0 examples/sec; 0.921 sec/batch)\n",
      "2017-05-29 08:02:54.748658: step 24800, loss = 1.03 (261.1 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 08:03:04.574074: step 24810, loss = 1.26 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 08:03:14.410337: step 24820, loss = 1.11 (260.3 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 08:03:24.319770: step 24830, loss = 1.04 (258.3 examples/sec; 0.991 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 08:03:34.123137: step 24840, loss = 1.01 (261.1 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 08:03:44.009948: step 24850, loss = 1.02 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 08:03:53.922028: step 24860, loss = 1.03 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 08:04:03.903495: step 24870, loss = 1.04 (256.5 examples/sec; 0.998 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.913306\n",
      "2017-05-29 08:04:25.230429: step 24880, loss = 1.12 (120.0 examples/sec; 2.133 sec/batch)\n",
      "2017-05-29 08:04:34.413906: step 24890, loss = 1.20 (278.8 examples/sec; 0.918 sec/batch)\n",
      "2017-05-29 08:04:44.248686: step 24900, loss = 1.04 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 08:04:54.168510: step 24910, loss = 0.97 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 08:05:04.081069: step 24920, loss = 1.12 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 08:05:13.851304: step 24930, loss = 1.06 (262.0 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 08:05:23.823836: step 24940, loss = 1.10 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 08:05:33.679940: step 24950, loss = 1.10 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 08:05:43.688019: step 24960, loss = 0.94 (255.8 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 08:05:53.551538: step 24970, loss = 0.98 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 08:06:13.848317: step 24980, loss = 1.06 (126.1 examples/sec; 2.030 sec/batch)\n",
      "2017-05-29 08:06:20.554349: step 24990, loss = 0.97 (381.7 examples/sec; 0.671 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4368  Precision @ 1 train: 0.8531\n",
      "2017-05-29 08:06:27.601313: step 25000, loss = 0.99 (363.3 examples/sec; 0.705 sec/batch)\n",
      "2017-05-29 08:06:34.371841: step 25010, loss = 1.01 (378.1 examples/sec; 0.677 sec/batch)\n",
      "2017-05-29 08:06:41.785025: step 25020, loss = 1.12 (345.3 examples/sec; 0.741 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4115  Precision @ 1 eval: 0.8037\n",
      "INFO:tensorflow:global_step/sec: 0.715637\n",
      "2017-05-29 08:06:51.070234: step 25030, loss = 1.00 (275.7 examples/sec; 0.929 sec/batch)\n",
      "2017-05-29 08:07:00.921625: step 25040, loss = 1.06 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 08:07:10.667127: step 25050, loss = 0.93 (262.7 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 08:07:20.660721: step 25060, loss = 0.95 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 08:07:30.570956: step 25070, loss = 1.05 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 08:07:40.417958: step 25080, loss = 1.12 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 08:07:50.395053: step 25090, loss = 1.03 (256.6 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 08:08:00.237989: step 25100, loss = 1.13 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 08:08:10.314115: step 25110, loss = 1.23 (254.1 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 08:08:20.205405: step 25120, loss = 1.01 (258.8 examples/sec; 0.989 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.907213\n",
      "2017-05-29 08:08:40.601993: step 25130, loss = 1.05 (125.5 examples/sec; 2.040 sec/batch)\n",
      "2017-05-29 08:08:50.227533: step 25140, loss = 0.99 (266.0 examples/sec; 0.963 sec/batch)\n",
      "2017-05-29 08:09:00.042083: step 25150, loss = 1.09 (260.8 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 08:09:10.056832: step 25160, loss = 1.05 (255.6 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 08:09:19.980996: step 25170, loss = 1.11 (258.0 examples/sec; 0.992 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 23153 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 08:09:33.246596: step 25180, loss = 1.06 (193.0 examples/sec; 1.327 sec/batch)\n",
      "2017-05-29 08:09:42.906210: step 25190, loss = 0.97 (265.0 examples/sec; 0.966 sec/batch)\n",
      "2017-05-29 08:09:52.913416: step 25200, loss = 1.20 (255.8 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 08:10:02.699562: step 25210, loss = 0.97 (261.6 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 08:10:12.502111: step 25220, loss = 1.13 (261.2 examples/sec; 0.980 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.909791\n",
      "2017-05-29 08:10:30.934125: step 25230, loss = 1.03 (138.9 examples/sec; 1.843 sec/batch)\n",
      "2017-05-29 08:10:40.764335: step 25240, loss = 0.99 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 08:10:50.732984: step 25250, loss = 1.12 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 08:11:00.736420: step 25260, loss = 1.04 (255.9 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 08:11:10.545262: step 25270, loss = 1.04 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 08:11:20.325545: step 25280, loss = 1.06 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 08:11:30.354659: step 25290, loss = 1.09 (255.3 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 08:11:40.147087: step 25300, loss = 1.01 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 08:11:50.112630: step 25310, loss = 1.01 (256.9 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 08:11:59.981277: step 25320, loss = 1.08 (259.4 examples/sec; 0.987 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.926365\n",
      "2017-05-29 08:12:18.410697: step 25330, loss = 1.16 (138.9 examples/sec; 1.843 sec/batch)\n",
      "2017-05-29 08:12:28.415773: step 25340, loss = 1.08 (255.9 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 08:12:38.352098: step 25350, loss = 1.04 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 08:12:48.186263: step 25360, loss = 1.05 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 08:12:58.128867: step 25370, loss = 1.11 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 08:13:08.190297: step 25380, loss = 0.95 (254.4 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 08:13:17.926208: step 25390, loss = 1.03 (262.9 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 08:13:27.958303: step 25400, loss = 1.07 (255.2 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 08:13:37.942977: step 25410, loss = 1.11 (256.4 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 08:13:47.833685: step 25420, loss = 1.16 (258.8 examples/sec; 0.989 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.927365\n",
      "2017-05-29 08:14:06.368808: step 25430, loss = 1.10 (138.1 examples/sec; 1.854 sec/batch)\n",
      "2017-05-29 08:14:16.040742: step 25440, loss = 1.03 (264.7 examples/sec; 0.967 sec/batch)\n",
      "2017-05-29 08:14:25.930190: step 25450, loss = 1.03 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 08:14:35.759592: step 25460, loss = 1.06 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 08:14:45.649109: step 25470, loss = 0.99 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 08:14:55.536279: step 25480, loss = 0.94 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 08:15:05.315477: step 25490, loss = 0.98 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 08:15:15.263138: step 25500, loss = 1.22 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 08:15:25.089325: step 25510, loss = 1.11 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 08:15:35.159060: step 25520, loss = 1.15 (254.2 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 08:15:54.648580: step 25530, loss = 0.91 (131.4 examples/sec; 1.949 sec/batch)\n",
      "2017-05-29 08:16:01.757959: step 25540, loss = 1.13 (360.1 examples/sec; 0.711 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4374  Precision @ 1 train: 0.8543\n",
      "2017-05-29 08:16:08.430656: step 25550, loss = 1.01 (383.7 examples/sec; 0.667 sec/batch)\n",
      "2017-05-29 08:16:15.477045: step 25560, loss = 1.04 (363.3 examples/sec; 0.705 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4095  Precision @ 1 eval: 0.7998\n",
      "INFO:tensorflow:global_step/sec: 0.713501\n",
      "2017-05-29 08:16:23.027847: step 25570, loss = 0.94 (339.0 examples/sec; 0.755 sec/batch)\n",
      "2017-05-29 08:16:32.910740: step 25580, loss = 1.05 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 08:16:42.678704: step 25590, loss = 1.11 (262.1 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 08:16:52.687342: step 25600, loss = 0.97 (255.8 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 08:17:02.585555: step 25610, loss = 1.07 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 08:17:12.362996: step 25620, loss = 0.98 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 08:17:22.360889: step 25630, loss = 0.97 (256.1 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 08:17:32.190691: step 25640, loss = 1.04 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 08:17:42.267038: step 25650, loss = 0.90 (254.1 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 08:17:52.152737: step 25660, loss = 1.16 (259.0 examples/sec; 0.989 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.903337\n",
      "2017-05-29 08:18:13.396582: step 25670, loss = 1.00 (120.5 examples/sec; 2.124 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 08:18:22.873975: step 25680, loss = 0.94 (270.1 examples/sec; 0.948 sec/batch)\n",
      "2017-05-29 08:18:32.807775: step 25690, loss = 0.99 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 08:18:42.616356: step 25700, loss = 0.96 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 08:18:52.274015: step 25710, loss = 1.06 (265.1 examples/sec; 0.966 sec/batch)\n",
      "2017-05-29 08:19:02.420934: step 25720, loss = 0.99 (252.3 examples/sec; 1.015 sec/batch)\n",
      "2017-05-29 08:19:12.214775: step 25730, loss = 1.06 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 08:19:22.189108: step 25740, loss = 1.07 (256.7 examples/sec; 0.997 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 23677 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 08:19:34.480525: step 25750, loss = 1.00 (208.3 examples/sec; 1.229 sec/batch)\n",
      "2017-05-29 08:19:44.333015: step 25760, loss = 0.89 (259.8 examples/sec; 0.985 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.910657\n",
      "2017-05-29 08:20:03.234258: step 25770, loss = 1.00 (135.4 examples/sec; 1.890 sec/batch)\n",
      "2017-05-29 08:20:12.860063: step 25780, loss = 1.01 (266.0 examples/sec; 0.963 sec/batch)\n",
      "2017-05-29 08:20:22.690117: step 25790, loss = 0.98 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 08:20:32.538144: step 25800, loss = 1.14 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 08:20:42.497873: step 25810, loss = 1.03 (257.0 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 08:20:52.336317: step 25820, loss = 0.95 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 08:21:02.155886: step 25830, loss = 1.09 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 08:21:12.087135: step 25840, loss = 1.06 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 08:21:22.097246: step 25850, loss = 1.07 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 08:21:32.057888: step 25860, loss = 1.04 (257.0 examples/sec; 0.996 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.927513\n",
      "2017-05-29 08:21:51.021671: step 25870, loss = 0.93 (135.0 examples/sec; 1.896 sec/batch)\n",
      "2017-05-29 08:22:00.609373: step 25880, loss = 1.06 (267.0 examples/sec; 0.959 sec/batch)\n",
      "2017-05-29 08:22:10.466932: step 25890, loss = 0.91 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 08:22:20.388137: step 25900, loss = 0.94 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 08:22:30.520685: step 25910, loss = 1.05 (252.7 examples/sec; 1.013 sec/batch)\n",
      "2017-05-29 08:22:40.435892: step 25920, loss = 1.05 (258.2 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 08:22:50.455187: step 25930, loss = 1.00 (255.5 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 08:23:00.317324: step 25940, loss = 1.12 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 08:23:10.128518: step 25950, loss = 1.18 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 08:23:20.010238: step 25960, loss = 1.08 (259.1 examples/sec; 0.988 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.908531\n",
      "2017-05-29 08:23:41.127573: step 25970, loss = 1.08 (121.2 examples/sec; 2.112 sec/batch)\n",
      "2017-05-29 08:23:50.446358: step 25980, loss = 1.08 (274.7 examples/sec; 0.932 sec/batch)\n",
      "2017-05-29 08:24:00.447886: step 25990, loss = 1.08 (256.0 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 08:24:10.310593: step 26000, loss = 1.12 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 08:24:20.267128: step 26010, loss = 1.08 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 08:24:30.120145: step 26020, loss = 1.03 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 08:24:39.867301: step 26030, loss = 0.92 (262.6 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 08:24:49.857918: step 26040, loss = 1.01 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 08:24:59.552821: step 26050, loss = 1.01 (264.1 examples/sec; 0.969 sec/batch)\n",
      "2017-05-29 08:25:09.559211: step 26060, loss = 0.91 (255.8 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 08:25:27.571591: step 26070, loss = 0.99 (142.1 examples/sec; 1.801 sec/batch)\n",
      "2017-05-29 08:25:35.341998: step 26080, loss = 0.91 (329.5 examples/sec; 0.777 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4345  Precision @ 1 train: 0.8486\n",
      "2017-05-29 08:25:42.080732: step 26090, loss = 1.09 (379.9 examples/sec; 0.674 sec/batch)\n",
      "2017-05-29 08:25:49.727449: step 26100, loss = 1.05 (334.8 examples/sec; 0.765 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4073  Precision @ 1 eval: 0.7955\n",
      "2017-05-29 08:25:56.660832: step 26110, loss = 1.05 (369.2 examples/sec; 0.693 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.721285\n",
      "2017-05-29 08:26:06.102572: step 26120, loss = 1.13 (271.1 examples/sec; 0.944 sec/batch)\n",
      "2017-05-29 08:26:15.897647: step 26130, loss = 1.07 (261.4 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 08:26:25.752445: step 26140, loss = 1.09 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 08:26:35.807495: step 26150, loss = 1.17 (254.6 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 08:26:45.626894: step 26160, loss = 1.02 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 08:26:55.476083: step 26170, loss = 1.00 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 08:27:05.508913: step 26180, loss = 1.01 (255.2 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 08:27:15.349710: step 26190, loss = 1.13 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 08:27:25.289387: step 26200, loss = 1.12 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 08:27:35.288287: step 26210, loss = 1.09 (256.0 examples/sec; 1.000 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.92347\n",
      "2017-05-29 08:27:54.148534: step 26220, loss = 1.16 (135.7 examples/sec; 1.886 sec/batch)\n",
      "2017-05-29 08:28:04.040302: step 26230, loss = 1.13 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 08:28:13.922676: step 26240, loss = 0.92 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 08:28:23.603471: step 26250, loss = 0.94 (264.4 examples/sec; 0.968 sec/batch)\n",
      "2017-05-29 08:28:33.448482: step 26260, loss = 1.07 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 08:28:43.324349: step 26270, loss = 1.00 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 08:28:53.271684: step 26280, loss = 1.02 (257.4 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 08:29:03.325614: step 26290, loss = 0.99 (254.6 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 08:29:13.248850: step 26300, loss = 0.98 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 08:29:23.078986: step 26310, loss = 0.99 (260.4 examples/sec; 0.983 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 24200 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.904289\n",
      "2017-05-29 08:29:44.204347: step 26320, loss = 0.98 (121.2 examples/sec; 2.113 sec/batch)\n",
      "2017-05-29 08:29:54.101789: step 26330, loss = 1.08 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 08:30:03.976143: step 26340, loss = 1.02 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 08:30:13.948188: step 26350, loss = 1.17 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 08:30:23.794304: step 26360, loss = 1.05 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 08:30:33.708063: step 26370, loss = 1.11 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 08:30:43.565226: step 26380, loss = 0.98 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 08:30:53.483781: step 26390, loss = 1.14 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 08:31:03.405577: step 26400, loss = 1.03 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 08:31:13.316408: step 26410, loss = 1.03 (258.3 examples/sec; 0.991 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.92036\n",
      "2017-05-29 08:31:32.945996: step 26420, loss = 0.97 (130.4 examples/sec; 1.963 sec/batch)\n",
      "2017-05-29 08:31:42.938629: step 26430, loss = 0.86 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 08:31:52.799817: step 26440, loss = 0.88 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 08:32:02.659115: step 26450, loss = 0.97 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 08:32:12.599503: step 26460, loss = 0.86 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 08:32:22.560922: step 26470, loss = 0.99 (257.0 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 08:32:32.596782: step 26480, loss = 1.10 (255.1 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 08:32:42.451451: step 26490, loss = 1.09 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 08:32:52.376557: step 26500, loss = 1.16 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 08:33:02.242360: step 26510, loss = 1.20 (259.5 examples/sec; 0.987 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.929378\n",
      "2017-05-29 08:33:20.504728: step 26520, loss = 1.05 (140.2 examples/sec; 1.826 sec/batch)\n",
      "2017-05-29 08:33:30.295721: step 26530, loss = 1.21 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 08:33:40.125201: step 26540, loss = 1.04 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 08:33:50.122801: step 26550, loss = 0.99 (256.1 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 08:33:59.951381: step 26560, loss = 1.05 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 08:34:10.005625: step 26570, loss = 1.03 (254.6 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 08:34:19.835986: step 26580, loss = 0.98 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 08:34:29.783858: step 26590, loss = 1.02 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 08:34:39.748626: step 26600, loss = 1.05 (256.9 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 08:34:49.588718: step 26610, loss = 1.08 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 08:35:08.006696: step 26620, loss = 1.02 (139.0 examples/sec; 1.842 sec/batch)\n",
      "2017-05-29 08:35:15.115867: step 26630, loss = 0.98 (360.1 examples/sec; 0.711 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4348  Precision @ 1 train: 0.8492\n",
      "2017-05-29 08:35:21.871180: step 26640, loss = 1.10 (379.0 examples/sec; 0.676 sec/batch)\n",
      "2017-05-29 08:35:28.881001: step 26650, loss = 1.07 (365.2 examples/sec; 0.701 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4150  Precision @ 1 eval: 0.8105\n",
      "INFO:tensorflow:global_step/sec: 0.712295\n",
      "2017-05-29 08:35:37.768954: step 26660, loss = 1.15 (288.0 examples/sec; 0.889 sec/batch)\n",
      "2017-05-29 08:35:47.584969: step 26670, loss = 0.94 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 08:35:57.359827: step 26680, loss = 1.03 (261.9 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 08:36:07.279811: step 26690, loss = 1.07 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 08:36:17.431483: step 26700, loss = 1.13 (252.2 examples/sec; 1.015 sec/batch)\n",
      "2017-05-29 08:36:27.479306: step 26710, loss = 1.14 (254.8 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 08:36:37.383442: step 26720, loss = 1.17 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 08:36:47.448726: step 26730, loss = 1.03 (254.3 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 08:36:57.473322: step 26740, loss = 0.98 (255.4 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 08:37:07.504024: step 26750, loss = 1.12 (255.2 examples/sec; 1.003 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.91688\n",
      "2017-05-29 08:37:26.091297: step 26760, loss = 0.92 (137.7 examples/sec; 1.859 sec/batch)\n",
      "2017-05-29 08:37:36.369853: step 26770, loss = 1.12 (249.1 examples/sec; 1.028 sec/batch)\n",
      "2017-05-29 08:37:46.237600: step 26780, loss = 1.11 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 08:37:56.063802: step 26790, loss = 1.03 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 08:38:05.996762: step 26800, loss = 1.00 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 08:38:15.805782: step 26810, loss = 1.14 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 08:38:25.786996: step 26820, loss = 1.07 (256.5 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 08:38:35.514208: step 26830, loss = 1.08 (263.2 examples/sec; 0.973 sec/batch)\n",
      "2017-05-29 08:38:45.507742: step 26840, loss = 1.16 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 08:38:55.332370: step 26850, loss = 1.17 (260.6 examples/sec; 0.982 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.909298\n",
      "2017-05-29 08:39:16.111422: step 26860, loss = 0.99 (123.2 examples/sec; 2.078 sec/batch)\n",
      "2017-05-29 08:39:25.688010: step 26870, loss = 1.01 (267.3 examples/sec; 0.958 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 24724 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 08:39:38.305264: step 26880, loss = 1.07 (202.9 examples/sec; 1.262 sec/batch)\n",
      "2017-05-29 08:39:48.361766: step 26890, loss = 1.08 (254.6 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 08:39:59.478342: step 26900, loss = 1.01 (230.3 examples/sec; 1.112 sec/batch)\n",
      "2017-05-29 08:40:09.780103: step 26910, loss = 0.97 (248.5 examples/sec; 1.030 sec/batch)\n",
      "2017-05-29 08:40:19.617025: step 26920, loss = 1.01 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 08:40:29.466226: step 26930, loss = 0.96 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 08:40:39.445701: step 26940, loss = 1.14 (256.5 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 08:40:49.378649: step 26950, loss = 1.09 (257.7 examples/sec; 0.993 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.872753\n",
      "2017-05-29 08:41:10.731608: step 26960, loss = 1.01 (119.9 examples/sec; 2.135 sec/batch)\n",
      "2017-05-29 08:41:20.295640: step 26970, loss = 1.11 (267.7 examples/sec; 0.956 sec/batch)\n",
      "2017-05-29 08:41:30.333662: step 26980, loss = 1.18 (255.0 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 08:41:40.083038: step 26990, loss = 1.20 (262.6 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 08:41:50.219402: step 27000, loss = 1.02 (252.6 examples/sec; 1.014 sec/batch)\n",
      "2017-05-29 08:42:00.033901: step 27010, loss = 1.00 (260.8 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 08:42:09.942940: step 27020, loss = 1.08 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 08:42:19.815668: step 27030, loss = 0.99 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 08:42:29.776251: step 27040, loss = 1.06 (257.0 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 08:42:39.534641: step 27050, loss = 1.08 (262.3 examples/sec; 0.976 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.910619\n",
      "2017-05-29 08:43:00.790413: step 27060, loss = 1.05 (120.4 examples/sec; 2.126 sec/batch)\n",
      "2017-05-29 08:43:10.390337: step 27070, loss = 0.89 (266.7 examples/sec; 0.960 sec/batch)\n",
      "2017-05-29 08:43:20.455849: step 27080, loss = 1.03 (254.3 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 08:43:30.296429: step 27090, loss = 1.06 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 08:43:40.165347: step 27100, loss = 1.04 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 08:43:50.228649: step 27110, loss = 0.95 (254.4 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 08:44:00.224101: step 27120, loss = 1.03 (256.1 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 08:44:10.160958: step 27130, loss = 1.04 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 08:44:20.003991: step 27140, loss = 1.03 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 08:44:29.765474: step 27150, loss = 0.94 (262.3 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 08:44:46.880184: step 27160, loss = 0.97 (149.6 examples/sec; 1.711 sec/batch)\n",
      "2017-05-29 08:44:54.900924: step 27170, loss = 1.12 (319.2 examples/sec; 0.802 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4523  Precision @ 1 train: 0.8834\n",
      "2017-05-29 08:45:01.684290: step 27180, loss = 1.03 (377.4 examples/sec; 0.678 sec/batch)\n",
      "2017-05-29 08:45:08.779252: step 27190, loss = 0.98 (360.8 examples/sec; 0.709 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4189  Precision @ 1 eval: 0.8182\n",
      "INFO:tensorflow:global_step/sec: 0.720483\n",
      "2017-05-29 08:45:15.825714: step 27200, loss = 0.95 (363.3 examples/sec; 0.705 sec/batch)\n",
      "2017-05-29 08:45:25.675119: step 27210, loss = 1.03 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 08:45:35.547644: step 27220, loss = 1.06 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 08:45:45.382632: step 27230, loss = 1.04 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 08:45:55.254179: step 27240, loss = 0.95 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 08:46:05.045508: step 27250, loss = 1.14 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 08:46:15.049303: step 27260, loss = 1.06 (255.9 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 08:46:24.885675: step 27270, loss = 1.07 (260.3 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 08:46:34.857460: step 27280, loss = 0.96 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 08:46:44.670738: step 27290, loss = 1.06 (260.9 examples/sec; 0.981 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.921731\n",
      "2017-05-29 08:47:04.317337: step 27300, loss = 1.06 (130.3 examples/sec; 1.965 sec/batch)\n",
      "2017-05-29 08:47:13.570230: step 27310, loss = 0.89 (276.7 examples/sec; 0.925 sec/batch)\n",
      "2017-05-29 08:47:23.535377: step 27320, loss = 1.05 (256.9 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 08:47:33.324390: step 27330, loss = 0.96 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 08:47:43.139986: step 27340, loss = 1.09 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 08:47:52.955346: step 27350, loss = 0.96 (260.8 examples/sec; 0.982 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 08:48:02.993532: step 27360, loss = 1.17 (255.0 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 08:48:12.829266: step 27370, loss = 1.10 (260.3 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 08:48:22.854065: step 27380, loss = 1.09 (255.4 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 08:48:32.673903: step 27390, loss = 1.03 (260.7 examples/sec; 0.982 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.910822\n",
      "2017-05-29 08:48:54.108955: step 27400, loss = 1.23 (119.4 examples/sec; 2.144 sec/batch)\n",
      "2017-05-29 08:49:03.323175: step 27410, loss = 1.04 (277.8 examples/sec; 0.921 sec/batch)\n",
      "2017-05-29 08:49:13.197644: step 27420, loss = 1.02 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 08:49:22.965775: step 27430, loss = 1.09 (262.1 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 08:49:32.967459: step 27440, loss = 1.06 (256.0 examples/sec; 1.000 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 25243 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 08:49:44.759893: step 27450, loss = 1.12 (217.1 examples/sec; 1.179 sec/batch)\n",
      "2017-05-29 08:49:54.770484: step 27460, loss = 1.12 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 08:50:04.579488: step 27470, loss = 1.12 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 08:50:14.354797: step 27480, loss = 1.14 (261.9 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 08:50:24.416091: step 27490, loss = 0.99 (254.4 examples/sec; 1.006 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.916928\n",
      "2017-05-29 08:50:43.168632: step 27500, loss = 1.10 (136.5 examples/sec; 1.875 sec/batch)\n",
      "2017-05-29 08:50:52.362126: step 27510, loss = 1.12 (278.5 examples/sec; 0.919 sec/batch)\n",
      "2017-05-29 08:51:02.236228: step 27520, loss = 1.01 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 08:51:12.426915: step 27530, loss = 1.00 (251.2 examples/sec; 1.019 sec/batch)\n",
      "2017-05-29 08:51:22.300919: step 27540, loss = 1.00 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 08:51:32.199340: step 27550, loss = 1.03 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 08:51:42.133554: step 27560, loss = 1.07 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 08:51:52.083151: step 27570, loss = 1.04 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 08:52:01.940625: step 27580, loss = 1.04 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 08:52:11.856338: step 27590, loss = 1.03 (258.2 examples/sec; 0.992 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.910739\n",
      "2017-05-29 08:52:32.969312: step 27600, loss = 1.05 (121.3 examples/sec; 2.111 sec/batch)\n",
      "2017-05-29 08:52:42.129103: step 27610, loss = 1.06 (279.5 examples/sec; 0.916 sec/batch)\n",
      "2017-05-29 08:52:51.892854: step 27620, loss = 1.02 (262.2 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 08:53:01.756971: step 27630, loss = 1.01 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 08:53:11.641757: step 27640, loss = 1.01 (259.0 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 08:53:21.556686: step 27650, loss = 0.94 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 08:53:31.553861: step 27660, loss = 0.99 (256.1 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 08:53:41.449626: step 27670, loss = 1.03 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 08:53:51.267814: step 27680, loss = 1.02 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 08:54:01.369976: step 27690, loss = 1.05 (253.4 examples/sec; 1.010 sec/batch)\n",
      "2017-05-29 08:54:22.172349: step 27700, loss = 0.90 (123.1 examples/sec; 2.080 sec/batch)\n",
      "2017-05-29 08:54:28.875835: step 27710, loss = 1.09 (381.9 examples/sec; 0.670 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4461  Precision @ 1 train: 0.8713\n",
      "2017-05-29 08:54:36.079702: step 27720, loss = 1.03 (355.4 examples/sec; 0.720 sec/batch)\n",
      "2017-05-29 08:54:42.810745: step 27730, loss = 1.01 (380.3 examples/sec; 0.673 sec/batch)\n",
      "2017-05-29 08:54:49.837419: step 27740, loss = 0.96 (364.3 examples/sec; 0.703 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4213  Precision @ 1 eval: 0.8229\n",
      "INFO:tensorflow:global_step/sec: 0.714352\n",
      "2017-05-29 08:54:58.917344: step 27750, loss = 1.07 (281.9 examples/sec; 0.908 sec/batch)\n",
      "2017-05-29 08:55:08.664028: step 27760, loss = 1.07 (262.7 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 08:55:18.722985: step 27770, loss = 1.03 (254.5 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 08:55:28.611680: step 27780, loss = 1.15 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 08:55:38.628945: step 27790, loss = 1.04 (255.6 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 08:55:48.473858: step 27800, loss = 1.03 (260.0 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 08:55:58.425796: step 27810, loss = 1.02 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 08:56:08.298100: step 27820, loss = 1.04 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 08:56:18.187023: step 27830, loss = 0.98 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 08:56:28.177399: step 27840, loss = 1.13 (256.2 examples/sec; 0.999 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.916063\n",
      "2017-05-29 08:56:47.637762: step 27850, loss = 1.01 (131.5 examples/sec; 1.946 sec/batch)\n",
      "2017-05-29 08:56:57.371498: step 27860, loss = 0.98 (263.0 examples/sec; 0.973 sec/batch)\n",
      "2017-05-29 08:57:07.308086: step 27870, loss = 1.02 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 08:57:17.131782: step 27880, loss = 0.95 (260.6 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 08:57:27.122035: step 27890, loss = 0.97 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 08:57:36.905635: step 27900, loss = 0.99 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 08:57:46.727568: step 27910, loss = 1.02 (260.6 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 08:57:56.630577: step 27920, loss = 0.91 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 08:58:06.720161: step 27930, loss = 1.02 (253.7 examples/sec; 1.009 sec/batch)\n",
      "2017-05-29 08:58:16.626157: step 27940, loss = 1.06 (258.4 examples/sec; 0.991 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.924442\n",
      "2017-05-29 08:58:35.692861: step 27950, loss = 1.02 (134.3 examples/sec; 1.907 sec/batch)\n",
      "2017-05-29 08:58:45.620474: step 27960, loss = 0.93 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 08:58:55.324722: step 27970, loss = 1.01 (263.8 examples/sec; 0.970 sec/batch)\n",
      "2017-05-29 08:59:05.452086: step 27980, loss = 0.98 (252.8 examples/sec; 1.013 sec/batch)\n",
      "2017-05-29 08:59:15.227841: step 27990, loss = 1.05 (261.9 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 08:59:25.281558: step 28000, loss = 1.09 (254.6 examples/sec; 1.005 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 25767 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 08:59:37.382342: step 28010, loss = 1.04 (211.6 examples/sec; 1.210 sec/batch)\n",
      "2017-05-29 08:59:46.829585: step 28020, loss = 1.11 (271.0 examples/sec; 0.945 sec/batch)\n",
      "2017-05-29 08:59:56.703824: step 28030, loss = 1.13 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 09:00:06.505996: step 28040, loss = 1.03 (261.2 examples/sec; 0.980 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.912933\n",
      "2017-05-29 09:00:25.244214: step 28050, loss = 0.97 (136.6 examples/sec; 1.874 sec/batch)\n",
      "2017-05-29 09:00:35.007012: step 28060, loss = 1.13 (262.2 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 09:00:45.074472: step 28070, loss = 1.04 (254.3 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 09:00:54.876971: step 28080, loss = 1.04 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 09:01:05.028062: step 28090, loss = 1.10 (252.2 examples/sec; 1.015 sec/batch)\n",
      "2017-05-29 09:01:14.907740: step 28100, loss = 0.97 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 09:01:25.108853: step 28110, loss = 1.05 (251.0 examples/sec; 1.020 sec/batch)\n",
      "2017-05-29 09:01:34.990780: step 28120, loss = 1.09 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 09:01:44.818950: step 28130, loss = 0.93 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 09:01:54.635907: step 28140, loss = 0.97 (260.8 examples/sec; 0.982 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.907191\n",
      "2017-05-29 09:02:15.430654: step 28150, loss = 0.97 (123.1 examples/sec; 2.079 sec/batch)\n",
      "2017-05-29 09:02:25.123748: step 28160, loss = 1.07 (264.1 examples/sec; 0.969 sec/batch)\n",
      "2017-05-29 09:02:35.112360: step 28170, loss = 1.12 (256.3 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 09:02:45.047323: step 28180, loss = 1.06 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 09:02:55.080203: step 28190, loss = 1.10 (255.2 examples/sec; 1.003 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 09:03:04.953434: step 28200, loss = 1.09 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 09:03:14.752536: step 28210, loss = 1.18 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 09:03:24.581981: step 28220, loss = 1.10 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 09:03:34.379223: step 28230, loss = 1.11 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 09:03:44.424822: step 28240, loss = 1.04 (254.8 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 09:04:03.150619: step 28250, loss = 1.14 (136.7 examples/sec; 1.873 sec/batch)\n",
      "2017-05-29 09:04:10.653333: step 28260, loss = 1.01 (341.2 examples/sec; 0.750 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4380  Precision @ 1 train: 0.8555\n",
      "2017-05-29 09:04:18.726774: step 28270, loss = 1.11 (317.1 examples/sec; 0.807 sec/batch)\n",
      "2017-05-29 09:04:26.573941: step 28280, loss = 1.07 (326.2 examples/sec; 0.785 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4112  Precision @ 1 eval: 0.8031\n",
      "INFO:tensorflow:global_step/sec: 0.701981\n",
      "2017-05-29 09:04:34.512275: step 28290, loss = 0.97 (322.5 examples/sec; 0.794 sec/batch)\n",
      "2017-05-29 09:04:45.577427: step 28300, loss = 0.89 (231.4 examples/sec; 1.107 sec/batch)\n",
      "2017-05-29 09:04:56.075284: step 28310, loss = 0.99 (243.9 examples/sec; 1.050 sec/batch)\n",
      "2017-05-29 09:05:06.147612: step 28320, loss = 0.92 (254.2 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 09:05:15.987882: step 28330, loss = 1.00 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 09:05:25.946700: step 28340, loss = 1.17 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 09:05:35.952310: step 28350, loss = 0.88 (255.9 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 09:05:45.964121: step 28360, loss = 1.02 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 09:05:55.913861: step 28370, loss = 1.08 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 09:06:05.796004: step 28380, loss = 0.94 (259.1 examples/sec; 0.988 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.893085\n",
      "2017-05-29 09:06:26.145374: step 28390, loss = 1.03 (125.8 examples/sec; 2.035 sec/batch)\n",
      "2017-05-29 09:06:35.723574: step 28400, loss = 1.18 (267.3 examples/sec; 0.958 sec/batch)\n",
      "2017-05-29 09:06:45.709044: step 28410, loss = 0.99 (256.4 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 09:06:55.775972: step 28420, loss = 0.99 (254.3 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 09:07:05.743745: step 28430, loss = 1.00 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 09:07:15.761801: step 28440, loss = 0.99 (255.5 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 09:07:25.649238: step 28450, loss = 1.05 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 09:07:35.446511: step 28460, loss = 1.10 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 09:07:45.310531: step 28470, loss = 1.04 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 09:07:55.146142: step 28480, loss = 1.13 (260.3 examples/sec; 0.984 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.925243\n",
      "2017-05-29 09:08:14.237734: step 28490, loss = 1.12 (134.1 examples/sec; 1.909 sec/batch)\n",
      "2017-05-29 09:08:23.864057: step 28500, loss = 0.93 (265.9 examples/sec; 0.963 sec/batch)\n",
      "2017-05-29 09:08:33.808728: step 28510, loss = 1.04 (257.4 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 09:08:43.656379: step 28520, loss = 0.97 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 09:08:53.595285: step 28530, loss = 1.20 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 09:09:03.544551: step 28540, loss = 1.06 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 09:09:13.459471: step 28550, loss = 0.99 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 09:09:23.390077: step 28560, loss = 1.12 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 09:09:33.319206: step 28570, loss = 0.94 (257.8 examples/sec; 0.993 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 26285 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 09:09:45.339518: step 28580, loss = 1.13 (213.0 examples/sec; 1.202 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.912255\n",
      "2017-05-29 09:10:03.868628: step 28590, loss = 0.98 (138.2 examples/sec; 1.853 sec/batch)\n",
      "2017-05-29 09:10:14.109576: step 28600, loss = 0.99 (250.0 examples/sec; 1.024 sec/batch)\n",
      "2017-05-29 09:10:23.875028: step 28610, loss = 1.17 (262.1 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 09:10:33.884911: step 28620, loss = 1.20 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 09:10:43.749420: step 28630, loss = 1.09 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 09:10:53.679467: step 28640, loss = 1.02 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 09:11:03.541007: step 28650, loss = 1.14 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 09:11:13.397204: step 28660, loss = 1.11 (259.7 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 09:11:23.428972: step 28670, loss = 0.92 (255.2 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 09:11:33.301032: step 28680, loss = 1.10 (259.3 examples/sec; 0.987 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.92096\n",
      "2017-05-29 09:11:52.513955: step 28690, loss = 1.10 (133.2 examples/sec; 1.921 sec/batch)\n",
      "2017-05-29 09:12:02.312796: step 28700, loss = 1.13 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 09:12:12.217794: step 28710, loss = 1.18 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 09:12:22.256111: step 28720, loss = 1.07 (255.0 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 09:12:31.986935: step 28730, loss = 0.94 (263.1 examples/sec; 0.973 sec/batch)\n",
      "2017-05-29 09:12:42.149158: step 28740, loss = 1.06 (251.9 examples/sec; 1.016 sec/batch)\n",
      "2017-05-29 09:12:51.995956: step 28750, loss = 1.02 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 09:13:01.950783: step 28760, loss = 1.06 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 09:13:11.797121: step 28770, loss = 0.95 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 09:13:21.845480: step 28780, loss = 1.02 (254.8 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 09:13:40.735903: step 28790, loss = 1.05 (135.5 examples/sec; 1.889 sec/batch)\n",
      "2017-05-29 09:13:48.410093: step 28800, loss = 0.98 (333.6 examples/sec; 0.767 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4489  Precision @ 1 train: 0.8768\n",
      "2017-05-29 09:13:55.192889: step 28810, loss = 1.13 (377.4 examples/sec; 0.678 sec/batch)\n",
      "2017-05-29 09:14:02.264526: step 28820, loss = 1.12 (362.0 examples/sec; 0.707 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4244  Precision @ 1 eval: 0.8289\n",
      "2017-05-29 09:14:09.328580: step 28830, loss = 0.97 (362.4 examples/sec; 0.706 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.714293\n",
      "2017-05-29 09:14:19.070185: step 28840, loss = 1.01 (262.8 examples/sec; 0.974 sec/batch)\n",
      "2017-05-29 09:14:29.104413: step 28850, loss = 0.98 (255.1 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 09:14:39.088486: step 28860, loss = 1.02 (256.4 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 09:14:49.021980: step 28870, loss = 1.12 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 09:14:58.941871: step 28880, loss = 1.05 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 09:15:08.974239: step 28890, loss = 1.08 (255.2 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 09:15:18.888251: step 28900, loss = 0.94 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 09:15:28.915739: step 28910, loss = 1.00 (255.3 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 09:15:38.797944: step 28920, loss = 0.95 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 09:15:48.714644: step 28930, loss = 0.94 (258.2 examples/sec; 0.992 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.906511\n",
      "2017-05-29 09:16:08.521694: step 28940, loss = 0.95 (129.2 examples/sec; 1.981 sec/batch)\n",
      "2017-05-29 09:16:18.391793: step 28950, loss = 1.12 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 09:16:28.179892: step 28960, loss = 1.07 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 09:16:38.168473: step 28970, loss = 1.04 (256.3 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 09:16:48.216222: step 28980, loss = 1.16 (254.8 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 09:16:58.150973: step 28990, loss = 1.12 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 09:17:08.099341: step 29000, loss = 1.09 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 09:17:17.967883: step 29010, loss = 1.17 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 09:17:28.111384: step 29020, loss = 1.01 (252.4 examples/sec; 1.014 sec/batch)\n",
      "2017-05-29 09:17:38.038426: step 29030, loss = 1.15 (257.9 examples/sec; 0.993 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.90808\n",
      "2017-05-29 09:17:58.529750: step 29040, loss = 1.06 (124.9 examples/sec; 2.049 sec/batch)\n",
      "2017-05-29 09:18:08.401919: step 29050, loss = 1.07 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 09:18:18.304636: step 29060, loss = 1.02 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 09:18:28.535508: step 29070, loss = 1.08 (250.2 examples/sec; 1.023 sec/batch)\n",
      "2017-05-29 09:18:38.413352: step 29080, loss = 1.06 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 09:18:48.318614: step 29090, loss = 1.03 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 09:18:58.230563: step 29100, loss = 1.02 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 09:19:08.148601: step 29110, loss = 1.04 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 09:19:18.070708: step 29120, loss = 1.01 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 09:19:27.993595: step 29130, loss = 0.97 (258.0 examples/sec; 0.992 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 26800 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.882049\n",
      "2017-05-29 09:19:51.860995: step 29140, loss = 0.96 (107.3 examples/sec; 2.387 sec/batch)\n",
      "2017-05-29 09:20:02.010679: step 29150, loss = 0.98 (252.2 examples/sec; 1.015 sec/batch)\n",
      "2017-05-29 09:20:11.966299: step 29160, loss = 1.01 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 09:20:21.900305: step 29170, loss = 1.08 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 09:20:31.833281: step 29180, loss = 1.02 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 09:20:41.841490: step 29190, loss = 1.17 (255.8 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 09:20:51.674475: step 29200, loss = 0.99 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 09:21:01.656663: step 29210, loss = 1.01 (256.5 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 09:21:11.576766: step 29220, loss = 0.97 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 09:21:21.420499: step 29230, loss = 1.06 (260.1 examples/sec; 0.984 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.911877\n",
      "2017-05-29 09:21:41.519317: step 29240, loss = 0.93 (127.4 examples/sec; 2.010 sec/batch)\n",
      "2017-05-29 09:21:51.504009: step 29250, loss = 1.15 (256.4 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 09:22:01.553039: step 29260, loss = 0.97 (254.8 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 09:22:11.597421: step 29270, loss = 1.04 (254.9 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 09:22:21.656471: step 29280, loss = 0.94 (254.5 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 09:22:31.753686: step 29290, loss = 1.04 (253.5 examples/sec; 1.010 sec/batch)\n",
      "2017-05-29 09:22:41.865912: step 29300, loss = 1.17 (253.2 examples/sec; 1.011 sec/batch)\n",
      "2017-05-29 09:22:51.834501: step 29310, loss = 1.08 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 09:23:01.869413: step 29320, loss = 1.13 (255.1 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 09:23:11.762217: step 29330, loss = 1.07 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 09:23:29.333006: step 29340, loss = 0.92 (145.7 examples/sec; 1.757 sec/batch)\n",
      "2017-05-29 09:23:36.565358: step 29350, loss = 0.97 (354.0 examples/sec; 0.723 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4389  Precision @ 1 train: 0.8572\n",
      "2017-05-29 09:23:43.981248: step 29360, loss = 1.00 (345.2 examples/sec; 0.742 sec/batch)\n",
      "2017-05-29 09:23:51.448676: step 29370, loss = 1.10 (342.8 examples/sec; 0.747 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4156  Precision @ 1 eval: 0.8117\n",
      "INFO:tensorflow:global_step/sec: 0.707093\n",
      "2017-05-29 09:23:59.755071: step 29380, loss = 0.91 (308.2 examples/sec; 0.831 sec/batch)\n",
      "2017-05-29 09:24:09.775272: step 29390, loss = 0.99 (255.5 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 09:24:19.687066: step 29400, loss = 1.02 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 09:24:29.603769: step 29410, loss = 1.08 (258.2 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 09:24:39.615134: step 29420, loss = 0.99 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 09:24:49.524396: step 29430, loss = 1.07 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 09:24:59.607722: step 29440, loss = 0.96 (253.9 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 09:25:09.510380: step 29450, loss = 1.11 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 09:25:19.382043: step 29460, loss = 1.14 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 09:25:29.346034: step 29470, loss = 1.03 (256.9 examples/sec; 0.996 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.905359\n",
      "2017-05-29 09:25:49.599137: step 29480, loss = 1.08 (126.4 examples/sec; 2.025 sec/batch)\n",
      "2017-05-29 09:25:59.413122: step 29490, loss = 1.03 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 09:26:09.233353: step 29500, loss = 0.95 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 09:26:19.316527: step 29510, loss = 1.11 (253.9 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 09:26:29.251047: step 29520, loss = 1.07 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 09:26:39.224112: step 29530, loss = 1.29 (256.7 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 09:26:49.094357: step 29540, loss = 0.99 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 09:26:59.205426: step 29550, loss = 1.18 (253.2 examples/sec; 1.011 sec/batch)\n",
      "2017-05-29 09:27:09.247313: step 29560, loss = 1.01 (254.9 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 09:27:19.461705: step 29570, loss = 1.13 (250.6 examples/sec; 1.021 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.92218\n",
      "2017-05-29 09:27:38.011998: step 29580, loss = 0.94 (138.0 examples/sec; 1.855 sec/batch)\n",
      "2017-05-29 09:27:47.793427: step 29590, loss = 1.03 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 09:27:57.890839: step 29600, loss = 1.09 (253.5 examples/sec; 1.010 sec/batch)\n",
      "2017-05-29 09:28:07.795146: step 29610, loss = 1.05 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 09:28:17.692678: step 29620, loss = 1.07 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 09:28:27.570269: step 29630, loss = 0.91 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 09:28:37.586898: step 29640, loss = 1.03 (255.6 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 09:28:47.568035: step 29650, loss = 0.92 (256.5 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 09:28:57.458939: step 29660, loss = 1.10 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 09:29:07.426248: step 29670, loss = 0.96 (256.8 examples/sec; 0.997 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.915268\n",
      "2017-05-29 09:29:27.298770: step 29680, loss = 1.03 (128.8 examples/sec; 1.987 sec/batch)\n",
      "2017-05-29 09:29:37.196877: step 29690, loss = 0.97 (258.6 examples/sec; 0.990 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 27319 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 09:29:49.292416: step 29700, loss = 1.04 (211.6 examples/sec; 1.210 sec/batch)\n",
      "2017-05-29 09:29:59.315386: step 29710, loss = 1.08 (255.4 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 09:30:09.201761: step 29720, loss = 1.21 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 09:30:19.104948: step 29730, loss = 1.15 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 09:30:29.196297: step 29740, loss = 1.09 (253.7 examples/sec; 1.009 sec/batch)\n",
      "2017-05-29 09:30:39.237038: step 29750, loss = 0.94 (255.0 examples/sec; 1.004 sec/batch)\n",
      "2017-05-29 09:30:49.031633: step 29760, loss = 0.89 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 09:30:59.131539: step 29770, loss = 1.02 (253.5 examples/sec; 1.010 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.886872\n",
      "2017-05-29 09:31:19.971439: step 29780, loss = 1.07 (122.8 examples/sec; 2.084 sec/batch)\n",
      "2017-05-29 09:31:29.674077: step 29790, loss = 1.16 (263.8 examples/sec; 0.970 sec/batch)\n",
      "2017-05-29 09:31:39.666922: step 29800, loss = 1.19 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 09:31:49.542663: step 29810, loss = 1.00 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 09:31:59.467761: step 29820, loss = 1.14 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 09:32:09.305416: step 29830, loss = 1.05 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 09:32:19.388952: step 29840, loss = 0.91 (253.9 examples/sec; 1.008 sec/batch)\n",
      "2017-05-29 09:32:29.167137: step 29850, loss = 1.03 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 09:32:39.212178: step 29860, loss = 1.08 (254.9 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 09:32:49.087107: step 29870, loss = 0.94 (259.2 examples/sec; 0.987 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 09:33:08.641882: step 29880, loss = 1.07 (130.9 examples/sec; 1.955 sec/batch)\n",
      "2017-05-29 09:33:15.815422: step 29890, loss = 1.11 (356.9 examples/sec; 0.717 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4410  Precision @ 1 train: 0.8613\n",
      "2017-05-29 09:33:22.616509: step 29900, loss = 0.96 (376.4 examples/sec; 0.680 sec/batch)\n",
      "2017-05-29 09:33:29.718333: step 29910, loss = 1.06 (360.5 examples/sec; 0.710 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4164  Precision @ 1 eval: 0.8133\n",
      "INFO:tensorflow:global_step/sec: 0.710175\n",
      "2017-05-29 09:33:37.376030: step 29920, loss = 1.01 (334.3 examples/sec; 0.766 sec/batch)\n",
      "2017-05-29 09:33:47.448329: step 29930, loss = 0.95 (254.2 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 09:33:57.337167: step 29940, loss = 1.04 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 09:34:07.348931: step 29950, loss = 1.09 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 09:34:17.339710: step 29960, loss = 0.99 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-29 09:34:27.307626: step 29970, loss = 0.98 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-29 09:34:37.327398: step 29980, loss = 0.99 (255.5 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 09:34:47.223365: step 29990, loss = 0.98 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 09:34:57.419908: step 30000, loss = 0.99 (251.1 examples/sec; 1.020 sec/batch)\n",
      "2017-05-29 09:35:07.467946: step 30010, loss = 0.96 (254.8 examples/sec; 1.005 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.89884\n",
      "2017-05-29 09:35:28.631738: step 30020, loss = 1.00 (121.0 examples/sec; 2.116 sec/batch)\n",
      "2017-05-29 09:35:37.879195: step 30030, loss = 1.03 (276.8 examples/sec; 0.925 sec/batch)\n",
      "2017-05-29 09:35:47.789374: step 30040, loss = 1.08 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 09:35:57.753361: step 30050, loss = 0.96 (256.9 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 09:36:07.697683: step 30060, loss = 1.13 (257.4 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 09:36:17.479727: step 30070, loss = 1.15 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 09:36:27.345937: step 30080, loss = 1.09 (259.5 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 09:36:37.305317: step 30090, loss = 0.96 (257.0 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 09:36:47.180330: step 30100, loss = 1.04 (259.2 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 09:36:57.174134: step 30110, loss = 1.08 (256.2 examples/sec; 0.999 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.906999\n",
      "2017-05-29 09:37:18.883873: step 30120, loss = 0.88 (117.9 examples/sec; 2.171 sec/batch)\n",
      "2017-05-29 09:37:28.115872: step 30130, loss = 0.97 (277.3 examples/sec; 0.923 sec/batch)\n",
      "2017-05-29 09:37:37.967263: step 30140, loss = 1.08 (259.9 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 09:37:48.143538: step 30150, loss = 0.89 (251.6 examples/sec; 1.018 sec/batch)\n",
      "2017-05-29 09:37:58.069923: step 30160, loss = 0.91 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 09:38:08.164649: step 30170, loss = 1.11 (253.6 examples/sec; 1.009 sec/batch)\n",
      "2017-05-29 09:38:17.994678: step 30180, loss = 1.07 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 09:38:27.907281: step 30190, loss = 0.96 (258.3 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 09:38:37.811627: step 30200, loss = 0.91 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 09:38:47.688818: step 30210, loss = 1.17 (259.2 examples/sec; 0.988 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.906327\n",
      "2017-05-29 09:39:09.219327: step 30220, loss = 1.08 (118.9 examples/sec; 2.153 sec/batch)\n",
      "2017-05-29 09:39:18.427391: step 30230, loss = 1.01 (278.0 examples/sec; 0.921 sec/batch)\n",
      "2017-05-29 09:39:28.480530: step 30240, loss = 1.03 (254.6 examples/sec; 1.005 sec/batch)\n",
      "2017-05-29 09:39:38.361166: step 30250, loss = 1.03 (259.1 examples/sec; 0.988 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 27834 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 09:39:51.845284: step 30260, loss = 1.21 (189.9 examples/sec; 1.348 sec/batch)\n",
      "2017-05-29 09:40:02.169970: step 30270, loss = 1.00 (247.9 examples/sec; 1.032 sec/batch)\n",
      "2017-05-29 09:40:12.042970: step 30280, loss = 0.99 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 09:40:21.917447: step 30290, loss = 1.00 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 09:40:31.810906: step 30300, loss = 0.96 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 09:40:41.723374: step 30310, loss = 1.11 (258.3 examples/sec; 0.991 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.885172\n",
      "2017-05-29 09:41:02.191980: step 30320, loss = 1.00 (125.1 examples/sec; 2.047 sec/batch)\n",
      "2017-05-29 09:41:11.549540: step 30330, loss = 1.03 (273.6 examples/sec; 0.936 sec/batch)\n",
      "2017-05-29 09:41:21.397014: step 30340, loss = 1.04 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 09:41:31.282199: step 30350, loss = 0.94 (259.0 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 09:41:41.293559: step 30360, loss = 1.06 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-29 09:41:51.236351: step 30370, loss = 1.12 (257.5 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 09:42:01.183410: step 30380, loss = 1.13 (257.4 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 09:42:11.166058: step 30390, loss = 1.07 (256.4 examples/sec; 0.998 sec/batch)\n",
      "2017-05-29 09:42:21.283284: step 30400, loss = 1.17 (253.0 examples/sec; 1.012 sec/batch)\n",
      "2017-05-29 09:42:31.517339: step 30410, loss = 1.00 (250.1 examples/sec; 1.023 sec/batch)\n",
      "2017-05-29 09:42:52.516710: step 30420, loss = 1.01 (121.9 examples/sec; 2.100 sec/batch)\n",
      "2017-05-29 09:42:59.265888: step 30430, loss = 1.02 (379.3 examples/sec; 0.675 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4397  Precision @ 1 train: 0.8588\n",
      "2017-05-29 09:43:06.462307: step 30440, loss = 1.08 (355.7 examples/sec; 0.720 sec/batch)\n",
      "2017-05-29 09:43:13.942081: step 30450, loss = 1.02 (342.3 examples/sec; 0.748 sec/batch)\n",
      "2017-05-29 09:43:21.358615: step 30460, loss = 1.04 (345.2 examples/sec; 0.742 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4128  Precision @ 1 eval: 0.8063\n",
      "INFO:tensorflow:global_step/sec: 0.703956\n",
      "2017-05-29 09:43:30.154974: step 30470, loss = 1.25 (291.0 examples/sec; 0.880 sec/batch)\n",
      "2017-05-29 09:43:39.937507: step 30480, loss = 1.02 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 09:43:50.122318: step 30490, loss = 1.04 (251.4 examples/sec; 1.018 sec/batch)\n",
      "2017-05-29 09:44:00.007648: step 30500, loss = 1.01 (259.0 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 09:44:09.753180: step 30510, loss = 1.13 (262.7 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 09:44:19.684703: step 30520, loss = 1.07 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 09:44:29.604926: step 30530, loss = 0.94 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 09:44:39.376788: step 30540, loss = 1.06 (262.0 examples/sec; 0.977 sec/batch)\n",
      "2017-05-29 09:44:49.282083: step 30550, loss = 1.10 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 09:44:59.258189: step 30560, loss = 0.92 (256.6 examples/sec; 0.998 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.903076\n",
      "2017-05-29 09:45:20.325118: step 30570, loss = 0.97 (121.5 examples/sec; 2.107 sec/batch)\n",
      "2017-05-29 09:45:30.020058: step 30580, loss = 1.12 (264.1 examples/sec; 0.969 sec/batch)\n",
      "2017-05-29 09:45:39.782299: step 30590, loss = 1.05 (262.2 examples/sec; 0.976 sec/batch)\n",
      "2017-05-29 09:45:49.715245: step 30600, loss = 1.06 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 09:45:59.510676: step 30610, loss = 1.10 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 09:46:09.534688: step 30620, loss = 1.21 (255.4 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 09:46:19.280618: step 30630, loss = 0.92 (262.7 examples/sec; 0.975 sec/batch)\n",
      "2017-05-29 09:46:29.066879: step 30640, loss = 1.08 (261.6 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 09:46:38.975312: step 30650, loss = 1.07 (258.4 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 09:46:48.909136: step 30660, loss = 1.04 (257.7 examples/sec; 0.993 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.917411\n",
      "2017-05-29 09:47:09.396322: step 30670, loss = 1.02 (125.0 examples/sec; 2.049 sec/batch)\n",
      "2017-05-29 09:47:19.110268: step 30680, loss = 1.06 (263.5 examples/sec; 0.971 sec/batch)\n",
      "2017-05-29 09:47:29.195516: step 30690, loss = 1.03 (253.8 examples/sec; 1.009 sec/batch)\n",
      "2017-05-29 09:47:39.029610: step 30700, loss = 0.96 (260.3 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 09:47:48.870607: step 30710, loss = 0.89 (260.1 examples/sec; 0.984 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 09:47:58.707267: step 30720, loss = 0.99 (260.3 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 09:48:08.764938: step 30730, loss = 1.04 (254.5 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 09:48:18.556139: step 30740, loss = 1.09 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 09:48:28.383989: step 30750, loss = 1.08 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 09:48:38.253611: step 30760, loss = 1.15 (259.4 examples/sec; 0.987 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.91321\n",
      "2017-05-29 09:48:58.929341: step 30770, loss = 1.12 (123.8 examples/sec; 2.068 sec/batch)\n",
      "2017-05-29 09:49:08.750891: step 30780, loss = 1.17 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-29 09:49:18.597032: step 30790, loss = 1.07 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 09:49:28.593873: step 30800, loss = 1.07 (256.1 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 09:49:38.399680: step 30810, loss = 0.91 (261.1 examples/sec; 0.981 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 28350 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 09:49:51.657894: step 30820, loss = 1.05 (193.1 examples/sec; 1.326 sec/batch)\n",
      "2017-05-29 09:50:01.774322: step 30830, loss = 1.11 (253.1 examples/sec; 1.012 sec/batch)\n",
      "2017-05-29 09:50:11.671100: step 30840, loss = 1.12 (258.7 examples/sec; 0.990 sec/batch)\n",
      "2017-05-29 09:50:21.586004: step 30850, loss = 0.85 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 09:50:31.548790: step 30860, loss = 0.94 (257.0 examples/sec; 0.996 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.87409\n",
      "2017-05-29 09:50:53.153476: step 30870, loss = 1.01 (118.5 examples/sec; 2.160 sec/batch)\n",
      "2017-05-29 09:51:02.937161: step 30880, loss = 1.09 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 09:51:12.882736: step 30890, loss = 1.06 (257.4 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 09:51:22.667195: step 30900, loss = 1.04 (261.6 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 09:51:32.519751: step 30910, loss = 0.95 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 09:51:42.432627: step 30920, loss = 0.84 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 09:51:52.222476: step 30930, loss = 1.06 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 09:52:02.103190: step 30940, loss = 1.00 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-29 09:52:11.932715: step 30950, loss = 0.95 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 09:52:21.744629: step 30960, loss = 0.95 (260.9 examples/sec; 0.981 sec/batch)\n",
      "2017-05-29 09:52:41.064077: step 30970, loss = 1.15 (132.5 examples/sec; 1.932 sec/batch)\n",
      "2017-05-29 09:52:48.298709: step 30980, loss = 1.04 (353.9 examples/sec; 0.723 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4404  Precision @ 1 train: 0.8602\n",
      "2017-05-29 09:52:55.150662: step 30990, loss = 1.05 (373.6 examples/sec; 0.685 sec/batch)\n",
      "2017-05-29 09:53:02.390002: step 31000, loss = 0.90 (353.6 examples/sec; 0.724 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4177  Precision @ 1 eval: 0.8158\n",
      "INFO:tensorflow:global_step/sec: 0.710324\n",
      "2017-05-29 09:53:10.698063: step 31010, loss = 1.02 (308.1 examples/sec; 0.831 sec/batch)\n",
      "2017-05-29 09:53:20.568925: step 31020, loss = 0.91 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 09:53:30.351886: step 31030, loss = 1.03 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 09:53:40.191247: step 31040, loss = 1.03 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 09:53:50.044230: step 31050, loss = 1.04 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 09:53:59.896095: step 31060, loss = 1.05 (259.8 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 09:54:09.810534: step 31070, loss = 1.00 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-29 09:54:19.682555: step 31080, loss = 1.02 (259.3 examples/sec; 0.987 sec/batch)\n",
      "2017-05-29 09:54:29.464514: step 31090, loss = 1.14 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 09:54:39.291989: step 31100, loss = 1.11 (260.5 examples/sec; 0.983 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.925714\n",
      "2017-05-29 09:54:58.316728: step 31110, loss = 0.96 (134.6 examples/sec; 1.902 sec/batch)\n",
      "2017-05-29 09:55:07.984741: step 31120, loss = 0.93 (264.8 examples/sec; 0.967 sec/batch)\n",
      "2017-05-29 09:55:18.152282: step 31130, loss = 1.20 (251.8 examples/sec; 1.017 sec/batch)\n",
      "2017-05-29 09:55:28.175538: step 31140, loss = 1.08 (255.4 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 09:55:37.963233: step 31150, loss = 1.08 (261.6 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 09:55:47.924456: step 31160, loss = 0.98 (257.0 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 09:55:57.939654: step 31170, loss = 1.10 (255.6 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 09:56:07.787255: step 31180, loss = 0.95 (260.0 examples/sec; 0.985 sec/batch)\n",
      "2017-05-29 09:56:17.650388: step 31190, loss = 1.11 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 09:56:27.440977: step 31200, loss = 1.00 (261.5 examples/sec; 0.979 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.908525\n",
      "2017-05-29 09:56:48.439038: step 31210, loss = 1.03 (121.9 examples/sec; 2.100 sec/batch)\n",
      "2017-05-29 09:56:58.097872: step 31220, loss = 0.95 (265.0 examples/sec; 0.966 sec/batch)\n",
      "2017-05-29 09:57:07.928851: step 31230, loss = 0.95 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 09:57:17.732021: step 31240, loss = 0.95 (261.1 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 09:57:27.535104: step 31250, loss = 0.96 (261.1 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 09:57:37.323559: step 31260, loss = 1.10 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 09:57:47.150550: step 31270, loss = 1.00 (260.5 examples/sec; 0.983 sec/batch)\n",
      "2017-05-29 09:57:56.953080: step 31280, loss = 1.10 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-29 09:58:06.734706: step 31290, loss = 1.05 (261.7 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 09:58:16.467875: step 31300, loss = 1.06 (263.0 examples/sec; 0.973 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.922211\n",
      "2017-05-29 09:58:36.888872: step 31310, loss = 0.94 (125.4 examples/sec; 2.042 sec/batch)\n",
      "2017-05-29 09:58:46.449154: step 31320, loss = 1.13 (267.8 examples/sec; 0.956 sec/batch)\n",
      "2017-05-29 09:58:56.311491: step 31330, loss = 0.96 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 09:59:06.507827: step 31340, loss = 1.00 (251.1 examples/sec; 1.020 sec/batch)\n",
      "2017-05-29 09:59:16.564775: step 31350, loss = 1.01 (254.6 examples/sec; 1.006 sec/batch)\n",
      "2017-05-29 09:59:26.355141: step 31360, loss = 1.04 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 09:59:36.358652: step 31370, loss = 0.99 (255.9 examples/sec; 1.000 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 28868 into /home/ipython/cnn-cifar10/tb_log/res3/train/model.ckpt.\n",
      "2017-05-29 09:59:49.234753: step 31380, loss = 1.16 (198.8 examples/sec; 1.288 sec/batch)\n",
      "2017-05-29 10:00:00.553001: step 31390, loss = 1.15 (226.2 examples/sec; 1.132 sec/batch)\n",
      "2017-05-29 10:00:11.108415: step 31400, loss = 1.02 (242.5 examples/sec; 1.056 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.861773\n",
      "2017-05-29 10:00:32.908552: step 31410, loss = 1.05 (117.4 examples/sec; 2.180 sec/batch)\n",
      "2017-05-29 10:00:42.372727: step 31420, loss = 1.10 (270.5 examples/sec; 0.946 sec/batch)\n",
      "2017-05-29 10:00:52.324391: step 31430, loss = 1.05 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-29 10:01:02.955370: step 31440, loss = 1.04 (240.8 examples/sec; 1.063 sec/batch)\n",
      "2017-05-29 10:01:13.377419: step 31450, loss = 0.98 (245.6 examples/sec; 1.042 sec/batch)\n",
      "2017-05-29 10:01:23.411140: step 31460, loss = 1.08 (255.1 examples/sec; 1.003 sec/batch)\n",
      "2017-05-29 10:01:34.321991: step 31470, loss = 0.93 (234.6 examples/sec; 1.091 sec/batch)\n",
      "2017-05-29 10:01:45.155556: step 31480, loss = 1.08 (236.3 examples/sec; 1.083 sec/batch)\n",
      "2017-05-29 10:01:55.224279: step 31490, loss = 1.03 (254.3 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 10:02:05.560251: step 31500, loss = 0.91 (247.7 examples/sec; 1.034 sec/batch)\n",
      "2017-05-29 10:02:24.074232: step 31510, loss = 0.98 (138.3 examples/sec; 1.851 sec/batch)\n",
      "2017-05-29 10:02:32.505864: step 31520, loss = 0.97 (303.6 examples/sec; 0.843 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4413  Precision @ 1 train: 0.8619\n",
      "2017-05-29 10:02:40.190499: step 31530, loss = 1.09 (333.1 examples/sec; 0.768 sec/batch)\n",
      "2017-05-29 10:02:48.554670: step 31540, loss = 1.01 (306.1 examples/sec; 0.836 sec/batch)\n",
      "  Num examples: 5120  Num correct: 4163  Precision @ 1 eval: 0.8131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-29 10:02:56.683113: step 31550, loss = 1.07 (314.9 examples/sec; 0.813 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.680528\n",
      "2017-05-29 10:03:06.091379: step 31560, loss = 0.96 (272.1 examples/sec; 0.941 sec/batch)\n",
      "2017-05-29 10:03:16.113467: step 31570, loss = 1.12 (255.4 examples/sec; 1.002 sec/batch)\n",
      "2017-05-29 10:03:26.032827: step 31580, loss = 1.02 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 10:03:35.970662: step 31590, loss = 0.89 (257.6 examples/sec; 0.994 sec/batch)\n",
      "2017-05-29 10:03:45.814423: step 31600, loss = 1.09 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 10:03:55.653654: step 31610, loss = 0.95 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-29 10:04:05.543481: step 31620, loss = 0.97 (258.9 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 10:04:15.337378: step 31630, loss = 1.01 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 10:04:25.652626: step 31640, loss = 0.97 (248.2 examples/sec; 1.032 sec/batch)\n",
      "2017-05-29 10:04:35.586887: step 31650, loss = 1.00 (257.7 examples/sec; 0.993 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.900533\n",
      "2017-05-29 10:04:56.487490: step 31660, loss = 1.04 (122.5 examples/sec; 2.090 sec/batch)\n",
      "2017-05-29 10:05:06.348479: step 31670, loss = 1.01 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 10:05:16.241768: step 31680, loss = 1.04 (258.8 examples/sec; 0.989 sec/batch)\n",
      "2017-05-29 10:05:26.160375: step 31690, loss = 1.05 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-29 10:05:36.228776: step 31700, loss = 0.99 (254.3 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 10:05:46.502524: step 31710, loss = 1.03 (249.2 examples/sec; 1.027 sec/batch)\n",
      "2017-05-29 10:05:56.287215: step 31720, loss = 0.99 (261.6 examples/sec; 0.978 sec/batch)\n",
      "2017-05-29 10:06:06.287625: step 31730, loss = 0.93 (256.0 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 10:06:16.244403: step 31740, loss = 1.07 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-29 10:06:26.071005: step 31750, loss = 0.99 (260.5 examples/sec; 0.983 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.909966\n",
      "2017-05-29 10:06:46.458465: step 31760, loss = 1.03 (125.6 examples/sec; 2.039 sec/batch)\n",
      "2017-05-29 10:06:56.249418: step 31770, loss = 1.16 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 10:07:06.316285: step 31780, loss = 0.99 (254.3 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 10:07:16.383109: step 31790, loss = 1.17 (254.3 examples/sec; 1.007 sec/batch)\n",
      "2017-05-29 10:07:26.317158: step 31800, loss = 0.99 (257.7 examples/sec; 0.993 sec/batch)\n",
      "2017-05-29 10:07:36.668116: step 31810, loss = 0.84 (247.3 examples/sec; 1.035 sec/batch)\n",
      "2017-05-29 10:07:46.523604: step 31820, loss = 0.97 (259.8 examples/sec; 0.986 sec/batch)\n",
      "2017-05-29 10:07:56.527415: step 31830, loss = 0.99 (255.9 examples/sec; 1.000 sec/batch)\n",
      "2017-05-29 10:08:06.321327: step 31840, loss = 1.02 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-29 10:08:16.432406: step 31850, loss = 1.02 (253.2 examples/sec; 1.011 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.923942\n",
      "2017-05-29 10:08:34.927288: step 31860, loss = 1.10 (138.4 examples/sec; 1.849 sec/batch)\n",
      "2017-05-29 10:08:45.619663: step 31870, loss = 0.91 (239.4 examples/sec; 1.069 sec/batch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 1049, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 1009, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 500, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python2.7/posixpath.py\", line 375, in realpath\n",
      "    path, ok = _joinrealpath('', filename, {})\n",
      "  File \"/usr/lib/python2.7/posixpath.py\", line 400, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1822\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1824\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1826\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1412\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1320\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m             )\n\u001b[1;32m   1322\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "Arguments.set_inference(\"resnet3\")\n",
    "print(Arguments.train_dir)\n",
    "\n",
    "cifar10_train.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
