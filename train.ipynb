{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# restart notebook when retrain model as some initial problem\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from cifar10 import cifar10_train\n",
    "from cifar10.cifar10_args import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "/home/ipython/cnn-cifar10/tb_log/res2/train\n",
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "(256,)\n",
      "INFO:tensorflow:Summary name conv1/weight_loss (raw) is illegal; using conv1/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res1-conv/weight_loss (raw) is illegal; using res1-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res1-res_conv/weight_loss (raw) is illegal; using res1-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res2-conv/weight_loss (raw) is illegal; using res2-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res2-res_conv/weight_loss (raw) is illegal; using res2-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res3-conv/weight_loss (raw) is illegal; using res3-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res3-res_conv/weight_loss (raw) is illegal; using res3-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res4-conv/weight_loss (raw) is illegal; using res4-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res4-res_conv/weight_loss (raw) is illegal; using res4-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res4-res_conv/res_conv_pad/weight_loss (raw) is illegal; using res4-res_conv/res_conv_pad/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res5-conv/weight_loss (raw) is illegal; using res5-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res5-res_conv/weight_loss (raw) is illegal; using res5-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res6-conv/weight_loss (raw) is illegal; using res6-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res6-res_conv/weight_loss (raw) is illegal; using res6-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res7-conv/weight_loss (raw) is illegal; using res7-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res7-res_conv/weight_loss (raw) is illegal; using res7-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res7-res_conv/res_conv_pad/weight_loss (raw) is illegal; using res7-res_conv/res_conv_pad/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res8-conv/weight_loss (raw) is illegal; using res8-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res8-res_conv/weight_loss (raw) is illegal; using res8-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res9-conv/weight_loss (raw) is illegal; using res9-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res9-res_conv/weight_loss (raw) is illegal; using res9-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res9-res_conv/res_conv_pad/weight_loss (raw) is illegal; using res9-res_conv/res_conv_pad/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res10-conv/weight_loss (raw) is illegal; using res10-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res10-res_conv/weight_loss (raw) is illegal; using res10-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res11-conv/weight_loss (raw) is illegal; using res11-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res11-res_conv/weight_loss (raw) is illegal; using res11-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res11-res_conv/res_conv_pad/weight_loss (raw) is illegal; using res11-res_conv/res_conv_pad/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res12-conv/weight_loss (raw) is illegal; using res12-conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name res12-res_conv/weight_loss (raw) is illegal; using res12-res_conv/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local4/weight_loss (raw) is illegal; using local4/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name softmax_linear/weight_loss (raw) is illegal; using softmax_linear/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name cross_entropy (raw) is illegal; using cross_entropy__raw_ instead.\n",
      "INFO:tensorflow:Summary name total_loss (raw) is illegal; using total_loss__raw_ instead.\n",
      "10000000\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-27 23:32:34.825195: step 0, loss = 47.96 (117.0 examples/sec; 2.187 sec/batch)\n",
      "2017-05-27 23:32:42.405621: step 10, loss = 30.29 (337.7 examples/sec; 0.758 sec/batch)\n",
      "2017-05-27 23:32:50.017095: step 20, loss = 18.79 (336.3 examples/sec; 0.761 sec/batch)\n",
      "2017-05-27 23:32:58.029837: step 30, loss = 11.68 (319.5 examples/sec; 0.801 sec/batch)\n",
      "2017-05-27 23:33:05.794683: step 40, loss = 7.49 (329.7 examples/sec; 0.776 sec/batch)\n",
      "2017-05-27 23:33:13.384288: step 50, loss = 5.05 (337.3 examples/sec; 0.759 sec/batch)\n",
      "2017-05-27 23:33:20.997688: step 60, loss = 3.74 (336.2 examples/sec; 0.761 sec/batch)\n",
      "2017-05-27 23:33:29.018282: step 70, loss = 2.98 (319.2 examples/sec; 0.802 sec/batch)\n",
      "2017-05-27 23:33:37.089343: step 80, loss = 2.60 (317.2 examples/sec; 0.807 sec/batch)\n",
      "2017-05-27 23:33:45.052411: step 90, loss = 2.36 (321.5 examples/sec; 0.796 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17978\n",
      "2017-05-27 23:33:58.381954: step 100, loss = 2.21 (192.1 examples/sec; 1.333 sec/batch)\n",
      "2017-05-27 23:34:05.684151: step 110, loss = 2.18 (350.6 examples/sec; 0.730 sec/batch)\n",
      "2017-05-27 23:34:13.857042: step 120, loss = 2.16 (313.2 examples/sec; 0.817 sec/batch)\n",
      "2017-05-27 23:34:21.760504: step 130, loss = 2.13 (323.9 examples/sec; 0.790 sec/batch)\n",
      "2017-05-27 23:34:29.659839: step 140, loss = 2.08 (324.1 examples/sec; 0.790 sec/batch)\n",
      "2017-05-27 23:34:38.384416: step 150, loss = 2.12 (293.4 examples/sec; 0.872 sec/batch)\n",
      "2017-05-27 23:34:46.572803: step 160, loss = 2.13 (312.6 examples/sec; 0.819 sec/batch)\n",
      "2017-05-27 23:34:54.631440: step 170, loss = 2.19 (317.7 examples/sec; 0.806 sec/batch)\n",
      "2017-05-27 23:35:02.594039: step 180, loss = 2.10 (321.5 examples/sec; 0.796 sec/batch)\n",
      "2017-05-27 23:35:11.138230: step 190, loss = 1.99 (299.6 examples/sec; 0.854 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1931\n",
      "2017-05-27 23:35:22.201267: step 200, loss = 1.99 (231.5 examples/sec; 1.106 sec/batch)\n",
      "2017-05-27 23:35:29.779102: step 210, loss = 2.09 (337.6 examples/sec; 0.758 sec/batch)\n",
      "2017-05-27 23:35:38.671453: step 220, loss = 2.03 (287.9 examples/sec; 0.889 sec/batch)\n",
      "2017-05-27 23:35:46.908363: step 230, loss = 2.04 (310.8 examples/sec; 0.824 sec/batch)\n",
      "2017-05-27 23:35:54.753659: step 240, loss = 2.02 (326.3 examples/sec; 0.785 sec/batch)\n",
      "2017-05-27 23:36:02.887871: step 250, loss = 1.93 (314.7 examples/sec; 0.813 sec/batch)\n",
      "2017-05-27 23:36:10.795876: step 260, loss = 2.00 (323.7 examples/sec; 0.791 sec/batch)\n",
      "2017-05-27 23:36:18.710533: step 270, loss = 2.07 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-27 23:36:26.602993: step 280, loss = 1.99 (324.4 examples/sec; 0.789 sec/batch)\n",
      "2017-05-27 23:36:35.098797: step 290, loss = 1.98 (301.3 examples/sec; 0.850 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18373\n",
      "2017-05-27 23:36:46.676367: step 300, loss = 1.96 (221.1 examples/sec; 1.158 sec/batch)\n",
      "2017-05-27 23:36:54.096089: step 310, loss = 1.98 (345.0 examples/sec; 0.742 sec/batch)\n",
      "2017-05-27 23:37:02.323549: step 320, loss = 1.97 (311.2 examples/sec; 0.823 sec/batch)\n",
      "2017-05-27 23:37:10.536322: step 330, loss = 1.91 (311.7 examples/sec; 0.821 sec/batch)\n",
      "2017-05-27 23:37:19.473234: step 340, loss = 1.85 (286.5 examples/sec; 0.894 sec/batch)\n",
      "2017-05-27 23:37:28.511955: step 350, loss = 1.82 (283.2 examples/sec; 0.904 sec/batch)\n",
      "2017-05-27 23:37:38.189258: step 360, loss = 1.91 (264.5 examples/sec; 0.968 sec/batch)\n",
      "2017-05-27 23:37:47.147717: step 370, loss = 1.77 (285.8 examples/sec; 0.896 sec/batch)\n",
      "2017-05-27 23:37:55.065028: step 380, loss = 1.88 (323.3 examples/sec; 0.792 sec/batch)\n",
      "2017-05-27 23:38:02.981235: step 390, loss = 2.02 (323.4 examples/sec; 0.792 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10988\n",
      "2017-05-27 23:38:16.779266: step 400, loss = 1.94 (185.5 examples/sec; 1.380 sec/batch)\n",
      "2017-05-27 23:38:24.102224: step 410, loss = 1.86 (349.6 examples/sec; 0.732 sec/batch)\n",
      "2017-05-27 23:38:32.001627: step 420, loss = 1.93 (324.1 examples/sec; 0.790 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-27 23:38:39.913724: step 430, loss = 1.82 (323.6 examples/sec; 0.791 sec/batch)\n",
      "2017-05-27 23:38:48.029019: step 440, loss = 1.83 (315.5 examples/sec; 0.812 sec/batch)\n",
      "2017-05-27 23:38:57.047117: step 450, loss = 1.94 (283.9 examples/sec; 0.902 sec/batch)\n",
      "2017-05-27 23:39:06.263615: step 460, loss = 1.96 (277.8 examples/sec; 0.922 sec/batch)\n",
      "2017-05-27 23:39:15.254869: step 470, loss = 1.85 (284.7 examples/sec; 0.899 sec/batch)\n",
      "2017-05-27 23:39:24.068963: step 480, loss = 1.79 (290.4 examples/sec; 0.881 sec/batch)\n",
      "2017-05-27 23:39:32.407161: step 490, loss = 1.79 (307.0 examples/sec; 0.834 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12862\n",
      "2017-05-27 23:39:45.381825: step 500, loss = 1.71 (197.3 examples/sec; 1.297 sec/batch)\n",
      "2017-05-27 23:39:53.308357: step 510, loss = 1.78 (323.0 examples/sec; 0.793 sec/batch)\n",
      "2017-05-27 23:40:01.910238: step 520, loss = 1.77 (297.6 examples/sec; 0.860 sec/batch)\n",
      "2017-05-27 23:40:10.136976: step 530, loss = 1.64 (311.2 examples/sec; 0.823 sec/batch)\n",
      "2017-05-27 23:40:18.913334: step 540, loss = 1.76 (291.7 examples/sec; 0.878 sec/batch)\n",
      "2017-05-27 23:40:27.254198: step 550, loss = 1.85 (306.9 examples/sec; 0.834 sec/batch)\n",
      "2017-05-27 23:40:35.337717: step 560, loss = 1.68 (316.7 examples/sec; 0.808 sec/batch)\n",
      "2017-05-27 23:40:43.925601: step 570, loss = 1.80 (298.1 examples/sec; 0.859 sec/batch)\n",
      "2017-05-27 23:40:52.418436: step 580, loss = 1.73 (301.4 examples/sec; 0.849 sec/batch)\n",
      "2017-05-27 23:41:00.561722: step 590, loss = 1.70 (314.4 examples/sec; 0.814 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11716\n",
      "2017-05-27 23:41:14.897876: step 600, loss = 1.69 (178.6 examples/sec; 1.434 sec/batch)\n",
      "2017-05-27 23:41:22.521053: step 610, loss = 1.74 (335.8 examples/sec; 0.762 sec/batch)\n",
      "2017-05-27 23:41:30.489527: step 620, loss = 1.75 (321.3 examples/sec; 0.797 sec/batch)\n",
      "2017-05-27 23:41:38.709739: step 630, loss = 1.57 (311.4 examples/sec; 0.822 sec/batch)\n",
      "2017-05-27 23:41:47.343997: step 640, loss = 1.74 (296.5 examples/sec; 0.863 sec/batch)\n",
      "2017-05-27 23:41:56.703389: step 650, loss = 1.65 (273.5 examples/sec; 0.936 sec/batch)\n",
      "2017-05-27 23:42:05.787279: step 660, loss = 1.60 (281.8 examples/sec; 0.908 sec/batch)\n",
      "2017-05-27 23:42:15.190043: step 670, loss = 1.72 (272.3 examples/sec; 0.940 sec/batch)\n",
      "2017-05-27 23:42:23.740061: step 680, loss = 1.64 (299.4 examples/sec; 0.855 sec/batch)\n",
      "2017-05-27 23:42:31.590373: step 690, loss = 1.72 (326.1 examples/sec; 0.785 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 694 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.10635\n",
      "2017-05-27 23:42:45.288242: step 700, loss = 1.58 (186.9 examples/sec; 1.370 sec/batch)\n",
      "2017-05-27 23:42:52.819367: step 710, loss = 1.72 (339.9 examples/sec; 0.753 sec/batch)\n",
      "2017-05-27 23:43:00.768140: step 720, loss = 1.62 (322.1 examples/sec; 0.795 sec/batch)\n",
      "2017-05-27 23:43:08.640003: step 730, loss = 1.70 (325.2 examples/sec; 0.787 sec/batch)\n",
      "2017-05-27 23:43:16.501220: step 740, loss = 1.68 (325.6 examples/sec; 0.786 sec/batch)\n",
      "2017-05-27 23:43:24.444171: step 750, loss = 1.57 (322.3 examples/sec; 0.794 sec/batch)\n",
      "2017-05-27 23:43:32.347723: step 760, loss = 1.62 (323.9 examples/sec; 0.790 sec/batch)\n",
      "2017-05-27 23:43:40.699057: step 770, loss = 1.63 (306.5 examples/sec; 0.835 sec/batch)\n",
      "2017-05-27 23:43:48.843079: step 780, loss = 1.63 (314.3 examples/sec; 0.814 sec/batch)\n",
      "2017-05-27 23:43:56.611380: step 790, loss = 1.65 (329.5 examples/sec; 0.777 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19657\n",
      "2017-05-27 23:44:08.857685: step 800, loss = 1.67 (209.0 examples/sec; 1.225 sec/batch)\n",
      "2017-05-27 23:44:16.246296: step 810, loss = 1.45 (346.5 examples/sec; 0.739 sec/batch)\n",
      "2017-05-27 23:44:24.127377: step 820, loss = 1.65 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-27 23:44:32.846149: step 830, loss = 1.57 (293.6 examples/sec; 0.872 sec/batch)\n",
      "2017-05-27 23:44:41.953530: step 840, loss = 1.70 (281.1 examples/sec; 0.911 sec/batch)\n",
      "2017-05-27 23:44:50.847862: step 850, loss = 1.56 (287.8 examples/sec; 0.889 sec/batch)\n",
      "2017-05-27 23:44:59.494781: step 860, loss = 1.62 (296.1 examples/sec; 0.865 sec/batch)\n",
      "2017-05-27 23:45:08.079331: step 870, loss = 1.75 (298.2 examples/sec; 0.858 sec/batch)\n",
      "2017-05-27 23:45:16.795639: step 880, loss = 1.59 (293.7 examples/sec; 0.872 sec/batch)\n",
      "2017-05-27 23:45:25.196870: step 890, loss = 1.54 (304.7 examples/sec; 0.840 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10144\n",
      "2017-05-27 23:45:39.643568: step 900, loss = 1.54 (177.2 examples/sec; 1.445 sec/batch)\n",
      "2017-05-27 23:45:47.494877: step 910, loss = 1.59 (326.1 examples/sec; 0.785 sec/batch)\n",
      "2017-05-27 23:45:55.437195: step 920, loss = 1.50 (322.3 examples/sec; 0.794 sec/batch)\n",
      "2017-05-27 23:46:04.104483: step 930, loss = 1.54 (295.4 examples/sec; 0.867 sec/batch)\n",
      "2017-05-27 23:46:12.308699: step 940, loss = 1.51 (312.0 examples/sec; 0.820 sec/batch)\n",
      "2017-05-27 23:46:20.282155: step 950, loss = 1.58 (321.1 examples/sec; 0.797 sec/batch)\n",
      "2017-05-27 23:46:28.164721: step 960, loss = 1.50 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-27 23:46:36.597808: step 970, loss = 1.63 (303.6 examples/sec; 0.843 sec/batch)\n",
      "2017-05-27 23:46:45.447035: step 980, loss = 1.58 (289.3 examples/sec; 0.885 sec/batch)\n",
      "2017-05-27 23:46:54.248331: step 990, loss = 1.63 (290.9 examples/sec; 0.880 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15367\n",
      "2017-05-27 23:47:06.323781: step 1000, loss = 1.52 (212.0 examples/sec; 1.208 sec/batch)\n",
      "2017-05-27 23:47:13.836971: step 1010, loss = 1.46 (340.7 examples/sec; 0.751 sec/batch)\n",
      "2017-05-27 23:47:22.252217: step 1020, loss = 1.53 (304.2 examples/sec; 0.842 sec/batch)\n",
      "2017-05-27 23:47:30.156036: step 1030, loss = 1.60 (323.9 examples/sec; 0.790 sec/batch)\n",
      "2017-05-27 23:47:38.639785: step 1040, loss = 1.59 (301.8 examples/sec; 0.848 sec/batch)\n",
      "2017-05-27 23:47:46.606148: step 1050, loss = 1.54 (321.4 examples/sec; 0.797 sec/batch)\n",
      "2017-05-27 23:47:54.548016: step 1060, loss = 1.53 (322.3 examples/sec; 0.794 sec/batch)\n",
      "2017-05-27 23:48:02.550402: step 1070, loss = 1.40 (319.9 examples/sec; 0.800 sec/batch)\n",
      "2017-05-27 23:48:10.950951: step 1080, loss = 1.63 (304.7 examples/sec; 0.840 sec/batch)\n",
      "2017-05-27 23:48:19.537660: step 1090, loss = 1.52 (298.1 examples/sec; 0.859 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18484\n",
      "2017-05-27 23:48:30.726619: step 1100, loss = 1.52 (228.8 examples/sec; 1.119 sec/batch)\n",
      "2017-05-27 23:48:38.553666: step 1110, loss = 1.43 (327.1 examples/sec; 0.783 sec/batch)\n",
      "2017-05-27 23:48:46.842187: step 1120, loss = 1.52 (308.9 examples/sec; 0.829 sec/batch)\n",
      "2017-05-27 23:48:55.172678: step 1130, loss = 1.50 (307.3 examples/sec; 0.833 sec/batch)\n",
      "2017-05-27 23:49:03.571341: step 1140, loss = 1.56 (304.8 examples/sec; 0.840 sec/batch)\n",
      "2017-05-27 23:49:12.397520: step 1150, loss = 1.43 (290.0 examples/sec; 0.883 sec/batch)\n",
      "2017-05-27 23:49:21.183688: step 1160, loss = 1.56 (291.4 examples/sec; 0.879 sec/batch)\n",
      "2017-05-27 23:49:29.531555: step 1170, loss = 1.54 (306.7 examples/sec; 0.835 sec/batch)\n",
      "2017-05-27 23:49:37.948026: step 1180, loss = 1.46 (304.2 examples/sec; 0.842 sec/batch)\n",
      "2017-05-27 23:49:46.320356: step 1190, loss = 1.50 (305.8 examples/sec; 0.837 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10562\n",
      "2017-05-27 23:50:01.171666: step 1200, loss = 1.46 (172.4 examples/sec; 1.485 sec/batch)\n",
      "2017-05-27 23:50:09.338604: step 1210, loss = 1.51 (313.5 examples/sec; 0.817 sec/batch)\n",
      "2017-05-27 23:50:17.720539: step 1220, loss = 1.62 (305.4 examples/sec; 0.838 sec/batch)\n",
      "2017-05-27 23:50:26.614579: step 1230, loss = 1.57 (287.8 examples/sec; 0.889 sec/batch)\n",
      "2017-05-27 23:50:36.458931: step 1240, loss = 1.50 (260.0 examples/sec; 0.984 sec/batch)\n",
      "2017-05-27 23:50:44.610665: step 1250, loss = 1.44 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-27 23:50:52.791478: step 1260, loss = 1.54 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-27 23:51:01.172448: step 1270, loss = 1.45 (305.5 examples/sec; 0.838 sec/batch)\n",
      "2017-05-27 23:51:09.501771: step 1280, loss = 1.43 (307.3 examples/sec; 0.833 sec/batch)\n",
      "2017-05-27 23:51:19.313006: step 1290, loss = 1.44 (260.9 examples/sec; 0.981 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.09725\n",
      "2017-05-27 23:51:32.307431: step 1300, loss = 1.57 (197.0 examples/sec; 1.299 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-27 23:51:40.052018: step 1310, loss = 1.47 (330.6 examples/sec; 0.774 sec/batch)\n",
      "2017-05-27 23:51:48.374776: step 1320, loss = 1.46 (307.6 examples/sec; 0.832 sec/batch)\n",
      "2017-05-27 23:51:56.383456: step 1330, loss = 1.40 (319.7 examples/sec; 0.801 sec/batch)\n",
      "2017-05-27 23:52:04.474290: step 1340, loss = 1.50 (316.4 examples/sec; 0.809 sec/batch)\n",
      "2017-05-27 23:52:12.467108: step 1350, loss = 1.39 (320.3 examples/sec; 0.799 sec/batch)\n",
      "2017-05-27 23:52:20.370734: step 1360, loss = 1.48 (323.9 examples/sec; 0.790 sec/batch)\n",
      "2017-05-27 23:52:28.692776: step 1370, loss = 1.51 (307.6 examples/sec; 0.832 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 1378 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-27 23:52:37.648758: step 1380, loss = 1.47 (285.8 examples/sec; 0.896 sec/batch)\n",
      "2017-05-27 23:52:45.349843: step 1390, loss = 1.54 (332.4 examples/sec; 0.770 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16432\n",
      "2017-05-27 23:52:58.193455: step 1400, loss = 1.48 (199.3 examples/sec; 1.284 sec/batch)\n",
      "2017-05-27 23:53:06.180904: step 1410, loss = 1.31 (320.5 examples/sec; 0.799 sec/batch)\n",
      "2017-05-27 23:53:15.295172: step 1420, loss = 1.42 (280.9 examples/sec; 0.911 sec/batch)\n",
      "2017-05-27 23:53:23.880845: step 1430, loss = 1.51 (298.2 examples/sec; 0.859 sec/batch)\n",
      "2017-05-27 23:53:32.040490: step 1440, loss = 1.40 (313.7 examples/sec; 0.816 sec/batch)\n",
      "2017-05-27 23:53:40.442694: step 1450, loss = 1.48 (304.7 examples/sec; 0.840 sec/batch)\n",
      "2017-05-27 23:53:48.466621: step 1460, loss = 1.50 (319.0 examples/sec; 0.802 sec/batch)\n",
      "2017-05-27 23:53:57.181216: step 1470, loss = 1.42 (293.8 examples/sec; 0.871 sec/batch)\n",
      "2017-05-27 23:54:06.025176: step 1480, loss = 1.39 (289.5 examples/sec; 0.884 sec/batch)\n",
      "2017-05-27 23:54:14.929862: step 1490, loss = 1.49 (287.5 examples/sec; 0.890 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10754\n",
      "2017-05-27 23:54:28.487253: step 1500, loss = 1.36 (188.8 examples/sec; 1.356 sec/batch)\n",
      "2017-05-27 23:54:37.465823: step 1510, loss = 1.41 (285.1 examples/sec; 0.898 sec/batch)\n",
      "2017-05-27 23:54:45.516665: step 1520, loss = 1.48 (318.0 examples/sec; 0.805 sec/batch)\n",
      "2017-05-27 23:54:54.313796: step 1530, loss = 1.44 (291.0 examples/sec; 0.880 sec/batch)\n",
      "2017-05-27 23:55:03.346074: step 1540, loss = 1.60 (283.4 examples/sec; 0.903 sec/batch)\n",
      "2017-05-27 23:55:11.884925: step 1550, loss = 1.55 (299.8 examples/sec; 0.854 sec/batch)\n",
      "2017-05-27 23:55:21.502197: step 1560, loss = 1.35 (266.2 examples/sec; 0.962 sec/batch)\n",
      "2017-05-27 23:55:30.755987: step 1570, loss = 1.49 (276.6 examples/sec; 0.925 sec/batch)\n",
      "2017-05-27 23:55:39.332564: step 1580, loss = 1.44 (298.5 examples/sec; 0.858 sec/batch)\n",
      "2017-05-27 23:55:47.258131: step 1590, loss = 1.46 (323.0 examples/sec; 0.793 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.08587\n",
      "2017-05-27 23:56:00.578176: step 1600, loss = 1.44 (192.2 examples/sec; 1.332 sec/batch)\n",
      "2017-05-27 23:56:08.043164: step 1610, loss = 1.29 (342.9 examples/sec; 0.746 sec/batch)\n",
      "2017-05-27 23:56:15.928775: step 1620, loss = 1.55 (324.6 examples/sec; 0.789 sec/batch)\n",
      "2017-05-27 23:56:23.895545: step 1630, loss = 1.41 (321.3 examples/sec; 0.797 sec/batch)\n",
      "2017-05-27 23:56:31.800866: step 1640, loss = 1.40 (323.8 examples/sec; 0.791 sec/batch)\n",
      "2017-05-27 23:56:40.370618: step 1650, loss = 1.51 (298.7 examples/sec; 0.857 sec/batch)\n",
      "2017-05-27 23:56:48.334631: step 1660, loss = 1.41 (321.4 examples/sec; 0.796 sec/batch)\n",
      "2017-05-27 23:56:56.254664: step 1670, loss = 1.44 (323.2 examples/sec; 0.792 sec/batch)\n",
      "2017-05-27 23:57:04.346635: step 1680, loss = 1.32 (316.4 examples/sec; 0.809 sec/batch)\n",
      "2017-05-27 23:57:12.309885: step 1690, loss = 1.51 (321.5 examples/sec; 0.796 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17693\n",
      "2017-05-27 23:57:25.547662: step 1700, loss = 1.34 (193.4 examples/sec; 1.324 sec/batch)\n",
      "2017-05-27 23:57:32.898477: step 1710, loss = 1.50 (348.3 examples/sec; 0.735 sec/batch)\n",
      "2017-05-27 23:57:40.873627: step 1720, loss = 1.46 (321.0 examples/sec; 0.798 sec/batch)\n",
      "2017-05-27 23:57:48.789354: step 1730, loss = 1.39 (323.4 examples/sec; 0.792 sec/batch)\n",
      "2017-05-27 23:57:56.910301: step 1740, loss = 1.40 (315.2 examples/sec; 0.812 sec/batch)\n",
      "2017-05-27 23:58:04.932040: step 1750, loss = 1.39 (319.1 examples/sec; 0.802 sec/batch)\n",
      "2017-05-27 23:58:12.883831: step 1760, loss = 1.35 (321.9 examples/sec; 0.795 sec/batch)\n",
      "2017-05-27 23:58:21.175809: step 1770, loss = 1.26 (308.7 examples/sec; 0.829 sec/batch)\n",
      "2017-05-27 23:58:29.225146: step 1780, loss = 1.38 (318.0 examples/sec; 0.805 sec/batch)\n",
      "2017-05-27 23:58:37.090869: step 1790, loss = 1.47 (325.5 examples/sec; 0.787 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20962\n",
      "2017-05-27 23:58:48.217888: step 1800, loss = 1.36 (230.1 examples/sec; 1.113 sec/batch)\n",
      "2017-05-27 23:58:56.058053: step 1810, loss = 1.36 (326.5 examples/sec; 0.784 sec/batch)\n",
      "2017-05-27 23:59:04.208320: step 1820, loss = 1.40 (314.1 examples/sec; 0.815 sec/batch)\n",
      "2017-05-27 23:59:12.205522: step 1830, loss = 1.42 (320.1 examples/sec; 0.800 sec/batch)\n",
      "2017-05-27 23:59:20.103848: step 1840, loss = 1.39 (324.1 examples/sec; 0.790 sec/batch)\n",
      "2017-05-27 23:59:28.008700: step 1850, loss = 1.35 (323.9 examples/sec; 0.790 sec/batch)\n",
      "2017-05-27 23:59:36.377752: step 1860, loss = 1.43 (305.9 examples/sec; 0.837 sec/batch)\n",
      "2017-05-27 23:59:44.356383: step 1870, loss = 1.41 (320.9 examples/sec; 0.798 sec/batch)\n",
      "2017-05-27 23:59:52.168698: step 1880, loss = 1.49 (327.7 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 00:00:00.345705: step 1890, loss = 1.42 (313.1 examples/sec; 0.818 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20211\n",
      "2017-05-28 00:00:11.400220: step 1900, loss = 1.48 (231.6 examples/sec; 1.105 sec/batch)\n",
      "2017-05-28 00:00:18.792477: step 1910, loss = 1.31 (346.3 examples/sec; 0.739 sec/batch)\n",
      "2017-05-28 00:00:26.737286: step 1920, loss = 1.59 (322.2 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 00:00:35.036663: step 1930, loss = 1.42 (308.5 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 00:00:43.272557: step 1940, loss = 1.40 (310.8 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 00:00:51.342362: step 1950, loss = 1.30 (317.2 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 00:00:59.289118: step 1960, loss = 1.53 (322.1 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 00:01:07.771126: step 1970, loss = 1.31 (301.8 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 00:01:15.740413: step 1980, loss = 1.39 (321.2 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 00:01:23.620055: step 1990, loss = 1.48 (324.9 examples/sec; 0.788 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19678\n",
      "2017-05-28 00:01:34.960986: step 2000, loss = 1.40 (225.7 examples/sec; 1.134 sec/batch)\n",
      "2017-05-28 00:01:42.439566: step 2010, loss = 1.32 (342.3 examples/sec; 0.748 sec/batch)\n",
      "2017-05-28 00:01:50.283560: step 2020, loss = 1.31 (326.4 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 00:01:58.181475: step 2030, loss = 1.38 (324.1 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 00:02:06.096904: step 2040, loss = 1.39 (323.4 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 00:02:14.044894: step 2050, loss = 1.37 (322.1 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 00:02:22.421336: step 2060, loss = 1.30 (305.6 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 00:02:30.542040: step 2070, loss = 1.30 (315.2 examples/sec; 0.812 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 2076 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 00:02:39.413634: step 2080, loss = 1.40 (288.6 examples/sec; 0.887 sec/batch)\n",
      "2017-05-28 00:02:47.300132: step 2090, loss = 1.27 (324.6 examples/sec; 0.789 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18805\n",
      "2017-05-28 00:02:59.129893: step 2100, loss = 1.28 (216.4 examples/sec; 1.183 sec/batch)\n",
      "2017-05-28 00:03:06.663127: step 2110, loss = 1.20 (339.8 examples/sec; 0.753 sec/batch)\n",
      "2017-05-28 00:03:15.030385: step 2120, loss = 1.29 (306.0 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 00:03:22.890279: step 2130, loss = 1.56 (325.7 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 00:03:31.038248: step 2140, loss = 1.31 (314.2 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 00:03:39.133001: step 2150, loss = 1.40 (316.3 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 00:03:47.042048: step 2160, loss = 1.31 (323.7 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 00:03:54.950059: step 2170, loss = 1.38 (323.7 examples/sec; 0.791 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 00:04:02.884061: step 2180, loss = 1.31 (322.7 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 00:04:10.941741: step 2190, loss = 1.30 (317.7 examples/sec; 0.806 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18372\n",
      "2017-05-28 00:04:23.612488: step 2200, loss = 1.30 (202.0 examples/sec; 1.267 sec/batch)\n",
      "2017-05-28 00:04:30.979708: step 2210, loss = 1.36 (347.5 examples/sec; 0.737 sec/batch)\n",
      "2017-05-28 00:04:38.804483: step 2220, loss = 1.35 (327.2 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 00:04:46.785887: step 2230, loss = 1.30 (320.7 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 00:04:54.884837: step 2240, loss = 1.35 (316.1 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 00:05:02.992629: step 2250, loss = 1.35 (315.7 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 00:05:11.231568: step 2260, loss = 1.29 (310.7 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 00:05:19.208943: step 2270, loss = 1.28 (320.9 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 00:05:27.088011: step 2280, loss = 1.23 (324.9 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 00:05:34.962242: step 2290, loss = 1.28 (325.1 examples/sec; 0.787 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18248\n",
      "2017-05-28 00:05:48.178170: step 2300, loss = 1.35 (193.7 examples/sec; 1.322 sec/batch)\n",
      "2017-05-28 00:05:55.544358: step 2310, loss = 1.25 (347.5 examples/sec; 0.737 sec/batch)\n",
      "2017-05-28 00:06:03.734040: step 2320, loss = 1.41 (312.6 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 00:06:11.706475: step 2330, loss = 1.29 (321.1 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 00:06:19.602754: step 2340, loss = 1.36 (324.2 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 00:06:27.552524: step 2350, loss = 1.54 (322.0 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 00:06:35.460575: step 2360, loss = 1.42 (323.7 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 00:06:43.370454: step 2370, loss = 1.27 (323.6 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 00:06:51.326496: step 2380, loss = 1.32 (321.8 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 00:06:59.799772: step 2390, loss = 1.32 (302.1 examples/sec; 0.847 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20613\n",
      "2017-05-28 00:07:11.089805: step 2400, loss = 1.29 (226.7 examples/sec; 1.129 sec/batch)\n",
      "2017-05-28 00:07:18.466544: step 2410, loss = 1.32 (347.0 examples/sec; 0.738 sec/batch)\n",
      "2017-05-28 00:07:26.435315: step 2420, loss = 1.54 (321.3 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 00:07:34.319761: step 2430, loss = 1.36 (324.7 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 00:07:42.299136: step 2440, loss = 1.32 (320.8 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 00:07:50.751216: step 2450, loss = 1.24 (302.9 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 00:07:58.750158: step 2460, loss = 1.28 (320.0 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 00:08:06.744774: step 2470, loss = 1.23 (320.2 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 00:08:14.791794: step 2480, loss = 1.26 (318.1 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 00:08:22.655483: step 2490, loss = 1.33 (325.5 examples/sec; 0.786 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20854\n",
      "2017-05-28 00:08:33.836544: step 2500, loss = 1.41 (229.0 examples/sec; 1.118 sec/batch)\n",
      "2017-05-28 00:08:41.533620: step 2510, loss = 1.36 (332.6 examples/sec; 0.770 sec/batch)\n",
      "2017-05-28 00:08:49.696112: step 2520, loss = 1.33 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 00:08:57.616921: step 2530, loss = 1.31 (323.2 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 00:09:05.539280: step 2540, loss = 1.30 (323.1 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 00:09:13.522750: step 2550, loss = 1.26 (320.7 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 00:09:21.475986: step 2560, loss = 1.22 (321.9 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 00:09:29.349564: step 2570, loss = 1.29 (325.1 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 00:09:37.379446: step 2580, loss = 1.45 (318.8 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 00:09:45.705275: step 2590, loss = 1.21 (307.5 examples/sec; 0.833 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17808\n",
      "2017-05-28 00:09:58.720197: step 2600, loss = 1.44 (196.7 examples/sec; 1.301 sec/batch)\n",
      "2017-05-28 00:10:06.845527: step 2610, loss = 1.32 (315.1 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 00:10:16.105964: step 2620, loss = 1.28 (276.4 examples/sec; 0.926 sec/batch)\n",
      "2017-05-28 00:10:24.822063: step 2630, loss = 1.25 (293.7 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 00:10:34.295067: step 2640, loss = 1.41 (270.2 examples/sec; 0.947 sec/batch)\n",
      "2017-05-28 00:10:42.595125: step 2650, loss = 1.17 (308.4 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 00:10:51.671389: step 2660, loss = 1.27 (282.1 examples/sec; 0.908 sec/batch)\n",
      "2017-05-28 00:11:00.623470: step 2670, loss = 1.25 (286.0 examples/sec; 0.895 sec/batch)\n",
      "2017-05-28 00:11:10.625992: step 2680, loss = 1.28 (255.9 examples/sec; 1.000 sec/batch)\n",
      "2017-05-28 00:11:20.151487: step 2690, loss = 1.21 (268.8 examples/sec; 0.953 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.07608\n",
      "2017-05-28 00:11:31.647919: step 2700, loss = 1.33 (222.7 examples/sec; 1.150 sec/batch)\n",
      "2017-05-28 00:11:39.112363: step 2710, loss = 1.18 (343.0 examples/sec; 0.746 sec/batch)\n",
      "2017-05-28 00:11:47.500646: step 2720, loss = 1.37 (305.2 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 00:11:55.537710: step 2730, loss = 1.14 (318.5 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 00:12:03.809408: step 2740, loss = 1.26 (309.5 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 00:12:13.091199: step 2750, loss = 1.11 (275.8 examples/sec; 0.928 sec/batch)\n",
      "2017-05-28 00:12:21.977595: step 2760, loss = 1.32 (288.1 examples/sec; 0.889 sec/batch)\n",
      "2017-05-28 00:12:30.792243: step 2770, loss = 1.28 (290.4 examples/sec; 0.881 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 2776 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 00:12:40.594592: step 2780, loss = 1.27 (261.2 examples/sec; 0.980 sec/batch)\n",
      "2017-05-28 00:12:50.417392: step 2790, loss = 1.35 (260.6 examples/sec; 0.982 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.09089\n",
      "2017-05-28 00:13:03.313802: step 2800, loss = 1.28 (198.5 examples/sec; 1.290 sec/batch)\n",
      "2017-05-28 00:13:11.764607: step 2810, loss = 1.23 (302.9 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 00:13:20.966227: step 2820, loss = 1.18 (278.2 examples/sec; 0.920 sec/batch)\n",
      "2017-05-28 00:13:29.674831: step 2830, loss = 1.28 (294.0 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 00:13:38.788617: step 2840, loss = 1.33 (280.9 examples/sec; 0.911 sec/batch)\n",
      "2017-05-28 00:13:47.539632: step 2850, loss = 1.44 (292.5 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 00:13:56.718515: step 2860, loss = 1.30 (278.9 examples/sec; 0.918 sec/batch)\n",
      "2017-05-28 00:14:07.100630: step 2870, loss = 1.31 (246.6 examples/sec; 1.038 sec/batch)\n",
      "2017-05-28 00:14:16.505545: step 2880, loss = 1.31 (272.2 examples/sec; 0.940 sec/batch)\n",
      "2017-05-28 00:14:27.001398: step 2890, loss = 1.34 (243.9 examples/sec; 1.050 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.02505\n",
      "2017-05-28 00:14:40.871898: step 2900, loss = 1.20 (184.6 examples/sec; 1.387 sec/batch)\n",
      "2017-05-28 00:14:48.256138: step 2910, loss = 1.24 (346.7 examples/sec; 0.738 sec/batch)\n",
      "2017-05-28 00:14:56.184300: step 2920, loss = 1.36 (322.9 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 00:15:04.305455: step 2930, loss = 1.27 (315.2 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 00:15:12.638925: step 2940, loss = 1.25 (307.2 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 00:15:20.786320: step 2950, loss = 1.33 (314.2 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 00:15:28.726084: step 2960, loss = 1.31 (322.4 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 00:15:37.135999: step 2970, loss = 1.22 (304.4 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 00:15:45.919657: step 2980, loss = 1.29 (291.5 examples/sec; 0.878 sec/batch)\n",
      "2017-05-28 00:15:54.234815: step 2990, loss = 1.32 (307.9 examples/sec; 0.832 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14285\n",
      "2017-05-28 00:16:08.370509: step 3000, loss = 1.27 (181.1 examples/sec; 1.414 sec/batch)\n",
      "2017-05-28 00:16:16.665050: step 3010, loss = 1.24 (308.6 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 00:16:26.177837: step 3020, loss = 1.35 (269.1 examples/sec; 0.951 sec/batch)\n",
      "2017-05-28 00:16:35.450705: step 3030, loss = 1.27 (276.1 examples/sec; 0.927 sec/batch)\n",
      "2017-05-28 00:16:44.143798: step 3040, loss = 1.24 (294.5 examples/sec; 0.869 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 00:16:53.446441: step 3050, loss = 1.34 (275.2 examples/sec; 0.930 sec/batch)\n",
      "2017-05-28 00:17:02.950480: step 3060, loss = 1.25 (269.4 examples/sec; 0.950 sec/batch)\n",
      "2017-05-28 00:17:12.091425: step 3070, loss = 1.33 (280.1 examples/sec; 0.914 sec/batch)\n",
      "2017-05-28 00:17:22.083274: step 3080, loss = 1.27 (256.2 examples/sec; 0.999 sec/batch)\n",
      "2017-05-28 00:17:31.498096: step 3090, loss = 1.27 (271.9 examples/sec; 0.941 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.03565\n",
      "2017-05-28 00:17:44.933217: step 3100, loss = 1.20 (190.5 examples/sec; 1.344 sec/batch)\n",
      "2017-05-28 00:17:53.730874: step 3110, loss = 1.21 (291.0 examples/sec; 0.880 sec/batch)\n",
      "2017-05-28 00:18:03.027414: step 3120, loss = 1.36 (275.4 examples/sec; 0.930 sec/batch)\n",
      "2017-05-28 00:18:12.180458: step 3130, loss = 1.25 (279.7 examples/sec; 0.915 sec/batch)\n",
      "2017-05-28 00:18:22.059273: step 3140, loss = 1.33 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-28 00:18:31.103859: step 3150, loss = 1.15 (283.0 examples/sec; 0.904 sec/batch)\n",
      "2017-05-28 00:18:39.983932: step 3160, loss = 1.23 (288.3 examples/sec; 0.888 sec/batch)\n",
      "2017-05-28 00:18:48.967696: step 3170, loss = 1.26 (285.0 examples/sec; 0.898 sec/batch)\n",
      "2017-05-28 00:18:58.117736: step 3180, loss = 1.22 (279.8 examples/sec; 0.915 sec/batch)\n",
      "2017-05-28 00:19:07.758359: step 3190, loss = 1.24 (265.5 examples/sec; 0.964 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.02138\n",
      "2017-05-28 00:19:22.841643: step 3200, loss = 1.13 (169.7 examples/sec; 1.508 sec/batch)\n",
      "2017-05-28 00:19:31.748818: step 3210, loss = 1.09 (287.4 examples/sec; 0.891 sec/batch)\n",
      "2017-05-28 00:19:40.755283: step 3220, loss = 1.19 (284.2 examples/sec; 0.901 sec/batch)\n",
      "2017-05-28 00:19:49.932406: step 3230, loss = 1.29 (279.0 examples/sec; 0.918 sec/batch)\n",
      "2017-05-28 00:19:58.298753: step 3240, loss = 1.26 (306.0 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 00:20:06.740479: step 3250, loss = 1.33 (303.3 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 00:20:15.019850: step 3260, loss = 1.10 (309.2 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 00:20:23.274562: step 3270, loss = 1.31 (310.1 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 00:20:31.651537: step 3280, loss = 1.22 (305.6 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 00:20:39.986520: step 3290, loss = 1.16 (307.1 examples/sec; 0.833 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11139\n",
      "2017-05-28 00:20:52.812660: step 3300, loss = 1.26 (199.6 examples/sec; 1.283 sec/batch)\n",
      "2017-05-28 00:21:01.123248: step 3310, loss = 1.23 (308.0 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 00:21:10.258105: step 3320, loss = 1.21 (280.2 examples/sec; 0.913 sec/batch)\n",
      "2017-05-28 00:21:20.093800: step 3330, loss = 1.16 (260.3 examples/sec; 0.984 sec/batch)\n",
      "2017-05-28 00:21:29.037451: step 3340, loss = 1.30 (286.2 examples/sec; 0.894 sec/batch)\n",
      "2017-05-28 00:21:38.737196: step 3350, loss = 1.20 (263.9 examples/sec; 0.970 sec/batch)\n",
      "2017-05-28 00:21:47.258747: step 3360, loss = 1.26 (300.4 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 00:21:56.330123: step 3370, loss = 1.16 (282.2 examples/sec; 0.907 sec/batch)\n",
      "2017-05-28 00:22:05.474719: step 3380, loss = 1.21 (279.9 examples/sec; 0.914 sec/batch)\n",
      "2017-05-28 00:22:14.289884: step 3390, loss = 1.25 (290.4 examples/sec; 0.882 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.05505\n",
      "2017-05-28 00:22:27.597440: step 3400, loss = 1.09 (192.4 examples/sec; 1.331 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 3411 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 00:22:36.726258: step 3410, loss = 1.20 (280.4 examples/sec; 0.913 sec/batch)\n",
      "2017-05-28 00:22:44.649480: step 3420, loss = 1.28 (323.1 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 00:22:54.139159: step 3430, loss = 1.22 (269.8 examples/sec; 0.949 sec/batch)\n",
      "2017-05-28 00:23:02.713096: step 3440, loss = 1.30 (298.6 examples/sec; 0.857 sec/batch)\n",
      "2017-05-28 00:23:11.394568: step 3450, loss = 1.23 (294.9 examples/sec; 0.868 sec/batch)\n",
      "2017-05-28 00:23:19.803675: step 3460, loss = 1.27 (304.4 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 00:23:28.192929: step 3470, loss = 1.19 (305.2 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 00:23:38.063494: step 3480, loss = 1.18 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-28 00:23:47.241294: step 3490, loss = 1.17 (278.9 examples/sec; 0.918 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.05412\n",
      "2017-05-28 00:24:02.463707: step 3500, loss = 1.23 (168.2 examples/sec; 1.522 sec/batch)\n",
      "2017-05-28 00:24:10.495482: step 3510, loss = 1.22 (318.7 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 00:24:18.627564: step 3520, loss = 1.18 (314.8 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 00:24:28.447581: step 3530, loss = 1.30 (260.7 examples/sec; 0.982 sec/batch)\n",
      "2017-05-28 00:24:37.667815: step 3540, loss = 1.21 (277.7 examples/sec; 0.922 sec/batch)\n",
      "2017-05-28 00:24:46.371577: step 3550, loss = 1.18 (294.1 examples/sec; 0.870 sec/batch)\n",
      "2017-05-28 00:24:55.364796: step 3560, loss = 1.24 (284.7 examples/sec; 0.899 sec/batch)\n",
      "2017-05-28 00:25:04.288678: step 3570, loss = 1.15 (286.9 examples/sec; 0.892 sec/batch)\n",
      "2017-05-28 00:25:14.216140: step 3580, loss = 1.31 (257.9 examples/sec; 0.993 sec/batch)\n",
      "2017-05-28 00:25:23.143253: step 3590, loss = 1.13 (286.8 examples/sec; 0.893 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.04782\n",
      "2017-05-28 00:25:37.903288: step 3600, loss = 1.25 (173.4 examples/sec; 1.476 sec/batch)\n",
      "2017-05-28 00:25:46.649746: step 3610, loss = 1.37 (292.7 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 00:25:56.255903: step 3620, loss = 1.31 (266.5 examples/sec; 0.961 sec/batch)\n",
      "2017-05-28 00:26:06.415634: step 3630, loss = 1.15 (252.0 examples/sec; 1.016 sec/batch)\n",
      "2017-05-28 00:26:15.225377: step 3640, loss = 1.22 (290.6 examples/sec; 0.881 sec/batch)\n",
      "2017-05-28 00:26:23.889358: step 3650, loss = 1.14 (295.5 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 00:26:33.147912: step 3660, loss = 1.28 (276.5 examples/sec; 0.926 sec/batch)\n",
      "2017-05-28 00:26:42.447587: step 3670, loss = 1.12 (275.3 examples/sec; 0.930 sec/batch)\n",
      "2017-05-28 00:26:51.036443: step 3680, loss = 1.17 (298.1 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 00:26:59.304901: step 3690, loss = 1.21 (309.6 examples/sec; 0.827 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.03327\n",
      "2017-05-28 00:27:14.679948: step 3700, loss = 1.18 (166.5 examples/sec; 1.538 sec/batch)\n",
      "2017-05-28 00:27:23.083309: step 3710, loss = 1.22 (304.6 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 00:27:32.604629: step 3720, loss = 1.20 (268.9 examples/sec; 0.952 sec/batch)\n",
      "2017-05-28 00:27:41.666225: step 3730, loss = 1.12 (282.5 examples/sec; 0.906 sec/batch)\n",
      "2017-05-28 00:27:50.117254: step 3740, loss = 1.28 (302.9 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 00:27:58.748027: step 3750, loss = 1.34 (296.6 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 00:28:07.509999: step 3760, loss = 1.29 (292.2 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 00:28:16.349292: step 3770, loss = 1.24 (289.6 examples/sec; 0.884 sec/batch)\n",
      "2017-05-28 00:28:26.044304: step 3780, loss = 1.23 (264.1 examples/sec; 0.970 sec/batch)\n",
      "2017-05-28 00:28:34.578683: step 3790, loss = 1.24 (300.0 examples/sec; 0.853 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.08762\n",
      "2017-05-28 00:28:46.624706: step 3800, loss = 1.19 (212.5 examples/sec; 1.205 sec/batch)\n",
      "2017-05-28 00:28:54.900667: step 3810, loss = 1.25 (309.3 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 00:29:04.015725: step 3820, loss = 1.13 (280.9 examples/sec; 0.912 sec/batch)\n",
      "2017-05-28 00:29:12.645627: step 3830, loss = 1.13 (296.6 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 00:29:21.578842: step 3840, loss = 1.13 (286.6 examples/sec; 0.893 sec/batch)\n",
      "2017-05-28 00:29:30.143970: step 3850, loss = 1.20 (298.9 examples/sec; 0.857 sec/batch)\n",
      "2017-05-28 00:29:39.938543: step 3860, loss = 1.16 (261.4 examples/sec; 0.979 sec/batch)\n",
      "2017-05-28 00:29:48.665854: step 3870, loss = 1.11 (293.3 examples/sec; 0.873 sec/batch)\n",
      "2017-05-28 00:29:57.423382: step 3880, loss = 1.15 (292.3 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 00:30:06.512761: step 3890, loss = 1.24 (281.6 examples/sec; 0.909 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.06298\n",
      "2017-05-28 00:30:20.700688: step 3900, loss = 1.33 (180.4 examples/sec; 1.419 sec/batch)\n",
      "2017-05-28 00:30:28.891844: step 3910, loss = 1.26 (312.5 examples/sec; 0.819 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 00:30:38.131455: step 3920, loss = 1.24 (277.1 examples/sec; 0.924 sec/batch)\n",
      "2017-05-28 00:30:46.798932: step 3930, loss = 1.21 (295.4 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 00:30:56.510897: step 3940, loss = 1.32 (263.6 examples/sec; 0.971 sec/batch)\n",
      "2017-05-28 00:31:05.621056: step 3950, loss = 1.22 (281.0 examples/sec; 0.911 sec/batch)\n",
      "2017-05-28 00:31:14.752983: step 3960, loss = 1.15 (280.3 examples/sec; 0.913 sec/batch)\n",
      "2017-05-28 00:31:24.135657: step 3970, loss = 1.29 (272.8 examples/sec; 0.938 sec/batch)\n",
      "2017-05-28 00:31:33.410793: step 3980, loss = 1.14 (276.0 examples/sec; 0.928 sec/batch)\n",
      "2017-05-28 00:31:42.386436: step 3990, loss = 1.22 (285.2 examples/sec; 0.898 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.05935\n",
      "2017-05-28 00:31:55.097516: step 4000, loss = 1.28 (201.4 examples/sec; 1.271 sec/batch)\n",
      "2017-05-28 00:32:03.824703: step 4010, loss = 1.22 (293.3 examples/sec; 0.873 sec/batch)\n",
      "2017-05-28 00:32:12.439360: step 4020, loss = 1.21 (297.2 examples/sec; 0.861 sec/batch)\n",
      "2017-05-28 00:32:21.329135: step 4030, loss = 1.19 (288.0 examples/sec; 0.889 sec/batch)\n",
      "2017-05-28 00:32:30.831184: step 4040, loss = 1.22 (269.4 examples/sec; 0.950 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 4046 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 00:32:42.578442: step 4050, loss = 1.15 (217.9 examples/sec; 1.175 sec/batch)\n",
      "2017-05-28 00:32:52.183186: step 4060, loss = 1.12 (266.5 examples/sec; 0.960 sec/batch)\n",
      "2017-05-28 00:33:01.671181: step 4070, loss = 1.22 (269.8 examples/sec; 0.949 sec/batch)\n",
      "2017-05-28 00:33:11.639909: step 4080, loss = 1.39 (256.8 examples/sec; 0.997 sec/batch)\n",
      "2017-05-28 00:33:20.790090: step 4090, loss = 1.20 (279.8 examples/sec; 0.915 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.01462\n",
      "2017-05-28 00:33:33.654522: step 4100, loss = 1.26 (199.0 examples/sec; 1.286 sec/batch)\n",
      "2017-05-28 00:33:42.798849: step 4110, loss = 1.15 (280.0 examples/sec; 0.914 sec/batch)\n",
      "2017-05-28 00:33:52.559532: step 4120, loss = 1.03 (262.3 examples/sec; 0.976 sec/batch)\n",
      "2017-05-28 00:34:01.774446: step 4130, loss = 1.21 (277.8 examples/sec; 0.921 sec/batch)\n",
      "2017-05-28 00:34:11.166410: step 4140, loss = 1.08 (272.6 examples/sec; 0.939 sec/batch)\n",
      "2017-05-28 00:34:20.295930: step 4150, loss = 1.16 (280.4 examples/sec; 0.913 sec/batch)\n",
      "2017-05-28 00:34:30.227474: step 4160, loss = 1.12 (257.8 examples/sec; 0.993 sec/batch)\n",
      "2017-05-28 00:34:39.475893: step 4170, loss = 1.06 (276.8 examples/sec; 0.925 sec/batch)\n",
      "2017-05-28 00:34:49.242512: step 4180, loss = 1.26 (262.1 examples/sec; 0.977 sec/batch)\n",
      "2017-05-28 00:34:58.088120: step 4190, loss = 1.29 (289.4 examples/sec; 0.885 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.00179\n",
      "2017-05-28 00:35:13.478322: step 4200, loss = 1.17 (166.3 examples/sec; 1.539 sec/batch)\n",
      "2017-05-28 00:35:22.176642: step 4210, loss = 1.24 (294.3 examples/sec; 0.870 sec/batch)\n",
      "2017-05-28 00:35:31.235197: step 4220, loss = 1.26 (282.6 examples/sec; 0.906 sec/batch)\n",
      "2017-05-28 00:35:40.520128: step 4230, loss = 1.17 (275.7 examples/sec; 0.928 sec/batch)\n",
      "2017-05-28 00:35:49.511513: step 4240, loss = 1.13 (284.7 examples/sec; 0.899 sec/batch)\n",
      "2017-05-28 00:35:58.341953: step 4250, loss = 1.21 (289.9 examples/sec; 0.883 sec/batch)\n",
      "2017-05-28 00:36:06.887896: step 4260, loss = 1.21 (299.6 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 00:36:16.912092: step 4270, loss = 1.17 (255.4 examples/sec; 1.002 sec/batch)\n",
      "2017-05-28 00:36:26.332114: step 4280, loss = 1.31 (271.8 examples/sec; 0.942 sec/batch)\n",
      "2017-05-28 00:36:35.702813: step 4290, loss = 1.30 (273.2 examples/sec; 0.937 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.04965\n",
      "2017-05-28 00:36:48.744125: step 4300, loss = 1.14 (196.3 examples/sec; 1.304 sec/batch)\n",
      "2017-05-28 00:36:56.713167: step 4310, loss = 1.00 (321.2 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 00:37:05.846481: step 4320, loss = 1.20 (280.3 examples/sec; 0.913 sec/batch)\n",
      "2017-05-28 00:37:15.072212: step 4330, loss = 1.18 (277.5 examples/sec; 0.923 sec/batch)\n",
      "2017-05-28 00:37:24.255545: step 4340, loss = 1.24 (278.8 examples/sec; 0.918 sec/batch)\n",
      "2017-05-28 00:37:33.243311: step 4350, loss = 1.15 (284.8 examples/sec; 0.899 sec/batch)\n",
      "2017-05-28 00:37:43.260396: step 4360, loss = 1.14 (255.6 examples/sec; 1.002 sec/batch)\n",
      "2017-05-28 00:37:53.385593: step 4370, loss = 1.06 (252.8 examples/sec; 1.013 sec/batch)\n",
      "2017-05-28 00:38:03.427133: step 4380, loss = 1.22 (254.9 examples/sec; 1.004 sec/batch)\n",
      "2017-05-28 00:38:13.303091: step 4390, loss = 1.16 (259.2 examples/sec; 0.988 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.01676\n",
      "2017-05-28 00:38:27.100436: step 4400, loss = 1.11 (185.5 examples/sec; 1.380 sec/batch)\n",
      "2017-05-28 00:38:35.355076: step 4410, loss = 1.16 (310.1 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 00:38:44.611454: step 4420, loss = 1.03 (276.6 examples/sec; 0.926 sec/batch)\n",
      "2017-05-28 00:38:53.988033: step 4430, loss = 1.09 (273.0 examples/sec; 0.938 sec/batch)\n",
      "2017-05-28 00:39:02.992649: step 4440, loss = 1.14 (284.3 examples/sec; 0.900 sec/batch)\n",
      "2017-05-28 00:39:12.799948: step 4450, loss = 1.23 (261.0 examples/sec; 0.981 sec/batch)\n",
      "2017-05-28 00:39:22.142897: step 4460, loss = 1.16 (274.0 examples/sec; 0.934 sec/batch)\n",
      "2017-05-28 00:39:31.934293: step 4470, loss = 1.22 (261.5 examples/sec; 0.979 sec/batch)\n",
      "2017-05-28 00:39:40.625890: step 4480, loss = 1.13 (294.5 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 00:39:49.304826: step 4490, loss = 1.14 (295.0 examples/sec; 0.868 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.03087\n",
      "2017-05-28 00:40:04.103817: step 4500, loss = 1.22 (173.0 examples/sec; 1.480 sec/batch)\n",
      "2017-05-28 00:40:12.173864: step 4510, loss = 1.13 (317.2 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 00:40:20.748512: step 4520, loss = 1.15 (298.6 examples/sec; 0.857 sec/batch)\n",
      "2017-05-28 00:40:30.186240: step 4530, loss = 1.14 (271.3 examples/sec; 0.944 sec/batch)\n",
      "2017-05-28 00:40:39.252102: step 4540, loss = 1.21 (282.4 examples/sec; 0.907 sec/batch)\n",
      "2017-05-28 00:40:48.194585: step 4550, loss = 1.15 (286.3 examples/sec; 0.894 sec/batch)\n",
      "2017-05-28 00:40:56.944859: step 4560, loss = 1.12 (292.6 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 00:41:06.677635: step 4570, loss = 1.22 (263.0 examples/sec; 0.973 sec/batch)\n",
      "2017-05-28 00:41:15.691220: step 4580, loss = 1.20 (284.0 examples/sec; 0.901 sec/batch)\n",
      "2017-05-28 00:41:25.024343: step 4590, loss = 1.15 (274.3 examples/sec; 0.933 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.06729\n",
      "2017-05-28 00:41:37.811725: step 4600, loss = 1.09 (200.2 examples/sec; 1.279 sec/batch)\n",
      "2017-05-28 00:41:46.658315: step 4610, loss = 1.17 (289.4 examples/sec; 0.885 sec/batch)\n",
      "2017-05-28 00:41:56.557474: step 4620, loss = 1.08 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-28 00:42:06.049501: step 4630, loss = 1.10 (269.7 examples/sec; 0.949 sec/batch)\n",
      "2017-05-28 00:42:15.115063: step 4640, loss = 1.15 (282.4 examples/sec; 0.907 sec/batch)\n",
      "2017-05-28 00:42:23.407856: step 4650, loss = 1.19 (308.7 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 00:42:32.090245: step 4660, loss = 1.12 (294.8 examples/sec; 0.868 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 4666 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 00:42:41.012074: step 4670, loss = 1.24 (286.9 examples/sec; 0.892 sec/batch)\n",
      "2017-05-28 00:42:49.035479: step 4680, loss = 0.99 (319.1 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 00:42:57.217111: step 4690, loss = 1.12 (312.9 examples/sec; 0.818 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.08713\n",
      "2017-05-28 00:43:09.782384: step 4700, loss = 1.22 (203.7 examples/sec; 1.257 sec/batch)\n",
      "2017-05-28 00:43:17.919921: step 4710, loss = 1.27 (314.6 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 00:43:26.803651: step 4720, loss = 1.14 (288.2 examples/sec; 0.888 sec/batch)\n",
      "2017-05-28 00:43:35.759058: step 4730, loss = 1.11 (285.9 examples/sec; 0.896 sec/batch)\n",
      "2017-05-28 00:43:43.974898: step 4740, loss = 1.20 (311.6 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 00:43:53.231209: step 4750, loss = 1.20 (276.6 examples/sec; 0.926 sec/batch)\n",
      "2017-05-28 00:44:02.751207: step 4760, loss = 1.15 (268.9 examples/sec; 0.952 sec/batch)\n",
      "2017-05-28 00:44:10.886415: step 4770, loss = 1.10 (314.7 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 00:44:18.957714: step 4780, loss = 1.12 (317.2 examples/sec; 0.807 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 00:44:27.075801: step 4790, loss = 1.17 (315.3 examples/sec; 0.812 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10392\n",
      "2017-05-28 00:44:40.371433: step 4800, loss = 1.15 (192.5 examples/sec; 1.330 sec/batch)\n",
      "2017-05-28 00:44:48.068247: step 4810, loss = 1.11 (332.6 examples/sec; 0.770 sec/batch)\n",
      "2017-05-28 00:44:56.926023: step 4820, loss = 1.20 (289.0 examples/sec; 0.886 sec/batch)\n",
      "2017-05-28 00:45:05.981639: step 4830, loss = 1.14 (282.7 examples/sec; 0.906 sec/batch)\n",
      "2017-05-28 00:45:14.467609: step 4840, loss = 1.10 (301.7 examples/sec; 0.849 sec/batch)\n",
      "2017-05-28 00:45:24.039734: step 4850, loss = 1.17 (267.4 examples/sec; 0.957 sec/batch)\n",
      "2017-05-28 00:45:33.242993: step 4860, loss = 1.17 (278.2 examples/sec; 0.920 sec/batch)\n",
      "2017-05-28 00:45:41.649965: step 4870, loss = 1.26 (304.5 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 00:45:49.829451: step 4880, loss = 1.28 (313.0 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 00:45:58.214602: step 4890, loss = 1.21 (305.3 examples/sec; 0.839 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1096\n",
      "2017-05-28 00:46:10.492085: step 4900, loss = 1.21 (208.5 examples/sec; 1.228 sec/batch)\n",
      "2017-05-28 00:46:18.340228: step 4910, loss = 1.18 (326.2 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 00:46:28.135977: step 4920, loss = 1.18 (261.3 examples/sec; 0.980 sec/batch)\n",
      "2017-05-28 00:46:36.877898: step 4930, loss = 1.01 (292.8 examples/sec; 0.874 sec/batch)\n",
      "2017-05-28 00:46:45.514603: step 4940, loss = 1.18 (296.4 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 00:46:54.162178: step 4950, loss = 1.17 (296.0 examples/sec; 0.865 sec/batch)\n",
      "2017-05-28 00:47:04.024742: step 4960, loss = 0.95 (259.6 examples/sec; 0.986 sec/batch)\n",
      "2017-05-28 00:47:13.164786: step 4970, loss = 1.17 (280.1 examples/sec; 0.914 sec/batch)\n",
      "2017-05-28 00:47:22.717764: step 4980, loss = 1.13 (268.0 examples/sec; 0.955 sec/batch)\n",
      "2017-05-28 00:47:31.668131: step 4990, loss = 1.23 (286.0 examples/sec; 0.895 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.06769\n",
      "2017-05-28 00:47:44.154739: step 5000, loss = 1.17 (205.0 examples/sec; 1.249 sec/batch)\n",
      "2017-05-28 00:47:52.429090: step 5010, loss = 1.13 (309.4 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 00:48:01.490360: step 5020, loss = 1.05 (282.5 examples/sec; 0.906 sec/batch)\n",
      "2017-05-28 00:48:09.796471: step 5030, loss = 1.04 (308.2 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 00:48:18.125652: step 5040, loss = 1.15 (307.4 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 00:48:26.335173: step 5050, loss = 1.17 (311.8 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 00:48:34.894915: step 5060, loss = 1.22 (299.1 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 00:48:43.566387: step 5070, loss = 1.05 (295.2 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 00:48:52.103566: step 5080, loss = 1.19 (299.9 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 00:49:01.143588: step 5090, loss = 1.30 (283.2 examples/sec; 0.904 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13386\n",
      "2017-05-28 00:49:12.345925: step 5100, loss = 1.15 (228.5 examples/sec; 1.120 sec/batch)\n",
      "2017-05-28 00:49:19.645163: step 5110, loss = 1.08 (350.7 examples/sec; 0.730 sec/batch)\n",
      "2017-05-28 00:49:27.683782: step 5120, loss = 1.01 (318.5 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 00:49:36.064544: step 5130, loss = 1.21 (305.5 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 00:49:44.846062: step 5140, loss = 1.08 (291.5 examples/sec; 0.878 sec/batch)\n",
      "2017-05-28 00:49:54.190994: step 5150, loss = 1.26 (273.9 examples/sec; 0.934 sec/batch)\n",
      "2017-05-28 00:50:03.525238: step 5160, loss = 1.15 (274.3 examples/sec; 0.933 sec/batch)\n",
      "2017-05-28 00:50:13.483696: step 5170, loss = 1.25 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-28 00:50:22.463135: step 5180, loss = 1.06 (285.1 examples/sec; 0.898 sec/batch)\n",
      "2017-05-28 00:50:31.483302: step 5190, loss = 1.05 (283.8 examples/sec; 0.902 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.05808\n",
      "2017-05-28 00:50:46.858134: step 5200, loss = 1.09 (166.5 examples/sec; 1.537 sec/batch)\n",
      "2017-05-28 00:50:54.797121: step 5210, loss = 1.08 (322.5 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 00:51:04.093640: step 5220, loss = 1.15 (275.4 examples/sec; 0.930 sec/batch)\n",
      "2017-05-28 00:51:12.317232: step 5230, loss = 1.26 (311.3 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 00:51:20.381945: step 5240, loss = 1.02 (317.4 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 00:51:28.571198: step 5250, loss = 1.12 (312.6 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 00:51:36.881639: step 5260, loss = 1.03 (308.0 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 00:51:44.726836: step 5270, loss = 1.23 (326.3 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 00:51:52.551224: step 5280, loss = 1.14 (327.2 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 00:52:01.463741: step 5290, loss = 1.06 (287.2 examples/sec; 0.891 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13359\n",
      "2017-05-28 00:52:15.071787: step 5300, loss = 1.10 (188.1 examples/sec; 1.361 sec/batch)\n",
      "2017-05-28 00:52:22.786686: step 5310, loss = 1.12 (331.8 examples/sec; 0.771 sec/batch)\n",
      "2017-05-28 00:52:31.229272: step 5320, loss = 1.19 (303.2 examples/sec; 0.844 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 5328 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 00:52:40.481897: step 5330, loss = 1.17 (276.7 examples/sec; 0.925 sec/batch)\n",
      "2017-05-28 00:52:48.744035: step 5340, loss = 1.06 (309.8 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 00:52:56.822511: step 5350, loss = 1.07 (316.9 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 00:53:05.811199: step 5360, loss = 1.25 (284.8 examples/sec; 0.899 sec/batch)\n",
      "2017-05-28 00:53:15.503449: step 5370, loss = 1.13 (264.1 examples/sec; 0.969 sec/batch)\n",
      "2017-05-28 00:53:24.705567: step 5380, loss = 1.16 (278.2 examples/sec; 0.920 sec/batch)\n",
      "2017-05-28 00:53:32.830146: step 5390, loss = 1.16 (315.1 examples/sec; 0.812 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12887\n",
      "2017-05-28 00:53:43.660436: step 5400, loss = 1.06 (236.4 examples/sec; 1.083 sec/batch)\n",
      "2017-05-28 00:53:51.728055: step 5410, loss = 1.31 (317.3 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 00:54:00.663536: step 5420, loss = 1.08 (286.5 examples/sec; 0.894 sec/batch)\n",
      "2017-05-28 00:54:09.457739: step 5430, loss = 1.03 (291.1 examples/sec; 0.879 sec/batch)\n",
      "2017-05-28 00:54:17.761344: step 5440, loss = 1.10 (308.3 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 00:54:26.116025: step 5450, loss = 1.12 (306.4 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 00:54:34.186114: step 5460, loss = 1.26 (317.2 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 00:54:44.206370: step 5470, loss = 1.05 (255.5 examples/sec; 1.002 sec/batch)\n",
      "2017-05-28 00:54:53.209668: step 5480, loss = 1.10 (284.3 examples/sec; 0.900 sec/batch)\n",
      "2017-05-28 00:55:02.077703: step 5490, loss = 1.16 (288.7 examples/sec; 0.887 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.0772\n",
      "2017-05-28 00:55:16.491447: step 5500, loss = 1.21 (177.6 examples/sec; 1.441 sec/batch)\n",
      "2017-05-28 00:55:24.184001: step 5510, loss = 1.13 (332.8 examples/sec; 0.769 sec/batch)\n",
      "2017-05-28 00:55:32.727825: step 5520, loss = 1.13 (299.6 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 00:55:42.310259: step 5530, loss = 1.12 (267.2 examples/sec; 0.958 sec/batch)\n",
      "2017-05-28 00:55:51.395366: step 5540, loss = 1.01 (281.8 examples/sec; 0.909 sec/batch)\n",
      "2017-05-28 00:55:59.451789: step 5550, loss = 1.14 (317.8 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 00:56:07.635284: step 5560, loss = 1.05 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 00:56:17.008767: step 5570, loss = 1.14 (273.1 examples/sec; 0.937 sec/batch)\n",
      "2017-05-28 00:56:25.268846: step 5580, loss = 1.20 (309.9 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 00:56:34.012301: step 5590, loss = 1.25 (292.8 examples/sec; 0.874 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1068\n",
      "2017-05-28 00:56:46.839977: step 5600, loss = 1.12 (199.6 examples/sec; 1.283 sec/batch)\n",
      "2017-05-28 00:56:54.537147: step 5610, loss = 1.04 (332.6 examples/sec; 0.770 sec/batch)\n",
      "2017-05-28 00:57:02.588283: step 5620, loss = 1.28 (318.0 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 00:57:12.373166: step 5630, loss = 1.18 (261.6 examples/sec; 0.978 sec/batch)\n",
      "2017-05-28 00:57:20.193210: step 5640, loss = 1.11 (327.4 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 00:57:28.504373: step 5650, loss = 1.08 (308.0 examples/sec; 0.831 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 00:57:37.641091: step 5660, loss = 1.08 (280.2 examples/sec; 0.914 sec/batch)\n",
      "2017-05-28 00:57:46.104192: step 5670, loss = 1.23 (302.5 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 00:57:54.174250: step 5680, loss = 1.17 (317.2 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 00:58:02.151298: step 5690, loss = 1.13 (320.9 examples/sec; 0.798 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13052\n",
      "2017-05-28 00:58:15.295423: step 5700, loss = 1.13 (194.8 examples/sec; 1.314 sec/batch)\n",
      "2017-05-28 00:58:22.596953: step 5710, loss = 0.97 (350.6 examples/sec; 0.730 sec/batch)\n",
      "2017-05-28 00:58:30.610260: step 5720, loss = 1.12 (319.5 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 00:58:38.902855: step 5730, loss = 1.05 (308.7 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 00:58:46.918133: step 5740, loss = 1.14 (319.4 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 00:58:55.086736: step 5750, loss = 1.13 (313.4 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 00:59:04.955167: step 5760, loss = 1.13 (259.4 examples/sec; 0.987 sec/batch)\n",
      "2017-05-28 00:59:14.518337: step 5770, loss = 1.17 (267.7 examples/sec; 0.956 sec/batch)\n",
      "2017-05-28 00:59:24.470088: step 5780, loss = 1.06 (257.2 examples/sec; 0.995 sec/batch)\n",
      "2017-05-28 00:59:33.633847: step 5790, loss = 1.01 (279.4 examples/sec; 0.916 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.05867\n",
      "2017-05-28 00:59:49.755819: step 5800, loss = 1.03 (158.8 examples/sec; 1.612 sec/batch)\n",
      "2017-05-28 00:59:58.055489: step 5810, loss = 1.18 (308.4 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 01:00:07.317404: step 5820, loss = 1.15 (276.4 examples/sec; 0.926 sec/batch)\n",
      "2017-05-28 01:00:16.616874: step 5830, loss = 1.03 (275.3 examples/sec; 0.930 sec/batch)\n",
      "2017-05-28 01:00:25.784438: step 5840, loss = 1.13 (279.2 examples/sec; 0.917 sec/batch)\n",
      "2017-05-28 01:00:34.679134: step 5850, loss = 1.08 (287.8 examples/sec; 0.889 sec/batch)\n",
      "2017-05-28 01:00:43.984189: step 5860, loss = 1.03 (275.1 examples/sec; 0.931 sec/batch)\n",
      "2017-05-28 01:00:52.598996: step 5870, loss = 1.02 (297.2 examples/sec; 0.861 sec/batch)\n",
      "2017-05-28 01:01:01.018817: step 5880, loss = 1.33 (304.0 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 01:01:10.163812: step 5890, loss = 1.18 (279.9 examples/sec; 0.914 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.0619\n",
      "2017-05-28 01:01:23.924051: step 5900, loss = 0.98 (186.0 examples/sec; 1.376 sec/batch)\n",
      "2017-05-28 01:01:32.049651: step 5910, loss = 1.18 (315.1 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 01:01:40.363793: step 5920, loss = 1.00 (307.9 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 01:01:49.104479: step 5930, loss = 1.26 (292.9 examples/sec; 0.874 sec/batch)\n",
      "2017-05-28 01:01:57.792231: step 5940, loss = 1.10 (294.7 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 01:02:06.176537: step 5950, loss = 0.91 (305.3 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 01:02:14.693331: step 5960, loss = 1.16 (300.6 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 01:02:24.052269: step 5970, loss = 1.14 (273.5 examples/sec; 0.936 sec/batch)\n",
      "2017-05-28 01:02:33.533522: step 5980, loss = 1.08 (270.0 examples/sec; 0.948 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 5985 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 01:02:43.980015: step 5990, loss = 1.12 (245.1 examples/sec; 1.045 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.06919\n",
      "2017-05-28 01:02:57.454746: step 6000, loss = 1.17 (190.0 examples/sec; 1.347 sec/batch)\n",
      "2017-05-28 01:03:05.028606: step 6010, loss = 1.09 (338.0 examples/sec; 0.757 sec/batch)\n",
      "2017-05-28 01:03:13.356661: step 6020, loss = 1.12 (307.4 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 01:03:21.522723: step 6030, loss = 1.10 (313.5 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 01:03:29.570363: step 6040, loss = 1.15 (318.1 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 01:03:37.728267: step 6050, loss = 1.19 (313.8 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 01:03:46.268532: step 6060, loss = 1.17 (299.8 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 01:03:54.114121: step 6070, loss = 1.16 (326.3 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 01:04:02.182790: step 6080, loss = 1.04 (317.3 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 01:04:10.111537: step 6090, loss = 0.98 (322.9 examples/sec; 0.793 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19222\n",
      "2017-05-28 01:04:21.333209: step 6100, loss = 1.08 (228.1 examples/sec; 1.122 sec/batch)\n",
      "2017-05-28 01:04:28.731586: step 6110, loss = 1.18 (346.0 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 01:04:37.602782: step 6120, loss = 1.05 (288.6 examples/sec; 0.887 sec/batch)\n",
      "2017-05-28 01:04:45.861990: step 6130, loss = 1.29 (310.0 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 01:04:53.829753: step 6140, loss = 1.11 (321.3 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 01:05:01.798330: step 6150, loss = 1.13 (321.3 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 01:05:09.752335: step 6160, loss = 0.99 (321.9 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 01:05:17.815139: step 6170, loss = 1.00 (317.5 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 01:05:26.072976: step 6180, loss = 1.11 (310.0 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 01:05:34.804004: step 6190, loss = 1.05 (293.2 examples/sec; 0.873 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17737\n",
      "2017-05-28 01:05:46.263663: step 6200, loss = 1.06 (223.4 examples/sec; 1.146 sec/batch)\n",
      "2017-05-28 01:05:53.638681: step 6210, loss = 1.15 (347.1 examples/sec; 0.738 sec/batch)\n",
      "2017-05-28 01:06:01.551764: step 6220, loss = 1.02 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 01:06:09.484414: step 6230, loss = 1.03 (322.7 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 01:06:17.953080: step 6240, loss = 1.03 (302.3 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 01:06:26.288183: step 6250, loss = 1.14 (307.1 examples/sec; 0.834 sec/batch)\n",
      "2017-05-28 01:06:34.480537: step 6260, loss = 1.26 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 01:06:42.924026: step 6270, loss = 1.08 (303.2 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 01:06:51.913987: step 6280, loss = 1.10 (284.8 examples/sec; 0.899 sec/batch)\n",
      "2017-05-28 01:07:00.148076: step 6290, loss = 1.12 (310.9 examples/sec; 0.823 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1588\n",
      "2017-05-28 01:07:12.564384: step 6300, loss = 1.07 (206.2 examples/sec; 1.242 sec/batch)\n",
      "2017-05-28 01:07:20.301196: step 6310, loss = 1.21 (330.9 examples/sec; 0.774 sec/batch)\n",
      "2017-05-28 01:07:28.307022: step 6320, loss = 1.03 (319.8 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 01:07:36.544574: step 6330, loss = 1.13 (310.8 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 01:07:44.418674: step 6340, loss = 1.11 (325.1 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 01:07:52.243866: step 6350, loss = 1.06 (327.1 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 01:08:00.498394: step 6360, loss = 1.12 (310.1 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 01:08:08.625406: step 6370, loss = 1.03 (315.0 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 01:08:17.303638: step 6380, loss = 1.17 (295.0 examples/sec; 0.868 sec/batch)\n",
      "2017-05-28 01:08:25.549646: step 6390, loss = 1.06 (310.5 examples/sec; 0.825 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18435\n",
      "2017-05-28 01:08:36.995106: step 6400, loss = 1.13 (223.7 examples/sec; 1.145 sec/batch)\n",
      "2017-05-28 01:08:44.741570: step 6410, loss = 1.00 (330.5 examples/sec; 0.775 sec/batch)\n",
      "2017-05-28 01:08:52.898255: step 6420, loss = 1.06 (313.9 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 01:09:00.826266: step 6430, loss = 1.00 (322.9 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 01:09:08.657201: step 6440, loss = 1.13 (326.9 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 01:09:16.806662: step 6450, loss = 1.11 (314.1 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 01:09:25.137599: step 6460, loss = 1.05 (307.3 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 01:09:33.552088: step 6470, loss = 1.05 (304.2 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 01:09:41.753557: step 6480, loss = 1.07 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 01:09:49.999965: step 6490, loss = 1.08 (310.4 examples/sec; 0.825 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17987\n",
      "2017-05-28 01:10:01.750339: step 6500, loss = 1.21 (217.9 examples/sec; 1.175 sec/batch)\n",
      "2017-05-28 01:10:09.171176: step 6510, loss = 1.04 (345.0 examples/sec; 0.742 sec/batch)\n",
      "2017-05-28 01:10:17.471043: step 6520, loss = 1.10 (308.4 examples/sec; 0.830 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 01:10:25.440056: step 6530, loss = 1.04 (321.2 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 01:10:33.447126: step 6540, loss = 1.08 (319.7 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 01:10:41.347782: step 6550, loss = 1.11 (324.0 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 01:10:49.363553: step 6560, loss = 1.13 (319.4 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 01:10:57.228800: step 6570, loss = 0.96 (325.5 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 01:11:05.512672: step 6580, loss = 1.08 (309.0 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 01:11:13.470250: step 6590, loss = 1.11 (321.7 examples/sec; 0.796 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18644\n",
      "2017-05-28 01:11:26.039762: step 6600, loss = 1.08 (203.7 examples/sec; 1.257 sec/batch)\n",
      "2017-05-28 01:11:33.685054: step 6610, loss = 1.20 (334.8 examples/sec; 0.765 sec/batch)\n",
      "2017-05-28 01:11:42.148872: step 6620, loss = 1.06 (302.5 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 01:11:50.916692: step 6630, loss = 1.06 (292.0 examples/sec; 0.877 sec/batch)\n",
      "2017-05-28 01:11:58.955972: step 6640, loss = 1.10 (318.4 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 01:12:08.103167: step 6650, loss = 1.08 (279.9 examples/sec; 0.915 sec/batch)\n",
      "2017-05-28 01:12:17.297208: step 6660, loss = 1.14 (278.4 examples/sec; 0.919 sec/batch)\n",
      "2017-05-28 01:12:26.802219: step 6670, loss = 1.05 (269.3 examples/sec; 0.951 sec/batch)\n",
      "2017-05-28 01:12:36.094741: step 6680, loss = 1.10 (275.5 examples/sec; 0.929 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 6683 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 01:12:47.080760: step 6690, loss = 1.15 (233.0 examples/sec; 1.099 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.06164\n",
      "2017-05-28 01:13:00.229737: step 6700, loss = 1.04 (194.7 examples/sec; 1.315 sec/batch)\n",
      "2017-05-28 01:13:09.488808: step 6710, loss = 1.08 (276.5 examples/sec; 0.926 sec/batch)\n",
      "2017-05-28 01:13:18.112681: step 6720, loss = 1.11 (296.9 examples/sec; 0.862 sec/batch)\n",
      "2017-05-28 01:13:26.582524: step 6730, loss = 1.17 (302.2 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 01:13:36.310912: step 6740, loss = 1.09 (263.1 examples/sec; 0.973 sec/batch)\n",
      "2017-05-28 01:13:45.289129: step 6750, loss = 1.09 (285.1 examples/sec; 0.898 sec/batch)\n",
      "2017-05-28 01:13:54.858414: step 6760, loss = 1.05 (267.5 examples/sec; 0.957 sec/batch)\n",
      "2017-05-28 01:14:03.946818: step 6770, loss = 1.01 (281.7 examples/sec; 0.909 sec/batch)\n",
      "2017-05-28 01:14:13.190101: step 6780, loss = 1.08 (277.0 examples/sec; 0.924 sec/batch)\n",
      "2017-05-28 01:14:21.583765: step 6790, loss = 1.11 (305.0 examples/sec; 0.839 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.04319\n",
      "2017-05-28 01:14:36.095848: step 6800, loss = 1.00 (176.4 examples/sec; 1.451 sec/batch)\n",
      "2017-05-28 01:14:43.680431: step 6810, loss = 0.99 (337.5 examples/sec; 0.758 sec/batch)\n",
      "2017-05-28 01:14:51.610070: step 6820, loss = 1.05 (322.8 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 01:14:59.623835: step 6830, loss = 1.05 (319.5 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 01:15:08.192627: step 6840, loss = 1.10 (298.8 examples/sec; 0.857 sec/batch)\n",
      "2017-05-28 01:15:17.592618: step 6850, loss = 0.98 (272.3 examples/sec; 0.940 sec/batch)\n",
      "2017-05-28 01:15:26.302246: step 6860, loss = 1.02 (293.9 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 01:15:34.796860: step 6870, loss = 1.13 (301.4 examples/sec; 0.849 sec/batch)\n",
      "2017-05-28 01:15:44.186894: step 6880, loss = 1.11 (272.6 examples/sec; 0.939 sec/batch)\n",
      "2017-05-28 01:15:53.642948: step 6890, loss = 1.02 (270.7 examples/sec; 0.946 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10853\n",
      "2017-05-28 01:16:06.298562: step 6900, loss = 1.12 (202.3 examples/sec; 1.266 sec/batch)\n",
      "2017-05-28 01:16:14.203754: step 6910, loss = 0.98 (323.8 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 01:16:23.428055: step 6920, loss = 0.99 (277.5 examples/sec; 0.922 sec/batch)\n",
      "2017-05-28 01:16:32.989623: step 6930, loss = 1.17 (267.7 examples/sec; 0.956 sec/batch)\n",
      "2017-05-28 01:16:42.364355: step 6940, loss = 1.04 (273.1 examples/sec; 0.937 sec/batch)\n",
      "2017-05-28 01:16:50.819227: step 6950, loss = 0.98 (302.8 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 01:16:58.981214: step 6960, loss = 1.04 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 01:17:07.394797: step 6970, loss = 1.11 (304.3 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 01:17:16.109254: step 6980, loss = 1.19 (293.8 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 01:17:24.610120: step 6990, loss = 1.13 (301.1 examples/sec; 0.850 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.0995\n",
      "2017-05-28 01:17:37.249799: step 7000, loss = 1.02 (202.5 examples/sec; 1.264 sec/batch)\n",
      "2017-05-28 01:17:45.493860: step 7010, loss = 1.19 (310.5 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 01:17:54.141733: step 7020, loss = 1.06 (296.0 examples/sec; 0.865 sec/batch)\n",
      "2017-05-28 01:18:02.167306: step 7030, loss = 1.16 (319.0 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 01:18:10.197284: step 7040, loss = 1.13 (318.8 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 01:18:18.317077: step 7050, loss = 1.13 (315.3 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 01:18:26.566586: step 7060, loss = 1.00 (310.3 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 01:18:34.511359: step 7070, loss = 0.91 (322.2 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 01:18:42.634857: step 7080, loss = 0.99 (315.1 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 01:18:50.686969: step 7090, loss = 0.92 (317.9 examples/sec; 0.805 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16899\n",
      "2017-05-28 01:19:02.797410: step 7100, loss = 1.18 (211.4 examples/sec; 1.211 sec/batch)\n",
      "2017-05-28 01:19:10.474140: step 7110, loss = 1.20 (333.5 examples/sec; 0.768 sec/batch)\n",
      "2017-05-28 01:19:19.582171: step 7120, loss = 1.16 (281.1 examples/sec; 0.911 sec/batch)\n",
      "2017-05-28 01:19:28.627263: step 7130, loss = 1.08 (283.0 examples/sec; 0.905 sec/batch)\n",
      "2017-05-28 01:19:37.034092: step 7140, loss = 1.08 (304.5 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 01:19:45.301447: step 7150, loss = 0.99 (309.7 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 01:19:53.369692: step 7160, loss = 1.02 (317.3 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 01:20:01.726989: step 7170, loss = 1.06 (306.3 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 01:20:09.808924: step 7180, loss = 1.07 (316.8 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 01:20:18.156937: step 7190, loss = 1.12 (306.7 examples/sec; 0.835 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.143\n",
      "2017-05-28 01:20:30.283534: step 7200, loss = 1.02 (211.1 examples/sec; 1.213 sec/batch)\n",
      "2017-05-28 01:20:37.798355: step 7210, loss = 1.14 (340.7 examples/sec; 0.751 sec/batch)\n",
      "2017-05-28 01:20:46.310866: step 7220, loss = 1.09 (300.7 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 01:20:54.486266: step 7230, loss = 1.11 (313.1 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 01:21:03.001304: step 7240, loss = 1.24 (300.6 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 01:21:11.244500: step 7250, loss = 1.00 (310.6 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 01:21:19.224040: step 7260, loss = 1.04 (320.8 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 01:21:27.229885: step 7270, loss = 1.10 (319.8 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 01:21:35.140714: step 7280, loss = 1.04 (323.6 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 01:21:43.080718: step 7290, loss = 1.06 (322.4 examples/sec; 0.794 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15497\n",
      "2017-05-28 01:21:56.870175: step 7300, loss = 0.96 (185.6 examples/sec; 1.379 sec/batch)\n",
      "2017-05-28 01:22:04.588373: step 7310, loss = 1.05 (331.7 examples/sec; 0.772 sec/batch)\n",
      "2017-05-28 01:22:12.638269: step 7320, loss = 1.01 (318.0 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 01:22:20.920683: step 7330, loss = 1.18 (309.1 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 01:22:29.182487: step 7340, loss = 1.19 (309.9 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 01:22:37.652501: step 7350, loss = 1.04 (302.2 examples/sec; 0.847 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 7352 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 01:22:46.527756: step 7360, loss = 1.01 (288.4 examples/sec; 0.888 sec/batch)\n",
      "2017-05-28 01:22:55.037458: step 7370, loss = 1.12 (300.8 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 01:23:03.145687: step 7380, loss = 1.07 (315.7 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 01:23:11.673682: step 7390, loss = 1.10 (300.2 examples/sec; 0.853 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.15438\n",
      "2017-05-28 01:23:23.491489: step 7400, loss = 1.12 (216.6 examples/sec; 1.182 sec/batch)\n",
      "2017-05-28 01:23:30.783961: step 7410, loss = 1.13 (351.0 examples/sec; 0.729 sec/batch)\n",
      "2017-05-28 01:23:39.336974: step 7420, loss = 0.90 (299.3 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 01:23:47.601326: step 7430, loss = 1.01 (309.8 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 01:23:55.983854: step 7440, loss = 1.07 (305.4 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 01:24:05.138500: step 7450, loss = 1.19 (279.6 examples/sec; 0.915 sec/batch)\n",
      "2017-05-28 01:24:13.244800: step 7460, loss = 1.10 (315.8 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 01:24:21.677319: step 7470, loss = 1.11 (303.6 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 01:24:30.436209: step 7480, loss = 1.03 (292.3 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 01:24:38.611996: step 7490, loss = 1.03 (313.1 examples/sec; 0.818 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14452\n",
      "2017-05-28 01:24:50.867559: step 7500, loss = 0.98 (208.9 examples/sec; 1.226 sec/batch)\n",
      "2017-05-28 01:24:58.634383: step 7510, loss = 1.07 (329.6 examples/sec; 0.777 sec/batch)\n",
      "2017-05-28 01:25:06.756615: step 7520, loss = 0.96 (315.2 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 01:25:16.768631: step 7530, loss = 1.02 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-28 01:25:25.100215: step 7540, loss = 1.08 (307.3 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 01:25:33.287066: step 7550, loss = 1.19 (312.7 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 01:25:41.766133: step 7560, loss = 1.10 (301.9 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 01:25:50.173787: step 7570, loss = 1.03 (304.5 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 01:25:59.194836: step 7580, loss = 0.99 (283.8 examples/sec; 0.902 sec/batch)\n",
      "2017-05-28 01:26:07.947897: step 7590, loss = 0.88 (292.5 examples/sec; 0.875 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13013\n",
      "2017-05-28 01:26:19.349997: step 7600, loss = 0.98 (224.5 examples/sec; 1.140 sec/batch)\n",
      "2017-05-28 01:26:27.703873: step 7610, loss = 0.98 (306.4 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 01:26:35.799011: step 7620, loss = 1.15 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 01:26:43.705833: step 7630, loss = 1.05 (323.8 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 01:26:52.110742: step 7640, loss = 1.30 (304.6 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 01:27:00.499361: step 7650, loss = 1.04 (305.2 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 01:27:08.631117: step 7660, loss = 1.17 (314.8 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 01:27:16.764392: step 7670, loss = 1.04 (314.8 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 01:27:24.679005: step 7680, loss = 1.27 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 01:27:32.694388: step 7690, loss = 0.96 (319.4 examples/sec; 0.802 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18066\n",
      "2017-05-28 01:27:44.053240: step 7700, loss = 1.15 (225.4 examples/sec; 1.136 sec/batch)\n",
      "2017-05-28 01:27:51.503790: step 7710, loss = 1.10 (343.6 examples/sec; 0.745 sec/batch)\n",
      "2017-05-28 01:27:59.980621: step 7720, loss = 0.97 (302.0 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 01:28:08.463410: step 7730, loss = 1.10 (301.8 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 01:28:16.654734: step 7740, loss = 1.11 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 01:28:24.979061: step 7750, loss = 1.09 (307.5 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 01:28:33.180257: step 7760, loss = 1.03 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 01:28:41.405097: step 7770, loss = 1.17 (311.3 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 01:28:49.511361: step 7780, loss = 1.01 (315.8 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 01:28:57.623044: step 7790, loss = 1.09 (315.6 examples/sec; 0.811 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16114\n",
      "2017-05-28 01:29:10.170811: step 7800, loss = 1.08 (204.0 examples/sec; 1.255 sec/batch)\n",
      "2017-05-28 01:29:17.992967: step 7810, loss = 1.05 (327.3 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 01:29:26.468917: step 7820, loss = 1.07 (302.0 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 01:29:35.402617: step 7830, loss = 1.05 (286.6 examples/sec; 0.893 sec/batch)\n",
      "2017-05-28 01:29:43.673277: step 7840, loss = 1.06 (309.5 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 01:29:52.754628: step 7850, loss = 1.15 (281.9 examples/sec; 0.908 sec/batch)\n",
      "2017-05-28 01:30:00.964810: step 7860, loss = 1.00 (311.8 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 01:30:09.060215: step 7870, loss = 1.15 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 01:30:17.523320: step 7880, loss = 1.08 (302.5 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 01:30:25.648800: step 7890, loss = 0.94 (315.1 examples/sec; 0.813 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14948\n",
      "2017-05-28 01:30:37.171423: step 7900, loss = 1.01 (222.2 examples/sec; 1.152 sec/batch)\n",
      "2017-05-28 01:30:44.559637: step 7910, loss = 1.00 (346.5 examples/sec; 0.739 sec/batch)\n",
      "2017-05-28 01:30:52.404791: step 7920, loss = 1.02 (326.3 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 01:31:00.518648: step 7930, loss = 1.04 (315.5 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 01:31:08.501440: step 7940, loss = 1.10 (320.7 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 01:31:16.509274: step 7950, loss = 1.01 (319.7 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 01:31:25.127369: step 7960, loss = 0.95 (297.0 examples/sec; 0.862 sec/batch)\n",
      "2017-05-28 01:31:33.193947: step 7970, loss = 1.03 (317.4 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 01:31:41.268984: step 7980, loss = 1.05 (317.0 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 01:31:49.206308: step 7990, loss = 1.04 (322.5 examples/sec; 0.794 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19115\n",
      "2017-05-28 01:32:01.119234: step 8000, loss = 0.99 (214.9 examples/sec; 1.191 sec/batch)\n",
      "2017-05-28 01:32:09.123249: step 8010, loss = 1.17 (319.8 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 01:32:17.281464: step 8020, loss = 0.99 (313.8 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 01:32:25.483829: step 8030, loss = 1.03 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 01:32:34.230871: step 8040, loss = 1.04 (292.7 examples/sec; 0.875 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 8046 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 01:32:43.492422: step 8050, loss = 0.88 (276.4 examples/sec; 0.926 sec/batch)\n",
      "2017-05-28 01:32:51.752329: step 8060, loss = 1.19 (309.9 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 01:33:00.122651: step 8070, loss = 0.92 (305.8 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 01:33:08.387606: step 8080, loss = 1.11 (309.7 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 01:33:16.929189: step 8090, loss = 1.12 (299.7 examples/sec; 0.854 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11299\n",
      "2017-05-28 01:33:30.967424: step 8100, loss = 1.04 (182.4 examples/sec; 1.404 sec/batch)\n",
      "2017-05-28 01:33:38.828848: step 8110, loss = 1.04 (325.6 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 01:33:47.562248: step 8120, loss = 1.06 (293.1 examples/sec; 0.873 sec/batch)\n",
      "2017-05-28 01:33:55.958830: step 8130, loss = 1.02 (304.9 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 01:34:05.019291: step 8140, loss = 1.11 (282.5 examples/sec; 0.906 sec/batch)\n",
      "2017-05-28 01:34:13.362908: step 8150, loss = 1.00 (306.8 examples/sec; 0.834 sec/batch)\n",
      "2017-05-28 01:34:22.441575: step 8160, loss = 0.96 (282.0 examples/sec; 0.908 sec/batch)\n",
      "2017-05-28 01:34:32.061088: step 8170, loss = 1.13 (266.1 examples/sec; 0.962 sec/batch)\n",
      "2017-05-28 01:34:41.424431: step 8180, loss = 1.02 (273.4 examples/sec; 0.936 sec/batch)\n",
      "2017-05-28 01:34:50.516119: step 8190, loss = 1.05 (281.6 examples/sec; 0.909 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.0917\n",
      "2017-05-28 01:35:02.567106: step 8200, loss = 1.07 (212.4 examples/sec; 1.205 sec/batch)\n",
      "2017-05-28 01:35:10.212278: step 8210, loss = 0.93 (334.9 examples/sec; 0.765 sec/batch)\n",
      "2017-05-28 01:35:19.007463: step 8220, loss = 1.02 (291.1 examples/sec; 0.880 sec/batch)\n",
      "2017-05-28 01:35:27.852839: step 8230, loss = 1.10 (289.4 examples/sec; 0.885 sec/batch)\n",
      "2017-05-28 01:35:36.385039: step 8240, loss = 1.17 (300.0 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 01:35:45.222641: step 8250, loss = 1.00 (289.7 examples/sec; 0.884 sec/batch)\n",
      "2017-05-28 01:35:54.167231: step 8260, loss = 1.07 (286.2 examples/sec; 0.894 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 01:36:04.124809: step 8270, loss = 1.05 (257.1 examples/sec; 0.996 sec/batch)\n",
      "2017-05-28 01:36:13.535629: step 8280, loss = 0.96 (272.0 examples/sec; 0.941 sec/batch)\n",
      "2017-05-28 01:36:22.810693: step 8290, loss = 1.12 (276.0 examples/sec; 0.928 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.05982\n",
      "2017-05-28 01:36:36.926070: step 8300, loss = 1.04 (181.4 examples/sec; 1.412 sec/batch)\n",
      "2017-05-28 01:36:45.204492: step 8310, loss = 1.07 (309.2 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 01:36:53.639869: step 8320, loss = 1.09 (303.5 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 01:37:02.432145: step 8330, loss = 1.00 (291.2 examples/sec; 0.879 sec/batch)\n",
      "2017-05-28 01:37:11.400046: step 8340, loss = 1.05 (285.5 examples/sec; 0.897 sec/batch)\n",
      "2017-05-28 01:37:20.241291: step 8350, loss = 1.10 (289.6 examples/sec; 0.884 sec/batch)\n",
      "2017-05-28 01:37:28.945716: step 8360, loss = 1.02 (294.1 examples/sec; 0.870 sec/batch)\n",
      "2017-05-28 01:37:37.696603: step 8370, loss = 1.00 (292.5 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 01:37:46.455719: step 8380, loss = 1.01 (292.3 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 01:37:56.157834: step 8390, loss = 1.16 (263.9 examples/sec; 0.970 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.07202\n",
      "2017-05-28 01:38:10.208265: step 8400, loss = 1.05 (182.2 examples/sec; 1.405 sec/batch)\n",
      "2017-05-28 01:38:18.096211: step 8410, loss = 1.11 (324.5 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 01:38:26.419616: step 8420, loss = 0.99 (307.6 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 01:38:34.444821: step 8430, loss = 1.06 (319.0 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 01:38:42.885661: step 8440, loss = 0.98 (303.3 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 01:38:51.676803: step 8450, loss = 0.91 (291.2 examples/sec; 0.879 sec/batch)\n",
      "2017-05-28 01:38:59.912803: step 8460, loss = 1.02 (310.8 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 01:39:08.391003: step 8470, loss = 1.09 (302.0 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 01:39:16.981971: step 8480, loss = 1.05 (298.0 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 01:39:25.283328: step 8490, loss = 1.06 (308.4 examples/sec; 0.830 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14419\n",
      "2017-05-28 01:39:37.602995: step 8500, loss = 1.13 (207.8 examples/sec; 1.232 sec/batch)\n",
      "2017-05-28 01:39:45.811855: step 8510, loss = 0.95 (311.9 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 01:39:55.626857: step 8520, loss = 1.06 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-28 01:40:04.265434: step 8530, loss = 1.04 (296.3 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 01:40:12.625617: step 8540, loss = 0.87 (306.2 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 01:40:21.476056: step 8550, loss = 0.99 (289.3 examples/sec; 0.885 sec/batch)\n",
      "2017-05-28 01:40:30.031239: step 8560, loss = 1.11 (299.2 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 01:40:38.466569: step 8570, loss = 1.00 (303.5 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 01:40:47.510739: step 8580, loss = 0.92 (283.1 examples/sec; 0.904 sec/batch)\n",
      "2017-05-28 01:40:56.231891: step 8590, loss = 1.00 (293.5 examples/sec; 0.872 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10605\n",
      "2017-05-28 01:41:08.015232: step 8600, loss = 0.95 (217.3 examples/sec; 1.178 sec/batch)\n",
      "2017-05-28 01:41:15.859179: step 8610, loss = 1.03 (326.4 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 01:41:24.382546: step 8620, loss = 1.11 (300.4 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 01:41:32.758552: step 8630, loss = 1.03 (305.6 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 01:41:41.139187: step 8640, loss = 0.94 (305.5 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 01:41:50.309980: step 8650, loss = 1.02 (279.1 examples/sec; 0.917 sec/batch)\n",
      "2017-05-28 01:41:58.816349: step 8660, loss = 1.05 (301.0 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 01:42:07.202554: step 8670, loss = 1.01 (305.3 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 01:42:15.708583: step 8680, loss = 1.11 (301.0 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 01:42:24.825809: step 8690, loss = 1.13 (280.8 examples/sec; 0.912 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12636\n",
      "2017-05-28 01:42:36.796777: step 8700, loss = 0.94 (213.9 examples/sec; 1.197 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 8704 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 01:42:45.454196: step 8710, loss = 0.98 (295.7 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 01:42:54.496247: step 8720, loss = 1.07 (283.1 examples/sec; 0.904 sec/batch)\n",
      "2017-05-28 01:43:02.946831: step 8730, loss = 1.12 (302.9 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 01:43:11.358409: step 8740, loss = 0.99 (304.3 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 01:43:19.924508: step 8750, loss = 0.96 (298.9 examples/sec; 0.857 sec/batch)\n",
      "2017-05-28 01:43:28.569548: step 8760, loss = 1.02 (296.1 examples/sec; 0.865 sec/batch)\n",
      "2017-05-28 01:43:37.537198: step 8770, loss = 1.00 (285.5 examples/sec; 0.897 sec/batch)\n",
      "2017-05-28 01:43:46.249044: step 8780, loss = 1.09 (293.9 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 01:43:54.839600: step 8790, loss = 1.05 (298.0 examples/sec; 0.859 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11227\n",
      "2017-05-28 01:44:06.702884: step 8800, loss = 1.17 (215.8 examples/sec; 1.186 sec/batch)\n",
      "2017-05-28 01:44:15.008330: step 8810, loss = 1.10 (308.2 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 01:44:23.644646: step 8820, loss = 1.02 (296.4 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 01:44:32.107938: step 8830, loss = 1.09 (302.5 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 01:44:40.662713: step 8840, loss = 1.00 (299.2 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 01:44:49.194486: step 8850, loss = 1.03 (300.1 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 01:44:58.501438: step 8860, loss = 0.98 (275.1 examples/sec; 0.931 sec/batch)\n",
      "2017-05-28 01:45:07.178982: step 8870, loss = 1.06 (295.0 examples/sec; 0.868 sec/batch)\n",
      "2017-05-28 01:45:15.198290: step 8880, loss = 1.15 (319.2 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 01:45:23.437573: step 8890, loss = 1.03 (310.7 examples/sec; 0.824 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14164\n",
      "2017-05-28 01:45:34.295210: step 8900, loss = 1.03 (235.8 examples/sec; 1.086 sec/batch)\n",
      "2017-05-28 01:45:42.116420: step 8910, loss = 1.11 (327.3 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 01:45:50.855104: step 8920, loss = 1.01 (293.0 examples/sec; 0.874 sec/batch)\n",
      "2017-05-28 01:45:59.435903: step 8930, loss = 0.96 (298.3 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 01:46:07.983417: step 8940, loss = 1.08 (299.5 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 01:46:16.479823: step 8950, loss = 0.95 (301.3 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 01:46:25.581907: step 8960, loss = 0.97 (281.3 examples/sec; 0.910 sec/batch)\n",
      "2017-05-28 01:46:34.035548: step 8970, loss = 1.19 (302.8 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 01:46:42.467273: step 8980, loss = 1.09 (303.6 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 01:46:51.037075: step 8990, loss = 1.02 (298.7 examples/sec; 0.857 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1129\n",
      "2017-05-28 01:47:04.150470: step 9000, loss = 0.99 (195.2 examples/sec; 1.311 sec/batch)\n",
      "2017-05-28 01:47:11.996263: step 9010, loss = 1.02 (326.3 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 01:47:20.366661: step 9020, loss = 1.01 (305.8 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 01:47:28.907576: step 9030, loss = 0.96 (299.7 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 01:47:37.497462: step 9040, loss = 1.05 (298.0 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 01:47:46.374999: step 9050, loss = 0.95 (288.4 examples/sec; 0.888 sec/batch)\n",
      "2017-05-28 01:47:55.211015: step 9060, loss = 1.05 (289.7 examples/sec; 0.884 sec/batch)\n",
      "2017-05-28 01:48:04.302659: step 9070, loss = 0.98 (281.6 examples/sec; 0.909 sec/batch)\n",
      "2017-05-28 01:48:12.777832: step 9080, loss = 1.21 (302.1 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 01:48:21.210023: step 9090, loss = 0.93 (303.6 examples/sec; 0.843 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.122\n",
      "2017-05-28 01:48:33.278008: step 9100, loss = 0.99 (212.1 examples/sec; 1.207 sec/batch)\n",
      "2017-05-28 01:48:41.055096: step 9110, loss = 1.03 (329.2 examples/sec; 0.778 sec/batch)\n",
      "2017-05-28 01:48:49.469311: step 9120, loss = 1.01 (304.2 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 01:48:58.101527: step 9130, loss = 1.06 (296.6 examples/sec; 0.863 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 01:49:07.162514: step 9140, loss = 1.07 (282.5 examples/sec; 0.906 sec/batch)\n",
      "2017-05-28 01:49:15.539986: step 9150, loss = 1.00 (305.6 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 01:49:23.927759: step 9160, loss = 1.03 (305.2 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 01:49:32.837092: step 9170, loss = 1.10 (287.3 examples/sec; 0.891 sec/batch)\n",
      "2017-05-28 01:49:41.437168: step 9180, loss = 1.00 (297.7 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 01:49:50.372504: step 9190, loss = 1.02 (286.5 examples/sec; 0.894 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11075\n",
      "2017-05-28 01:50:03.308630: step 9200, loss = 1.03 (197.9 examples/sec; 1.294 sec/batch)\n",
      "2017-05-28 01:50:11.295005: step 9210, loss = 1.11 (320.5 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 01:50:19.674490: step 9220, loss = 1.01 (305.5 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 01:50:27.951409: step 9230, loss = 0.95 (309.3 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 01:50:35.956132: step 9240, loss = 1.06 (319.8 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 01:50:44.133564: step 9250, loss = 1.04 (313.1 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 01:50:52.297290: step 9260, loss = 0.99 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 01:51:01.520112: step 9270, loss = 1.03 (277.6 examples/sec; 0.922 sec/batch)\n",
      "2017-05-28 01:51:09.883673: step 9280, loss = 0.92 (306.1 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 01:51:18.158219: step 9290, loss = 1.13 (309.4 examples/sec; 0.827 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14331\n",
      "2017-05-28 01:51:30.771698: step 9300, loss = 1.01 (203.0 examples/sec; 1.261 sec/batch)\n",
      "2017-05-28 01:51:39.127522: step 9310, loss = 0.96 (306.4 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 01:51:47.672873: step 9320, loss = 1.10 (299.6 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 01:51:56.209496: step 9330, loss = 0.98 (299.9 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 01:52:05.113370: step 9340, loss = 1.01 (287.5 examples/sec; 0.890 sec/batch)\n",
      "2017-05-28 01:52:13.559844: step 9350, loss = 1.11 (303.1 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 01:52:22.238605: step 9360, loss = 1.18 (295.0 examples/sec; 0.868 sec/batch)\n",
      "2017-05-28 01:52:31.332673: step 9370, loss = 1.00 (281.5 examples/sec; 0.909 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 9380 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 01:52:41.002779: step 9380, loss = 0.98 (264.7 examples/sec; 0.967 sec/batch)\n",
      "2017-05-28 01:52:48.961860: step 9390, loss = 1.10 (321.6 examples/sec; 0.796 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.09935\n",
      "2017-05-28 01:53:01.737344: step 9400, loss = 0.96 (200.4 examples/sec; 1.278 sec/batch)\n",
      "2017-05-28 01:53:09.725986: step 9410, loss = 1.12 (320.5 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 01:53:18.327529: step 9420, loss = 0.89 (297.6 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 01:53:26.629718: step 9430, loss = 1.00 (308.4 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 01:53:35.078108: step 9440, loss = 1.16 (303.0 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 01:53:44.055584: step 9450, loss = 0.97 (285.2 examples/sec; 0.898 sec/batch)\n",
      "2017-05-28 01:53:52.441794: step 9460, loss = 1.16 (305.3 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 01:54:00.878586: step 9470, loss = 1.02 (303.4 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 01:54:09.349883: step 9480, loss = 1.12 (302.2 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 01:54:18.202452: step 9490, loss = 1.01 (289.2 examples/sec; 0.885 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1301\n",
      "2017-05-28 01:54:30.222619: step 9500, loss = 0.94 (213.0 examples/sec; 1.202 sec/batch)\n",
      "2017-05-28 01:54:37.994731: step 9510, loss = 1.10 (329.4 examples/sec; 0.777 sec/batch)\n",
      "2017-05-28 01:54:46.440044: step 9520, loss = 1.01 (303.1 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 01:54:54.835918: step 9530, loss = 1.19 (304.9 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 01:55:03.981610: step 9540, loss = 0.94 (279.9 examples/sec; 0.915 sec/batch)\n",
      "2017-05-28 01:55:12.686902: step 9550, loss = 0.96 (294.1 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 01:55:20.596375: step 9560, loss = 1.07 (323.7 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 01:55:28.624250: step 9570, loss = 1.01 (318.9 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 01:55:36.801532: step 9580, loss = 1.01 (313.1 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 01:55:44.730677: step 9590, loss = 1.02 (322.9 examples/sec; 0.793 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16631\n",
      "2017-05-28 01:55:55.962782: step 9600, loss = 0.99 (227.9 examples/sec; 1.123 sec/batch)\n",
      "2017-05-28 01:56:03.385032: step 9610, loss = 0.88 (344.9 examples/sec; 0.742 sec/batch)\n",
      "2017-05-28 01:56:11.398459: step 9620, loss = 1.08 (319.5 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 01:56:20.263930: step 9630, loss = 0.88 (288.8 examples/sec; 0.887 sec/batch)\n",
      "2017-05-28 01:56:29.041940: step 9640, loss = 0.97 (291.6 examples/sec; 0.878 sec/batch)\n",
      "2017-05-28 01:56:37.082157: step 9650, loss = 0.98 (318.4 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 01:56:45.062756: step 9660, loss = 0.99 (320.8 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 01:56:53.697972: step 9670, loss = 0.88 (296.5 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 01:57:02.503955: step 9680, loss = 0.89 (290.7 examples/sec; 0.881 sec/batch)\n",
      "2017-05-28 01:57:10.862996: step 9690, loss = 0.98 (306.3 examples/sec; 0.836 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15252\n",
      "2017-05-28 01:57:22.729364: step 9700, loss = 0.98 (215.7 examples/sec; 1.187 sec/batch)\n",
      "2017-05-28 01:57:30.518240: step 9710, loss = 1.11 (328.7 examples/sec; 0.779 sec/batch)\n",
      "2017-05-28 01:57:39.514989: step 9720, loss = 1.03 (284.5 examples/sec; 0.900 sec/batch)\n",
      "2017-05-28 01:57:47.884139: step 9730, loss = 1.00 (305.9 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 01:57:55.942287: step 9740, loss = 1.01 (317.7 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 01:58:04.424420: step 9750, loss = 1.14 (301.8 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 01:58:12.803343: step 9760, loss = 1.01 (305.5 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 01:58:21.415561: step 9770, loss = 1.14 (297.3 examples/sec; 0.861 sec/batch)\n",
      "2017-05-28 01:58:29.468053: step 9780, loss = 1.01 (317.9 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 01:58:38.123563: step 9790, loss = 1.08 (295.8 examples/sec; 0.866 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14708\n",
      "2017-05-28 01:58:49.906663: step 9800, loss = 0.99 (217.3 examples/sec; 1.178 sec/batch)\n",
      "2017-05-28 01:58:57.175360: step 9810, loss = 1.07 (352.2 examples/sec; 0.727 sec/batch)\n",
      "2017-05-28 01:59:05.347098: step 9820, loss = 0.94 (313.3 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 01:59:13.576310: step 9830, loss = 0.96 (311.1 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 01:59:21.715286: step 9840, loss = 1.02 (314.5 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 01:59:30.232288: step 9850, loss = 0.89 (300.6 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 01:59:38.661856: step 9860, loss = 1.17 (303.7 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 01:59:47.325074: step 9870, loss = 1.04 (295.5 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 01:59:56.147088: step 9880, loss = 0.93 (290.2 examples/sec; 0.882 sec/batch)\n",
      "2017-05-28 02:00:04.724661: step 9890, loss = 0.94 (298.5 examples/sec; 0.858 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14828\n",
      "2017-05-28 02:00:16.994196: step 9900, loss = 0.85 (208.6 examples/sec; 1.227 sec/batch)\n",
      "2017-05-28 02:00:24.525888: step 9910, loss = 0.87 (339.9 examples/sec; 0.753 sec/batch)\n",
      "2017-05-28 02:00:32.734099: step 9920, loss = 0.96 (311.9 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 02:00:41.021532: step 9930, loss = 1.04 (308.9 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 02:00:49.336140: step 9940, loss = 1.04 (307.9 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 02:00:57.339144: step 9950, loss = 0.98 (319.9 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 02:01:05.784296: step 9960, loss = 1.08 (303.1 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 02:01:14.269188: step 9970, loss = 0.94 (301.7 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 02:01:23.062228: step 9980, loss = 1.05 (291.1 examples/sec; 0.879 sec/batch)\n",
      "2017-05-28 02:01:31.869610: step 9990, loss = 0.96 (290.7 examples/sec; 0.881 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16012\n",
      "2017-05-28 02:01:43.191951: step 10000, loss = 0.95 (226.1 examples/sec; 1.132 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 02:01:51.353610: step 10010, loss = 1.05 (313.7 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 02:02:00.128892: step 10020, loss = 1.10 (291.7 examples/sec; 0.878 sec/batch)\n",
      "2017-05-28 02:02:08.629126: step 10030, loss = 0.98 (301.2 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 02:02:17.116867: step 10040, loss = 1.01 (301.6 examples/sec; 0.849 sec/batch)\n",
      "2017-05-28 02:02:25.593030: step 10050, loss = 1.15 (302.0 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 02:02:34.144601: step 10060, loss = 0.94 (299.4 examples/sec; 0.855 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 10067 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 02:02:43.539024: step 10070, loss = 0.95 (272.5 examples/sec; 0.939 sec/batch)\n",
      "2017-05-28 02:02:52.312765: step 10080, loss = 0.98 (291.8 examples/sec; 0.877 sec/batch)\n",
      "2017-05-28 02:03:01.268915: step 10090, loss = 0.95 (285.8 examples/sec; 0.896 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1166\n",
      "2017-05-28 02:03:12.749016: step 10100, loss = 1.10 (223.0 examples/sec; 1.148 sec/batch)\n",
      "2017-05-28 02:03:20.941766: step 10110, loss = 0.99 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 02:03:29.568676: step 10120, loss = 1.03 (296.7 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 02:03:38.019253: step 10130, loss = 1.07 (302.9 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 02:03:46.265556: step 10140, loss = 0.98 (310.4 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 02:03:54.810836: step 10150, loss = 1.02 (299.6 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 02:04:03.172847: step 10160, loss = 1.05 (306.1 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 02:04:12.157667: step 10170, loss = 0.92 (284.9 examples/sec; 0.898 sec/batch)\n",
      "2017-05-28 02:04:20.578341: step 10180, loss = 0.90 (304.0 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 02:04:29.124377: step 10190, loss = 0.92 (299.6 examples/sec; 0.855 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11951\n",
      "2017-05-28 02:04:42.076698: step 10200, loss = 1.12 (197.6 examples/sec; 1.295 sec/batch)\n",
      "2017-05-28 02:04:50.147637: step 10210, loss = 0.92 (317.2 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 02:04:58.672255: step 10220, loss = 1.17 (300.3 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 02:05:07.109856: step 10230, loss = 1.08 (303.4 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 02:05:15.456477: step 10240, loss = 1.02 (306.7 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 02:05:24.179317: step 10250, loss = 0.95 (293.5 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 02:05:32.895478: step 10260, loss = 1.00 (293.7 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 02:05:41.315228: step 10270, loss = 1.10 (304.0 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 02:05:49.583141: step 10280, loss = 0.96 (309.6 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 02:05:57.508492: step 10290, loss = 0.97 (323.0 examples/sec; 0.793 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15146\n",
      "2017-05-28 02:06:08.919599: step 10300, loss = 1.02 (224.3 examples/sec; 1.141 sec/batch)\n",
      "2017-05-28 02:06:16.251360: step 10310, loss = 1.06 (349.2 examples/sec; 0.733 sec/batch)\n",
      "2017-05-28 02:06:24.126681: step 10320, loss = 0.91 (325.1 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 02:06:32.773199: step 10330, loss = 1.14 (296.1 examples/sec; 0.865 sec/batch)\n",
      "2017-05-28 02:06:41.436830: step 10340, loss = 1.02 (295.5 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 02:06:49.465263: step 10350, loss = 0.91 (318.9 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 02:06:57.905172: step 10360, loss = 0.97 (303.3 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 02:07:06.578190: step 10370, loss = 0.97 (295.2 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 02:07:15.282909: step 10380, loss = 1.08 (294.1 examples/sec; 0.870 sec/batch)\n",
      "2017-05-28 02:07:23.131191: step 10390, loss = 0.95 (326.2 examples/sec; 0.785 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15358\n",
      "2017-05-28 02:07:35.609586: step 10400, loss = 0.98 (205.2 examples/sec; 1.248 sec/batch)\n",
      "2017-05-28 02:07:43.071606: step 10410, loss = 0.92 (343.1 examples/sec; 0.746 sec/batch)\n",
      "2017-05-28 02:07:51.016818: step 10420, loss = 1.05 (322.2 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 02:07:59.115528: step 10430, loss = 1.01 (316.1 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 02:08:07.700576: step 10440, loss = 0.86 (298.2 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 02:08:16.222754: step 10450, loss = 0.95 (300.4 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 02:08:24.649559: step 10460, loss = 1.03 (303.8 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 02:08:33.165419: step 10470, loss = 0.98 (300.6 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 02:08:42.016427: step 10480, loss = 0.98 (289.2 examples/sec; 0.885 sec/batch)\n",
      "2017-05-28 02:08:50.430867: step 10490, loss = 1.09 (304.2 examples/sec; 0.841 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15223\n",
      "2017-05-28 02:09:02.394280: step 10500, loss = 1.05 (214.0 examples/sec; 1.196 sec/batch)\n",
      "2017-05-28 02:09:10.434690: step 10510, loss = 0.99 (318.4 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 02:09:19.295272: step 10520, loss = 0.95 (288.9 examples/sec; 0.886 sec/batch)\n",
      "2017-05-28 02:09:27.627781: step 10530, loss = 1.16 (307.2 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 02:09:36.319875: step 10540, loss = 1.00 (294.5 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 02:09:44.356378: step 10550, loss = 0.98 (318.5 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 02:09:52.728541: step 10560, loss = 0.93 (305.8 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 02:10:00.980654: step 10570, loss = 1.03 (310.2 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 02:10:08.901571: step 10580, loss = 1.09 (323.2 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 02:10:16.849155: step 10590, loss = 0.98 (322.1 examples/sec; 0.795 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15417\n",
      "2017-05-28 02:10:29.042364: step 10600, loss = 0.95 (210.0 examples/sec; 1.219 sec/batch)\n",
      "2017-05-28 02:10:37.183708: step 10610, loss = 1.02 (314.4 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 02:10:45.924058: step 10620, loss = 0.96 (292.9 examples/sec; 0.874 sec/batch)\n",
      "2017-05-28 02:10:53.956395: step 10630, loss = 0.98 (318.7 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 02:11:02.106424: step 10640, loss = 0.94 (314.1 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 02:11:10.265796: step 10650, loss = 0.93 (313.7 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 02:11:18.157564: step 10660, loss = 0.94 (324.4 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 02:11:26.021705: step 10670, loss = 0.93 (325.5 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 02:11:33.964030: step 10680, loss = 0.94 (322.3 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 02:11:41.961842: step 10690, loss = 0.93 (320.1 examples/sec; 0.800 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19529\n",
      "2017-05-28 02:11:52.701326: step 10700, loss = 1.03 (238.4 examples/sec; 1.074 sec/batch)\n",
      "2017-05-28 02:12:00.172835: step 10710, loss = 1.10 (342.6 examples/sec; 0.747 sec/batch)\n",
      "2017-05-28 02:12:08.017085: step 10720, loss = 1.02 (326.4 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 02:12:15.896635: step 10730, loss = 0.98 (324.9 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 02:12:23.850033: step 10740, loss = 1.04 (321.9 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 02:12:32.380614: step 10750, loss = 0.96 (300.1 examples/sec; 0.853 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 10760 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 02:12:41.564338: step 10760, loss = 1.01 (278.8 examples/sec; 0.918 sec/batch)\n",
      "2017-05-28 02:12:49.071590: step 10770, loss = 1.03 (341.0 examples/sec; 0.751 sec/batch)\n",
      "2017-05-28 02:12:57.139687: step 10780, loss = 1.02 (317.3 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 02:13:05.063782: step 10790, loss = 1.02 (323.1 examples/sec; 0.792 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19578\n",
      "2017-05-28 02:13:16.325790: step 10800, loss = 0.87 (227.3 examples/sec; 1.126 sec/batch)\n",
      "2017-05-28 02:13:23.642994: step 10810, loss = 0.98 (349.9 examples/sec; 0.732 sec/batch)\n",
      "2017-05-28 02:13:32.292665: step 10820, loss = 0.95 (296.0 examples/sec; 0.865 sec/batch)\n",
      "2017-05-28 02:13:40.735218: step 10830, loss = 0.89 (303.2 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 02:13:48.713629: step 10840, loss = 1.02 (320.9 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 02:13:57.279318: step 10850, loss = 1.03 (298.9 examples/sec; 0.857 sec/batch)\n",
      "2017-05-28 02:14:05.564445: step 10860, loss = 1.03 (309.0 examples/sec; 0.829 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 02:14:13.434696: step 10870, loss = 1.00 (325.3 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 02:14:21.284509: step 10880, loss = 0.93 (326.1 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 02:14:29.150393: step 10890, loss = 0.94 (325.5 examples/sec; 0.787 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15256\n",
      "2017-05-28 02:14:43.092057: step 10900, loss = 0.96 (183.6 examples/sec; 1.394 sec/batch)\n",
      "2017-05-28 02:14:50.761628: step 10910, loss = 0.96 (333.8 examples/sec; 0.767 sec/batch)\n",
      "2017-05-28 02:14:59.241979: step 10920, loss = 1.09 (301.9 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 02:15:07.659325: step 10930, loss = 1.09 (304.1 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 02:15:16.014855: step 10940, loss = 0.97 (306.4 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 02:15:24.102604: step 10950, loss = 1.03 (316.5 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 02:15:32.730336: step 10960, loss = 1.05 (296.7 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 02:15:41.681371: step 10970, loss = 0.99 (286.0 examples/sec; 0.895 sec/batch)\n",
      "2017-05-28 02:15:50.740393: step 10980, loss = 1.09 (282.6 examples/sec; 0.906 sec/batch)\n",
      "2017-05-28 02:15:59.643283: step 10990, loss = 0.97 (287.5 examples/sec; 0.890 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12395\n",
      "2017-05-28 02:16:12.060387: step 11000, loss = 1.15 (206.2 examples/sec; 1.242 sec/batch)\n",
      "2017-05-28 02:16:19.777683: step 11010, loss = 0.93 (331.7 examples/sec; 0.772 sec/batch)\n",
      "2017-05-28 02:16:28.166677: step 11020, loss = 0.96 (305.2 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 02:16:36.492958: step 11030, loss = 0.95 (307.5 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 02:16:44.789599: step 11040, loss = 0.97 (308.6 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 02:16:52.664248: step 11050, loss = 0.89 (325.1 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 02:17:00.559853: step 11060, loss = 0.91 (324.2 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 02:17:08.440279: step 11070, loss = 0.99 (324.9 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 02:17:16.267016: step 11080, loss = 0.87 (327.1 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 02:17:24.146985: step 11090, loss = 0.90 (324.9 examples/sec; 0.788 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17549\n",
      "2017-05-28 02:17:37.136080: step 11100, loss = 1.01 (197.1 examples/sec; 1.299 sec/batch)\n",
      "2017-05-28 02:17:44.561850: step 11110, loss = 1.08 (344.7 examples/sec; 0.743 sec/batch)\n",
      "2017-05-28 02:17:52.428962: step 11120, loss = 0.91 (325.4 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 02:18:00.406437: step 11130, loss = 0.99 (320.9 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 02:18:08.318848: step 11140, loss = 0.90 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 02:18:16.220427: step 11150, loss = 1.05 (324.0 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 02:18:24.592673: step 11160, loss = 1.11 (305.8 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 02:18:32.653876: step 11170, loss = 1.09 (317.6 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 02:18:40.649043: step 11180, loss = 1.05 (320.2 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 02:18:48.551865: step 11190, loss = 0.98 (323.9 examples/sec; 0.790 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21136\n",
      "2017-05-28 02:18:59.683666: step 11200, loss = 0.98 (230.0 examples/sec; 1.113 sec/batch)\n",
      "2017-05-28 02:19:07.448833: step 11210, loss = 0.92 (329.7 examples/sec; 0.777 sec/batch)\n",
      "2017-05-28 02:19:15.483211: step 11220, loss = 1.16 (318.6 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 02:19:23.376822: step 11230, loss = 1.01 (324.3 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 02:19:31.667330: step 11240, loss = 0.99 (308.8 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 02:19:39.857815: step 11250, loss = 1.07 (312.6 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 02:19:47.718890: step 11260, loss = 1.04 (325.7 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 02:19:55.703601: step 11270, loss = 0.95 (320.6 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 02:20:03.568797: step 11280, loss = 1.03 (325.5 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 02:20:11.571031: step 11290, loss = 0.98 (319.9 examples/sec; 0.800 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20513\n",
      "2017-05-28 02:20:22.664227: step 11300, loss = 0.94 (230.8 examples/sec; 1.109 sec/batch)\n",
      "2017-05-28 02:20:30.018523: step 11310, loss = 1.03 (348.1 examples/sec; 0.735 sec/batch)\n",
      "2017-05-28 02:20:37.903600: step 11320, loss = 1.05 (324.7 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 02:20:45.847560: step 11330, loss = 0.90 (322.3 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 02:20:53.761629: step 11340, loss = 0.89 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 02:21:02.297311: step 11350, loss = 1.01 (299.9 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 02:21:10.384675: step 11360, loss = 0.99 (316.5 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 02:21:18.312637: step 11370, loss = 1.01 (322.9 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 02:21:26.240598: step 11380, loss = 1.03 (322.9 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 02:21:35.417693: step 11390, loss = 1.01 (279.0 examples/sec; 0.918 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18259\n",
      "2017-05-28 02:21:47.222921: step 11400, loss = 0.89 (216.9 examples/sec; 1.181 sec/batch)\n",
      "2017-05-28 02:21:54.517520: step 11410, loss = 0.95 (350.9 examples/sec; 0.729 sec/batch)\n",
      "2017-05-28 02:22:02.517603: step 11420, loss = 0.93 (320.0 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 02:22:10.390975: step 11430, loss = 0.91 (325.1 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 02:22:18.266683: step 11440, loss = 1.01 (325.0 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 02:22:26.247495: step 11450, loss = 1.14 (320.8 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 02:22:34.701767: step 11460, loss = 1.00 (302.8 examples/sec; 0.845 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 11468 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 02:22:43.454322: step 11470, loss = 0.91 (292.5 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 02:22:51.313276: step 11480, loss = 1.06 (325.7 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 02:22:59.265709: step 11490, loss = 0.94 (321.9 examples/sec; 0.795 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20458\n",
      "2017-05-28 02:23:10.241863: step 11500, loss = 0.94 (233.2 examples/sec; 1.098 sec/batch)\n",
      "2017-05-28 02:23:17.553598: step 11510, loss = 0.98 (350.1 examples/sec; 0.731 sec/batch)\n",
      "2017-05-28 02:23:25.772167: step 11520, loss = 0.97 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 02:23:33.824941: step 11530, loss = 0.95 (317.9 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 02:23:41.708296: step 11540, loss = 1.07 (324.7 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 02:23:49.624197: step 11550, loss = 1.07 (323.4 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 02:23:57.450339: step 11560, loss = 0.93 (327.1 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 02:24:05.389100: step 11570, loss = 1.06 (322.5 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 02:24:13.785417: step 11580, loss = 1.00 (304.9 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 02:24:21.653567: step 11590, loss = 0.88 (325.4 examples/sec; 0.787 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.208\n",
      "2017-05-28 02:24:33.020781: step 11600, loss = 1.04 (225.2 examples/sec; 1.137 sec/batch)\n",
      "2017-05-28 02:24:40.345022: step 11610, loss = 0.90 (349.5 examples/sec; 0.732 sec/batch)\n",
      "2017-05-28 02:24:48.269191: step 11620, loss = 0.98 (323.1 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 02:24:56.676952: step 11630, loss = 1.02 (304.5 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 02:25:04.625140: step 11640, loss = 1.06 (322.1 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 02:25:12.494712: step 11650, loss = 0.99 (325.3 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 02:25:20.332753: step 11660, loss = 1.10 (326.6 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 02:25:28.495046: step 11670, loss = 1.14 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 02:25:36.804012: step 11680, loss = 1.02 (308.1 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 02:25:44.685914: step 11690, loss = 0.84 (324.8 examples/sec; 0.788 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21185\n",
      "2017-05-28 02:25:55.540049: step 11700, loss = 0.92 (235.9 examples/sec; 1.085 sec/batch)\n",
      "2017-05-28 02:26:02.983114: step 11710, loss = 0.96 (343.9 examples/sec; 0.744 sec/batch)\n",
      "2017-05-28 02:26:11.214888: step 11720, loss = 0.90 (311.0 examples/sec; 0.823 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 02:26:19.111271: step 11730, loss = 0.97 (324.2 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 02:26:27.013207: step 11740, loss = 0.94 (324.0 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 02:26:35.522355: step 11750, loss = 0.98 (300.9 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 02:26:44.341942: step 11760, loss = 0.99 (290.3 examples/sec; 0.882 sec/batch)\n",
      "2017-05-28 02:26:52.284582: step 11770, loss = 1.23 (322.3 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 02:27:00.425974: step 11780, loss = 0.91 (314.4 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 02:27:08.294612: step 11790, loss = 0.97 (325.3 examples/sec; 0.787 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17638\n",
      "2017-05-28 02:27:20.547619: step 11800, loss = 0.95 (208.9 examples/sec; 1.225 sec/batch)\n",
      "2017-05-28 02:27:28.080312: step 11810, loss = 0.98 (339.9 examples/sec; 0.753 sec/batch)\n",
      "2017-05-28 02:27:36.065638: step 11820, loss = 0.89 (320.6 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 02:27:43.984330: step 11830, loss = 0.91 (323.3 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 02:27:51.860690: step 11840, loss = 0.87 (325.0 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 02:27:59.792112: step 11850, loss = 0.91 (322.8 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 02:28:07.702003: step 11860, loss = 0.88 (323.6 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 02:28:15.976456: step 11870, loss = 0.87 (309.4 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 02:28:23.947618: step 11880, loss = 1.02 (321.2 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 02:28:31.892149: step 11890, loss = 0.95 (322.2 examples/sec; 0.794 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21635\n",
      "2017-05-28 02:28:42.758365: step 11900, loss = 0.97 (235.6 examples/sec; 1.087 sec/batch)\n",
      "2017-05-28 02:28:50.715150: step 11910, loss = 0.95 (321.7 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 02:28:58.770971: step 11920, loss = 1.09 (317.8 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 02:29:06.657627: step 11930, loss = 0.87 (324.6 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 02:29:14.649309: step 11940, loss = 0.88 (320.3 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 02:29:22.565386: step 11950, loss = 1.04 (323.4 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 02:29:30.893186: step 11960, loss = 1.05 (307.4 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 02:29:38.886927: step 11970, loss = 1.01 (320.3 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 02:29:46.713978: step 11980, loss = 1.00 (327.1 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 02:29:54.770513: step 11990, loss = 0.94 (317.8 examples/sec; 0.806 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19287\n",
      "2017-05-28 02:30:06.592354: step 12000, loss = 1.04 (216.5 examples/sec; 1.182 sec/batch)\n",
      "2017-05-28 02:30:14.124226: step 12010, loss = 1.01 (339.9 examples/sec; 0.753 sec/batch)\n",
      "2017-05-28 02:30:22.094010: step 12020, loss = 0.95 (321.2 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 02:30:30.081177: step 12030, loss = 1.03 (320.5 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 02:30:37.940699: step 12040, loss = 0.92 (325.7 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 02:30:45.821150: step 12050, loss = 0.80 (324.9 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 02:30:53.720324: step 12060, loss = 1.00 (324.1 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 02:31:01.772431: step 12070, loss = 0.93 (317.9 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 02:31:09.653761: step 12080, loss = 0.90 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 02:31:17.917962: step 12090, loss = 0.94 (309.8 examples/sec; 0.826 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21619\n",
      "2017-05-28 02:31:28.813145: step 12100, loss = 0.88 (235.0 examples/sec; 1.090 sec/batch)\n",
      "2017-05-28 02:31:36.214136: step 12110, loss = 1.13 (345.9 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 02:31:45.597153: step 12120, loss = 0.95 (272.8 examples/sec; 0.938 sec/batch)\n",
      "2017-05-28 02:31:54.111741: step 12130, loss = 1.01 (300.7 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 02:32:02.210876: step 12140, loss = 1.04 (316.1 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 02:32:10.272109: step 12150, loss = 0.99 (317.6 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 02:32:18.133043: step 12160, loss = 1.04 (325.7 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 02:32:26.540467: step 12170, loss = 0.86 (304.5 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 02:32:34.638983: step 12180, loss = 1.05 (316.1 examples/sec; 0.810 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 12188 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 02:32:43.468605: step 12190, loss = 0.90 (289.9 examples/sec; 0.883 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17248\n",
      "2017-05-28 02:32:54.107287: step 12200, loss = 1.00 (240.6 examples/sec; 1.064 sec/batch)\n",
      "2017-05-28 02:33:01.932971: step 12210, loss = 0.88 (327.1 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 02:33:10.040127: step 12220, loss = 0.96 (315.8 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 02:33:17.937046: step 12230, loss = 0.98 (324.2 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 02:33:25.777635: step 12240, loss = 1.00 (326.5 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 02:33:34.015896: step 12250, loss = 1.00 (310.7 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 02:33:41.895759: step 12260, loss = 0.93 (324.9 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 02:33:49.740475: step 12270, loss = 0.89 (326.3 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 02:33:57.772958: step 12280, loss = 0.92 (318.7 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 02:34:06.070852: step 12290, loss = 1.21 (308.5 examples/sec; 0.830 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20615\n",
      "2017-05-28 02:34:17.015615: step 12300, loss = 0.95 (233.9 examples/sec; 1.094 sec/batch)\n",
      "2017-05-28 02:34:24.315296: step 12310, loss = 1.04 (350.7 examples/sec; 0.730 sec/batch)\n",
      "2017-05-28 02:34:32.260049: step 12320, loss = 0.93 (322.2 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 02:34:40.125979: step 12330, loss = 1.10 (325.5 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 02:34:48.198265: step 12340, loss = 0.86 (317.1 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 02:34:56.504706: step 12350, loss = 0.89 (308.2 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 02:35:04.608636: step 12360, loss = 0.96 (315.9 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 02:35:12.437281: step 12370, loss = 0.92 (327.0 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 02:35:20.830625: step 12380, loss = 0.93 (305.0 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 02:35:28.787762: step 12390, loss = 1.08 (321.7 examples/sec; 0.796 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20602\n",
      "2017-05-28 02:35:39.928948: step 12400, loss = 0.95 (229.8 examples/sec; 1.114 sec/batch)\n",
      "2017-05-28 02:35:47.139646: step 12410, loss = 0.91 (355.0 examples/sec; 0.721 sec/batch)\n",
      "2017-05-28 02:35:55.007596: step 12420, loss = 1.08 (325.4 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 02:36:02.888691: step 12430, loss = 1.02 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 02:36:10.990201: step 12440, loss = 1.07 (316.0 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 02:36:18.946407: step 12450, loss = 0.95 (321.8 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 02:36:27.165476: step 12460, loss = 1.16 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 02:36:35.212420: step 12470, loss = 1.02 (318.1 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 02:36:43.050015: step 12480, loss = 0.90 (326.6 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 02:36:52.006163: step 12490, loss = 0.95 (285.8 examples/sec; 0.896 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17315\n",
      "2017-05-28 02:37:05.172284: step 12500, loss = 0.88 (194.4 examples/sec; 1.317 sec/batch)\n",
      "2017-05-28 02:37:13.116829: step 12510, loss = 0.83 (322.2 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 02:37:21.508598: step 12520, loss = 1.01 (305.1 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 02:37:29.477697: step 12530, loss = 1.04 (321.2 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 02:37:38.261798: step 12540, loss = 1.04 (291.4 examples/sec; 0.878 sec/batch)\n",
      "2017-05-28 02:37:47.240999: step 12550, loss = 0.97 (285.1 examples/sec; 0.898 sec/batch)\n",
      "2017-05-28 02:37:55.903542: step 12560, loss = 0.95 (295.5 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 02:38:04.397879: step 12570, loss = 0.85 (301.4 examples/sec; 0.849 sec/batch)\n",
      "2017-05-28 02:38:12.770591: step 12580, loss = 0.96 (305.8 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 02:38:20.644980: step 12590, loss = 0.93 (325.1 examples/sec; 0.787 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.12148\n",
      "2017-05-28 02:38:34.338925: step 12600, loss = 0.87 (186.9 examples/sec; 1.369 sec/batch)\n",
      "2017-05-28 02:38:42.076715: step 12610, loss = 0.88 (330.8 examples/sec; 0.774 sec/batch)\n",
      "2017-05-28 02:38:50.132196: step 12620, loss = 0.99 (317.8 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 02:38:58.596919: step 12630, loss = 1.04 (302.4 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 02:39:07.057966: step 12640, loss = 0.88 (302.6 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 02:39:15.544584: step 12650, loss = 0.98 (301.7 examples/sec; 0.849 sec/batch)\n",
      "2017-05-28 02:39:24.480161: step 12660, loss = 0.98 (286.5 examples/sec; 0.894 sec/batch)\n",
      "2017-05-28 02:39:32.777625: step 12670, loss = 1.00 (308.5 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 02:39:41.418057: step 12680, loss = 0.99 (296.3 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 02:39:49.913144: step 12690, loss = 0.82 (301.4 examples/sec; 0.850 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14199\n",
      "2017-05-28 02:40:01.908351: step 12700, loss = 0.99 (213.4 examples/sec; 1.200 sec/batch)\n",
      "2017-05-28 02:40:10.031639: step 12710, loss = 0.92 (315.1 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 02:40:18.356361: step 12720, loss = 0.95 (307.5 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 02:40:26.569415: step 12730, loss = 1.00 (311.7 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 02:40:34.635647: step 12740, loss = 0.87 (317.4 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 02:40:42.482669: step 12750, loss = 0.90 (326.2 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 02:40:50.404930: step 12760, loss = 0.92 (323.1 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 02:40:58.766175: step 12770, loss = 0.90 (306.2 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 02:41:07.342066: step 12780, loss = 0.89 (298.5 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 02:41:15.719287: step 12790, loss = 1.01 (305.6 examples/sec; 0.838 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17896\n",
      "2017-05-28 02:41:26.725544: step 12800, loss = 0.89 (232.6 examples/sec; 1.101 sec/batch)\n",
      "2017-05-28 02:41:35.079303: step 12810, loss = 0.93 (306.4 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 02:41:43.677482: step 12820, loss = 1.01 (297.7 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 02:41:52.143442: step 12830, loss = 1.08 (302.4 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 02:42:01.366010: step 12840, loss = 0.85 (277.6 examples/sec; 0.922 sec/batch)\n",
      "2017-05-28 02:42:09.419474: step 12850, loss = 1.07 (317.9 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 02:42:17.903012: step 12860, loss = 0.88 (301.8 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 02:42:26.299311: step 12870, loss = 0.90 (304.9 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 02:42:34.849709: step 12880, loss = 0.94 (299.4 examples/sec; 0.855 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 12888 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 02:42:44.148775: step 12890, loss = 0.81 (275.3 examples/sec; 0.930 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10331\n",
      "2017-05-28 02:42:57.365782: step 12900, loss = 0.96 (193.7 examples/sec; 1.322 sec/batch)\n",
      "2017-05-28 02:43:05.348521: step 12910, loss = 0.89 (320.7 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 02:43:13.835726: step 12920, loss = 0.91 (301.6 examples/sec; 0.849 sec/batch)\n",
      "2017-05-28 02:43:22.329489: step 12930, loss = 1.06 (301.4 examples/sec; 0.849 sec/batch)\n",
      "2017-05-28 02:43:30.850124: step 12940, loss = 0.98 (300.4 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 02:43:39.249651: step 12950, loss = 1.02 (304.8 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 02:43:48.075582: step 12960, loss = 1.04 (290.1 examples/sec; 0.883 sec/batch)\n",
      "2017-05-28 02:43:56.613848: step 12970, loss = 1.08 (299.8 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 02:44:04.970438: step 12980, loss = 0.79 (306.3 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 02:44:13.569381: step 12990, loss = 0.94 (297.7 examples/sec; 0.860 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11506\n",
      "2017-05-28 02:44:27.045137: step 13000, loss = 0.91 (190.0 examples/sec; 1.348 sec/batch)\n",
      "2017-05-28 02:44:34.926770: step 13010, loss = 0.91 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 02:44:43.486529: step 13020, loss = 1.01 (299.1 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 02:44:52.075794: step 13030, loss = 0.94 (298.0 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 02:45:00.989065: step 13040, loss = 1.05 (287.2 examples/sec; 0.891 sec/batch)\n",
      "2017-05-28 02:45:09.666779: step 13050, loss = 0.87 (295.0 examples/sec; 0.868 sec/batch)\n",
      "2017-05-28 02:45:18.145177: step 13060, loss = 0.95 (301.9 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 02:45:26.588973: step 13070, loss = 0.99 (303.2 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 02:45:35.083817: step 13080, loss = 0.92 (301.4 examples/sec; 0.849 sec/batch)\n",
      "2017-05-28 02:45:43.143624: step 13090, loss = 0.99 (317.6 examples/sec; 0.806 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11042\n",
      "2017-05-28 02:45:57.099545: step 13100, loss = 0.88 (183.4 examples/sec; 1.396 sec/batch)\n",
      "2017-05-28 02:46:04.896410: step 13110, loss = 1.01 (328.3 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 02:46:13.347110: step 13120, loss = 0.83 (302.9 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 02:46:21.802027: step 13130, loss = 0.91 (302.8 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 02:46:30.315013: step 13140, loss = 0.93 (300.7 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 02:46:39.201931: step 13150, loss = 1.02 (288.1 examples/sec; 0.889 sec/batch)\n",
      "2017-05-28 02:46:47.844950: step 13160, loss = 1.06 (296.2 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 02:46:56.242093: step 13170, loss = 1.05 (304.9 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 02:47:05.111619: step 13180, loss = 1.04 (288.6 examples/sec; 0.887 sec/batch)\n",
      "2017-05-28 02:47:13.685204: step 13190, loss = 0.88 (298.6 examples/sec; 0.857 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14778\n",
      "2017-05-28 02:47:24.221915: step 13200, loss = 0.99 (243.0 examples/sec; 1.054 sec/batch)\n",
      "2017-05-28 02:47:31.864603: step 13210, loss = 0.96 (335.0 examples/sec; 0.764 sec/batch)\n",
      "2017-05-28 02:47:39.661426: step 13220, loss = 1.03 (328.3 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 02:47:47.559527: step 13230, loss = 1.04 (324.1 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 02:47:55.690674: step 13240, loss = 0.91 (314.8 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 02:48:03.711037: step 13250, loss = 0.93 (319.2 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 02:48:11.713865: step 13260, loss = 0.96 (319.9 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 02:48:19.978392: step 13270, loss = 0.86 (309.8 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 02:48:27.935796: step 13280, loss = 0.91 (321.7 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 02:48:36.421280: step 13290, loss = 1.05 (301.7 examples/sec; 0.849 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20156\n",
      "2017-05-28 02:48:47.448004: step 13300, loss = 0.89 (232.2 examples/sec; 1.103 sec/batch)\n",
      "2017-05-28 02:48:54.826208: step 13310, loss = 1.01 (347.0 examples/sec; 0.738 sec/batch)\n",
      "2017-05-28 02:49:02.823754: step 13320, loss = 1.03 (320.1 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 02:49:10.838743: step 13330, loss = 0.89 (319.4 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 02:49:18.860234: step 13340, loss = 0.94 (319.1 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 02:49:26.651685: step 13350, loss = 1.06 (328.6 examples/sec; 0.779 sec/batch)\n",
      "2017-05-28 02:49:34.556859: step 13360, loss = 0.93 (323.8 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 02:49:42.467010: step 13370, loss = 1.02 (323.6 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 02:49:50.402190: step 13380, loss = 0.95 (322.6 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 02:49:58.404799: step 13390, loss = 1.01 (319.9 examples/sec; 0.800 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19803\n",
      "2017-05-28 02:50:10.920491: step 13400, loss = 0.92 (204.5 examples/sec; 1.252 sec/batch)\n",
      "2017-05-28 02:50:18.169969: step 13410, loss = 0.98 (353.1 examples/sec; 0.725 sec/batch)\n",
      "2017-05-28 02:50:26.020894: step 13420, loss = 1.01 (326.1 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 02:50:34.344609: step 13430, loss = 0.96 (307.6 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 02:50:42.395145: step 13440, loss = 1.02 (318.0 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 02:50:50.387914: step 13450, loss = 0.90 (320.3 examples/sec; 0.799 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 02:50:58.213952: step 13460, loss = 0.88 (327.1 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 02:51:06.134402: step 13470, loss = 0.95 (323.2 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 02:51:14.501862: step 13480, loss = 0.93 (305.9 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 02:51:22.393431: step 13490, loss = 0.84 (324.4 examples/sec; 0.789 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19748\n",
      "2017-05-28 02:51:34.426892: step 13500, loss = 0.93 (212.7 examples/sec; 1.203 sec/batch)\n",
      "2017-05-28 02:51:41.772823: step 13510, loss = 1.01 (348.5 examples/sec; 0.735 sec/batch)\n",
      "2017-05-28 02:51:50.157640: step 13520, loss = 1.05 (305.3 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 02:51:58.047987: step 13530, loss = 0.95 (324.4 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 02:52:06.120333: step 13540, loss = 0.98 (317.1 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 02:52:14.832125: step 13550, loss = 0.90 (293.9 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 02:52:22.913869: step 13560, loss = 1.01 (316.8 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 02:52:31.314052: step 13570, loss = 0.90 (304.8 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 02:52:39.406889: step 13580, loss = 0.83 (316.3 examples/sec; 0.809 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 13583 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 02:52:48.056141: step 13590, loss = 0.95 (296.0 examples/sec; 0.865 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18217\n",
      "2017-05-28 02:52:59.017188: step 13600, loss = 0.92 (233.6 examples/sec; 1.096 sec/batch)\n",
      "2017-05-28 02:53:06.338786: step 13610, loss = 0.89 (349.7 examples/sec; 0.732 sec/batch)\n",
      "2017-05-28 02:53:14.322256: step 13620, loss = 0.99 (320.7 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 02:53:22.459516: step 13630, loss = 0.99 (314.6 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 02:53:30.618450: step 13640, loss = 1.08 (313.8 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 02:53:38.586784: step 13650, loss = 0.93 (321.3 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 02:53:46.987127: step 13660, loss = 0.97 (304.7 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 02:53:54.837506: step 13670, loss = 0.92 (326.1 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 02:54:02.939449: step 13680, loss = 0.81 (316.0 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 02:54:10.746895: step 13690, loss = 0.95 (327.9 examples/sec; 0.781 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19072\n",
      "2017-05-28 02:54:23.000212: step 13700, loss = 0.97 (208.9 examples/sec; 1.225 sec/batch)\n",
      "2017-05-28 02:54:30.417294: step 13710, loss = 0.94 (345.1 examples/sec; 0.742 sec/batch)\n",
      "2017-05-28 02:54:38.376874: step 13720, loss = 0.98 (321.6 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 02:54:46.286113: step 13730, loss = 1.03 (323.7 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 02:54:54.467172: step 13740, loss = 0.94 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 02:55:02.748920: step 13750, loss = 0.99 (309.1 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 02:55:10.764505: step 13760, loss = 0.91 (319.4 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 02:55:18.577840: step 13770, loss = 0.92 (327.6 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 02:55:26.535227: step 13780, loss = 1.07 (321.7 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 02:55:34.570438: step 13790, loss = 0.87 (318.6 examples/sec; 0.804 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19824\n",
      "2017-05-28 02:55:46.457057: step 13800, loss = 0.93 (215.4 examples/sec; 1.189 sec/batch)\n",
      "2017-05-28 02:55:53.706515: step 13810, loss = 0.85 (353.1 examples/sec; 0.725 sec/batch)\n",
      "2017-05-28 02:56:01.781601: step 13820, loss = 0.96 (317.0 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 02:56:09.935552: step 13830, loss = 0.93 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 02:56:18.044548: step 13840, loss = 1.04 (315.7 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 02:56:25.941353: step 13850, loss = 1.04 (324.2 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 02:56:33.929200: step 13860, loss = 0.87 (320.5 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 02:56:42.351885: step 13870, loss = 0.92 (303.9 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 02:56:50.292463: step 13880, loss = 0.86 (322.4 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 02:56:58.372169: step 13890, loss = 0.85 (316.8 examples/sec; 0.808 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18444\n",
      "2017-05-28 02:57:10.887166: step 13900, loss = 0.95 (204.6 examples/sec; 1.251 sec/batch)\n",
      "2017-05-28 02:57:19.237347: step 13910, loss = 0.93 (306.6 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 02:57:27.416031: step 13920, loss = 0.79 (313.0 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 02:57:35.688267: step 13930, loss = 0.88 (309.5 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 02:57:44.027978: step 13940, loss = 1.13 (307.0 examples/sec; 0.834 sec/batch)\n",
      "2017-05-28 02:57:52.659322: step 13950, loss = 0.89 (296.6 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 02:58:01.099848: step 13960, loss = 0.96 (303.3 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 02:58:10.075569: step 13970, loss = 0.99 (285.2 examples/sec; 0.898 sec/batch)\n",
      "2017-05-28 02:58:18.617406: step 13980, loss = 0.97 (299.7 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 02:58:26.986626: step 13990, loss = 1.01 (305.9 examples/sec; 0.837 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14077\n",
      "2017-05-28 02:58:38.544026: step 14000, loss = 1.00 (221.5 examples/sec; 1.156 sec/batch)\n",
      "2017-05-28 02:58:46.355981: step 14010, loss = 0.96 (327.7 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 02:58:54.358316: step 14020, loss = 0.98 (319.9 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 02:59:02.775623: step 14030, loss = 1.05 (304.1 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 02:59:11.616667: step 14040, loss = 0.96 (289.6 examples/sec; 0.884 sec/batch)\n",
      "2017-05-28 02:59:20.121009: step 14050, loss = 0.83 (301.0 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 02:59:28.183442: step 14060, loss = 0.98 (317.5 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 02:59:37.372426: step 14070, loss = 0.96 (278.6 examples/sec; 0.919 sec/batch)\n",
      "2017-05-28 02:59:45.454743: step 14080, loss = 1.05 (316.7 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 02:59:53.796369: step 14090, loss = 0.96 (306.9 examples/sec; 0.834 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1506\n",
      "2017-05-28 03:00:05.457875: step 14100, loss = 0.98 (219.5 examples/sec; 1.166 sec/batch)\n",
      "2017-05-28 03:00:14.054388: step 14110, loss = 0.93 (297.8 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 03:00:22.578351: step 14120, loss = 0.93 (300.3 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 03:00:31.098868: step 14130, loss = 0.87 (300.5 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 03:00:40.010198: step 14140, loss = 1.03 (287.3 examples/sec; 0.891 sec/batch)\n",
      "2017-05-28 03:00:48.611823: step 14150, loss = 0.90 (297.6 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 03:00:56.973984: step 14160, loss = 1.00 (306.1 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 03:01:05.775106: step 14170, loss = 1.02 (290.9 examples/sec; 0.880 sec/batch)\n",
      "2017-05-28 03:01:14.121631: step 14180, loss = 0.90 (306.7 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 03:01:22.360277: step 14190, loss = 0.84 (310.7 examples/sec; 0.824 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.0986\n",
      "2017-05-28 03:01:36.483581: step 14200, loss = 0.88 (181.3 examples/sec; 1.412 sec/batch)\n",
      "2017-05-28 03:01:44.049234: step 14210, loss = 0.79 (338.4 examples/sec; 0.757 sec/batch)\n",
      "2017-05-28 03:01:52.426667: step 14220, loss = 0.81 (305.6 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 03:02:00.729664: step 14230, loss = 0.93 (308.3 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 03:02:09.394424: step 14240, loss = 0.98 (295.4 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 03:02:17.791327: step 14250, loss = 0.97 (304.9 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 03:02:26.687724: step 14260, loss = 0.81 (287.8 examples/sec; 0.890 sec/batch)\n",
      "2017-05-28 03:02:35.692054: step 14270, loss = 0.94 (284.3 examples/sec; 0.900 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 14278 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 03:02:44.465610: step 14280, loss = 0.84 (291.8 examples/sec; 0.877 sec/batch)\n",
      "2017-05-28 03:02:52.285659: step 14290, loss = 0.88 (327.4 examples/sec; 0.782 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14477\n",
      "2017-05-28 03:03:03.833682: step 14300, loss = 0.94 (221.7 examples/sec; 1.155 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 03:03:11.110293: step 14310, loss = 0.80 (351.8 examples/sec; 0.728 sec/batch)\n",
      "2017-05-28 03:03:19.076290: step 14320, loss = 0.85 (321.4 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 03:03:27.330843: step 14330, loss = 0.87 (310.1 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 03:03:35.637661: step 14340, loss = 0.88 (308.2 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 03:03:43.506245: step 14350, loss = 0.94 (325.3 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 03:03:51.406853: step 14360, loss = 1.10 (324.0 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 03:03:59.229079: step 14370, loss = 0.96 (327.3 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 03:04:07.287645: step 14380, loss = 0.95 (317.7 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 03:04:15.221925: step 14390, loss = 0.97 (322.7 examples/sec; 0.793 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20096\n",
      "2017-05-28 03:04:27.099905: step 14400, loss = 0.94 (215.5 examples/sec; 1.188 sec/batch)\n",
      "2017-05-28 03:04:34.519044: step 14410, loss = 0.94 (345.1 examples/sec; 0.742 sec/batch)\n",
      "2017-05-28 03:04:42.346918: step 14420, loss = 0.84 (327.0 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 03:04:50.304705: step 14430, loss = 0.97 (321.7 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 03:04:58.108295: step 14440, loss = 0.80 (328.1 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 03:05:06.141589: step 14450, loss = 0.97 (318.7 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 03:05:14.084156: step 14460, loss = 0.98 (322.3 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 03:05:21.989134: step 14470, loss = 0.91 (323.8 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 03:05:30.295814: step 14480, loss = 0.79 (308.2 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 03:05:38.336769: step 14490, loss = 0.98 (318.4 examples/sec; 0.804 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21873\n",
      "2017-05-28 03:05:49.157951: step 14500, loss = 1.04 (236.6 examples/sec; 1.082 sec/batch)\n",
      "2017-05-28 03:05:56.421219: step 14510, loss = 0.94 (352.5 examples/sec; 0.726 sec/batch)\n",
      "2017-05-28 03:06:04.438595: step 14520, loss = 0.97 (319.3 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 03:06:12.705968: step 14530, loss = 0.93 (309.7 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 03:06:20.710911: step 14540, loss = 0.85 (319.8 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 03:06:28.635023: step 14550, loss = 0.82 (323.1 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 03:06:36.691096: step 14560, loss = 0.86 (317.8 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 03:06:44.637612: step 14570, loss = 0.98 (322.2 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 03:06:52.475614: step 14580, loss = 0.96 (326.6 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 03:07:00.393036: step 14590, loss = 0.94 (323.3 examples/sec; 0.792 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21779\n",
      "2017-05-28 03:07:11.269784: step 14600, loss = 0.96 (235.4 examples/sec; 1.088 sec/batch)\n",
      "2017-05-28 03:07:18.919899: step 14610, loss = 0.94 (334.6 examples/sec; 0.765 sec/batch)\n",
      "2017-05-28 03:07:27.344855: step 14620, loss = 0.98 (303.9 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 03:07:36.819352: step 14630, loss = 0.85 (270.2 examples/sec; 0.947 sec/batch)\n",
      "2017-05-28 03:07:45.381176: step 14640, loss = 1.00 (299.0 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 03:07:53.320608: step 14650, loss = 0.89 (322.4 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 03:08:01.301522: step 14660, loss = 0.92 (320.8 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 03:08:09.662108: step 14670, loss = 0.93 (306.2 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 03:08:17.627620: step 14680, loss = 1.03 (321.4 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 03:08:25.541058: step 14690, loss = 0.82 (323.5 examples/sec; 0.791 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17533\n",
      "2017-05-28 03:08:36.352018: step 14700, loss = 0.85 (236.8 examples/sec; 1.081 sec/batch)\n",
      "2017-05-28 03:08:44.059773: step 14710, loss = 0.97 (332.1 examples/sec; 0.771 sec/batch)\n",
      "2017-05-28 03:08:52.157020: step 14720, loss = 0.82 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 03:09:00.085380: step 14730, loss = 1.01 (322.9 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 03:09:08.044038: step 14740, loss = 0.93 (321.7 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 03:09:15.908825: step 14750, loss = 1.06 (325.5 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 03:09:23.776955: step 14760, loss = 0.89 (325.4 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 03:09:31.917329: step 14770, loss = 0.95 (314.5 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 03:09:39.953618: step 14780, loss = 0.84 (318.6 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 03:09:47.843135: step 14790, loss = 0.85 (324.5 examples/sec; 0.789 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.204\n",
      "2017-05-28 03:09:59.409992: step 14800, loss = 0.94 (221.3 examples/sec; 1.157 sec/batch)\n",
      "2017-05-28 03:10:06.805765: step 14810, loss = 0.96 (346.1 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 03:10:14.721797: step 14820, loss = 0.89 (323.4 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 03:10:23.118726: step 14830, loss = 0.99 (304.9 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 03:10:31.167189: step 14840, loss = 0.93 (318.1 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 03:10:39.153178: step 14850, loss = 0.86 (320.6 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 03:10:47.003615: step 14860, loss = 0.91 (326.1 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 03:10:55.374912: step 14870, loss = 0.90 (305.8 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 03:11:03.686746: step 14880, loss = 1.03 (308.0 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 03:11:11.573642: step 14890, loss = 0.94 (324.6 examples/sec; 0.789 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17979\n",
      "2017-05-28 03:11:24.171963: step 14900, loss = 0.92 (203.2 examples/sec; 1.260 sec/batch)\n",
      "2017-05-28 03:11:31.588625: step 14910, loss = 0.84 (345.2 examples/sec; 0.742 sec/batch)\n",
      "2017-05-28 03:11:39.452120: step 14920, loss = 0.97 (325.6 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 03:11:47.427310: step 14930, loss = 0.90 (321.0 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 03:11:55.342945: step 14940, loss = 0.84 (323.4 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 03:12:03.354054: step 14950, loss = 0.93 (319.6 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 03:12:11.209287: step 14960, loss = 0.80 (325.9 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 03:12:19.130812: step 14970, loss = 0.98 (323.2 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 03:12:27.079009: step 14980, loss = 0.90 (322.1 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 03:12:35.043378: step 14990, loss = 0.95 (321.4 examples/sec; 0.796 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 14998 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.17247\n",
      "2017-05-28 03:12:49.462589: step 15000, loss = 0.92 (177.5 examples/sec; 1.442 sec/batch)\n",
      "2017-05-28 03:12:56.784067: step 15010, loss = 0.93 (349.7 examples/sec; 0.732 sec/batch)\n",
      "2017-05-28 03:13:05.390884: step 15020, loss = 0.95 (297.4 examples/sec; 0.861 sec/batch)\n",
      "2017-05-28 03:13:14.249982: step 15030, loss = 1.01 (289.0 examples/sec; 0.886 sec/batch)\n",
      "2017-05-28 03:13:22.512338: step 15040, loss = 0.84 (309.8 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 03:13:30.570285: step 15050, loss = 0.90 (317.7 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 03:13:39.273510: step 15060, loss = 0.85 (294.1 examples/sec; 0.870 sec/batch)\n",
      "2017-05-28 03:13:47.673314: step 15070, loss = 0.93 (304.8 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 03:13:55.814144: step 15080, loss = 1.03 (314.5 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 03:14:04.249872: step 15090, loss = 0.89 (303.5 examples/sec; 0.844 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14252\n",
      "2017-05-28 03:14:16.986153: step 15100, loss = 0.96 (201.0 examples/sec; 1.274 sec/batch)\n",
      "2017-05-28 03:14:24.695974: step 15110, loss = 0.93 (332.0 examples/sec; 0.771 sec/batch)\n",
      "2017-05-28 03:14:33.233499: step 15120, loss = 0.84 (299.9 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 03:14:41.685795: step 15130, loss = 0.97 (302.9 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 03:14:50.088885: step 15140, loss = 0.97 (304.6 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 03:14:58.537852: step 15150, loss = 0.88 (303.0 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 03:15:07.399743: step 15160, loss = 1.02 (288.9 examples/sec; 0.886 sec/batch)\n",
      "2017-05-28 03:15:15.642273: step 15170, loss = 0.81 (310.6 examples/sec; 0.824 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 03:15:23.663501: step 15180, loss = 0.93 (319.2 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 03:15:32.059354: step 15190, loss = 0.90 (304.9 examples/sec; 0.840 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14809\n",
      "2017-05-28 03:15:44.086562: step 15200, loss = 0.91 (212.9 examples/sec; 1.203 sec/batch)\n",
      "2017-05-28 03:15:52.265204: step 15210, loss = 0.88 (313.0 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 03:16:00.537170: step 15220, loss = 0.86 (309.5 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 03:16:08.435020: step 15230, loss = 0.87 (324.1 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 03:16:16.310774: step 15240, loss = 0.84 (325.0 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 03:16:24.169139: step 15250, loss = 0.88 (325.8 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 03:16:32.957967: step 15260, loss = 1.03 (291.3 examples/sec; 0.879 sec/batch)\n",
      "2017-05-28 03:16:41.496612: step 15270, loss = 0.93 (299.8 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 03:16:49.577300: step 15280, loss = 0.92 (316.8 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 03:16:57.840233: step 15290, loss = 0.96 (309.8 examples/sec; 0.826 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15845\n",
      "2017-05-28 03:17:10.412469: step 15300, loss = 0.93 (203.6 examples/sec; 1.257 sec/batch)\n",
      "2017-05-28 03:17:18.134400: step 15310, loss = 0.84 (331.5 examples/sec; 0.772 sec/batch)\n",
      "2017-05-28 03:17:26.478729: step 15320, loss = 0.81 (306.8 examples/sec; 0.834 sec/batch)\n",
      "2017-05-28 03:17:35.257188: step 15330, loss = 0.97 (291.6 examples/sec; 0.878 sec/batch)\n",
      "2017-05-28 03:17:43.696834: step 15340, loss = 0.93 (303.3 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 03:17:53.053897: step 15350, loss = 0.77 (273.6 examples/sec; 0.936 sec/batch)\n",
      "2017-05-28 03:18:01.815403: step 15360, loss = 0.90 (292.2 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 03:18:10.066398: step 15370, loss = 0.97 (310.3 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 03:18:18.439452: step 15380, loss = 0.96 (305.7 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 03:18:26.910209: step 15390, loss = 0.95 (302.2 examples/sec; 0.847 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11433\n",
      "2017-05-28 03:18:40.148578: step 15400, loss = 1.18 (193.4 examples/sec; 1.324 sec/batch)\n",
      "2017-05-28 03:18:47.891964: step 15410, loss = 0.91 (330.6 examples/sec; 0.774 sec/batch)\n",
      "2017-05-28 03:18:56.405249: step 15420, loss = 0.86 (300.7 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 03:19:04.971473: step 15430, loss = 0.96 (298.8 examples/sec; 0.857 sec/batch)\n",
      "2017-05-28 03:19:13.507209: step 15440, loss = 0.91 (299.9 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 03:19:22.319320: step 15450, loss = 0.92 (290.5 examples/sec; 0.881 sec/batch)\n",
      "2017-05-28 03:19:31.007653: step 15460, loss = 0.98 (294.6 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 03:19:39.488608: step 15470, loss = 0.87 (301.9 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 03:19:47.696009: step 15480, loss = 0.98 (311.9 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 03:19:55.609218: step 15490, loss = 0.95 (323.5 examples/sec; 0.791 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15521\n",
      "2017-05-28 03:20:06.713116: step 15500, loss = 0.96 (230.5 examples/sec; 1.110 sec/batch)\n",
      "2017-05-28 03:20:14.464271: step 15510, loss = 0.94 (330.3 examples/sec; 0.775 sec/batch)\n",
      "2017-05-28 03:20:22.817969: step 15520, loss = 0.90 (306.5 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 03:20:31.207661: step 15530, loss = 0.89 (305.1 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 03:20:40.061060: step 15540, loss = 0.87 (289.2 examples/sec; 0.885 sec/batch)\n",
      "2017-05-28 03:20:48.716493: step 15550, loss = 0.93 (295.8 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 03:20:57.023843: step 15560, loss = 0.89 (308.2 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 03:21:05.852190: step 15570, loss = 0.85 (290.0 examples/sec; 0.883 sec/batch)\n",
      "2017-05-28 03:21:14.253728: step 15580, loss = 0.99 (304.7 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 03:21:22.713774: step 15590, loss = 0.96 (302.6 examples/sec; 0.846 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11725\n",
      "2017-05-28 03:21:36.217276: step 15600, loss = 0.96 (189.6 examples/sec; 1.350 sec/batch)\n",
      "2017-05-28 03:21:43.933309: step 15610, loss = 0.86 (331.8 examples/sec; 0.772 sec/batch)\n",
      "2017-05-28 03:21:52.411387: step 15620, loss = 0.87 (302.0 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 03:22:01.411686: step 15630, loss = 0.84 (284.4 examples/sec; 0.900 sec/batch)\n",
      "2017-05-28 03:22:09.499735: step 15640, loss = 0.82 (316.5 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 03:22:17.913212: step 15650, loss = 1.02 (304.3 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 03:22:26.501600: step 15660, loss = 0.95 (298.1 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 03:22:35.326973: step 15670, loss = 0.86 (290.1 examples/sec; 0.883 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 15679 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 03:22:45.101823: step 15680, loss = 0.85 (261.9 examples/sec; 0.977 sec/batch)\n",
      "2017-05-28 03:22:52.830641: step 15690, loss = 0.91 (331.2 examples/sec; 0.773 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11287\n",
      "2017-05-28 03:23:06.075560: step 15700, loss = 0.94 (193.3 examples/sec; 1.324 sec/batch)\n",
      "2017-05-28 03:23:13.640274: step 15710, loss = 0.99 (338.4 examples/sec; 0.756 sec/batch)\n",
      "2017-05-28 03:23:22.093983: step 15720, loss = 1.02 (302.8 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 03:23:30.134179: step 15730, loss = 0.88 (318.4 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 03:23:38.223039: step 15740, loss = 0.94 (316.5 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 03:23:46.268627: step 15750, loss = 0.85 (318.2 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 03:23:54.126773: step 15760, loss = 0.84 (325.8 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 03:24:02.280289: step 15770, loss = 0.81 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 03:24:10.715916: step 15780, loss = 0.96 (303.5 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 03:24:18.651871: step 15790, loss = 0.94 (322.6 examples/sec; 0.794 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18258\n",
      "2017-05-28 03:24:30.639086: step 15800, loss = 0.92 (213.6 examples/sec; 1.199 sec/batch)\n",
      "2017-05-28 03:24:38.309724: step 15810, loss = 1.00 (333.7 examples/sec; 0.767 sec/batch)\n",
      "2017-05-28 03:24:46.289557: step 15820, loss = 0.94 (320.8 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 03:24:54.637583: step 15830, loss = 0.79 (306.7 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 03:25:03.136331: step 15840, loss = 0.76 (301.2 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 03:25:11.380008: step 15850, loss = 0.91 (310.5 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 03:25:19.567280: step 15860, loss = 0.88 (312.7 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 03:25:28.515188: step 15870, loss = 0.87 (286.1 examples/sec; 0.895 sec/batch)\n",
      "2017-05-28 03:25:37.157714: step 15880, loss = 0.97 (296.2 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 03:25:45.607601: step 15890, loss = 0.88 (303.0 examples/sec; 0.845 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14416\n",
      "2017-05-28 03:25:58.039864: step 15900, loss = 1.09 (205.9 examples/sec; 1.243 sec/batch)\n",
      "2017-05-28 03:26:06.192434: step 15910, loss = 0.88 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 03:26:14.590311: step 15920, loss = 0.81 (304.8 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 03:26:23.058837: step 15930, loss = 0.95 (302.3 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 03:26:32.169608: step 15940, loss = 0.87 (281.0 examples/sec; 0.911 sec/batch)\n",
      "2017-05-28 03:26:40.681685: step 15950, loss = 0.85 (300.7 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 03:26:49.174854: step 15960, loss = 0.91 (301.4 examples/sec; 0.849 sec/batch)\n",
      "2017-05-28 03:26:57.623504: step 15970, loss = 0.93 (303.0 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 03:27:06.913907: step 15980, loss = 0.83 (275.6 examples/sec; 0.929 sec/batch)\n",
      "2017-05-28 03:27:14.992762: step 15990, loss = 1.01 (316.9 examples/sec; 0.808 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13399\n",
      "2017-05-28 03:27:26.222592: step 16000, loss = 0.92 (228.0 examples/sec; 1.123 sec/batch)\n",
      "2017-05-28 03:27:34.110638: step 16010, loss = 0.92 (324.5 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 03:27:42.503154: step 16020, loss = 0.93 (305.0 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 03:27:50.420261: step 16030, loss = 0.84 (323.4 examples/sec; 0.792 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 03:27:58.821714: step 16040, loss = 0.92 (304.7 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 03:28:08.424595: step 16050, loss = 0.88 (266.6 examples/sec; 0.960 sec/batch)\n",
      "2017-05-28 03:28:16.948367: step 16060, loss = 0.91 (300.3 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 03:28:24.969415: step 16070, loss = 0.88 (319.2 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 03:28:32.946678: step 16080, loss = 1.02 (320.9 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 03:28:40.835650: step 16090, loss = 1.10 (324.5 examples/sec; 0.789 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15995\n",
      "2017-05-28 03:28:52.433223: step 16100, loss = 0.89 (220.7 examples/sec; 1.160 sec/batch)\n",
      "2017-05-28 03:28:59.910947: step 16110, loss = 1.04 (342.4 examples/sec; 0.748 sec/batch)\n",
      "2017-05-28 03:29:09.057853: step 16120, loss = 0.94 (279.9 examples/sec; 0.915 sec/batch)\n",
      "2017-05-28 03:29:17.463001: step 16130, loss = 0.93 (304.6 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 03:29:25.988678: step 16140, loss = 0.87 (300.3 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 03:29:34.899634: step 16150, loss = 0.97 (287.3 examples/sec; 0.891 sec/batch)\n",
      "2017-05-28 03:29:43.283979: step 16160, loss = 0.99 (305.3 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 03:29:51.455031: step 16170, loss = 0.96 (313.3 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 03:29:59.826856: step 16180, loss = 0.90 (305.8 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 03:30:08.806632: step 16190, loss = 0.89 (285.1 examples/sec; 0.898 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14182\n",
      "2017-05-28 03:30:20.011159: step 16200, loss = 0.92 (228.5 examples/sec; 1.120 sec/batch)\n",
      "2017-05-28 03:30:28.183150: step 16210, loss = 0.99 (313.3 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 03:30:37.134537: step 16220, loss = 0.99 (286.0 examples/sec; 0.895 sec/batch)\n",
      "2017-05-28 03:30:45.606744: step 16230, loss = 0.91 (302.2 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 03:30:54.099964: step 16240, loss = 0.85 (301.4 examples/sec; 0.849 sec/batch)\n",
      "2017-05-28 03:31:02.635101: step 16250, loss = 0.98 (299.9 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 03:31:11.118933: step 16260, loss = 0.90 (301.8 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 03:31:19.807416: step 16270, loss = 0.98 (294.6 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 03:31:28.497543: step 16280, loss = 0.89 (294.6 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 03:31:36.912872: step 16290, loss = 0.92 (304.2 examples/sec; 0.842 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10393\n",
      "2017-05-28 03:31:50.598531: step 16300, loss = 0.84 (187.1 examples/sec; 1.369 sec/batch)\n",
      "2017-05-28 03:31:58.324863: step 16310, loss = 1.05 (331.3 examples/sec; 0.773 sec/batch)\n",
      "2017-05-28 03:32:06.912580: step 16320, loss = 0.89 (298.1 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 03:32:15.143616: step 16330, loss = 0.89 (311.0 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 03:32:23.310089: step 16340, loss = 0.98 (313.5 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 03:32:31.854199: step 16350, loss = 0.92 (299.6 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 03:32:40.714479: step 16360, loss = 0.83 (288.9 examples/sec; 0.886 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 16363 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 03:32:49.921887: step 16370, loss = 0.98 (278.0 examples/sec; 0.921 sec/batch)\n",
      "2017-05-28 03:32:58.086361: step 16380, loss = 0.94 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 03:33:06.437327: step 16390, loss = 0.86 (306.6 examples/sec; 0.835 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12948\n",
      "2017-05-28 03:33:19.133322: step 16400, loss = 0.98 (201.6 examples/sec; 1.270 sec/batch)\n",
      "2017-05-28 03:33:26.818603: step 16410, loss = 0.80 (333.1 examples/sec; 0.769 sec/batch)\n",
      "2017-05-28 03:33:35.374663: step 16420, loss = 0.92 (299.2 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 03:33:43.274380: step 16430, loss = 0.88 (324.1 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 03:33:51.214506: step 16440, loss = 0.89 (322.4 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 03:33:59.164884: step 16450, loss = 0.83 (322.0 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 03:34:07.515740: step 16460, loss = 0.92 (306.6 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 03:34:15.771380: step 16470, loss = 0.83 (310.1 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 03:34:24.174705: step 16480, loss = 0.80 (304.6 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 03:34:32.716894: step 16490, loss = 0.77 (299.7 examples/sec; 0.854 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1467\n",
      "2017-05-28 03:34:46.342280: step 16500, loss = 1.01 (187.9 examples/sec; 1.363 sec/batch)\n",
      "2017-05-28 03:34:54.255099: step 16510, loss = 0.83 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 03:35:02.877518: step 16520, loss = 0.91 (296.9 examples/sec; 0.862 sec/batch)\n",
      "2017-05-28 03:35:11.701013: step 16530, loss = 0.99 (290.1 examples/sec; 0.882 sec/batch)\n",
      "2017-05-28 03:35:20.342261: step 16540, loss = 0.97 (296.3 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 03:35:28.699355: step 16550, loss = 0.84 (306.3 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 03:35:37.037880: step 16560, loss = 0.99 (307.0 examples/sec; 0.834 sec/batch)\n",
      "2017-05-28 03:35:45.328672: step 16570, loss = 0.89 (308.8 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 03:35:53.955168: step 16580, loss = 0.88 (296.8 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 03:36:03.016092: step 16590, loss = 0.92 (282.5 examples/sec; 0.906 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10891\n",
      "2017-05-28 03:36:16.522129: step 16600, loss = 0.94 (189.5 examples/sec; 1.351 sec/batch)\n",
      "2017-05-28 03:36:24.170650: step 16610, loss = 0.88 (334.7 examples/sec; 0.765 sec/batch)\n",
      "2017-05-28 03:36:33.033536: step 16620, loss = 0.88 (288.8 examples/sec; 0.886 sec/batch)\n",
      "2017-05-28 03:36:41.344127: step 16630, loss = 0.83 (308.0 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 03:36:49.766020: step 16640, loss = 1.03 (304.0 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 03:36:58.649901: step 16650, loss = 0.92 (288.2 examples/sec; 0.888 sec/batch)\n",
      "2017-05-28 03:37:07.229648: step 16660, loss = 0.94 (298.4 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 03:37:16.188809: step 16670, loss = 0.84 (285.7 examples/sec; 0.896 sec/batch)\n",
      "2017-05-28 03:37:24.635042: step 16680, loss = 0.85 (303.1 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 03:37:33.180760: step 16690, loss = 0.88 (299.6 examples/sec; 0.855 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.123\n",
      "2017-05-28 03:37:45.569002: step 16700, loss = 1.02 (206.6 examples/sec; 1.239 sec/batch)\n",
      "2017-05-28 03:37:53.383617: step 16710, loss = 1.00 (327.6 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 03:38:01.986799: step 16720, loss = 0.98 (297.6 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 03:38:10.534717: step 16730, loss = 0.98 (299.5 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 03:38:19.065931: step 16740, loss = 0.79 (300.1 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 03:38:28.064756: step 16750, loss = 0.84 (284.5 examples/sec; 0.900 sec/batch)\n",
      "2017-05-28 03:38:37.228429: step 16760, loss = 0.88 (279.4 examples/sec; 0.916 sec/batch)\n",
      "2017-05-28 03:38:45.659630: step 16770, loss = 1.00 (303.6 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 03:38:53.441285: step 16780, loss = 0.83 (329.0 examples/sec; 0.778 sec/batch)\n",
      "2017-05-28 03:39:01.627735: step 16790, loss = 0.91 (312.7 examples/sec; 0.819 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14312\n",
      "2017-05-28 03:39:13.049120: step 16800, loss = 0.95 (224.1 examples/sec; 1.142 sec/batch)\n",
      "2017-05-28 03:39:20.869380: step 16810, loss = 0.98 (327.4 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 03:39:28.757079: step 16820, loss = 0.91 (324.6 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 03:39:37.517552: step 16830, loss = 0.79 (292.2 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 03:39:45.911619: step 16840, loss = 0.83 (305.0 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 03:39:54.442670: step 16850, loss = 0.89 (300.1 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 03:40:03.359830: step 16860, loss = 0.91 (287.1 examples/sec; 0.892 sec/batch)\n",
      "2017-05-28 03:40:12.363895: step 16870, loss = 0.91 (284.3 examples/sec; 0.900 sec/batch)\n",
      "2017-05-28 03:40:20.935912: step 16880, loss = 0.86 (298.6 examples/sec; 0.857 sec/batch)\n",
      "2017-05-28 03:40:29.313783: step 16890, loss = 0.94 (305.6 examples/sec; 0.838 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 03:40:42.957282: step 16900, loss = 0.90 (187.6 examples/sec; 1.364 sec/batch)\n",
      "2017-05-28 03:40:50.719979: step 16910, loss = 0.90 (329.8 examples/sec; 0.776 sec/batch)\n",
      "2017-05-28 03:40:59.113630: step 16920, loss = 0.91 (305.0 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 03:41:07.671305: step 16930, loss = 0.97 (299.1 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 03:41:15.879479: step 16940, loss = 0.85 (311.9 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 03:41:24.262645: step 16950, loss = 0.96 (305.4 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 03:41:32.996517: step 16960, loss = 0.91 (293.1 examples/sec; 0.873 sec/batch)\n",
      "2017-05-28 03:41:41.191806: step 16970, loss = 0.88 (312.4 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 03:41:49.073016: step 16980, loss = 0.92 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 03:41:57.189179: step 16990, loss = 1.00 (315.4 examples/sec; 0.812 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15002\n",
      "2017-05-28 03:42:09.911932: step 17000, loss = 0.77 (201.2 examples/sec; 1.272 sec/batch)\n",
      "2017-05-28 03:42:17.538277: step 17010, loss = 1.06 (335.7 examples/sec; 0.763 sec/batch)\n",
      "2017-05-28 03:42:25.714034: step 17020, loss = 0.88 (313.1 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 03:42:34.476799: step 17030, loss = 0.98 (292.1 examples/sec; 0.876 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 17040 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 03:42:44.620855: step 17040, loss = 0.84 (252.4 examples/sec; 1.014 sec/batch)\n",
      "2017-05-28 03:42:52.687164: step 17050, loss = 0.89 (317.4 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 03:43:01.192407: step 17060, loss = 0.82 (301.0 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 03:43:10.562766: step 17070, loss = 0.74 (273.2 examples/sec; 0.937 sec/batch)\n",
      "2017-05-28 03:43:18.921017: step 17080, loss = 0.81 (306.3 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 03:43:26.874669: step 17090, loss = 0.82 (321.9 examples/sec; 0.795 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10676\n",
      "2017-05-28 03:43:40.267896: step 17100, loss = 0.93 (191.1 examples/sec; 1.339 sec/batch)\n",
      "2017-05-28 03:43:48.446578: step 17110, loss = 0.84 (313.0 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 03:43:56.334074: step 17120, loss = 0.76 (324.6 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 03:44:04.748171: step 17130, loss = 0.98 (304.3 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 03:44:13.229599: step 17140, loss = 0.92 (301.8 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 03:44:21.104753: step 17150, loss = 0.82 (325.1 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 03:44:29.061177: step 17160, loss = 0.89 (321.8 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 03:44:37.711858: step 17170, loss = 0.83 (295.9 examples/sec; 0.865 sec/batch)\n",
      "2017-05-28 03:44:45.840224: step 17180, loss = 1.01 (314.9 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 03:44:53.761409: step 17190, loss = 0.92 (323.2 examples/sec; 0.792 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16731\n",
      "2017-05-28 03:45:05.931863: step 17200, loss = 0.86 (210.3 examples/sec; 1.217 sec/batch)\n",
      "2017-05-28 03:45:13.165635: step 17210, loss = 0.85 (353.9 examples/sec; 0.723 sec/batch)\n",
      "2017-05-28 03:45:21.618557: step 17220, loss = 1.00 (302.9 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 03:45:29.757362: step 17230, loss = 0.94 (314.5 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 03:45:37.813537: step 17240, loss = 0.99 (317.8 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 03:45:45.663248: step 17250, loss = 1.05 (326.1 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 03:45:53.590868: step 17260, loss = 0.82 (322.9 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 03:46:01.616460: step 17270, loss = 0.93 (319.0 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 03:46:10.242696: step 17280, loss = 0.94 (296.8 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 03:46:18.070875: step 17290, loss = 0.82 (327.0 examples/sec; 0.783 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20222\n",
      "2017-05-28 03:46:29.111766: step 17300, loss = 0.79 (231.9 examples/sec; 1.104 sec/batch)\n",
      "2017-05-28 03:46:36.624911: step 17310, loss = 0.91 (340.7 examples/sec; 0.751 sec/batch)\n",
      "2017-05-28 03:46:44.462665: step 17320, loss = 0.84 (326.6 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 03:46:52.938852: step 17330, loss = 0.75 (302.0 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 03:47:00.980251: step 17340, loss = 0.77 (318.4 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 03:47:08.990214: step 17350, loss = 0.85 (319.6 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 03:47:16.895522: step 17360, loss = 0.94 (323.8 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 03:47:25.044251: step 17370, loss = 0.82 (314.2 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 03:47:33.351175: step 17380, loss = 0.80 (308.2 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 03:47:41.322953: step 17390, loss = 0.94 (321.1 examples/sec; 0.797 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20418\n",
      "2017-05-28 03:47:52.158967: step 17400, loss = 0.85 (236.2 examples/sec; 1.084 sec/batch)\n",
      "2017-05-28 03:47:59.508694: step 17410, loss = 0.85 (348.3 examples/sec; 0.735 sec/batch)\n",
      "2017-05-28 03:48:07.718142: step 17420, loss = 0.92 (311.8 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 03:48:16.060738: step 17430, loss = 0.89 (306.9 examples/sec; 0.834 sec/batch)\n",
      "2017-05-28 03:48:24.010639: step 17440, loss = 0.93 (322.0 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 03:48:32.489256: step 17450, loss = 0.79 (301.9 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 03:48:40.566353: step 17460, loss = 0.87 (316.9 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 03:48:48.612352: step 17470, loss = 0.99 (318.2 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 03:48:58.049504: step 17480, loss = 0.83 (271.3 examples/sec; 0.944 sec/batch)\n",
      "2017-05-28 03:49:06.461373: step 17490, loss = 1.01 (304.3 examples/sec; 0.841 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17855\n",
      "2017-05-28 03:49:17.004843: step 17500, loss = 0.83 (242.8 examples/sec; 1.054 sec/batch)\n",
      "2017-05-28 03:49:24.454146: step 17510, loss = 0.95 (343.7 examples/sec; 0.745 sec/batch)\n",
      "2017-05-28 03:49:32.895638: step 17520, loss = 0.83 (303.3 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 03:49:41.432016: step 17530, loss = 0.75 (299.9 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 03:49:49.941814: step 17540, loss = 0.85 (300.8 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 03:49:58.389307: step 17550, loss = 0.95 (303.0 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 03:50:07.747949: step 17560, loss = 0.96 (273.5 examples/sec; 0.936 sec/batch)\n",
      "2017-05-28 03:50:16.245108: step 17570, loss = 0.85 (301.3 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 03:50:24.700842: step 17580, loss = 0.82 (302.8 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 03:50:33.128211: step 17590, loss = 0.93 (303.8 examples/sec; 0.843 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1251\n",
      "2017-05-28 03:50:45.886099: step 17600, loss = 0.91 (200.7 examples/sec; 1.276 sec/batch)\n",
      "2017-05-28 03:50:53.519562: step 17610, loss = 0.84 (335.4 examples/sec; 0.763 sec/batch)\n",
      "2017-05-28 03:51:01.565089: step 17620, loss = 0.91 (318.2 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 03:51:10.548598: step 17630, loss = 0.83 (285.0 examples/sec; 0.898 sec/batch)\n",
      "2017-05-28 03:51:19.099187: step 17640, loss = 0.92 (299.4 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 03:51:27.612231: step 17650, loss = 0.95 (300.7 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 03:51:36.579816: step 17660, loss = 0.99 (285.5 examples/sec; 0.897 sec/batch)\n",
      "2017-05-28 03:51:45.425813: step 17670, loss = 0.81 (289.4 examples/sec; 0.885 sec/batch)\n",
      "2017-05-28 03:51:54.025187: step 17680, loss = 0.94 (297.7 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 03:52:02.546556: step 17690, loss = 0.88 (300.4 examples/sec; 0.852 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11468\n",
      "2017-05-28 03:52:15.598714: step 17700, loss = 0.83 (196.1 examples/sec; 1.305 sec/batch)\n",
      "2017-05-28 03:52:23.338701: step 17710, loss = 0.92 (330.7 examples/sec; 0.774 sec/batch)\n",
      "2017-05-28 03:52:31.723144: step 17720, loss = 0.83 (305.3 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 03:52:40.603666: step 17730, loss = 0.96 (288.3 examples/sec; 0.888 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 17734 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 03:52:49.494483: step 17740, loss = 0.77 (287.9 examples/sec; 0.889 sec/batch)\n",
      "2017-05-28 03:52:57.716096: step 17750, loss = 0.98 (311.4 examples/sec; 0.822 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 03:53:06.186131: step 17760, loss = 0.83 (302.2 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 03:53:15.117839: step 17770, loss = 0.78 (286.6 examples/sec; 0.893 sec/batch)\n",
      "2017-05-28 03:53:23.522374: step 17780, loss = 0.86 (304.6 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 03:53:31.537371: step 17790, loss = 0.85 (319.4 examples/sec; 0.801 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14003\n",
      "2017-05-28 03:53:43.317397: step 17800, loss = 0.90 (217.3 examples/sec; 1.178 sec/batch)\n",
      "2017-05-28 03:53:50.852204: step 17810, loss = 1.01 (339.8 examples/sec; 0.753 sec/batch)\n",
      "2017-05-28 03:53:59.260517: step 17820, loss = 0.84 (304.5 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 03:54:08.671776: step 17830, loss = 0.93 (272.0 examples/sec; 0.941 sec/batch)\n",
      "2017-05-28 03:54:16.723494: step 17840, loss = 1.11 (317.9 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 03:54:24.636208: step 17850, loss = 0.88 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 03:54:32.704635: step 17860, loss = 0.88 (317.3 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 03:54:40.963915: step 17870, loss = 1.00 (310.0 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 03:54:48.819030: step 17880, loss = 0.84 (325.9 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 03:54:56.751286: step 17890, loss = 0.89 (322.7 examples/sec; 0.793 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17615\n",
      "2017-05-28 03:55:08.337527: step 17900, loss = 0.95 (221.0 examples/sec; 1.159 sec/batch)\n",
      "2017-05-28 03:55:16.042861: step 17910, loss = 0.81 (332.2 examples/sec; 0.771 sec/batch)\n",
      "2017-05-28 03:55:25.021863: step 17920, loss = 1.00 (285.1 examples/sec; 0.898 sec/batch)\n",
      "2017-05-28 03:55:33.613508: step 17930, loss = 0.91 (298.0 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 03:55:42.422555: step 17940, loss = 0.91 (290.6 examples/sec; 0.881 sec/batch)\n",
      "2017-05-28 03:55:50.857365: step 17950, loss = 0.86 (303.5 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 03:55:58.973729: step 17960, loss = 0.93 (315.4 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 03:56:07.866760: step 17970, loss = 0.89 (287.9 examples/sec; 0.889 sec/batch)\n",
      "2017-05-28 03:56:16.361091: step 17980, loss = 0.78 (301.4 examples/sec; 0.849 sec/batch)\n",
      "2017-05-28 03:56:24.434904: step 17990, loss = 0.86 (317.1 examples/sec; 0.807 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10383\n",
      "2017-05-28 03:56:38.933244: step 18000, loss = 0.88 (176.6 examples/sec; 1.450 sec/batch)\n",
      "2017-05-28 03:56:46.764167: step 18010, loss = 0.87 (326.9 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 03:56:54.638617: step 18020, loss = 0.85 (325.1 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 03:57:03.005891: step 18030, loss = 0.91 (306.0 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 03:57:11.736951: step 18040, loss = 1.02 (293.2 examples/sec; 0.873 sec/batch)\n",
      "2017-05-28 03:57:20.062040: step 18050, loss = 1.01 (307.5 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 03:57:28.383367: step 18060, loss = 0.98 (307.6 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 03:57:37.215617: step 18070, loss = 0.90 (289.8 examples/sec; 0.883 sec/batch)\n",
      "2017-05-28 03:57:45.883374: step 18080, loss = 0.98 (295.3 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 03:57:54.351064: step 18090, loss = 0.92 (302.3 examples/sec; 0.847 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12023\n",
      "2017-05-28 03:58:08.201430: step 18100, loss = 0.93 (184.8 examples/sec; 1.385 sec/batch)\n",
      "2017-05-28 03:58:15.962399: step 18110, loss = 0.86 (329.9 examples/sec; 0.776 sec/batch)\n",
      "2017-05-28 03:58:24.163671: step 18120, loss = 0.90 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 03:58:32.718581: step 18130, loss = 0.91 (299.2 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 03:58:41.881146: step 18140, loss = 0.90 (279.4 examples/sec; 0.916 sec/batch)\n",
      "2017-05-28 03:58:49.884266: step 18150, loss = 1.03 (319.9 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 03:58:58.282453: step 18160, loss = 1.00 (304.8 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 03:59:07.837552: step 18170, loss = 0.80 (267.9 examples/sec; 0.956 sec/batch)\n",
      "2017-05-28 03:59:16.163218: step 18180, loss = 0.88 (307.5 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 03:59:24.146198: step 18190, loss = 0.86 (320.7 examples/sec; 0.798 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10909\n",
      "2017-05-28 03:59:38.363593: step 18200, loss = 0.86 (180.1 examples/sec; 1.422 sec/batch)\n",
      "2017-05-28 03:59:45.639825: step 18210, loss = 0.98 (351.8 examples/sec; 0.728 sec/batch)\n",
      "2017-05-28 03:59:53.438303: step 18220, loss = 0.87 (328.3 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 04:00:01.401442: step 18230, loss = 1.02 (321.5 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 04:00:09.655993: step 18240, loss = 0.97 (310.1 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 04:00:17.520468: step 18250, loss = 0.91 (325.5 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 04:00:25.507379: step 18260, loss = 0.88 (320.5 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 04:00:33.977783: step 18270, loss = 0.81 (302.2 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 04:00:43.306833: step 18280, loss = 0.98 (274.4 examples/sec; 0.933 sec/batch)\n",
      "2017-05-28 04:00:51.782312: step 18290, loss = 0.96 (302.0 examples/sec; 0.848 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13641\n",
      "2017-05-28 04:01:06.360183: step 18300, loss = 0.96 (175.6 examples/sec; 1.458 sec/batch)\n",
      "2017-05-28 04:01:14.234812: step 18310, loss = 0.90 (325.1 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 04:01:22.273280: step 18320, loss = 1.10 (318.5 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 04:01:30.211652: step 18330, loss = 0.90 (322.5 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 04:01:38.907685: step 18340, loss = 0.89 (294.4 examples/sec; 0.870 sec/batch)\n",
      "2017-05-28 04:01:47.274343: step 18350, loss = 0.96 (306.0 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 04:01:55.591655: step 18360, loss = 0.86 (307.8 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 04:02:04.039884: step 18370, loss = 0.85 (303.0 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 04:02:13.103987: step 18380, loss = 0.79 (282.4 examples/sec; 0.906 sec/batch)\n",
      "2017-05-28 04:02:21.069531: step 18390, loss = 1.10 (321.4 examples/sec; 0.797 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14392\n",
      "2017-05-28 04:02:33.778175: step 18400, loss = 0.90 (201.4 examples/sec; 1.271 sec/batch)\n",
      "2017-05-28 04:02:41.319535: step 18410, loss = 0.92 (339.5 examples/sec; 0.754 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 18413 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 04:02:51.219796: step 18420, loss = 0.91 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-28 04:02:59.035908: step 18430, loss = 0.81 (327.5 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 04:03:07.323520: step 18440, loss = 0.90 (308.9 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 04:03:15.183611: step 18450, loss = 0.82 (325.7 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 04:03:23.443960: step 18460, loss = 0.89 (309.9 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 04:03:32.067537: step 18470, loss = 1.00 (296.9 examples/sec; 0.862 sec/batch)\n",
      "2017-05-28 04:03:41.321947: step 18480, loss = 0.78 (276.6 examples/sec; 0.925 sec/batch)\n",
      "2017-05-28 04:03:49.799938: step 18490, loss = 0.90 (302.0 examples/sec; 0.848 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14183\n",
      "2017-05-28 04:04:01.356222: step 18500, loss = 0.86 (221.5 examples/sec; 1.156 sec/batch)\n",
      "2017-05-28 04:04:09.787803: step 18510, loss = 0.87 (303.6 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 04:04:18.683290: step 18520, loss = 1.00 (287.8 examples/sec; 0.890 sec/batch)\n",
      "2017-05-28 04:04:26.914421: step 18530, loss = 0.82 (311.0 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 04:04:34.961317: step 18540, loss = 1.08 (318.1 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 04:04:43.520398: step 18550, loss = 0.96 (299.1 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 04:04:51.753155: step 18560, loss = 0.88 (311.0 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 04:04:59.503837: step 18570, loss = 0.89 (330.3 examples/sec; 0.775 sec/batch)\n",
      "2017-05-28 04:05:08.013996: step 18580, loss = 0.92 (300.8 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 04:05:15.915334: step 18590, loss = 0.84 (324.0 examples/sec; 0.790 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14947\n",
      "2017-05-28 04:05:28.355988: step 18600, loss = 0.84 (205.8 examples/sec; 1.244 sec/batch)\n",
      "2017-05-28 04:05:36.614270: step 18610, loss = 0.89 (310.0 examples/sec; 0.826 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 04:05:44.762916: step 18620, loss = 1.09 (314.2 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 04:05:52.964033: step 18630, loss = 0.83 (312.2 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 04:06:01.273612: step 18640, loss = 0.91 (308.1 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 04:06:10.248277: step 18650, loss = 0.89 (285.2 examples/sec; 0.897 sec/batch)\n",
      "2017-05-28 04:06:18.610706: step 18660, loss = 0.80 (306.1 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 04:06:27.041893: step 18670, loss = 0.98 (303.6 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 04:06:35.761658: step 18680, loss = 0.93 (293.6 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 04:06:43.908398: step 18690, loss = 0.89 (314.2 examples/sec; 0.815 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13598\n",
      "2017-05-28 04:06:56.386684: step 18700, loss = 0.86 (205.2 examples/sec; 1.248 sec/batch)\n",
      "2017-05-28 04:07:04.570925: step 18710, loss = 0.99 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 04:07:12.831064: step 18720, loss = 0.95 (309.9 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 04:07:21.285767: step 18730, loss = 0.96 (302.8 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 04:07:29.696869: step 18740, loss = 0.84 (304.4 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 04:07:38.784153: step 18750, loss = 0.96 (281.7 examples/sec; 0.909 sec/batch)\n",
      "2017-05-28 04:07:47.332387: step 18760, loss = 0.90 (299.5 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 04:07:55.689208: step 18770, loss = 0.82 (306.3 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 04:08:04.218407: step 18780, loss = 0.92 (300.1 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 04:08:13.328820: step 18790, loss = 0.92 (281.0 examples/sec; 0.911 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12955\n",
      "2017-05-28 04:08:24.915508: step 18800, loss = 0.93 (220.9 examples/sec; 1.159 sec/batch)\n",
      "2017-05-28 04:08:32.774567: step 18810, loss = 0.93 (325.7 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 04:08:42.027830: step 18820, loss = 0.86 (276.7 examples/sec; 0.925 sec/batch)\n",
      "2017-05-28 04:08:50.354048: step 18830, loss = 0.91 (307.5 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 04:08:58.150679: step 18840, loss = 0.86 (328.3 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 04:09:06.617173: step 18850, loss = 0.77 (302.4 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 04:09:14.760199: step 18860, loss = 0.85 (314.4 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 04:09:22.580106: step 18870, loss = 0.92 (327.4 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 04:09:31.745636: step 18880, loss = 1.06 (279.3 examples/sec; 0.917 sec/batch)\n",
      "2017-05-28 04:09:40.596032: step 18890, loss = 1.02 (289.3 examples/sec; 0.885 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14554\n",
      "2017-05-28 04:09:52.207376: step 18900, loss = 0.75 (220.5 examples/sec; 1.161 sec/batch)\n",
      "2017-05-28 04:09:59.542710: step 18910, loss = 0.91 (349.0 examples/sec; 0.734 sec/batch)\n",
      "2017-05-28 04:10:07.874900: step 18920, loss = 0.93 (307.2 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 04:10:16.543208: step 18930, loss = 0.87 (295.3 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 04:10:25.019622: step 18940, loss = 0.99 (302.0 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 04:10:33.243593: step 18950, loss = 0.84 (311.3 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 04:10:41.890126: step 18960, loss = 0.89 (296.1 examples/sec; 0.865 sec/batch)\n",
      "2017-05-28 04:10:49.766660: step 18970, loss = 0.93 (325.0 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 04:10:57.714208: step 18980, loss = 1.09 (322.1 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 04:11:06.785253: step 18990, loss = 0.89 (282.2 examples/sec; 0.907 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15871\n",
      "2017-05-28 04:11:18.510342: step 19000, loss = 0.98 (218.3 examples/sec; 1.173 sec/batch)\n",
      "2017-05-28 04:11:26.368156: step 19010, loss = 0.90 (325.8 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 04:11:35.274191: step 19020, loss = 0.98 (287.4 examples/sec; 0.891 sec/batch)\n",
      "2017-05-28 04:11:43.888386: step 19030, loss = 0.93 (297.2 examples/sec; 0.861 sec/batch)\n",
      "2017-05-28 04:11:52.782616: step 19040, loss = 0.74 (287.8 examples/sec; 0.889 sec/batch)\n",
      "2017-05-28 04:12:01.340676: step 19050, loss = 0.89 (299.1 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 04:12:10.015129: step 19060, loss = 0.96 (295.1 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 04:12:18.966707: step 19070, loss = 0.89 (286.0 examples/sec; 0.895 sec/batch)\n",
      "2017-05-28 04:12:27.398146: step 19080, loss = 0.97 (303.6 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 04:12:36.096017: step 19090, loss = 0.91 (294.3 examples/sec; 0.870 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 19100 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.08239\n",
      "2017-05-28 04:12:50.898873: step 19100, loss = 0.90 (172.9 examples/sec; 1.480 sec/batch)\n",
      "2017-05-28 04:12:58.537328: step 19110, loss = 1.00 (335.1 examples/sec; 0.764 sec/batch)\n",
      "2017-05-28 04:13:07.587211: step 19120, loss = 0.82 (282.9 examples/sec; 0.905 sec/batch)\n",
      "2017-05-28 04:13:16.046340: step 19130, loss = 0.87 (302.6 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 04:13:23.973925: step 19140, loss = 0.86 (322.9 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 04:13:32.775955: step 19150, loss = 0.72 (290.8 examples/sec; 0.880 sec/batch)\n",
      "2017-05-28 04:13:41.643776: step 19160, loss = 0.78 (288.7 examples/sec; 0.887 sec/batch)\n",
      "2017-05-28 04:13:50.001899: step 19170, loss = 0.86 (306.3 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 04:13:57.958178: step 19180, loss = 0.77 (321.8 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 04:14:06.715547: step 19190, loss = 0.79 (292.3 examples/sec; 0.876 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1467\n",
      "2017-05-28 04:14:18.105390: step 19200, loss = 0.84 (224.8 examples/sec; 1.139 sec/batch)\n",
      "2017-05-28 04:14:25.881677: step 19210, loss = 0.92 (329.2 examples/sec; 0.778 sec/batch)\n",
      "2017-05-28 04:14:34.511309: step 19220, loss = 0.89 (296.7 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 04:14:43.868407: step 19230, loss = 0.88 (273.6 examples/sec; 0.936 sec/batch)\n",
      "2017-05-28 04:14:52.396508: step 19240, loss = 0.84 (300.2 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 04:15:00.382489: step 19250, loss = 0.91 (320.6 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 04:15:08.795667: step 19260, loss = 0.93 (304.3 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 04:15:16.997070: step 19270, loss = 0.93 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 04:15:25.264242: step 19280, loss = 0.91 (309.7 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 04:15:34.013038: step 19290, loss = 0.83 (292.6 examples/sec; 0.875 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13101\n",
      "2017-05-28 04:15:46.522522: step 19300, loss = 0.89 (204.6 examples/sec; 1.251 sec/batch)\n",
      "2017-05-28 04:15:53.961419: step 19310, loss = 0.79 (344.1 examples/sec; 0.744 sec/batch)\n",
      "2017-05-28 04:16:02.359916: step 19320, loss = 0.80 (304.8 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 04:16:10.968657: step 19330, loss = 0.89 (297.4 examples/sec; 0.861 sec/batch)\n",
      "2017-05-28 04:16:19.939844: step 19340, loss = 0.84 (285.4 examples/sec; 0.897 sec/batch)\n",
      "2017-05-28 04:16:28.232002: step 19350, loss = 0.74 (308.7 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 04:16:36.596263: step 19360, loss = 0.81 (306.1 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 04:16:45.141111: step 19370, loss = 0.83 (299.6 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 04:16:53.528392: step 19380, loss = 0.92 (305.2 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 04:17:02.535405: step 19390, loss = 0.90 (284.2 examples/sec; 0.901 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13492\n",
      "2017-05-28 04:17:14.636755: step 19400, loss = 0.97 (211.5 examples/sec; 1.210 sec/batch)\n",
      "2017-05-28 04:17:22.452327: step 19410, loss = 0.79 (327.6 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 04:17:30.431556: step 19420, loss = 0.83 (320.8 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 04:17:39.030426: step 19430, loss = 0.93 (297.7 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 04:17:46.939991: step 19440, loss = 0.81 (323.7 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 04:17:55.746864: step 19450, loss = 0.92 (290.7 examples/sec; 0.881 sec/batch)\n",
      "2017-05-28 04:18:04.035731: step 19460, loss = 0.95 (308.8 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 04:18:13.255125: step 19470, loss = 0.91 (277.7 examples/sec; 0.922 sec/batch)\n",
      "2017-05-28 04:18:21.854045: step 19480, loss = 0.80 (297.7 examples/sec; 0.860 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 04:18:30.312093: step 19490, loss = 0.89 (302.7 examples/sec; 0.846 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14315\n",
      "2017-05-28 04:18:42.112144: step 19500, loss = 0.80 (216.9 examples/sec; 1.180 sec/batch)\n",
      "2017-05-28 04:18:49.867246: step 19510, loss = 0.95 (330.1 examples/sec; 0.776 sec/batch)\n",
      "2017-05-28 04:18:58.264588: step 19520, loss = 0.81 (304.9 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 04:19:07.095019: step 19530, loss = 0.86 (289.9 examples/sec; 0.883 sec/batch)\n",
      "2017-05-28 04:19:15.744820: step 19540, loss = 0.98 (296.0 examples/sec; 0.865 sec/batch)\n",
      "2017-05-28 04:19:24.623362: step 19550, loss = 0.81 (288.3 examples/sec; 0.888 sec/batch)\n",
      "2017-05-28 04:19:33.017381: step 19560, loss = 0.98 (305.0 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 04:19:41.501092: step 19570, loss = 0.87 (301.8 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 04:19:50.397500: step 19580, loss = 0.84 (287.8 examples/sec; 0.890 sec/batch)\n",
      "2017-05-28 04:19:59.123360: step 19590, loss = 0.89 (293.4 examples/sec; 0.873 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1293\n",
      "2017-05-28 04:20:10.664758: step 19600, loss = 0.85 (221.8 examples/sec; 1.154 sec/batch)\n",
      "2017-05-28 04:20:17.942927: step 19610, loss = 0.83 (351.7 examples/sec; 0.728 sec/batch)\n",
      "2017-05-28 04:20:25.930400: step 19620, loss = 0.94 (320.5 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 04:20:34.056921: step 19630, loss = 0.85 (315.0 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 04:20:42.503907: step 19640, loss = 0.92 (303.1 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 04:20:50.387262: step 19650, loss = 1.06 (324.7 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 04:20:58.612875: step 19660, loss = 0.88 (311.2 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 04:21:07.116179: step 19670, loss = 0.88 (301.1 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 04:21:15.313385: step 19680, loss = 0.93 (312.3 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 04:21:23.141112: step 19690, loss = 0.92 (327.0 examples/sec; 0.783 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17113\n",
      "2017-05-28 04:21:36.049682: step 19700, loss = 0.89 (198.3 examples/sec; 1.291 sec/batch)\n",
      "2017-05-28 04:21:43.435430: step 19710, loss = 1.00 (346.6 examples/sec; 0.739 sec/batch)\n",
      "2017-05-28 04:21:51.690058: step 19720, loss = 0.93 (310.1 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 04:21:59.763771: step 19730, loss = 0.86 (317.1 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 04:22:08.087944: step 19740, loss = 0.89 (307.5 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 04:22:16.503066: step 19750, loss = 0.92 (304.2 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 04:22:24.398850: step 19760, loss = 0.79 (324.2 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 04:22:32.379939: step 19770, loss = 0.92 (320.8 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 04:22:40.412148: step 19780, loss = 0.86 (318.7 examples/sec; 0.803 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 19786 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 04:22:49.085834: step 19790, loss = 0.87 (295.1 examples/sec; 0.867 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19308\n",
      "2017-05-28 04:22:59.865891: step 19800, loss = 0.89 (237.5 examples/sec; 1.078 sec/batch)\n",
      "2017-05-28 04:23:07.602137: step 19810, loss = 0.79 (330.9 examples/sec; 0.774 sec/batch)\n",
      "2017-05-28 04:23:15.600165: step 19820, loss = 0.85 (320.1 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 04:23:23.871846: step 19830, loss = 0.81 (309.5 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 04:23:32.099131: step 19840, loss = 0.94 (311.2 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 04:23:40.268206: step 19850, loss = 0.96 (313.4 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 04:23:48.602848: step 19860, loss = 0.94 (307.2 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 04:23:56.521586: step 19870, loss = 0.99 (323.3 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 04:24:04.826031: step 19880, loss = 0.84 (308.3 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 04:24:13.374193: step 19890, loss = 0.88 (299.5 examples/sec; 0.855 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1868\n",
      "2017-05-28 04:24:24.129478: step 19900, loss = 0.85 (238.0 examples/sec; 1.076 sec/batch)\n",
      "2017-05-28 04:24:31.527145: step 19910, loss = 0.75 (346.1 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 04:24:40.139003: step 19920, loss = 0.82 (297.3 examples/sec; 0.861 sec/batch)\n",
      "2017-05-28 04:24:48.224875: step 19930, loss = 0.93 (316.6 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 04:24:56.290755: step 19940, loss = 0.88 (317.4 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 04:25:05.486669: step 19950, loss = 0.79 (278.4 examples/sec; 0.920 sec/batch)\n",
      "2017-05-28 04:25:13.664723: step 19960, loss = 0.88 (313.0 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 04:25:21.583964: step 19970, loss = 0.87 (323.3 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 04:25:29.521855: step 19980, loss = 0.83 (322.5 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 04:25:38.006300: step 19990, loss = 0.91 (301.7 examples/sec; 0.848 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16751\n",
      "2017-05-28 04:25:49.781856: step 20000, loss = 0.85 (217.4 examples/sec; 1.178 sec/batch)\n",
      "2017-05-28 04:25:57.087776: step 20010, loss = 0.74 (350.4 examples/sec; 0.731 sec/batch)\n",
      "2017-05-28 04:26:05.218201: step 20020, loss = 0.89 (314.9 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 04:26:13.420777: step 20030, loss = 1.03 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 04:26:21.628822: step 20040, loss = 0.98 (311.9 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 04:26:29.659513: step 20050, loss = 1.02 (318.8 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 04:26:37.842585: step 20060, loss = 0.94 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 04:26:45.883949: step 20070, loss = 0.74 (318.4 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 04:26:53.759304: step 20080, loss = 0.88 (325.1 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 04:27:01.696160: step 20090, loss = 0.91 (322.5 examples/sec; 0.794 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18134\n",
      "2017-05-28 04:27:14.428625: step 20100, loss = 0.96 (201.1 examples/sec; 1.273 sec/batch)\n",
      "2017-05-28 04:27:21.712674: step 20110, loss = 0.79 (351.5 examples/sec; 0.728 sec/batch)\n",
      "2017-05-28 04:27:29.581989: step 20120, loss = 0.92 (325.3 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 04:27:38.299300: step 20130, loss = 0.79 (293.7 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 04:27:46.341815: step 20140, loss = 0.83 (318.3 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 04:27:54.243201: step 20150, loss = 0.80 (324.0 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 04:28:02.187535: step 20160, loss = 0.79 (322.2 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 04:28:10.703773: step 20170, loss = 0.87 (300.6 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 04:28:18.545590: step 20180, loss = 0.66 (326.5 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 04:28:26.598710: step 20190, loss = 0.90 (317.9 examples/sec; 0.805 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15905\n",
      "2017-05-28 04:28:40.707150: step 20200, loss = 0.99 (181.5 examples/sec; 1.411 sec/batch)\n",
      "2017-05-28 04:28:48.004642: step 20210, loss = 0.83 (350.8 examples/sec; 0.730 sec/batch)\n",
      "2017-05-28 04:28:55.970356: step 20220, loss = 0.91 (321.4 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 04:29:04.041819: step 20230, loss = 0.95 (317.2 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 04:29:12.083210: step 20240, loss = 1.00 (318.4 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 04:29:20.011175: step 20250, loss = 0.90 (322.9 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 04:29:27.936340: step 20260, loss = 0.79 (323.0 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 04:29:36.711763: step 20270, loss = 0.81 (291.7 examples/sec; 0.878 sec/batch)\n",
      "2017-05-28 04:29:44.739748: step 20280, loss = 1.01 (318.9 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 04:29:52.605248: step 20290, loss = 0.94 (325.5 examples/sec; 0.787 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1658\n",
      "2017-05-28 04:30:06.487277: step 20300, loss = 0.81 (184.4 examples/sec; 1.388 sec/batch)\n",
      "2017-05-28 04:30:15.018401: step 20310, loss = 0.84 (300.1 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 04:30:22.972206: step 20320, loss = 0.78 (321.9 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 04:30:30.819160: step 20330, loss = 0.82 (326.2 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 04:30:39.639981: step 20340, loss = 0.92 (290.2 examples/sec; 0.882 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 04:30:47.805582: step 20350, loss = 0.92 (313.5 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 04:30:55.751086: step 20360, loss = 1.01 (322.2 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 04:31:03.831500: step 20370, loss = 0.84 (316.8 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 04:31:12.416023: step 20380, loss = 0.94 (298.2 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 04:31:20.488145: step 20390, loss = 0.82 (317.1 examples/sec; 0.807 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17475\n",
      "2017-05-28 04:31:31.607991: step 20400, loss = 0.93 (230.2 examples/sec; 1.112 sec/batch)\n",
      "2017-05-28 04:31:39.463145: step 20410, loss = 0.88 (325.9 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 04:31:47.653509: step 20420, loss = 0.82 (312.6 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 04:31:55.496017: step 20430, loss = 0.87 (326.4 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 04:32:03.580350: step 20440, loss = 0.82 (316.7 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 04:32:12.331831: step 20450, loss = 0.84 (292.5 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 04:32:20.214129: step 20460, loss = 0.83 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 04:32:28.047801: step 20470, loss = 0.83 (326.8 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 04:32:36.123797: step 20480, loss = 0.89 (317.0 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 04:32:44.147501: step 20490, loss = 0.86 (319.1 examples/sec; 0.802 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 20492 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.18267\n",
      "2017-05-28 04:32:56.166077: step 20500, loss = 0.87 (213.0 examples/sec; 1.202 sec/batch)\n",
      "2017-05-28 04:33:04.039430: step 20510, loss = 0.88 (325.1 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 04:33:12.206998: step 20520, loss = 0.86 (313.4 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 04:33:20.073076: step 20530, loss = 0.88 (325.4 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 04:33:28.364560: step 20540, loss = 0.79 (308.8 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 04:33:36.776673: step 20550, loss = 0.81 (304.3 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 04:33:44.756618: step 20560, loss = 0.74 (320.8 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 04:33:52.692762: step 20570, loss = 0.94 (322.6 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 04:34:00.772527: step 20580, loss = 0.93 (316.8 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 04:34:09.655008: step 20590, loss = 0.88 (288.2 examples/sec; 0.888 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17128\n",
      "2017-05-28 04:34:21.542985: step 20600, loss = 0.86 (215.3 examples/sec; 1.189 sec/batch)\n",
      "2017-05-28 04:34:28.837865: step 20610, loss = 0.93 (350.9 examples/sec; 0.729 sec/batch)\n",
      "2017-05-28 04:34:37.146998: step 20620, loss = 0.76 (308.1 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 04:34:45.166022: step 20630, loss = 0.81 (319.2 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 04:34:53.031548: step 20640, loss = 0.92 (325.5 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 04:35:01.017297: step 20650, loss = 0.79 (320.6 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 04:35:09.650638: step 20660, loss = 0.88 (296.5 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 04:35:18.611873: step 20670, loss = 0.87 (285.7 examples/sec; 0.896 sec/batch)\n",
      "2017-05-28 04:35:26.973006: step 20680, loss = 0.91 (306.2 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 04:35:35.751330: step 20690, loss = 0.83 (291.6 examples/sec; 0.878 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16347\n",
      "2017-05-28 04:35:47.489836: step 20700, loss = 0.99 (218.1 examples/sec; 1.174 sec/batch)\n",
      "2017-05-28 04:35:55.301866: step 20710, loss = 0.87 (327.7 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 04:36:04.064175: step 20720, loss = 0.92 (292.2 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 04:36:13.183443: step 20730, loss = 0.92 (280.7 examples/sec; 0.912 sec/batch)\n",
      "2017-05-28 04:36:21.681806: step 20740, loss = 0.85 (301.2 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 04:36:29.909091: step 20750, loss = 0.93 (311.2 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 04:36:38.552005: step 20760, loss = 0.87 (296.2 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 04:36:47.505076: step 20770, loss = 0.83 (285.9 examples/sec; 0.895 sec/batch)\n",
      "2017-05-28 04:36:55.873492: step 20780, loss = 0.73 (305.9 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 04:37:04.951152: step 20790, loss = 0.92 (282.0 examples/sec; 0.908 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10441\n",
      "2017-05-28 04:37:18.038741: step 20800, loss = 0.83 (195.6 examples/sec; 1.309 sec/batch)\n",
      "2017-05-28 04:37:26.158090: step 20810, loss = 0.92 (315.3 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 04:37:34.878492: step 20820, loss = 0.85 (293.6 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 04:37:43.550249: step 20830, loss = 0.94 (295.2 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 04:37:52.068300: step 20840, loss = 0.82 (300.5 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 04:38:00.541452: step 20850, loss = 0.95 (302.1 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 04:38:09.101914: step 20860, loss = 0.83 (299.0 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 04:38:17.011080: step 20870, loss = 0.84 (323.7 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 04:38:25.137954: step 20880, loss = 0.83 (315.0 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 04:38:33.906222: step 20890, loss = 0.95 (292.0 examples/sec; 0.877 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12105\n",
      "2017-05-28 04:38:47.237410: step 20900, loss = 0.80 (192.0 examples/sec; 1.333 sec/batch)\n",
      "2017-05-28 04:38:54.990903: step 20910, loss = 0.86 (330.2 examples/sec; 0.775 sec/batch)\n",
      "2017-05-28 04:39:03.679589: step 20920, loss = 0.74 (294.6 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 04:39:12.388380: step 20930, loss = 0.97 (294.0 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 04:39:20.997507: step 20940, loss = 0.83 (297.4 examples/sec; 0.861 sec/batch)\n",
      "2017-05-28 04:39:29.823878: step 20950, loss = 0.87 (290.0 examples/sec; 0.883 sec/batch)\n",
      "2017-05-28 04:39:38.592762: step 20960, loss = 0.79 (291.9 examples/sec; 0.877 sec/batch)\n",
      "2017-05-28 04:39:47.667831: step 20970, loss = 0.82 (282.1 examples/sec; 0.908 sec/batch)\n",
      "2017-05-28 04:39:56.101474: step 20980, loss = 0.92 (303.5 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 04:40:04.173265: step 20990, loss = 0.84 (317.2 examples/sec; 0.807 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13375\n",
      "2017-05-28 04:40:15.440475: step 21000, loss = 0.86 (227.2 examples/sec; 1.127 sec/batch)\n",
      "2017-05-28 04:40:23.814878: step 21010, loss = 0.75 (305.7 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 04:40:32.223040: step 21020, loss = 1.00 (304.5 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 04:40:41.011195: step 21030, loss = 0.88 (291.3 examples/sec; 0.879 sec/batch)\n",
      "2017-05-28 04:40:49.209335: step 21040, loss = 0.79 (312.3 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 04:40:57.197667: step 21050, loss = 0.88 (320.5 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 04:41:05.454170: step 21060, loss = 0.98 (310.1 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 04:41:13.876356: step 21070, loss = 0.92 (304.0 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 04:41:22.021381: step 21080, loss = 1.03 (314.3 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 04:41:29.995284: step 21090, loss = 0.85 (321.0 examples/sec; 0.797 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13709\n",
      "2017-05-28 04:41:43.384651: step 21100, loss = 0.96 (191.2 examples/sec; 1.339 sec/batch)\n",
      "2017-05-28 04:41:51.310832: step 21110, loss = 0.75 (323.0 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 04:41:59.176765: step 21120, loss = 0.84 (325.5 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 04:42:07.427159: step 21130, loss = 0.91 (310.3 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 04:42:15.631579: step 21140, loss = 0.88 (312.0 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 04:42:24.062196: step 21150, loss = 0.80 (303.7 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 04:42:32.508310: step 21160, loss = 0.91 (303.1 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 04:42:41.665267: step 21170, loss = 0.93 (279.6 examples/sec; 0.916 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 21175 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 04:42:51.014102: step 21180, loss = 1.00 (273.8 examples/sec; 0.935 sec/batch)\n",
      "2017-05-28 04:42:59.498066: step 21190, loss = 0.91 (301.7 examples/sec; 0.848 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 04:43:12.376647: step 21200, loss = 0.88 (198.8 examples/sec; 1.288 sec/batch)\n",
      "2017-05-28 04:43:20.643254: step 21210, loss = 0.81 (309.7 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 04:43:29.084591: step 21220, loss = 0.83 (303.3 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 04:43:37.331703: step 21230, loss = 0.82 (310.4 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 04:43:45.572154: step 21240, loss = 0.84 (310.7 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 04:43:53.494240: step 21250, loss = 0.89 (323.1 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 04:44:02.299127: step 21260, loss = 0.84 (290.7 examples/sec; 0.880 sec/batch)\n",
      "2017-05-28 04:44:11.333503: step 21270, loss = 0.84 (283.4 examples/sec; 0.903 sec/batch)\n",
      "2017-05-28 04:44:19.319586: step 21280, loss = 0.88 (320.6 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 04:44:27.639265: step 21290, loss = 0.86 (307.7 examples/sec; 0.832 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13815\n",
      "2017-05-28 04:44:40.235644: step 21300, loss = 0.97 (203.2 examples/sec; 1.260 sec/batch)\n",
      "2017-05-28 04:44:47.949696: step 21310, loss = 0.86 (331.9 examples/sec; 0.771 sec/batch)\n",
      "2017-05-28 04:44:56.561876: step 21320, loss = 0.81 (297.3 examples/sec; 0.861 sec/batch)\n",
      "2017-05-28 04:45:04.692851: step 21330, loss = 0.93 (314.8 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 04:45:13.551824: step 21340, loss = 0.82 (289.0 examples/sec; 0.886 sec/batch)\n",
      "2017-05-28 04:45:21.981852: step 21350, loss = 0.83 (303.7 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 04:45:30.772282: step 21360, loss = 0.86 (291.2 examples/sec; 0.879 sec/batch)\n",
      "2017-05-28 04:45:39.102761: step 21370, loss = 0.90 (307.3 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 04:45:47.731056: step 21380, loss = 0.83 (296.7 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 04:45:55.938105: step 21390, loss = 0.78 (311.9 examples/sec; 0.821 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13236\n",
      "2017-05-28 04:46:08.556604: step 21400, loss = 0.97 (202.9 examples/sec; 1.262 sec/batch)\n",
      "2017-05-28 04:46:16.354161: step 21410, loss = 0.78 (328.3 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 04:46:24.257721: step 21420, loss = 0.74 (323.9 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 04:46:32.223901: step 21430, loss = 0.91 (321.4 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 04:46:40.657586: step 21440, loss = 0.80 (303.5 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 04:46:48.522349: step 21450, loss = 0.80 (325.5 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 04:46:56.568167: step 21460, loss = 0.91 (318.2 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 04:47:04.695370: step 21470, loss = 0.98 (315.0 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 04:47:13.492561: step 21480, loss = 0.90 (291.0 examples/sec; 0.880 sec/batch)\n",
      "2017-05-28 04:47:21.430049: step 21490, loss = 0.91 (322.5 examples/sec; 0.794 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16981\n",
      "2017-05-28 04:47:34.033775: step 21500, loss = 0.97 (203.1 examples/sec; 1.260 sec/batch)\n",
      "2017-05-28 04:47:41.837912: step 21510, loss = 1.00 (328.0 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 04:47:49.837165: step 21520, loss = 0.94 (320.0 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 04:47:57.849977: step 21530, loss = 0.95 (319.5 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 04:48:05.936530: step 21540, loss = 0.96 (316.6 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 04:48:13.916307: step 21550, loss = 0.83 (320.8 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 04:48:21.796031: step 21560, loss = 0.81 (324.9 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 04:48:29.888923: step 21570, loss = 0.85 (316.3 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 04:48:38.083198: step 21580, loss = 0.80 (312.4 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 04:48:46.668309: step 21590, loss = 0.82 (298.2 examples/sec; 0.859 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19226\n",
      "2017-05-28 04:48:57.909015: step 21600, loss = 0.73 (227.7 examples/sec; 1.124 sec/batch)\n",
      "2017-05-28 04:49:05.475682: step 21610, loss = 0.95 (338.3 examples/sec; 0.757 sec/batch)\n",
      "2017-05-28 04:49:14.125636: step 21620, loss = 0.86 (296.0 examples/sec; 0.865 sec/batch)\n",
      "2017-05-28 04:49:22.148078: step 21630, loss = 0.86 (319.1 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 04:49:30.115454: step 21640, loss = 0.85 (321.3 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 04:49:38.485732: step 21650, loss = 0.94 (305.8 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 04:49:47.007402: step 21660, loss = 0.78 (300.4 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 04:49:54.919415: step 21670, loss = 0.86 (323.6 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 04:50:02.833920: step 21680, loss = 0.80 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 04:50:11.178470: step 21690, loss = 0.89 (306.8 examples/sec; 0.834 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17352\n",
      "2017-05-28 04:50:23.121818: step 21700, loss = 0.95 (214.3 examples/sec; 1.194 sec/batch)\n",
      "2017-05-28 04:50:30.666968: step 21710, loss = 1.03 (339.3 examples/sec; 0.755 sec/batch)\n",
      "2017-05-28 04:50:40.388408: step 21720, loss = 0.93 (263.3 examples/sec; 0.972 sec/batch)\n",
      "2017-05-28 04:50:48.619564: step 21730, loss = 0.80 (311.0 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 04:50:57.053663: step 21740, loss = 0.74 (303.5 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 04:51:05.236958: step 21750, loss = 0.84 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 04:51:13.945329: step 21760, loss = 0.79 (294.0 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 04:51:22.106678: step 21770, loss = 0.78 (313.7 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 04:51:29.967828: step 21780, loss = 1.00 (325.7 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 04:51:38.214369: step 21790, loss = 0.81 (310.4 examples/sec; 0.825 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15534\n",
      "2017-05-28 04:51:49.676334: step 21800, loss = 0.97 (223.3 examples/sec; 1.146 sec/batch)\n",
      "2017-05-28 04:51:57.309359: step 21810, loss = 0.83 (335.4 examples/sec; 0.763 sec/batch)\n",
      "2017-05-28 04:52:05.424991: step 21820, loss = 0.98 (315.4 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 04:52:13.622487: step 21830, loss = 0.89 (312.3 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 04:52:21.482985: step 21840, loss = 0.85 (325.7 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 04:52:29.432610: step 21850, loss = 0.95 (322.0 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 04:52:37.883617: step 21860, loss = 0.98 (302.9 examples/sec; 0.845 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 21870 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 04:52:47.039527: step 21870, loss = 0.85 (279.6 examples/sec; 0.916 sec/batch)\n",
      "2017-05-28 04:52:54.841664: step 21880, loss = 0.93 (328.1 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 04:53:03.252682: step 21890, loss = 0.83 (304.4 examples/sec; 0.841 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15486\n",
      "2017-05-28 04:53:16.267063: step 21900, loss = 0.97 (196.7 examples/sec; 1.301 sec/batch)\n",
      "2017-05-28 04:53:23.753407: step 21910, loss = 0.83 (342.0 examples/sec; 0.749 sec/batch)\n",
      "2017-05-28 04:53:31.736872: step 21920, loss = 0.88 (320.7 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 04:53:40.007279: step 21930, loss = 0.73 (309.5 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 04:53:48.013719: step 21940, loss = 0.79 (319.7 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 04:53:55.991309: step 21950, loss = 0.82 (320.9 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 04:54:04.092004: step 21960, loss = 0.86 (316.0 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 04:54:12.756701: step 21970, loss = 0.86 (295.5 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 04:54:20.961704: step 21980, loss = 0.81 (312.0 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 04:54:28.876220: step 21990, loss = 0.81 (323.5 examples/sec; 0.791 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16752\n",
      "2017-05-28 04:54:41.917169: step 22000, loss = 0.89 (196.3 examples/sec; 1.304 sec/batch)\n",
      "2017-05-28 04:54:49.282215: step 22010, loss = 1.03 (347.6 examples/sec; 0.737 sec/batch)\n",
      "2017-05-28 04:54:57.122902: step 22020, loss = 0.83 (326.5 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 04:55:05.221722: step 22030, loss = 0.79 (316.1 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 04:55:13.269920: step 22040, loss = 0.83 (318.1 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 04:55:21.392042: step 22050, loss = 0.72 (315.2 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 04:55:29.454215: step 22060, loss = 0.89 (317.5 examples/sec; 0.806 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 04:55:37.718027: step 22070, loss = 0.94 (309.8 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 04:55:48.060307: step 22080, loss = 0.81 (247.5 examples/sec; 1.034 sec/batch)\n",
      "2017-05-28 04:55:56.152970: step 22090, loss = 0.84 (316.3 examples/sec; 0.809 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15052\n",
      "2017-05-28 04:56:08.832346: step 22100, loss = 0.88 (201.9 examples/sec; 1.268 sec/batch)\n",
      "2017-05-28 04:56:16.651808: step 22110, loss = 0.82 (327.4 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 04:56:25.008773: step 22120, loss = 0.93 (306.3 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 04:56:33.789854: step 22130, loss = 0.83 (291.5 examples/sec; 0.878 sec/batch)\n",
      "2017-05-28 04:56:42.482846: step 22140, loss = 0.85 (294.5 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 04:56:51.348681: step 22150, loss = 0.89 (288.7 examples/sec; 0.887 sec/batch)\n",
      "2017-05-28 04:56:59.911532: step 22160, loss = 0.93 (299.0 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 04:57:08.096654: step 22170, loss = 0.82 (312.8 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 04:57:16.527923: step 22180, loss = 0.85 (303.6 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 04:57:24.876492: step 22190, loss = 0.88 (306.6 examples/sec; 0.835 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13063\n",
      "2017-05-28 04:57:37.291007: step 22200, loss = 0.86 (206.2 examples/sec; 1.241 sec/batch)\n",
      "2017-05-28 04:57:44.836675: step 22210, loss = 0.88 (339.3 examples/sec; 0.755 sec/batch)\n",
      "2017-05-28 04:57:53.263819: step 22220, loss = 1.00 (303.8 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 04:58:01.906003: step 22230, loss = 0.74 (296.2 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 04:58:11.159179: step 22240, loss = 0.99 (276.7 examples/sec; 0.925 sec/batch)\n",
      "2017-05-28 04:58:19.841457: step 22250, loss = 0.83 (294.9 examples/sec; 0.868 sec/batch)\n",
      "2017-05-28 04:58:28.244798: step 22260, loss = 0.86 (304.6 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 04:58:36.509224: step 22270, loss = 0.84 (309.8 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 04:58:45.848489: step 22280, loss = 0.85 (274.1 examples/sec; 0.934 sec/batch)\n",
      "2017-05-28 04:58:53.832155: step 22290, loss = 0.99 (320.7 examples/sec; 0.798 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.09981\n",
      "2017-05-28 04:59:08.206203: step 22300, loss = 0.79 (178.1 examples/sec; 1.437 sec/batch)\n",
      "2017-05-28 04:59:16.424230: step 22310, loss = 0.80 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 04:59:24.842576: step 22320, loss = 0.93 (304.1 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 04:59:33.354447: step 22330, loss = 1.02 (300.8 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 04:59:42.143460: step 22340, loss = 0.90 (291.3 examples/sec; 0.879 sec/batch)\n",
      "2017-05-28 04:59:50.737735: step 22350, loss = 0.91 (297.9 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 04:59:59.152498: step 22360, loss = 0.83 (304.2 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 05:00:07.961275: step 22370, loss = 0.92 (290.6 examples/sec; 0.881 sec/batch)\n",
      "2017-05-28 05:00:16.780451: step 22380, loss = 0.93 (290.3 examples/sec; 0.882 sec/batch)\n",
      "2017-05-28 05:00:25.153327: step 22390, loss = 0.86 (305.7 examples/sec; 0.837 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.08363\n",
      "2017-05-28 05:00:40.487585: step 22400, loss = 0.97 (166.9 examples/sec; 1.533 sec/batch)\n",
      "2017-05-28 05:00:48.429317: step 22410, loss = 0.75 (322.3 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 05:00:56.931668: step 22420, loss = 0.83 (301.1 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 05:01:05.323215: step 22430, loss = 0.93 (305.1 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 05:01:13.942508: step 22440, loss = 0.79 (297.0 examples/sec; 0.862 sec/batch)\n",
      "2017-05-28 05:01:22.144196: step 22450, loss = 0.83 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 05:01:30.326925: step 22460, loss = 0.78 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 05:01:38.912261: step 22470, loss = 0.67 (298.2 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 05:01:47.506690: step 22480, loss = 0.80 (297.9 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 05:01:55.356032: step 22490, loss = 0.83 (326.1 examples/sec; 0.785 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13429\n",
      "2017-05-28 05:02:08.647104: step 22500, loss = 0.89 (192.6 examples/sec; 1.329 sec/batch)\n",
      "2017-05-28 05:02:16.202084: step 22510, loss = 0.86 (338.8 examples/sec; 0.755 sec/batch)\n",
      "2017-05-28 05:02:24.532619: step 22520, loss = 0.83 (307.3 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 05:02:33.733981: step 22530, loss = 0.97 (278.2 examples/sec; 0.920 sec/batch)\n",
      "2017-05-28 05:02:42.642468: step 22540, loss = 0.82 (287.4 examples/sec; 0.891 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 22545 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 05:02:51.361992: step 22550, loss = 0.78 (293.6 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 05:02:59.201842: step 22560, loss = 0.87 (326.5 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 05:03:08.446686: step 22570, loss = 0.77 (276.9 examples/sec; 0.924 sec/batch)\n",
      "2017-05-28 05:03:16.987013: step 22580, loss = 0.87 (299.8 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 05:03:24.903118: step 22590, loss = 0.78 (323.4 examples/sec; 0.792 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1292\n",
      "2017-05-28 05:03:37.205053: step 22600, loss = 0.93 (208.1 examples/sec; 1.230 sec/batch)\n",
      "2017-05-28 05:03:45.294853: step 22610, loss = 1.00 (316.4 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 05:03:53.800618: step 22620, loss = 0.83 (301.0 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 05:04:02.506572: step 22630, loss = 0.90 (294.1 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 05:04:10.802479: step 22640, loss = 0.88 (308.6 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 05:04:19.358689: step 22650, loss = 0.87 (299.2 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 05:04:27.689742: step 22660, loss = 0.88 (307.3 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 05:04:35.899259: step 22670, loss = 0.82 (311.8 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 05:04:44.476027: step 22680, loss = 0.89 (298.5 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 05:04:52.753920: step 22690, loss = 0.92 (309.3 examples/sec; 0.828 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11284\n",
      "2017-05-28 05:05:07.066947: step 22700, loss = 0.82 (178.9 examples/sec; 1.431 sec/batch)\n",
      "2017-05-28 05:05:14.652326: step 22710, loss = 0.96 (337.5 examples/sec; 0.759 sec/batch)\n",
      "2017-05-28 05:05:22.844305: step 22720, loss = 0.88 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 05:05:31.479723: step 22730, loss = 0.81 (296.5 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 05:05:39.771379: step 22740, loss = 0.96 (308.7 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 05:05:47.808404: step 22750, loss = 0.73 (318.5 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 05:05:56.204808: step 22760, loss = 0.74 (304.9 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 05:06:04.781060: step 22770, loss = 0.96 (298.5 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 05:06:13.333763: step 22780, loss = 0.82 (299.3 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 05:06:21.474382: step 22790, loss = 0.80 (314.5 examples/sec; 0.814 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14524\n",
      "2017-05-28 05:06:34.382681: step 22800, loss = 0.98 (198.3 examples/sec; 1.291 sec/batch)\n",
      "2017-05-28 05:06:41.821666: step 22810, loss = 0.81 (344.1 examples/sec; 0.744 sec/batch)\n",
      "2017-05-28 05:06:49.848304: step 22820, loss = 0.80 (318.9 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 05:06:57.981943: step 22830, loss = 0.96 (314.7 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 05:07:06.288039: step 22840, loss = 0.86 (308.2 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 05:07:15.147239: step 22850, loss = 0.79 (289.0 examples/sec; 0.886 sec/batch)\n",
      "2017-05-28 05:07:23.158072: step 22860, loss = 0.86 (319.6 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 05:07:31.303014: step 22870, loss = 0.91 (314.3 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 05:07:39.602797: step 22880, loss = 0.96 (308.4 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 05:07:47.956709: step 22890, loss = 0.73 (306.4 examples/sec; 0.835 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18785\n",
      "2017-05-28 05:07:58.569728: step 22900, loss = 0.92 (241.2 examples/sec; 1.061 sec/batch)\n",
      "2017-05-28 05:08:06.806742: step 22910, loss = 0.75 (310.8 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 05:08:15.100554: step 22920, loss = 0.92 (308.7 examples/sec; 0.829 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 05:08:23.221000: step 22930, loss = 0.94 (315.3 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 05:08:31.604137: step 22940, loss = 0.86 (305.4 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 05:08:39.741814: step 22950, loss = 0.90 (314.6 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 05:08:47.848154: step 22960, loss = 0.88 (315.8 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 05:08:56.219554: step 22970, loss = 0.98 (305.8 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 05:09:04.537144: step 22980, loss = 0.84 (307.8 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 05:09:12.657066: step 22990, loss = 0.80 (315.3 examples/sec; 0.812 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17673\n",
      "2017-05-28 05:09:23.551045: step 23000, loss = 0.79 (235.0 examples/sec; 1.089 sec/batch)\n",
      "2017-05-28 05:09:30.968610: step 23010, loss = 0.84 (345.1 examples/sec; 0.742 sec/batch)\n",
      "2017-05-28 05:09:39.811736: step 23020, loss = 0.85 (289.5 examples/sec; 0.884 sec/batch)\n",
      "2017-05-28 05:09:48.182579: step 23030, loss = 0.85 (305.8 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 05:09:56.054158: step 23040, loss = 0.93 (325.2 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 05:10:04.344665: step 23050, loss = 0.80 (308.8 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 05:10:12.849978: step 23060, loss = 0.89 (301.0 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 05:10:20.899639: step 23070, loss = 0.92 (318.0 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 05:10:28.813751: step 23080, loss = 0.85 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 05:10:36.913526: step 23090, loss = 0.83 (316.1 examples/sec; 0.810 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15627\n",
      "2017-05-28 05:10:50.039116: step 23100, loss = 0.86 (195.0 examples/sec; 1.313 sec/batch)\n",
      "2017-05-28 05:10:57.481214: step 23110, loss = 0.88 (344.0 examples/sec; 0.744 sec/batch)\n",
      "2017-05-28 05:11:07.312261: step 23120, loss = 0.86 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-28 05:11:16.156236: step 23130, loss = 1.00 (289.5 examples/sec; 0.884 sec/batch)\n",
      "2017-05-28 05:11:24.074760: step 23140, loss = 0.82 (323.3 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 05:11:32.096322: step 23150, loss = 0.98 (319.1 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 05:11:40.444577: step 23160, loss = 0.73 (306.7 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 05:11:48.951341: step 23170, loss = 0.85 (300.9 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 05:11:57.371392: step 23180, loss = 0.98 (304.0 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 05:12:05.525231: step 23190, loss = 0.91 (314.0 examples/sec; 0.815 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13413\n",
      "2017-05-28 05:12:18.208888: step 23200, loss = 0.84 (201.8 examples/sec; 1.268 sec/batch)\n",
      "2017-05-28 05:12:25.384207: step 23210, loss = 0.98 (356.8 examples/sec; 0.718 sec/batch)\n",
      "2017-05-28 05:12:33.489015: step 23220, loss = 0.86 (315.9 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 05:12:41.687086: step 23230, loss = 0.82 (312.3 examples/sec; 0.820 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 23237 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 05:12:50.638060: step 23240, loss = 0.91 (286.0 examples/sec; 0.895 sec/batch)\n",
      "2017-05-28 05:12:58.952030: step 23250, loss = 0.86 (307.9 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 05:13:07.266499: step 23260, loss = 0.83 (307.9 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 05:13:15.794229: step 23270, loss = 0.87 (300.2 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 05:13:24.092565: step 23280, loss = 0.82 (308.5 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 05:13:32.052736: step 23290, loss = 0.72 (321.6 examples/sec; 0.796 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1445\n",
      "2017-05-28 05:13:45.586847: step 23300, loss = 0.87 (189.2 examples/sec; 1.353 sec/batch)\n",
      "2017-05-28 05:13:53.033545: step 23310, loss = 0.93 (343.8 examples/sec; 0.745 sec/batch)\n",
      "2017-05-28 05:14:00.940943: step 23320, loss = 0.71 (323.7 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 05:14:09.943893: step 23330, loss = 0.81 (284.4 examples/sec; 0.900 sec/batch)\n",
      "2017-05-28 05:14:18.145653: step 23340, loss = 0.78 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 05:14:26.135139: step 23350, loss = 0.97 (320.4 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 05:14:34.144822: step 23360, loss = 0.95 (319.6 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 05:14:42.301811: step 23370, loss = 0.84 (313.8 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 05:14:50.347676: step 23380, loss = 0.94 (318.2 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 05:14:58.258605: step 23390, loss = 0.88 (323.6 examples/sec; 0.791 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15812\n",
      "2017-05-28 05:15:11.930999: step 23400, loss = 0.94 (187.2 examples/sec; 1.367 sec/batch)\n",
      "2017-05-28 05:15:19.220891: step 23410, loss = 0.87 (351.2 examples/sec; 0.729 sec/batch)\n",
      "2017-05-28 05:15:27.151606: step 23420, loss = 1.03 (322.8 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 05:15:35.167586: step 23430, loss = 0.88 (319.4 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 05:15:43.841521: step 23440, loss = 0.99 (295.1 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 05:15:51.999469: step 23450, loss = 0.70 (313.8 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 05:15:59.970272: step 23460, loss = 0.97 (321.2 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 05:16:09.029973: step 23470, loss = 0.82 (282.6 examples/sec; 0.906 sec/batch)\n",
      "2017-05-28 05:16:18.606566: step 23480, loss = 0.89 (267.3 examples/sec; 0.958 sec/batch)\n",
      "2017-05-28 05:16:26.591106: step 23490, loss = 0.79 (320.6 examples/sec; 0.798 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12745\n",
      "2017-05-28 05:16:40.628667: step 23500, loss = 0.79 (182.4 examples/sec; 1.404 sec/batch)\n",
      "2017-05-28 05:16:48.037314: step 23510, loss = 0.91 (345.5 examples/sec; 0.741 sec/batch)\n",
      "2017-05-28 05:16:55.955666: step 23520, loss = 0.88 (323.3 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 05:17:04.367514: step 23530, loss = 0.81 (304.3 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 05:17:13.088771: step 23540, loss = 0.72 (293.5 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 05:17:21.131277: step 23550, loss = 0.87 (318.3 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 05:17:29.198748: step 23560, loss = 0.73 (317.3 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 05:17:37.302222: step 23570, loss = 0.83 (315.9 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 05:17:46.163183: step 23580, loss = 0.83 (288.9 examples/sec; 0.886 sec/batch)\n",
      "2017-05-28 05:17:54.300987: step 23590, loss = 0.84 (314.6 examples/sec; 0.814 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16262\n",
      "2017-05-28 05:18:06.642737: step 23600, loss = 0.85 (207.4 examples/sec; 1.234 sec/batch)\n",
      "2017-05-28 05:18:14.355217: step 23610, loss = 0.82 (331.9 examples/sec; 0.771 sec/batch)\n",
      "2017-05-28 05:18:22.390773: step 23620, loss = 0.81 (318.6 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 05:18:30.287720: step 23630, loss = 0.88 (324.2 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 05:18:38.955635: step 23640, loss = 0.86 (295.3 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 05:18:47.450590: step 23650, loss = 1.03 (301.4 examples/sec; 0.849 sec/batch)\n",
      "2017-05-28 05:18:55.389255: step 23660, loss = 0.86 (322.5 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 05:19:03.766193: step 23670, loss = 0.68 (305.6 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 05:19:12.379308: step 23680, loss = 0.89 (297.2 examples/sec; 0.861 sec/batch)\n",
      "2017-05-28 05:19:20.614157: step 23690, loss = 0.79 (310.9 examples/sec; 0.823 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15289\n",
      "2017-05-28 05:19:33.381391: step 23700, loss = 0.79 (200.5 examples/sec; 1.277 sec/batch)\n",
      "2017-05-28 05:19:40.964219: step 23710, loss = 0.94 (337.6 examples/sec; 0.758 sec/batch)\n",
      "2017-05-28 05:19:49.053334: step 23720, loss = 0.78 (316.5 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 05:19:56.987441: step 23730, loss = 0.85 (322.7 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 05:20:05.044918: step 23740, loss = 0.79 (317.7 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 05:20:13.699953: step 23750, loss = 0.87 (295.8 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 05:20:21.768176: step 23760, loss = 0.91 (317.3 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 05:20:29.670766: step 23770, loss = 0.85 (323.9 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 05:20:38.186334: step 23780, loss = 0.79 (300.6 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 05:20:46.688066: step 23790, loss = 0.87 (301.1 examples/sec; 0.850 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.18811\n",
      "2017-05-28 05:20:57.545391: step 23800, loss = 0.73 (235.8 examples/sec; 1.086 sec/batch)\n",
      "2017-05-28 05:21:05.212262: step 23810, loss = 0.86 (333.9 examples/sec; 0.767 sec/batch)\n",
      "2017-05-28 05:21:13.411381: step 23820, loss = 0.99 (312.2 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 05:21:23.542461: step 23830, loss = 0.82 (252.7 examples/sec; 1.013 sec/batch)\n",
      "2017-05-28 05:21:31.778956: step 23840, loss = 0.76 (310.8 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 05:21:40.651599: step 23850, loss = 0.83 (288.5 examples/sec; 0.887 sec/batch)\n",
      "2017-05-28 05:21:48.978514: step 23860, loss = 0.85 (307.4 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 05:21:56.879930: step 23870, loss = 0.93 (324.0 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 05:22:05.029578: step 23880, loss = 0.70 (314.1 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 05:22:13.192531: step 23890, loss = 0.73 (313.6 examples/sec; 0.816 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15608\n",
      "2017-05-28 05:22:24.045974: step 23900, loss = 0.81 (235.9 examples/sec; 1.085 sec/batch)\n",
      "2017-05-28 05:22:31.867577: step 23910, loss = 0.91 (327.3 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 05:22:40.169912: step 23920, loss = 0.80 (308.3 examples/sec; 0.830 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 23929 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 05:22:49.281549: step 23930, loss = 0.83 (281.0 examples/sec; 0.911 sec/batch)\n",
      "2017-05-28 05:22:56.917629: step 23940, loss = 0.86 (335.3 examples/sec; 0.764 sec/batch)\n",
      "2017-05-28 05:23:05.316167: step 23950, loss = 0.83 (304.8 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 05:23:13.735481: step 23960, loss = 0.94 (304.1 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 05:23:21.919473: step 23970, loss = 0.90 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 05:23:30.351376: step 23980, loss = 0.83 (303.6 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 05:23:38.413859: step 23990, loss = 0.76 (317.5 examples/sec; 0.806 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16122\n",
      "2017-05-28 05:23:50.165423: step 24000, loss = 0.81 (217.8 examples/sec; 1.175 sec/batch)\n",
      "2017-05-28 05:23:57.439253: step 24010, loss = 0.75 (351.9 examples/sec; 0.727 sec/batch)\n",
      "2017-05-28 05:24:05.552464: step 24020, loss = 0.75 (315.5 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 05:24:14.391758: step 24030, loss = 0.92 (289.6 examples/sec; 0.884 sec/batch)\n",
      "2017-05-28 05:24:22.450815: step 24040, loss = 0.84 (317.7 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 05:24:30.783754: step 24050, loss = 0.79 (307.2 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 05:24:39.104920: step 24060, loss = 0.89 (307.6 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 05:24:47.274240: step 24070, loss = 0.85 (313.4 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 05:24:55.801735: step 24080, loss = 0.88 (300.2 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 05:25:03.835955: step 24090, loss = 0.88 (318.6 examples/sec; 0.803 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1519\n",
      "2017-05-28 05:25:16.977598: step 24100, loss = 0.91 (194.8 examples/sec; 1.314 sec/batch)\n",
      "2017-05-28 05:25:24.420715: step 24110, loss = 0.84 (343.9 examples/sec; 0.744 sec/batch)\n",
      "2017-05-28 05:25:32.531829: step 24120, loss = 0.91 (315.6 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 05:25:40.645484: step 24130, loss = 0.83 (315.5 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 05:25:49.395031: step 24140, loss = 0.79 (292.6 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 05:25:57.300845: step 24150, loss = 0.83 (323.8 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 05:26:05.404577: step 24160, loss = 0.73 (315.9 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 05:26:13.975524: step 24170, loss = 0.88 (298.7 examples/sec; 0.857 sec/batch)\n",
      "2017-05-28 05:26:22.372906: step 24180, loss = 0.95 (304.9 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 05:26:31.524218: step 24190, loss = 0.84 (279.7 examples/sec; 0.915 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15031\n",
      "2017-05-28 05:26:43.908347: step 24200, loss = 0.79 (206.7 examples/sec; 1.238 sec/batch)\n",
      "2017-05-28 05:26:51.669884: step 24210, loss = 0.82 (329.8 examples/sec; 0.776 sec/batch)\n",
      "2017-05-28 05:26:59.774465: step 24220, loss = 0.72 (315.9 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 05:27:07.932487: step 24230, loss = 0.84 (313.8 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 05:27:16.078641: step 24240, loss = 0.88 (314.3 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 05:27:24.057924: step 24250, loss = 0.92 (320.8 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 05:27:32.238457: step 24260, loss = 0.71 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 05:27:40.368087: step 24270, loss = 0.87 (314.9 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 05:27:49.129385: step 24280, loss = 0.80 (292.2 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 05:27:57.168044: step 24290, loss = 0.80 (318.5 examples/sec; 0.804 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16951\n",
      "2017-05-28 05:28:09.414223: step 24300, loss = 0.86 (209.0 examples/sec; 1.225 sec/batch)\n",
      "2017-05-28 05:28:17.340940: step 24310, loss = 0.75 (323.0 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 05:28:25.450577: step 24320, loss = 0.87 (315.7 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 05:28:33.559011: step 24330, loss = 0.69 (315.7 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 05:28:41.775199: step 24340, loss = 0.86 (311.6 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 05:28:50.200912: step 24350, loss = 0.86 (303.8 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 05:28:58.325365: step 24360, loss = 0.82 (315.1 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 05:29:06.545571: step 24370, loss = 0.89 (311.4 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 05:29:14.658694: step 24380, loss = 0.79 (315.5 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 05:29:23.418467: step 24390, loss = 0.88 (292.2 examples/sec; 0.876 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15142\n",
      "2017-05-28 05:29:36.265944: step 24400, loss = 0.80 (199.3 examples/sec; 1.285 sec/batch)\n",
      "2017-05-28 05:29:44.055452: step 24410, loss = 0.87 (328.6 examples/sec; 0.779 sec/batch)\n",
      "2017-05-28 05:29:52.171437: step 24420, loss = 0.78 (315.4 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 05:30:00.065729: step 24430, loss = 0.86 (324.3 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 05:30:08.231603: step 24440, loss = 0.72 (313.5 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 05:30:16.373902: step 24450, loss = 0.76 (314.4 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 05:30:24.877165: step 24460, loss = 0.93 (301.1 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 05:30:33.092669: step 24470, loss = 0.88 (311.6 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 05:30:41.649673: step 24480, loss = 0.91 (299.2 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 05:30:50.238872: step 24490, loss = 0.95 (298.0 examples/sec; 0.859 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17917\n",
      "2017-05-28 05:31:01.070197: step 24500, loss = 0.90 (236.4 examples/sec; 1.083 sec/batch)\n",
      "2017-05-28 05:31:08.795456: step 24510, loss = 1.05 (331.4 examples/sec; 0.773 sec/batch)\n",
      "2017-05-28 05:31:16.899929: step 24520, loss = 0.98 (315.9 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 05:31:25.369561: step 24530, loss = 0.89 (302.3 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 05:31:34.695179: step 24540, loss = 0.81 (274.5 examples/sec; 0.933 sec/batch)\n",
      "2017-05-28 05:31:43.452023: step 24550, loss = 0.90 (292.3 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 05:31:52.183160: step 24560, loss = 0.81 (293.2 examples/sec; 0.873 sec/batch)\n",
      "2017-05-28 05:32:00.286949: step 24570, loss = 0.81 (315.9 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 05:32:08.836768: step 24580, loss = 0.96 (299.4 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 05:32:17.388095: step 24590, loss = 0.86 (299.4 examples/sec; 0.855 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13276\n",
      "2017-05-28 05:32:29.351772: step 24600, loss = 0.75 (214.0 examples/sec; 1.196 sec/batch)\n",
      "2017-05-28 05:32:37.089312: step 24610, loss = 0.92 (330.9 examples/sec; 0.774 sec/batch)\n",
      "2017-05-28 05:32:45.225389: step 24620, loss = 0.92 (314.6 examples/sec; 0.814 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 24623 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 05:32:54.951569: step 24630, loss = 1.04 (263.2 examples/sec; 0.973 sec/batch)\n",
      "2017-05-28 05:33:02.937505: step 24640, loss = 0.86 (320.6 examples/sec; 0.799 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 05:33:11.054184: step 24650, loss = 0.85 (315.4 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 05:33:19.616484: step 24660, loss = 0.80 (299.0 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 05:33:27.753864: step 24670, loss = 0.90 (314.6 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 05:33:35.963124: step 24680, loss = 0.87 (311.8 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 05:33:44.635006: step 24690, loss = 0.82 (295.2 examples/sec; 0.867 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16239\n",
      "2017-05-28 05:33:55.377811: step 24700, loss = 0.92 (238.3 examples/sec; 1.074 sec/batch)\n",
      "2017-05-28 05:34:03.159316: step 24710, loss = 0.88 (329.0 examples/sec; 0.778 sec/batch)\n",
      "2017-05-28 05:34:11.290212: step 24720, loss = 0.89 (314.8 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 05:34:19.912164: step 24730, loss = 0.81 (296.9 examples/sec; 0.862 sec/batch)\n",
      "2017-05-28 05:34:28.054165: step 24740, loss = 0.74 (314.4 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 05:34:36.129775: step 24750, loss = 0.83 (317.0 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 05:34:44.299764: step 24760, loss = 0.90 (313.3 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 05:34:52.350705: step 24770, loss = 0.89 (318.0 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 05:35:00.352877: step 24780, loss = 0.73 (319.9 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 05:35:09.092077: step 24790, loss = 0.82 (292.9 examples/sec; 0.874 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14485\n",
      "2017-05-28 05:35:22.729376: step 24800, loss = 0.76 (187.7 examples/sec; 1.364 sec/batch)\n",
      "2017-05-28 05:35:30.131143: step 24810, loss = 0.72 (345.9 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 05:35:38.206357: step 24820, loss = 0.84 (317.0 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 05:35:46.450164: step 24830, loss = 0.81 (310.5 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 05:35:54.984735: step 24840, loss = 0.76 (300.0 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 05:36:02.916999: step 24850, loss = 0.69 (322.7 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 05:36:11.492263: step 24860, loss = 0.88 (298.5 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 05:36:19.853365: step 24870, loss = 0.83 (306.2 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 05:36:27.791225: step 24880, loss = 0.88 (322.5 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 05:36:35.889712: step 24890, loss = 0.81 (316.1 examples/sec; 0.810 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13819\n",
      "2017-05-28 05:36:50.586298: step 24900, loss = 0.77 (174.2 examples/sec; 1.470 sec/batch)\n",
      "2017-05-28 05:36:57.934595: step 24910, loss = 0.80 (348.4 examples/sec; 0.735 sec/batch)\n",
      "2017-05-28 05:37:06.155205: step 24920, loss = 0.88 (311.4 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 05:37:14.731619: step 24930, loss = 0.81 (298.5 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 05:37:23.421540: step 24940, loss = 0.95 (294.6 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 05:37:31.488548: step 24950, loss = 0.83 (317.3 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 05:37:39.652618: step 24960, loss = 0.90 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 05:37:48.476991: step 24970, loss = 0.72 (290.1 examples/sec; 0.882 sec/batch)\n",
      "2017-05-28 05:37:56.463963: step 24980, loss = 0.92 (320.5 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 05:38:04.469339: step 24990, loss = 0.80 (319.8 examples/sec; 0.801 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16187\n",
      "2017-05-28 05:38:16.654074: step 25000, loss = 0.74 (210.1 examples/sec; 1.218 sec/batch)\n",
      "2017-05-28 05:38:24.411270: step 25010, loss = 0.93 (330.0 examples/sec; 0.776 sec/batch)\n",
      "2017-05-28 05:38:32.599488: step 25020, loss = 0.81 (312.6 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 05:38:41.064230: step 25030, loss = 0.84 (302.4 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 05:38:49.666658: step 25040, loss = 0.74 (297.6 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 05:38:57.626597: step 25050, loss = 0.87 (321.6 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 05:39:05.681084: step 25060, loss = 0.80 (317.8 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 05:39:14.653639: step 25070, loss = 0.92 (285.3 examples/sec; 0.897 sec/batch)\n",
      "2017-05-28 05:39:22.845729: step 25080, loss = 0.87 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 05:39:30.692331: step 25090, loss = 0.82 (326.3 examples/sec; 0.785 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13838\n",
      "2017-05-28 05:39:44.498019: step 25100, loss = 0.79 (185.4 examples/sec; 1.381 sec/batch)\n",
      "2017-05-28 05:39:51.898321: step 25110, loss = 0.83 (345.9 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 05:39:59.815167: step 25120, loss = 0.79 (323.4 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 05:40:07.940918: step 25130, loss = 0.81 (315.0 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 05:40:16.560158: step 25140, loss = 0.91 (297.0 examples/sec; 0.862 sec/batch)\n",
      "2017-05-28 05:40:24.847766: step 25150, loss = 0.91 (308.9 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 05:40:33.044057: step 25160, loss = 0.86 (312.3 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 05:40:41.688063: step 25170, loss = 0.91 (296.2 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 05:40:49.921510: step 25180, loss = 0.73 (310.9 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 05:40:57.848166: step 25190, loss = 0.83 (323.0 examples/sec; 0.793 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14865\n",
      "2017-05-28 05:41:11.558415: step 25200, loss = 0.92 (186.7 examples/sec; 1.371 sec/batch)\n",
      "2017-05-28 05:41:19.106672: step 25210, loss = 0.86 (339.2 examples/sec; 0.755 sec/batch)\n",
      "2017-05-28 05:41:27.198116: step 25220, loss = 0.95 (316.4 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 05:41:35.230360: step 25230, loss = 0.83 (318.7 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 05:41:43.445246: step 25240, loss = 0.78 (311.6 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 05:41:53.223828: step 25250, loss = 0.80 (261.8 examples/sec; 0.978 sec/batch)\n",
      "2017-05-28 05:42:01.780303: step 25260, loss = 1.01 (299.2 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 05:42:10.245577: step 25270, loss = 0.77 (302.4 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 05:42:19.013330: step 25280, loss = 0.72 (292.0 examples/sec; 0.877 sec/batch)\n",
      "2017-05-28 05:42:27.057436: step 25290, loss = 0.85 (318.2 examples/sec; 0.804 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13388\n",
      "2017-05-28 05:42:39.752570: step 25300, loss = 0.76 (201.7 examples/sec; 1.270 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 25311 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 05:42:48.923984: step 25310, loss = 0.83 (279.1 examples/sec; 0.917 sec/batch)\n",
      "2017-05-28 05:42:56.443343: step 25320, loss = 0.86 (340.5 examples/sec; 0.752 sec/batch)\n",
      "2017-05-28 05:43:04.531999: step 25330, loss = 0.90 (316.5 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 05:43:13.175215: step 25340, loss = 0.85 (296.2 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 05:43:21.511938: step 25350, loss = 0.74 (307.1 examples/sec; 0.834 sec/batch)\n",
      "2017-05-28 05:43:29.452883: step 25360, loss = 0.95 (322.4 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 05:43:37.641318: step 25370, loss = 0.86 (312.6 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 05:43:46.166914: step 25380, loss = 0.83 (300.3 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 05:43:54.767063: step 25390, loss = 0.85 (297.7 examples/sec; 0.860 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12322\n",
      "2017-05-28 05:44:08.780156: step 25400, loss = 0.83 (182.7 examples/sec; 1.401 sec/batch)\n",
      "2017-05-28 05:44:16.294146: step 25410, loss = 0.83 (340.7 examples/sec; 0.751 sec/batch)\n",
      "2017-05-28 05:44:24.406204: step 25420, loss = 0.77 (315.6 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 05:44:32.879109: step 25430, loss = 0.94 (302.1 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 05:44:41.060382: step 25440, loss = 0.85 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 05:44:49.322951: step 25450, loss = 0.96 (309.8 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 05:44:57.405620: step 25460, loss = 0.88 (316.7 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 05:45:05.469316: step 25470, loss = 0.74 (317.5 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 05:45:14.117336: step 25480, loss = 0.84 (296.0 examples/sec; 0.865 sec/batch)\n",
      "2017-05-28 05:45:22.303164: step 25490, loss = 0.89 (312.7 examples/sec; 0.819 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16501\n",
      "2017-05-28 05:45:34.615667: step 25500, loss = 0.97 (207.9 examples/sec; 1.231 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 05:45:42.449802: step 25510, loss = 0.72 (326.8 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 05:45:50.592111: step 25520, loss = 0.77 (314.4 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 05:45:58.534701: step 25530, loss = 0.85 (322.3 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 05:46:06.604467: step 25540, loss = 0.94 (317.2 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 05:46:15.111046: step 25550, loss = 0.89 (300.9 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 05:46:23.571471: step 25560, loss = 0.79 (302.6 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 05:46:31.486056: step 25570, loss = 0.86 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 05:46:39.705594: step 25580, loss = 0.86 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 05:46:47.825262: step 25590, loss = 0.85 (315.3 examples/sec; 0.812 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15501\n",
      "2017-05-28 05:47:01.194998: step 25600, loss = 0.80 (191.5 examples/sec; 1.337 sec/batch)\n",
      "2017-05-28 05:47:09.045057: step 25610, loss = 0.74 (326.1 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 05:47:18.067858: step 25620, loss = 0.85 (283.7 examples/sec; 0.902 sec/batch)\n",
      "2017-05-28 05:47:26.302154: step 25630, loss = 0.95 (310.9 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 05:47:34.341272: step 25640, loss = 0.95 (318.4 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 05:47:43.069220: step 25650, loss = 0.80 (293.3 examples/sec; 0.873 sec/batch)\n",
      "2017-05-28 05:47:51.233551: step 25660, loss = 0.77 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 05:47:59.161458: step 25670, loss = 0.94 (322.9 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 05:48:07.674703: step 25680, loss = 0.85 (300.7 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 05:48:16.111093: step 25690, loss = 0.89 (303.4 examples/sec; 0.844 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16459\n",
      "2017-05-28 05:48:27.063239: step 25700, loss = 1.02 (233.7 examples/sec; 1.095 sec/batch)\n",
      "2017-05-28 05:48:34.925079: step 25710, loss = 0.82 (325.6 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 05:48:43.435082: step 25720, loss = 0.95 (300.8 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 05:48:51.650790: step 25730, loss = 0.79 (311.6 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 05:49:00.409022: step 25740, loss = 0.86 (292.3 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 05:49:08.581034: step 25750, loss = 0.97 (313.3 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 05:49:16.784170: step 25760, loss = 0.89 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 05:49:25.407176: step 25770, loss = 0.89 (296.9 examples/sec; 0.862 sec/batch)\n",
      "2017-05-28 05:49:33.635955: step 25780, loss = 0.87 (311.1 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 05:49:42.175509: step 25790, loss = 0.78 (299.8 examples/sec; 0.854 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14549\n",
      "2017-05-28 05:49:54.360178: step 25800, loss = 0.78 (210.1 examples/sec; 1.218 sec/batch)\n",
      "2017-05-28 05:50:01.766888: step 25810, loss = 0.89 (345.6 examples/sec; 0.741 sec/batch)\n",
      "2017-05-28 05:50:10.077245: step 25820, loss = 0.81 (308.0 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 05:50:18.209068: step 25830, loss = 0.78 (314.8 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 05:50:26.244573: step 25840, loss = 0.81 (318.6 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 05:50:34.955177: step 25850, loss = 0.72 (293.9 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 05:50:43.080922: step 25860, loss = 0.68 (315.0 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 05:50:51.638353: step 25870, loss = 0.79 (299.2 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 05:50:59.893907: step 25880, loss = 0.72 (310.1 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 05:51:08.123941: step 25890, loss = 0.78 (311.1 examples/sec; 0.823 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15673\n",
      "2017-05-28 05:51:20.811289: step 25900, loss = 0.86 (201.8 examples/sec; 1.269 sec/batch)\n",
      "2017-05-28 05:51:28.197061: step 25910, loss = 0.88 (346.6 examples/sec; 0.739 sec/batch)\n",
      "2017-05-28 05:51:36.309511: step 25920, loss = 0.88 (315.6 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 05:51:45.183088: step 25930, loss = 0.70 (288.5 examples/sec; 0.887 sec/batch)\n",
      "2017-05-28 05:51:53.383536: step 25940, loss = 0.74 (312.2 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 05:52:01.531212: step 25950, loss = 0.79 (314.2 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 05:52:11.691325: step 25960, loss = 0.77 (252.0 examples/sec; 1.016 sec/batch)\n",
      "2017-05-28 05:52:20.494989: step 25970, loss = 0.75 (290.8 examples/sec; 0.880 sec/batch)\n",
      "2017-05-28 05:52:28.677906: step 25980, loss = 0.82 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 05:52:37.393258: step 25990, loss = 0.97 (293.7 examples/sec; 0.872 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.126\n",
      "INFO:tensorflow:Saving checkpoints for 26001 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 05:52:51.061892: step 26000, loss = 0.80 (187.3 examples/sec; 1.367 sec/batch)\n",
      "2017-05-28 05:52:58.327347: step 26010, loss = 0.84 (352.4 examples/sec; 0.727 sec/batch)\n",
      "2017-05-28 05:53:06.564295: step 26020, loss = 0.79 (310.8 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 05:53:15.196618: step 26030, loss = 0.89 (296.6 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 05:53:23.437641: step 26040, loss = 0.82 (310.6 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 05:53:31.373291: step 26050, loss = 0.96 (322.6 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 05:53:39.887219: step 26060, loss = 0.73 (300.7 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 05:53:48.261352: step 26070, loss = 0.84 (305.7 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 05:53:56.381980: step 26080, loss = 0.80 (315.2 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 05:54:04.433040: step 26090, loss = 0.81 (318.0 examples/sec; 0.805 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14055\n",
      "2017-05-28 05:54:17.297919: step 26100, loss = 0.82 (199.0 examples/sec; 1.286 sec/batch)\n",
      "2017-05-28 05:54:24.915978: step 26110, loss = 0.91 (336.0 examples/sec; 0.762 sec/batch)\n",
      "2017-05-28 05:54:32.798299: step 26120, loss = 0.72 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 05:54:41.241397: step 26130, loss = 0.88 (303.2 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 05:54:49.360775: step 26140, loss = 0.76 (315.3 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 05:54:57.963329: step 26150, loss = 0.89 (297.6 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 05:55:06.188116: step 26160, loss = 0.78 (311.3 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 05:55:14.605205: step 26170, loss = 0.79 (304.1 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 05:55:23.226334: step 26180, loss = 0.91 (296.9 examples/sec; 0.862 sec/batch)\n",
      "2017-05-28 05:55:31.218090: step 26190, loss = 0.81 (320.3 examples/sec; 0.799 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14905\n",
      "2017-05-28 05:55:44.326405: step 26200, loss = 0.87 (195.3 examples/sec; 1.311 sec/batch)\n",
      "2017-05-28 05:55:51.690012: step 26210, loss = 0.83 (347.7 examples/sec; 0.736 sec/batch)\n",
      "2017-05-28 05:55:59.659607: step 26220, loss = 0.83 (321.2 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 05:56:08.008258: step 26230, loss = 0.88 (306.6 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 05:56:16.369779: step 26240, loss = 0.87 (306.2 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 05:56:24.408182: step 26250, loss = 0.86 (318.5 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 05:56:32.400468: step 26260, loss = 0.88 (320.3 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 05:56:40.982290: step 26270, loss = 0.99 (298.3 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 05:56:49.289238: step 26280, loss = 0.81 (308.2 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 05:56:57.307278: step 26290, loss = 0.89 (319.3 examples/sec; 0.802 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1761\n",
      "2017-05-28 05:57:09.353914: step 26300, loss = 0.84 (212.5 examples/sec; 1.205 sec/batch)\n",
      "2017-05-28 05:57:17.449010: step 26310, loss = 0.81 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 05:57:27.139226: step 26320, loss = 0.79 (264.2 examples/sec; 0.969 sec/batch)\n",
      "2017-05-28 05:57:35.404849: step 26330, loss = 0.85 (309.7 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 05:57:44.240248: step 26340, loss = 0.80 (289.7 examples/sec; 0.884 sec/batch)\n",
      "2017-05-28 05:57:52.969564: step 26350, loss = 0.97 (293.3 examples/sec; 0.873 sec/batch)\n",
      "2017-05-28 05:58:01.539130: step 26360, loss = 0.74 (298.7 examples/sec; 0.857 sec/batch)\n",
      "2017-05-28 05:58:10.495344: step 26370, loss = 0.77 (285.8 examples/sec; 0.896 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 05:58:19.331199: step 26380, loss = 0.86 (289.7 examples/sec; 0.884 sec/batch)\n",
      "2017-05-28 05:58:27.623918: step 26390, loss = 0.78 (308.7 examples/sec; 0.829 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.09499\n",
      "2017-05-28 05:58:40.677814: step 26400, loss = 0.91 (196.1 examples/sec; 1.305 sec/batch)\n",
      "2017-05-28 05:58:48.177380: step 26410, loss = 0.92 (341.4 examples/sec; 0.750 sec/batch)\n",
      "2017-05-28 05:58:56.296234: step 26420, loss = 0.81 (315.3 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 05:59:04.837679: step 26430, loss = 0.80 (299.7 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 05:59:13.745565: step 26440, loss = 0.79 (287.4 examples/sec; 0.891 sec/batch)\n",
      "2017-05-28 05:59:21.930500: step 26450, loss = 0.96 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 05:59:31.184292: step 26460, loss = 0.85 (276.6 examples/sec; 0.925 sec/batch)\n",
      "2017-05-28 05:59:40.016099: step 26470, loss = 0.77 (289.9 examples/sec; 0.883 sec/batch)\n",
      "2017-05-28 05:59:48.812694: step 26480, loss = 0.83 (291.0 examples/sec; 0.880 sec/batch)\n",
      "2017-05-28 05:59:57.029686: step 26490, loss = 0.78 (311.5 examples/sec; 0.822 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11105\n",
      "2017-05-28 06:00:10.685430: step 26500, loss = 0.83 (187.5 examples/sec; 1.366 sec/batch)\n",
      "2017-05-28 06:00:18.101958: step 26510, loss = 0.77 (345.2 examples/sec; 0.742 sec/batch)\n",
      "2017-05-28 06:00:27.034077: step 26520, loss = 0.87 (286.6 examples/sec; 0.893 sec/batch)\n",
      "2017-05-28 06:00:35.347407: step 26530, loss = 0.83 (307.9 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 06:00:43.571709: step 26540, loss = 0.70 (311.3 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 06:00:52.319284: step 26550, loss = 0.75 (292.7 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 06:01:00.603939: step 26560, loss = 0.84 (309.0 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 06:01:08.900510: step 26570, loss = 0.80 (308.6 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 06:01:17.700423: step 26580, loss = 0.83 (290.9 examples/sec; 0.880 sec/batch)\n",
      "2017-05-28 06:01:26.174594: step 26590, loss = 0.93 (302.1 examples/sec; 0.847 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11922\n",
      "2017-05-28 06:01:40.033991: step 26600, loss = 0.83 (184.7 examples/sec; 1.386 sec/batch)\n",
      "2017-05-28 06:01:47.601413: step 26610, loss = 0.88 (338.3 examples/sec; 0.757 sec/batch)\n",
      "2017-05-28 06:01:55.757033: step 26620, loss = 0.85 (313.9 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 06:02:03.902277: step 26630, loss = 0.72 (314.3 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 06:02:12.118763: step 26640, loss = 0.82 (311.6 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 06:02:20.809396: step 26650, loss = 0.67 (294.6 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 06:02:29.585924: step 26660, loss = 0.92 (291.7 examples/sec; 0.878 sec/batch)\n",
      "2017-05-28 06:02:38.614281: step 26670, loss = 0.83 (283.6 examples/sec; 0.903 sec/batch)\n",
      "2017-05-28 06:02:47.239367: step 26680, loss = 0.85 (296.8 examples/sec; 0.863 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 26684 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 06:02:56.138594: step 26690, loss = 0.81 (287.7 examples/sec; 0.890 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12725\n",
      "2017-05-28 06:03:08.741933: step 26700, loss = 0.79 (203.1 examples/sec; 1.260 sec/batch)\n",
      "2017-05-28 06:03:16.259573: step 26710, loss = 0.90 (340.5 examples/sec; 0.752 sec/batch)\n",
      "2017-05-28 06:03:25.405353: step 26720, loss = 0.83 (279.9 examples/sec; 0.915 sec/batch)\n",
      "2017-05-28 06:03:33.538884: step 26730, loss = 0.88 (314.7 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 06:03:42.199176: step 26740, loss = 0.89 (295.6 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 06:03:50.495048: step 26750, loss = 0.82 (308.6 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 06:03:58.591157: step 26760, loss = 0.83 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 06:04:06.817106: step 26770, loss = 0.81 (311.2 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 06:04:15.282666: step 26780, loss = 0.99 (302.4 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 06:04:23.820660: step 26790, loss = 0.81 (299.8 examples/sec; 0.854 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14366\n",
      "2017-05-28 06:04:36.184684: step 26800, loss = 0.83 (207.1 examples/sec; 1.236 sec/batch)\n",
      "2017-05-28 06:04:43.655214: step 26810, loss = 0.94 (342.7 examples/sec; 0.747 sec/batch)\n",
      "2017-05-28 06:04:52.248513: step 26820, loss = 0.85 (297.9 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 06:05:00.729113: step 26830, loss = 0.95 (301.9 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 06:05:08.873636: step 26840, loss = 0.78 (314.3 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 06:05:17.705105: step 26850, loss = 0.83 (289.9 examples/sec; 0.883 sec/batch)\n",
      "2017-05-28 06:05:26.013993: step 26860, loss = 0.79 (308.1 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 06:05:34.241322: step 26870, loss = 0.92 (311.2 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 06:05:42.998293: step 26880, loss = 0.81 (292.3 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 06:05:51.340131: step 26890, loss = 0.89 (306.9 examples/sec; 0.834 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14879\n",
      "2017-05-28 06:06:03.229404: step 26900, loss = 0.80 (215.3 examples/sec; 1.189 sec/batch)\n",
      "2017-05-28 06:06:10.718589: step 26910, loss = 1.04 (341.8 examples/sec; 0.749 sec/batch)\n",
      "2017-05-28 06:06:19.504078: step 26920, loss = 0.85 (291.4 examples/sec; 0.879 sec/batch)\n",
      "2017-05-28 06:06:27.803928: step 26930, loss = 0.75 (308.4 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 06:06:36.301544: step 26940, loss = 0.82 (301.3 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 06:06:44.762434: step 26950, loss = 0.80 (302.6 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 06:06:52.991933: step 26960, loss = 0.63 (311.1 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 06:07:01.683543: step 26970, loss = 0.88 (294.5 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 06:07:09.836729: step 26980, loss = 0.72 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 06:07:17.999226: step 26990, loss = 0.80 (313.6 examples/sec; 0.816 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15597\n",
      "2017-05-28 06:07:29.739431: step 27000, loss = 0.88 (218.1 examples/sec; 1.174 sec/batch)\n",
      "2017-05-28 06:07:38.919166: step 27010, loss = 0.73 (278.9 examples/sec; 0.918 sec/batch)\n",
      "2017-05-28 06:07:47.738791: step 27020, loss = 0.86 (290.3 examples/sec; 0.882 sec/batch)\n",
      "2017-05-28 06:07:56.552766: step 27030, loss = 0.80 (290.4 examples/sec; 0.881 sec/batch)\n",
      "2017-05-28 06:08:04.794110: step 27040, loss = 0.95 (310.6 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 06:08:13.697309: step 27050, loss = 0.83 (287.5 examples/sec; 0.890 sec/batch)\n",
      "2017-05-28 06:08:21.952966: step 27060, loss = 0.76 (310.1 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 06:08:30.635469: step 27070, loss = 0.90 (294.8 examples/sec; 0.868 sec/batch)\n",
      "2017-05-28 06:08:39.013662: step 27080, loss = 0.75 (305.6 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 06:08:47.212039: step 27090, loss = 0.96 (312.3 examples/sec; 0.820 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.09837\n",
      "2017-05-28 06:09:00.781120: step 27100, loss = 0.72 (188.7 examples/sec; 1.357 sec/batch)\n",
      "2017-05-28 06:09:08.267333: step 27110, loss = 0.83 (342.0 examples/sec; 0.749 sec/batch)\n",
      "2017-05-28 06:09:16.814233: step 27120, loss = 0.73 (299.5 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 06:09:25.174619: step 27130, loss = 0.81 (306.2 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 06:09:33.296676: step 27140, loss = 0.72 (315.2 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 06:09:41.855107: step 27150, loss = 0.72 (299.1 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 06:09:50.539470: step 27160, loss = 0.81 (294.8 examples/sec; 0.868 sec/batch)\n",
      "2017-05-28 06:09:58.615601: step 27170, loss = 0.83 (317.0 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 06:10:06.816022: step 27180, loss = 0.82 (312.2 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 06:10:15.524250: step 27190, loss = 0.79 (294.0 examples/sec; 0.871 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15325\n",
      "2017-05-28 06:10:27.491744: step 27200, loss = 0.84 (213.9 examples/sec; 1.197 sec/batch)\n",
      "2017-05-28 06:10:34.919920: step 27210, loss = 0.82 (344.6 examples/sec; 0.743 sec/batch)\n",
      "2017-05-28 06:10:43.593950: step 27220, loss = 0.85 (295.1 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 06:10:51.891401: step 27230, loss = 0.85 (308.5 examples/sec; 0.830 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 06:10:59.899029: step 27240, loss = 0.84 (319.7 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 06:11:08.341130: step 27250, loss = 0.85 (303.2 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 06:11:16.836358: step 27260, loss = 0.84 (301.3 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 06:11:25.373094: step 27270, loss = 0.76 (299.9 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 06:11:34.633009: step 27280, loss = 0.72 (276.5 examples/sec; 0.926 sec/batch)\n",
      "2017-05-28 06:11:42.988262: step 27290, loss = 0.77 (306.4 examples/sec; 0.836 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12226\n",
      "2017-05-28 06:11:56.600967: step 27300, loss = 0.88 (188.1 examples/sec; 1.361 sec/batch)\n",
      "2017-05-28 06:12:04.156229: step 27310, loss = 0.77 (338.8 examples/sec; 0.756 sec/batch)\n",
      "2017-05-28 06:12:12.282283: step 27320, loss = 0.74 (315.0 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 06:12:20.997825: step 27330, loss = 0.83 (293.7 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 06:12:29.050830: step 27340, loss = 0.97 (317.9 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 06:12:37.094200: step 27350, loss = 0.80 (318.3 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 06:12:45.594481: step 27360, loss = 0.95 (301.2 examples/sec; 0.850 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 27367 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 06:12:54.491094: step 27370, loss = 0.79 (287.8 examples/sec; 0.890 sec/batch)\n",
      "2017-05-28 06:13:04.141288: step 27380, loss = 0.84 (265.3 examples/sec; 0.965 sec/batch)\n",
      "2017-05-28 06:13:12.952686: step 27390, loss = 0.76 (290.5 examples/sec; 0.881 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.09573\n",
      "2017-05-28 06:13:27.865663: step 27400, loss = 0.85 (171.7 examples/sec; 1.491 sec/batch)\n",
      "2017-05-28 06:13:35.188570: step 27410, loss = 0.76 (349.6 examples/sec; 0.732 sec/batch)\n",
      "2017-05-28 06:13:43.303603: step 27420, loss = 0.84 (315.5 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 06:13:51.773349: step 27430, loss = 0.76 (302.3 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 06:14:00.256224: step 27440, loss = 0.82 (301.8 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 06:14:08.435839: step 27450, loss = 0.85 (313.0 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 06:14:16.553347: step 27460, loss = 0.86 (315.4 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 06:14:25.264405: step 27470, loss = 0.88 (293.9 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 06:14:33.403957: step 27480, loss = 0.78 (314.5 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 06:14:42.142572: step 27490, loss = 0.82 (293.0 examples/sec; 0.874 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15781\n",
      "2017-05-28 06:14:54.231314: step 27500, loss = 0.88 (211.8 examples/sec; 1.209 sec/batch)\n",
      "2017-05-28 06:15:01.655931: step 27510, loss = 0.79 (344.8 examples/sec; 0.742 sec/batch)\n",
      "2017-05-28 06:15:09.801374: step 27520, loss = 0.79 (314.3 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 06:15:18.490243: step 27530, loss = 0.89 (294.6 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 06:15:26.852590: step 27540, loss = 0.76 (306.1 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 06:15:35.239838: step 27550, loss = 0.84 (305.2 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 06:15:43.781931: step 27560, loss = 0.85 (299.7 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 06:15:52.012054: step 27570, loss = 0.85 (311.1 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 06:16:00.169928: step 27580, loss = 0.84 (313.8 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 06:16:08.372449: step 27590, loss = 0.86 (312.1 examples/sec; 0.820 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14745\n",
      "2017-05-28 06:16:21.381548: step 27600, loss = 0.87 (196.8 examples/sec; 1.301 sec/batch)\n",
      "2017-05-28 06:16:28.887969: step 27610, loss = 0.80 (341.0 examples/sec; 0.751 sec/batch)\n",
      "2017-05-28 06:16:37.114432: step 27620, loss = 0.76 (311.2 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 06:16:45.840081: step 27630, loss = 0.89 (293.4 examples/sec; 0.873 sec/batch)\n",
      "2017-05-28 06:16:54.025346: step 27640, loss = 0.83 (312.8 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 06:17:02.616767: step 27650, loss = 0.89 (298.0 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 06:17:10.936791: step 27660, loss = 0.81 (307.7 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 06:17:19.081203: step 27670, loss = 0.87 (314.3 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 06:17:27.471343: step 27680, loss = 0.82 (305.1 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 06:17:36.125820: step 27690, loss = 0.83 (295.8 examples/sec; 0.865 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12772\n",
      "2017-05-28 06:17:50.057500: step 27700, loss = 0.76 (183.8 examples/sec; 1.393 sec/batch)\n",
      "2017-05-28 06:17:57.551936: step 27710, loss = 0.89 (341.6 examples/sec; 0.749 sec/batch)\n",
      "2017-05-28 06:18:05.720290: step 27720, loss = 0.77 (313.4 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 06:18:15.491723: step 27730, loss = 0.90 (262.0 examples/sec; 0.977 sec/batch)\n",
      "2017-05-28 06:18:24.241696: step 27740, loss = 0.76 (292.6 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 06:18:32.525907: step 27750, loss = 0.77 (309.0 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 06:18:41.318764: step 27760, loss = 0.78 (291.1 examples/sec; 0.879 sec/batch)\n",
      "2017-05-28 06:18:49.508050: step 27770, loss = 0.90 (312.6 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 06:18:57.869647: step 27780, loss = 0.79 (306.2 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 06:19:06.123552: step 27790, loss = 0.77 (310.2 examples/sec; 0.825 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11101\n",
      "2017-05-28 06:19:20.063983: step 27800, loss = 0.77 (183.6 examples/sec; 1.394 sec/batch)\n",
      "2017-05-28 06:19:27.461970: step 27810, loss = 0.86 (346.0 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 06:19:35.625167: step 27820, loss = 0.68 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 06:19:44.435950: step 27830, loss = 0.87 (290.6 examples/sec; 0.881 sec/batch)\n",
      "2017-05-28 06:19:52.724707: step 27840, loss = 0.83 (308.9 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 06:20:01.275216: step 27850, loss = 0.89 (299.4 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 06:20:09.698208: step 27860, loss = 0.78 (303.9 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 06:20:17.842628: step 27870, loss = 0.73 (314.3 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 06:20:26.749913: step 27880, loss = 0.77 (287.4 examples/sec; 0.891 sec/batch)\n",
      "2017-05-28 06:20:35.055380: step 27890, loss = 0.64 (308.2 examples/sec; 0.831 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12296\n",
      "2017-05-28 06:20:49.117375: step 27900, loss = 0.76 (182.1 examples/sec; 1.406 sec/batch)\n",
      "2017-05-28 06:20:56.774888: step 27910, loss = 0.96 (334.3 examples/sec; 0.766 sec/batch)\n",
      "2017-05-28 06:21:04.952747: step 27920, loss = 0.70 (313.0 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 06:21:13.721548: step 27930, loss = 0.83 (291.9 examples/sec; 0.877 sec/batch)\n",
      "2017-05-28 06:21:21.989019: step 27940, loss = 0.84 (309.6 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 06:21:30.131706: step 27950, loss = 0.90 (314.4 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 06:21:38.903831: step 27960, loss = 0.93 (291.8 examples/sec; 0.877 sec/batch)\n",
      "2017-05-28 06:21:47.302534: step 27970, loss = 0.88 (304.8 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 06:21:55.721709: step 27980, loss = 0.83 (304.1 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 06:22:04.392006: step 27990, loss = 0.84 (295.3 examples/sec; 0.867 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12329\n",
      "2017-05-28 06:22:18.140410: step 28000, loss = 0.92 (186.2 examples/sec; 1.375 sec/batch)\n",
      "2017-05-28 06:22:25.864719: step 28010, loss = 0.78 (331.4 examples/sec; 0.772 sec/batch)\n",
      "2017-05-28 06:22:34.052044: step 28020, loss = 0.77 (312.7 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 06:22:42.243576: step 28030, loss = 0.81 (312.5 examples/sec; 0.819 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 28041 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 06:22:52.820679: step 28040, loss = 0.82 (242.0 examples/sec; 1.058 sec/batch)\n",
      "2017-05-28 06:23:00.639014: step 28050, loss = 0.80 (327.4 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 06:23:08.885005: step 28060, loss = 0.79 (310.5 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 06:23:17.509606: step 28070, loss = 0.89 (296.8 examples/sec; 0.862 sec/batch)\n",
      "2017-05-28 06:23:26.491346: step 28080, loss = 0.77 (285.0 examples/sec; 0.898 sec/batch)\n",
      "2017-05-28 06:23:35.479803: step 28090, loss = 0.90 (284.8 examples/sec; 0.899 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.09758\n",
      "2017-05-28 06:23:49.250785: step 28100, loss = 0.93 (185.9 examples/sec; 1.377 sec/batch)\n",
      "2017-05-28 06:23:56.980022: step 28110, loss = 0.84 (331.2 examples/sec; 0.773 sec/batch)\n",
      "2017-05-28 06:24:05.337956: step 28120, loss = 0.83 (306.3 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 06:24:13.513965: step 28130, loss = 0.83 (313.1 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 06:24:22.317199: step 28140, loss = 0.82 (290.8 examples/sec; 0.880 sec/batch)\n",
      "2017-05-28 06:24:30.511192: step 28150, loss = 0.96 (312.4 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 06:24:38.698688: step 28160, loss = 0.79 (312.7 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 06:24:47.359416: step 28170, loss = 0.78 (295.6 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 06:24:55.705000: step 28180, loss = 0.87 (306.7 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 06:25:04.023000: step 28190, loss = 0.91 (307.8 examples/sec; 0.832 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12031\n",
      "2017-05-28 06:25:18.508890: step 28200, loss = 0.79 (176.7 examples/sec; 1.449 sec/batch)\n",
      "2017-05-28 06:25:25.970901: step 28210, loss = 0.89 (343.1 examples/sec; 0.746 sec/batch)\n",
      "2017-05-28 06:25:34.581812: step 28220, loss = 0.68 (297.3 examples/sec; 0.861 sec/batch)\n",
      "2017-05-28 06:25:43.024263: step 28230, loss = 0.81 (303.2 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 06:25:51.451593: step 28240, loss = 0.88 (303.8 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 06:25:59.804726: step 28250, loss = 0.63 (306.5 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 06:26:08.212423: step 28260, loss = 0.91 (304.5 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 06:26:16.498590: step 28270, loss = 0.75 (308.9 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 06:26:25.165964: step 28280, loss = 0.73 (295.4 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 06:26:33.450606: step 28290, loss = 0.77 (309.0 examples/sec; 0.828 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1455\n",
      "2017-05-28 06:26:45.806644: step 28300, loss = 0.70 (207.2 examples/sec; 1.236 sec/batch)\n",
      "2017-05-28 06:26:53.240684: step 28310, loss = 0.86 (344.4 examples/sec; 0.743 sec/batch)\n",
      "2017-05-28 06:27:02.079933: step 28320, loss = 0.81 (289.6 examples/sec; 0.884 sec/batch)\n",
      "2017-05-28 06:27:10.179589: step 28330, loss = 0.69 (316.1 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 06:27:18.767986: step 28340, loss = 0.87 (298.1 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 06:27:27.126232: step 28350, loss = 0.83 (306.3 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 06:27:35.467422: step 28360, loss = 0.95 (306.9 examples/sec; 0.834 sec/batch)\n",
      "2017-05-28 06:27:44.112759: step 28370, loss = 0.82 (296.1 examples/sec; 0.865 sec/batch)\n",
      "2017-05-28 06:27:52.424551: step 28380, loss = 0.89 (308.0 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 06:28:01.410051: step 28390, loss = 0.84 (284.9 examples/sec; 0.899 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1384\n",
      "2017-05-28 06:28:13.649976: step 28400, loss = 0.82 (209.2 examples/sec; 1.224 sec/batch)\n",
      "2017-05-28 06:28:21.085401: step 28410, loss = 0.92 (344.3 examples/sec; 0.744 sec/batch)\n",
      "2017-05-28 06:28:31.439264: step 28420, loss = 0.94 (247.3 examples/sec; 1.035 sec/batch)\n",
      "2017-05-28 06:28:39.851752: step 28430, loss = 0.95 (304.3 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 06:28:48.637482: step 28440, loss = 0.80 (291.4 examples/sec; 0.879 sec/batch)\n",
      "2017-05-28 06:28:56.971049: step 28450, loss = 0.75 (307.2 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 06:29:05.257671: step 28460, loss = 0.82 (308.9 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 06:29:13.732380: step 28470, loss = 0.87 (302.1 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 06:29:22.292239: step 28480, loss = 0.79 (299.1 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 06:29:30.717013: step 28490, loss = 0.80 (303.9 examples/sec; 0.842 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.09106\n",
      "2017-05-28 06:29:45.305105: step 28500, loss = 0.83 (175.5 examples/sec; 1.459 sec/batch)\n",
      "2017-05-28 06:29:52.720113: step 28510, loss = 0.85 (345.2 examples/sec; 0.742 sec/batch)\n",
      "2017-05-28 06:30:01.089405: step 28520, loss = 0.87 (305.9 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 06:30:09.634210: step 28530, loss = 0.80 (299.6 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 06:30:17.951720: step 28540, loss = 0.75 (307.8 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 06:30:26.123269: step 28550, loss = 0.82 (313.3 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 06:30:35.056072: step 28560, loss = 0.86 (286.6 examples/sec; 0.893 sec/batch)\n",
      "2017-05-28 06:30:43.271942: step 28570, loss = 0.83 (311.6 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 06:30:51.511245: step 28580, loss = 0.83 (310.7 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 06:31:00.209015: step 28590, loss = 0.72 (294.3 examples/sec; 0.870 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14818\n",
      "2017-05-28 06:31:12.398108: step 28600, loss = 0.86 (210.0 examples/sec; 1.219 sec/batch)\n",
      "2017-05-28 06:31:19.777242: step 28610, loss = 0.83 (346.9 examples/sec; 0.738 sec/batch)\n",
      "2017-05-28 06:31:28.558671: step 28620, loss = 0.85 (291.5 examples/sec; 0.878 sec/batch)\n",
      "2017-05-28 06:31:36.972555: step 28630, loss = 0.91 (304.3 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 06:31:45.417813: step 28640, loss = 0.89 (303.1 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 06:31:53.927233: step 28650, loss = 0.79 (300.8 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 06:32:02.131538: step 28660, loss = 0.81 (312.0 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 06:32:10.459911: step 28670, loss = 0.96 (307.4 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 06:32:19.365748: step 28680, loss = 0.79 (287.5 examples/sec; 0.891 sec/batch)\n",
      "2017-05-28 06:32:27.481928: step 28690, loss = 0.83 (315.4 examples/sec; 0.812 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13242\n",
      "2017-05-28 06:32:40.706950: step 28700, loss = 0.81 (193.6 examples/sec; 1.323 sec/batch)\n",
      "2017-05-28 06:32:48.292360: step 28710, loss = 0.79 (337.5 examples/sec; 0.759 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 28714 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 06:32:57.187775: step 28720, loss = 0.89 (287.8 examples/sec; 0.890 sec/batch)\n",
      "2017-05-28 06:33:05.422102: step 28730, loss = 0.75 (310.9 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 06:33:14.176239: step 28740, loss = 0.88 (292.4 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 06:33:22.280756: step 28750, loss = 0.95 (315.9 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 06:33:30.430503: step 28760, loss = 0.83 (314.1 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 06:33:40.518717: step 28770, loss = 0.76 (253.8 examples/sec; 1.009 sec/batch)\n",
      "2017-05-28 06:33:49.155087: step 28780, loss = 0.84 (296.4 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 06:33:57.592828: step 28790, loss = 0.95 (303.4 examples/sec; 0.844 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10237\n",
      "2017-05-28 06:34:11.417995: step 28800, loss = 0.81 (185.2 examples/sec; 1.383 sec/batch)\n",
      "2017-05-28 06:34:18.758720: step 28810, loss = 0.79 (348.7 examples/sec; 0.734 sec/batch)\n",
      "2017-05-28 06:34:27.189782: step 28820, loss = 0.78 (303.6 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 06:34:35.878021: step 28830, loss = 0.84 (294.7 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 06:34:44.118971: step 28840, loss = 0.70 (310.6 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 06:34:52.319833: step 28850, loss = 0.82 (312.2 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 06:35:00.819205: step 28860, loss = 0.88 (301.2 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 06:35:09.561214: step 28870, loss = 0.77 (292.8 examples/sec; 0.874 sec/batch)\n",
      "2017-05-28 06:35:17.806099: step 28880, loss = 0.89 (310.5 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 06:35:26.007209: step 28890, loss = 0.79 (312.2 examples/sec; 0.820 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1296\n",
      "2017-05-28 06:35:39.946674: step 28900, loss = 0.90 (183.7 examples/sec; 1.394 sec/batch)\n",
      "2017-05-28 06:35:47.358604: step 28910, loss = 0.89 (345.4 examples/sec; 0.741 sec/batch)\n",
      "2017-05-28 06:35:55.648358: step 28920, loss = 0.88 (308.8 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 06:36:03.940083: step 28930, loss = 0.77 (308.7 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 06:36:12.537698: step 28940, loss = 0.79 (297.8 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 06:36:21.387299: step 28950, loss = 0.74 (289.3 examples/sec; 0.885 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 06:36:29.552930: step 28960, loss = 0.83 (313.5 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 06:36:38.343917: step 28970, loss = 0.89 (291.2 examples/sec; 0.879 sec/batch)\n",
      "2017-05-28 06:36:46.555488: step 28980, loss = 0.78 (311.8 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 06:36:54.664522: step 28990, loss = 0.90 (315.7 examples/sec; 0.811 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14766\n",
      "2017-05-28 06:37:07.081733: step 29000, loss = 0.77 (206.2 examples/sec; 1.242 sec/batch)\n",
      "2017-05-28 06:37:14.926921: step 29010, loss = 0.87 (326.3 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 06:37:23.027484: step 29020, loss = 0.86 (316.0 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 06:37:31.288618: step 29030, loss = 0.86 (309.9 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 06:37:39.883239: step 29040, loss = 0.79 (297.9 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 06:37:48.231505: step 29050, loss = 0.68 (306.7 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 06:37:56.391444: step 29060, loss = 0.80 (313.7 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 06:38:04.775986: step 29070, loss = 0.89 (305.3 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 06:38:13.492709: step 29080, loss = 0.86 (293.7 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 06:38:21.668198: step 29090, loss = 0.90 (313.1 examples/sec; 0.818 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13651\n",
      "2017-05-28 06:38:35.066954: step 29100, loss = 0.74 (191.1 examples/sec; 1.340 sec/batch)\n",
      "2017-05-28 06:38:42.499120: step 29110, loss = 0.81 (344.4 examples/sec; 0.743 sec/batch)\n",
      "2017-05-28 06:38:52.100058: step 29120, loss = 0.81 (266.6 examples/sec; 0.960 sec/batch)\n",
      "2017-05-28 06:39:00.885381: step 29130, loss = 0.77 (291.4 examples/sec; 0.879 sec/batch)\n",
      "2017-05-28 06:39:09.179251: step 29140, loss = 0.70 (308.7 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 06:39:18.067205: step 29150, loss = 0.81 (288.0 examples/sec; 0.889 sec/batch)\n",
      "2017-05-28 06:39:26.422487: step 29160, loss = 0.78 (306.4 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 06:39:34.968610: step 29170, loss = 0.78 (299.6 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 06:39:43.883244: step 29180, loss = 0.82 (287.2 examples/sec; 0.891 sec/batch)\n",
      "2017-05-28 06:39:52.284450: step 29190, loss = 0.82 (304.7 examples/sec; 0.840 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1276\n",
      "2017-05-28 06:40:03.757842: step 29200, loss = 0.69 (223.1 examples/sec; 1.147 sec/batch)\n",
      "2017-05-28 06:40:12.000343: step 29210, loss = 0.85 (310.6 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 06:40:20.453220: step 29220, loss = 0.88 (302.9 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 06:40:28.720958: step 29230, loss = 0.83 (309.6 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 06:40:37.362045: step 29240, loss = 0.71 (296.3 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 06:40:45.451951: step 29250, loss = 0.77 (316.4 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 06:40:53.636760: step 29260, loss = 0.72 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 06:41:01.748631: step 29270, loss = 0.75 (315.6 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 06:41:10.489136: step 29280, loss = 0.85 (292.9 examples/sec; 0.874 sec/batch)\n",
      "2017-05-28 06:41:18.555192: step 29290, loss = 0.76 (317.4 examples/sec; 0.807 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12936\n",
      "2017-05-28 06:41:32.297534: step 29300, loss = 0.93 (186.3 examples/sec; 1.374 sec/batch)\n",
      "2017-05-28 06:41:39.789771: step 29310, loss = 0.83 (341.7 examples/sec; 0.749 sec/batch)\n",
      "2017-05-28 06:41:47.997529: step 29320, loss = 0.78 (311.9 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 06:41:56.877058: step 29330, loss = 0.76 (288.3 examples/sec; 0.888 sec/batch)\n",
      "2017-05-28 06:42:05.095149: step 29340, loss = 0.79 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 06:42:13.205863: step 29350, loss = 0.73 (315.6 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 06:42:21.700583: step 29360, loss = 0.83 (301.4 examples/sec; 0.849 sec/batch)\n",
      "2017-05-28 06:42:30.211280: step 29370, loss = 0.84 (300.8 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 06:42:38.344871: step 29380, loss = 0.84 (314.7 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 06:42:46.413443: step 29390, loss = 0.76 (317.3 examples/sec; 0.807 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 29396 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.13727\n",
      "2017-05-28 06:43:00.226365: step 29400, loss = 0.79 (185.3 examples/sec; 1.381 sec/batch)\n",
      "2017-05-28 06:43:07.625321: step 29410, loss = 0.76 (346.0 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 06:43:15.770294: step 29420, loss = 0.85 (314.3 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 06:43:24.032230: step 29430, loss = 0.93 (309.9 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 06:43:32.761535: step 29440, loss = 0.91 (293.3 examples/sec; 0.873 sec/batch)\n",
      "2017-05-28 06:43:40.887360: step 29450, loss = 0.80 (315.0 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 06:43:49.052219: step 29460, loss = 0.86 (313.5 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 06:43:59.117037: step 29470, loss = 0.89 (254.4 examples/sec; 1.006 sec/batch)\n",
      "2017-05-28 06:44:07.996762: step 29480, loss = 0.86 (288.3 examples/sec; 0.888 sec/batch)\n",
      "2017-05-28 06:44:16.547305: step 29490, loss = 0.81 (299.4 examples/sec; 0.855 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11896\n",
      "2017-05-28 06:44:29.596160: step 29500, loss = 0.84 (196.2 examples/sec; 1.305 sec/batch)\n",
      "2017-05-28 06:44:37.079761: step 29510, loss = 0.89 (342.1 examples/sec; 0.748 sec/batch)\n",
      "2017-05-28 06:44:45.259768: step 29520, loss = 0.76 (313.0 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 06:44:54.002705: step 29530, loss = 0.84 (292.8 examples/sec; 0.874 sec/batch)\n",
      "2017-05-28 06:45:02.212376: step 29540, loss = 0.82 (311.8 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 06:45:10.348732: step 29550, loss = 0.83 (314.6 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 06:45:18.930542: step 29560, loss = 0.70 (298.3 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 06:45:27.434185: step 29570, loss = 0.96 (301.0 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 06:45:35.732565: step 29580, loss = 0.81 (308.5 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 06:45:44.017781: step 29590, loss = 0.85 (309.0 examples/sec; 0.829 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14912\n",
      "2017-05-28 06:45:56.618895: step 29600, loss = 0.80 (203.2 examples/sec; 1.260 sec/batch)\n",
      "2017-05-28 06:46:04.133792: step 29610, loss = 0.73 (340.7 examples/sec; 0.751 sec/batch)\n",
      "2017-05-28 06:46:12.817230: step 29620, loss = 0.80 (294.8 examples/sec; 0.868 sec/batch)\n",
      "2017-05-28 06:46:20.926517: step 29630, loss = 0.93 (315.7 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 06:46:29.040237: step 29640, loss = 0.92 (315.5 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 06:46:37.313613: step 29650, loss = 0.79 (309.4 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 06:46:45.434560: step 29660, loss = 0.82 (315.2 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 06:46:54.197114: step 29670, loss = 0.86 (292.2 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 06:47:02.389178: step 29680, loss = 0.78 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 06:47:10.959921: step 29690, loss = 0.75 (298.7 examples/sec; 0.857 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15469\n",
      "2017-05-28 06:47:23.223277: step 29700, loss = 0.73 (208.8 examples/sec; 1.226 sec/batch)\n",
      "2017-05-28 06:47:30.668098: step 29710, loss = 0.79 (343.9 examples/sec; 0.744 sec/batch)\n",
      "2017-05-28 06:47:38.793250: step 29720, loss = 0.77 (315.1 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 06:47:47.382076: step 29730, loss = 0.88 (298.1 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 06:47:55.763457: step 29740, loss = 0.70 (305.4 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 06:48:04.025742: step 29750, loss = 0.66 (309.8 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 06:48:12.686512: step 29760, loss = 0.74 (295.6 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 06:48:20.830554: step 29770, loss = 0.89 (314.3 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 06:48:29.556970: step 29780, loss = 0.82 (293.4 examples/sec; 0.873 sec/batch)\n",
      "2017-05-28 06:48:37.846254: step 29790, loss = 0.81 (308.8 examples/sec; 0.829 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15295\n",
      "2017-05-28 06:48:49.956895: step 29800, loss = 0.94 (211.4 examples/sec; 1.211 sec/batch)\n",
      "2017-05-28 06:48:57.819176: step 29810, loss = 0.76 (325.6 examples/sec; 0.786 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 06:49:06.877081: step 29820, loss = 0.82 (282.6 examples/sec; 0.906 sec/batch)\n",
      "2017-05-28 06:49:15.762445: step 29830, loss = 0.77 (288.1 examples/sec; 0.889 sec/batch)\n",
      "2017-05-28 06:49:24.606905: step 29840, loss = 0.86 (289.4 examples/sec; 0.884 sec/batch)\n",
      "2017-05-28 06:49:33.005278: step 29850, loss = 0.81 (304.8 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 06:49:41.237357: step 29860, loss = 0.77 (311.0 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 06:49:49.388646: step 29870, loss = 0.79 (314.1 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 06:49:57.795203: step 29880, loss = 0.74 (304.5 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 06:50:06.403064: step 29890, loss = 0.89 (297.4 examples/sec; 0.861 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1028\n",
      "2017-05-28 06:50:20.636711: step 29900, loss = 0.93 (179.9 examples/sec; 1.423 sec/batch)\n",
      "2017-05-28 06:50:27.984734: step 29910, loss = 0.77 (348.4 examples/sec; 0.735 sec/batch)\n",
      "2017-05-28 06:50:36.194481: step 29920, loss = 0.84 (311.8 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 06:50:45.104534: step 29930, loss = 0.94 (287.3 examples/sec; 0.891 sec/batch)\n",
      "2017-05-28 06:50:53.267851: step 29940, loss = 0.73 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 06:51:01.455484: step 29950, loss = 0.86 (312.7 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 06:51:09.567217: step 29960, loss = 0.97 (315.6 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 06:51:17.663747: step 29970, loss = 0.84 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 06:51:26.414308: step 29980, loss = 0.85 (292.6 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 06:51:34.654590: step 29990, loss = 0.83 (310.7 examples/sec; 0.824 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13872\n",
      "2017-05-28 06:51:48.453196: step 30000, loss = 0.73 (185.5 examples/sec; 1.380 sec/batch)\n",
      "2017-05-28 06:51:55.810417: step 30010, loss = 0.84 (348.0 examples/sec; 0.736 sec/batch)\n",
      "2017-05-28 06:52:03.940835: step 30020, loss = 0.81 (314.9 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 06:52:12.651500: step 30030, loss = 0.81 (293.9 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 06:52:20.914355: step 30040, loss = 0.85 (309.8 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 06:52:29.076118: step 30050, loss = 0.87 (313.7 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 06:52:37.378713: step 30060, loss = 0.73 (308.3 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 06:52:46.072941: step 30070, loss = 0.76 (294.4 examples/sec; 0.869 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 30077 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 06:52:55.055834: step 30080, loss = 1.02 (285.0 examples/sec; 0.898 sec/batch)\n",
      "2017-05-28 06:53:03.216381: step 30090, loss = 0.96 (313.7 examples/sec; 0.816 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13965\n",
      "2017-05-28 06:53:16.198420: step 30100, loss = 0.92 (197.2 examples/sec; 1.298 sec/batch)\n",
      "2017-05-28 06:53:23.630684: step 30110, loss = 0.87 (344.4 examples/sec; 0.743 sec/batch)\n",
      "2017-05-28 06:53:31.895231: step 30120, loss = 0.76 (309.8 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 06:53:40.138586: step 30130, loss = 0.94 (310.6 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 06:53:48.805564: step 30140, loss = 0.72 (295.4 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 06:53:56.978972: step 30150, loss = 0.85 (313.2 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 06:54:05.131946: step 30160, loss = 0.82 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 06:54:15.053443: step 30170, loss = 0.84 (258.0 examples/sec; 0.992 sec/batch)\n",
      "2017-05-28 06:54:24.052924: step 30180, loss = 0.76 (284.5 examples/sec; 0.900 sec/batch)\n",
      "2017-05-28 06:54:32.463302: step 30190, loss = 0.82 (304.4 examples/sec; 0.841 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11713\n",
      "2017-05-28 06:54:45.714767: step 30200, loss = 0.78 (193.2 examples/sec; 1.325 sec/batch)\n",
      "2017-05-28 06:54:53.105099: step 30210, loss = 0.91 (346.4 examples/sec; 0.739 sec/batch)\n",
      "2017-05-28 06:55:01.771681: step 30220, loss = 0.81 (295.4 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 06:55:10.058632: step 30230, loss = 0.82 (308.9 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 06:55:18.215905: step 30240, loss = 0.76 (313.8 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 06:55:26.359680: step 30250, loss = 0.87 (314.4 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 06:55:35.026177: step 30260, loss = 0.79 (295.4 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 06:55:43.473160: step 30270, loss = 0.76 (303.1 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 06:55:51.691714: step 30280, loss = 0.77 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 06:56:00.255376: step 30290, loss = 0.73 (298.9 examples/sec; 0.856 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14783\n",
      "2017-05-28 06:56:12.834968: step 30300, loss = 0.83 (203.5 examples/sec; 1.258 sec/batch)\n",
      "2017-05-28 06:56:20.316502: step 30310, loss = 0.77 (342.2 examples/sec; 0.748 sec/batch)\n",
      "2017-05-28 06:56:28.523795: step 30320, loss = 0.79 (311.9 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 06:56:37.127862: step 30330, loss = 0.95 (297.5 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 06:56:45.244950: step 30340, loss = 0.85 (315.4 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 06:56:53.996154: step 30350, loss = 0.80 (292.5 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 06:57:02.244321: step 30360, loss = 0.77 (310.4 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 06:57:10.395140: step 30370, loss = 0.99 (314.1 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 06:57:18.413932: step 30380, loss = 0.79 (319.3 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 06:57:26.492399: step 30390, loss = 0.72 (316.9 examples/sec; 0.808 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13915\n",
      "2017-05-28 06:57:40.620485: step 30400, loss = 0.78 (181.2 examples/sec; 1.413 sec/batch)\n",
      "2017-05-28 06:57:48.017604: step 30410, loss = 0.77 (346.1 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 06:57:56.187411: step 30420, loss = 0.76 (313.3 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 06:58:04.906384: step 30430, loss = 0.78 (293.6 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 06:58:13.209243: step 30440, loss = 0.81 (308.3 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 06:58:21.407475: step 30450, loss = 0.82 (312.3 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 06:58:29.842602: step 30460, loss = 0.73 (303.5 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 06:58:38.559834: step 30470, loss = 0.89 (293.7 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 06:58:46.761693: step 30480, loss = 0.87 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 06:58:55.578993: step 30490, loss = 0.83 (290.3 examples/sec; 0.882 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13838\n",
      "2017-05-28 06:59:08.467481: step 30500, loss = 0.80 (198.6 examples/sec; 1.289 sec/batch)\n",
      "2017-05-28 06:59:16.260546: step 30510, loss = 0.75 (328.5 examples/sec; 0.779 sec/batch)\n",
      "2017-05-28 06:59:25.519324: step 30520, loss = 0.83 (276.5 examples/sec; 0.926 sec/batch)\n",
      "2017-05-28 06:59:34.082109: step 30530, loss = 0.88 (299.0 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 06:59:43.071033: step 30540, loss = 0.71 (284.8 examples/sec; 0.899 sec/batch)\n",
      "2017-05-28 06:59:51.591152: step 30550, loss = 0.86 (300.5 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 07:00:00.560196: step 30560, loss = 0.89 (285.4 examples/sec; 0.897 sec/batch)\n",
      "2017-05-28 07:00:08.903339: step 30570, loss = 0.75 (306.8 examples/sec; 0.834 sec/batch)\n",
      "2017-05-28 07:00:17.098639: step 30580, loss = 0.86 (312.4 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 07:00:25.357791: step 30590, loss = 0.84 (310.0 examples/sec; 0.826 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11714\n",
      "2017-05-28 07:00:37.981264: step 30600, loss = 0.87 (202.8 examples/sec; 1.262 sec/batch)\n",
      "2017-05-28 07:00:45.563917: step 30610, loss = 0.91 (337.5 examples/sec; 0.758 sec/batch)\n",
      "2017-05-28 07:00:53.813657: step 30620, loss = 0.86 (310.3 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 07:01:02.261003: step 30630, loss = 0.96 (303.1 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 07:01:10.888789: step 30640, loss = 0.81 (296.7 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 07:01:18.968861: step 30650, loss = 0.74 (316.8 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 07:01:27.739313: step 30660, loss = 0.71 (291.9 examples/sec; 0.877 sec/batch)\n",
      "2017-05-28 07:01:36.006115: step 30670, loss = 0.83 (309.7 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 07:01:44.693273: step 30680, loss = 0.77 (294.7 examples/sec; 0.869 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 07:01:53.123348: step 30690, loss = 0.80 (303.7 examples/sec; 0.843 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14758\n",
      "2017-05-28 07:02:05.118446: step 30700, loss = 0.72 (213.4 examples/sec; 1.200 sec/batch)\n",
      "2017-05-28 07:02:13.103513: step 30710, loss = 0.86 (320.6 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 07:02:21.527892: step 30720, loss = 0.94 (303.9 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 07:02:29.624680: step 30730, loss = 0.73 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 07:02:38.031385: step 30740, loss = 0.70 (304.5 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 07:02:46.676016: step 30750, loss = 0.91 (296.1 examples/sec; 0.864 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 30757 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 07:02:55.653291: step 30760, loss = 0.81 (285.2 examples/sec; 0.898 sec/batch)\n",
      "2017-05-28 07:03:03.882652: step 30770, loss = 0.86 (311.1 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 07:03:12.619055: step 30780, loss = 0.79 (293.0 examples/sec; 0.874 sec/batch)\n",
      "2017-05-28 07:03:20.862253: step 30790, loss = 0.73 (310.6 examples/sec; 0.824 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12423\n",
      "2017-05-28 07:03:34.070693: step 30800, loss = 0.75 (193.8 examples/sec; 1.321 sec/batch)\n",
      "2017-05-28 07:03:41.761916: step 30810, loss = 0.97 (332.8 examples/sec; 0.769 sec/batch)\n",
      "2017-05-28 07:03:49.931339: step 30820, loss = 0.83 (313.4 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 07:03:58.074577: step 30830, loss = 0.79 (314.4 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 07:04:06.320378: step 30840, loss = 0.84 (310.5 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 07:04:15.116199: step 30850, loss = 0.77 (291.0 examples/sec; 0.880 sec/batch)\n",
      "2017-05-28 07:04:23.320140: step 30860, loss = 0.90 (312.0 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 07:04:32.465352: step 30870, loss = 0.84 (279.9 examples/sec; 0.915 sec/batch)\n",
      "2017-05-28 07:04:41.088615: step 30880, loss = 0.75 (296.9 examples/sec; 0.862 sec/batch)\n",
      "2017-05-28 07:04:49.975610: step 30890, loss = 0.78 (288.1 examples/sec; 0.889 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1348\n",
      "2017-05-28 07:05:02.189968: step 30900, loss = 0.83 (209.6 examples/sec; 1.221 sec/batch)\n",
      "2017-05-28 07:05:09.751157: step 30910, loss = 0.74 (338.6 examples/sec; 0.756 sec/batch)\n",
      "2017-05-28 07:05:18.406529: step 30920, loss = 0.86 (295.8 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 07:05:26.700545: step 30930, loss = 0.86 (308.7 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 07:05:35.233207: step 30940, loss = 0.79 (300.0 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 07:05:43.735426: step 30950, loss = 0.81 (301.1 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 07:05:51.929149: step 30960, loss = 0.81 (312.4 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 07:06:00.695457: step 30970, loss = 0.68 (292.0 examples/sec; 0.877 sec/batch)\n",
      "2017-05-28 07:06:08.982737: step 30980, loss = 0.94 (308.9 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 07:06:17.209660: step 30990, loss = 0.82 (311.2 examples/sec; 0.823 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1334\n",
      "2017-05-28 07:06:30.422792: step 31000, loss = 0.85 (193.7 examples/sec; 1.321 sec/batch)\n",
      "2017-05-28 07:06:38.081247: step 31010, loss = 0.78 (334.3 examples/sec; 0.766 sec/batch)\n",
      "2017-05-28 07:06:46.232871: step 31020, loss = 0.91 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 07:06:54.423663: step 31030, loss = 0.80 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 07:07:02.558058: step 31040, loss = 0.87 (314.7 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 07:07:11.373920: step 31050, loss = 0.76 (290.4 examples/sec; 0.882 sec/batch)\n",
      "2017-05-28 07:07:19.614145: step 31060, loss = 0.96 (310.7 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 07:07:27.773954: step 31070, loss = 0.69 (313.7 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 07:07:35.908728: step 31080, loss = 0.86 (314.7 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 07:07:44.545734: step 31090, loss = 0.78 (296.4 examples/sec; 0.864 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15732\n",
      "2017-05-28 07:07:56.826261: step 31100, loss = 0.84 (208.5 examples/sec; 1.228 sec/batch)\n",
      "2017-05-28 07:08:04.662270: step 31110, loss = 0.88 (326.7 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 07:08:13.008667: step 31120, loss = 0.81 (306.7 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 07:08:21.061405: step 31130, loss = 0.77 (317.9 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 07:08:29.288420: step 31140, loss = 0.92 (311.2 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 07:08:38.088165: step 31150, loss = 0.77 (290.9 examples/sec; 0.880 sec/batch)\n",
      "2017-05-28 07:08:46.446652: step 31160, loss = 0.89 (306.3 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 07:08:55.171984: step 31170, loss = 0.91 (293.4 examples/sec; 0.873 sec/batch)\n",
      "2017-05-28 07:09:03.349619: step 31180, loss = 0.90 (313.0 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 07:09:11.999855: step 31190, loss = 0.86 (295.9 examples/sec; 0.865 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14708\n",
      "2017-05-28 07:09:24.003731: step 31200, loss = 0.84 (213.3 examples/sec; 1.200 sec/batch)\n",
      "2017-05-28 07:09:31.785854: step 31210, loss = 0.75 (329.0 examples/sec; 0.778 sec/batch)\n",
      "2017-05-28 07:09:41.421588: step 31220, loss = 0.80 (265.7 examples/sec; 0.964 sec/batch)\n",
      "2017-05-28 07:09:50.356219: step 31230, loss = 0.91 (286.5 examples/sec; 0.893 sec/batch)\n",
      "2017-05-28 07:09:58.953799: step 31240, loss = 0.89 (297.8 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 07:10:07.494953: step 31250, loss = 0.84 (299.7 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 07:10:15.854194: step 31260, loss = 0.80 (306.2 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 07:10:24.098833: step 31270, loss = 0.77 (310.5 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 07:10:32.235484: step 31280, loss = 0.80 (314.6 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 07:10:41.048220: step 31290, loss = 0.86 (290.5 examples/sec; 0.881 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11226\n",
      "2017-05-28 07:10:53.913923: step 31300, loss = 0.85 (199.0 examples/sec; 1.287 sec/batch)\n",
      "2017-05-28 07:11:01.648838: step 31310, loss = 0.79 (331.0 examples/sec; 0.773 sec/batch)\n",
      "2017-05-28 07:11:09.809101: step 31320, loss = 0.70 (313.7 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 07:11:18.093443: step 31330, loss = 0.78 (309.0 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 07:11:26.788581: step 31340, loss = 0.85 (294.4 examples/sec; 0.870 sec/batch)\n",
      "2017-05-28 07:11:35.002248: step 31350, loss = 0.80 (311.7 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 07:11:43.189415: step 31360, loss = 0.82 (312.7 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 07:11:51.638328: step 31370, loss = 0.86 (303.0 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 07:12:00.130457: step 31380, loss = 0.80 (301.5 examples/sec; 0.849 sec/batch)\n",
      "2017-05-28 07:12:08.367403: step 31390, loss = 0.72 (310.8 examples/sec; 0.824 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12412\n",
      "2017-05-28 07:12:22.870936: step 31400, loss = 0.71 (176.5 examples/sec; 1.450 sec/batch)\n",
      "2017-05-28 07:12:30.453214: step 31410, loss = 0.80 (337.6 examples/sec; 0.758 sec/batch)\n",
      "2017-05-28 07:12:38.625056: step 31420, loss = 0.84 (313.3 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 07:12:47.037248: step 31430, loss = 0.73 (304.3 examples/sec; 0.841 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 31437 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 07:12:56.540027: step 31440, loss = 0.85 (269.4 examples/sec; 0.950 sec/batch)\n",
      "2017-05-28 07:13:04.684345: step 31450, loss = 0.76 (314.3 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 07:13:13.389719: step 31460, loss = 0.82 (294.1 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 07:13:21.635230: step 31470, loss = 0.70 (310.5 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 07:13:29.784820: step 31480, loss = 0.81 (314.1 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 07:13:37.945563: step 31490, loss = 0.78 (313.7 examples/sec; 0.816 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12897\n",
      "2017-05-28 07:13:51.446066: step 31500, loss = 0.77 (189.6 examples/sec; 1.350 sec/batch)\n",
      "2017-05-28 07:13:58.848263: step 31510, loss = 0.77 (345.8 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 07:14:07.528875: step 31520, loss = 0.90 (294.9 examples/sec; 0.868 sec/batch)\n",
      "2017-05-28 07:14:15.754372: step 31530, loss = 0.76 (311.2 examples/sec; 0.823 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 07:14:24.026341: step 31540, loss = 0.75 (309.5 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 07:14:32.518604: step 31550, loss = 0.82 (301.5 examples/sec; 0.849 sec/batch)\n",
      "2017-05-28 07:14:40.943148: step 31560, loss = 0.89 (303.9 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 07:14:50.222692: step 31570, loss = 0.83 (275.9 examples/sec; 0.928 sec/batch)\n",
      "2017-05-28 07:14:59.115925: step 31580, loss = 0.92 (287.9 examples/sec; 0.889 sec/batch)\n",
      "2017-05-28 07:15:08.353444: step 31590, loss = 0.79 (277.1 examples/sec; 0.924 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10849\n",
      "2017-05-28 07:15:21.659021: step 31600, loss = 0.94 (192.4 examples/sec; 1.331 sec/batch)\n",
      "2017-05-28 07:15:29.490481: step 31610, loss = 0.71 (326.9 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 07:15:37.971891: step 31620, loss = 0.73 (301.8 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 07:15:46.071259: step 31630, loss = 0.73 (316.1 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 07:15:54.553766: step 31640, loss = 0.80 (301.8 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 07:16:03.285100: step 31650, loss = 0.76 (293.2 examples/sec; 0.873 sec/batch)\n",
      "2017-05-28 07:16:11.505153: step 31660, loss = 0.82 (311.4 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 07:16:19.738291: step 31670, loss = 0.96 (310.9 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 07:16:28.585989: step 31680, loss = 0.90 (289.3 examples/sec; 0.885 sec/batch)\n",
      "2017-05-28 07:16:37.076111: step 31690, loss = 0.78 (301.5 examples/sec; 0.849 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13159\n",
      "2017-05-28 07:16:50.046982: step 31700, loss = 0.79 (197.4 examples/sec; 1.297 sec/batch)\n",
      "2017-05-28 07:16:57.821777: step 31710, loss = 0.87 (329.3 examples/sec; 0.777 sec/batch)\n",
      "2017-05-28 07:17:06.006904: step 31720, loss = 0.82 (312.8 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 07:17:14.144238: step 31730, loss = 0.79 (314.6 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 07:17:22.914736: step 31740, loss = 0.88 (291.9 examples/sec; 0.877 sec/batch)\n",
      "2017-05-28 07:17:31.372551: step 31750, loss = 0.79 (302.7 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 07:17:39.786698: step 31760, loss = 0.83 (304.2 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 07:17:48.318511: step 31770, loss = 0.99 (300.1 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 07:17:56.535199: step 31780, loss = 0.92 (311.6 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 07:18:04.755789: step 31790, loss = 0.85 (311.4 examples/sec; 0.822 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12523\n",
      "2017-05-28 07:18:18.901842: step 31800, loss = 0.76 (181.0 examples/sec; 1.415 sec/batch)\n",
      "2017-05-28 07:18:26.323372: step 31810, loss = 0.81 (344.9 examples/sec; 0.742 sec/batch)\n",
      "2017-05-28 07:18:34.611515: step 31820, loss = 0.75 (308.9 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 07:18:43.238804: step 31830, loss = 0.78 (296.7 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 07:18:51.480757: step 31840, loss = 0.86 (310.6 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 07:18:59.690017: step 31850, loss = 0.92 (311.8 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 07:19:07.839243: step 31860, loss = 0.86 (314.1 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 07:19:16.672084: step 31870, loss = 0.83 (289.8 examples/sec; 0.883 sec/batch)\n",
      "2017-05-28 07:19:24.817754: step 31880, loss = 0.86 (314.3 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 07:19:33.580216: step 31890, loss = 0.88 (292.2 examples/sec; 0.876 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1538\n",
      "2017-05-28 07:19:45.570116: step 31900, loss = 0.86 (213.5 examples/sec; 1.199 sec/batch)\n",
      "2017-05-28 07:19:53.464574: step 31910, loss = 0.84 (324.3 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 07:20:02.024952: step 31920, loss = 0.71 (299.1 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 07:20:10.157822: step 31930, loss = 0.82 (314.8 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 07:20:18.707441: step 31940, loss = 0.80 (299.4 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 07:20:28.718027: step 31950, loss = 0.72 (255.7 examples/sec; 1.001 sec/batch)\n",
      "2017-05-28 07:20:37.304576: step 31960, loss = 0.87 (298.1 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 07:20:45.530509: step 31970, loss = 0.71 (311.2 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 07:20:53.877365: step 31980, loss = 0.83 (306.7 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 07:21:02.725073: step 31990, loss = 0.71 (289.3 examples/sec; 0.885 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.09397\n",
      "2017-05-28 07:21:16.981431: step 32000, loss = 0.82 (179.6 examples/sec; 1.426 sec/batch)\n",
      "2017-05-28 07:21:24.646636: step 32010, loss = 0.80 (334.0 examples/sec; 0.767 sec/batch)\n",
      "2017-05-28 07:21:32.808013: step 32020, loss = 0.91 (313.7 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 07:21:41.640733: step 32030, loss = 0.87 (289.8 examples/sec; 0.883 sec/batch)\n",
      "2017-05-28 07:21:49.753363: step 32040, loss = 0.87 (315.6 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 07:21:57.939358: step 32050, loss = 0.80 (312.7 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 07:22:06.231732: step 32060, loss = 0.73 (308.7 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 07:22:14.353826: step 32070, loss = 0.71 (315.2 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 07:22:22.993768: step 32080, loss = 0.95 (296.3 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 07:22:31.242783: step 32090, loss = 0.97 (310.3 examples/sec; 0.825 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13229\n",
      "2017-05-28 07:22:45.296563: step 32100, loss = 0.81 (182.2 examples/sec; 1.405 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 32111 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 07:22:54.057512: step 32110, loss = 0.91 (292.2 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 07:23:01.600400: step 32120, loss = 0.86 (339.4 examples/sec; 0.754 sec/batch)\n",
      "2017-05-28 07:23:09.722673: step 32130, loss = 0.85 (315.2 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 07:23:18.357853: step 32140, loss = 0.89 (296.5 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 07:23:26.732187: step 32150, loss = 0.90 (305.7 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 07:23:35.238449: step 32160, loss = 0.86 (301.0 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 07:23:43.804316: step 32170, loss = 0.84 (298.9 examples/sec; 0.857 sec/batch)\n",
      "2017-05-28 07:23:51.966603: step 32180, loss = 0.86 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 07:24:00.745396: step 32190, loss = 0.87 (291.6 examples/sec; 0.878 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13803\n",
      "2017-05-28 07:24:13.166852: step 32200, loss = 0.82 (206.1 examples/sec; 1.242 sec/batch)\n",
      "2017-05-28 07:24:20.781955: step 32210, loss = 0.83 (336.2 examples/sec; 0.762 sec/batch)\n",
      "2017-05-28 07:24:28.932122: step 32220, loss = 0.80 (314.1 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 07:24:37.737118: step 32230, loss = 0.83 (290.7 examples/sec; 0.880 sec/batch)\n",
      "2017-05-28 07:24:46.032769: step 32240, loss = 0.85 (308.6 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 07:24:54.760587: step 32250, loss = 0.85 (293.3 examples/sec; 0.873 sec/batch)\n",
      "2017-05-28 07:25:03.233400: step 32260, loss = 0.92 (302.1 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 07:25:11.521029: step 32270, loss = 0.82 (308.9 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 07:25:19.960086: step 32280, loss = 0.77 (303.4 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 07:25:29.625553: step 32290, loss = 0.76 (264.9 examples/sec; 0.967 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11567\n",
      "2017-05-28 07:25:42.799868: step 32300, loss = 0.97 (194.3 examples/sec; 1.317 sec/batch)\n",
      "2017-05-28 07:25:51.415276: step 32310, loss = 0.63 (297.1 examples/sec; 0.862 sec/batch)\n",
      "2017-05-28 07:25:59.638674: step 32320, loss = 0.85 (311.3 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 07:26:07.993947: step 32330, loss = 0.83 (306.4 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 07:26:16.496939: step 32340, loss = 0.79 (301.1 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 07:26:24.925670: step 32350, loss = 0.84 (303.7 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 07:26:33.049798: step 32360, loss = 0.82 (315.1 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 07:26:41.972051: step 32370, loss = 0.89 (286.9 examples/sec; 0.892 sec/batch)\n",
      "2017-05-28 07:26:50.109558: step 32380, loss = 0.90 (314.6 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 07:26:58.263629: step 32390, loss = 0.91 (314.0 examples/sec; 0.815 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 07:27:12.296841: step 32400, loss = 0.74 (182.4 examples/sec; 1.403 sec/batch)\n",
      "2017-05-28 07:27:19.697810: step 32410, loss = 0.81 (345.9 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 07:27:27.900366: step 32420, loss = 0.72 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 07:27:36.612927: step 32430, loss = 0.78 (293.8 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 07:27:44.749059: step 32440, loss = 0.92 (314.6 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 07:27:52.922969: step 32450, loss = 0.79 (313.2 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 07:28:01.030301: step 32460, loss = 0.83 (315.8 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 07:28:09.744004: step 32470, loss = 0.76 (293.8 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 07:28:18.189786: step 32480, loss = 0.78 (303.1 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 07:28:26.325745: step 32490, loss = 0.74 (314.7 examples/sec; 0.814 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13405\n",
      "2017-05-28 07:28:40.477442: step 32500, loss = 0.84 (180.9 examples/sec; 1.415 sec/batch)\n",
      "2017-05-28 07:28:47.915293: step 32510, loss = 0.85 (344.2 examples/sec; 0.744 sec/batch)\n",
      "2017-05-28 07:28:56.097619: step 32520, loss = 0.85 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 07:29:04.562339: step 32530, loss = 0.88 (302.4 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 07:29:13.052574: step 32540, loss = 0.90 (301.5 examples/sec; 0.849 sec/batch)\n",
      "2017-05-28 07:29:21.260871: step 32550, loss = 0.79 (311.9 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 07:29:30.048008: step 32560, loss = 0.73 (291.3 examples/sec; 0.879 sec/batch)\n",
      "2017-05-28 07:29:38.345691: step 32570, loss = 0.83 (308.5 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 07:29:47.089585: step 32580, loss = 0.80 (292.8 examples/sec; 0.874 sec/batch)\n",
      "2017-05-28 07:29:55.367127: step 32590, loss = 0.69 (309.3 examples/sec; 0.828 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14878\n",
      "2017-05-28 07:30:07.524759: step 32600, loss = 0.85 (210.6 examples/sec; 1.216 sec/batch)\n",
      "2017-05-28 07:30:15.483170: step 32610, loss = 0.79 (321.7 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 07:30:23.660559: step 32620, loss = 0.73 (313.1 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 07:30:31.814614: step 32630, loss = 0.70 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 07:30:40.320515: step 32640, loss = 0.91 (301.0 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 07:30:48.840117: step 32650, loss = 0.79 (300.5 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 07:30:58.844137: step 32660, loss = 0.70 (255.9 examples/sec; 1.000 sec/batch)\n",
      "2017-05-28 07:31:07.506257: step 32670, loss = 0.75 (295.5 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 07:31:15.791350: step 32680, loss = 0.85 (309.0 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 07:31:24.138620: step 32690, loss = 0.77 (306.7 examples/sec; 0.835 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11417\n",
      "2017-05-28 07:31:37.282757: step 32700, loss = 0.74 (194.8 examples/sec; 1.314 sec/batch)\n",
      "2017-05-28 07:31:44.806674: step 32710, loss = 0.88 (340.2 examples/sec; 0.752 sec/batch)\n",
      "2017-05-28 07:31:52.962535: step 32720, loss = 0.85 (313.9 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 07:32:01.705037: step 32730, loss = 0.79 (292.8 examples/sec; 0.874 sec/batch)\n",
      "2017-05-28 07:32:09.899052: step 32740, loss = 0.80 (312.4 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 07:32:18.600455: step 32750, loss = 0.89 (294.2 examples/sec; 0.870 sec/batch)\n",
      "2017-05-28 07:32:26.999931: step 32760, loss = 0.69 (304.8 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 07:32:35.134385: step 32770, loss = 0.77 (314.7 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 07:32:43.545632: step 32780, loss = 0.85 (304.4 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 07:32:52.180975: step 32790, loss = 0.84 (296.5 examples/sec; 0.864 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 32792 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14043\n",
      "2017-05-28 07:33:04.962556: step 32800, loss = 0.72 (200.3 examples/sec; 1.278 sec/batch)\n",
      "2017-05-28 07:33:12.455020: step 32810, loss = 0.81 (341.7 examples/sec; 0.749 sec/batch)\n",
      "2017-05-28 07:33:20.542890: step 32820, loss = 0.73 (316.5 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 07:33:29.252914: step 32830, loss = 0.77 (293.9 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 07:33:37.725121: step 32840, loss = 0.69 (302.2 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 07:33:45.935277: step 32850, loss = 0.77 (311.8 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 07:33:54.626450: step 32860, loss = 0.83 (294.6 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 07:34:02.836520: step 32870, loss = 0.77 (311.8 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 07:34:11.112154: step 32880, loss = 0.90 (309.3 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 07:34:19.843181: step 32890, loss = 0.85 (293.2 examples/sec; 0.873 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15122\n",
      "2017-05-28 07:34:31.827796: step 32900, loss = 0.76 (213.6 examples/sec; 1.198 sec/batch)\n",
      "2017-05-28 07:34:39.288492: step 32910, loss = 0.82 (343.1 examples/sec; 0.746 sec/batch)\n",
      "2017-05-28 07:34:47.431926: step 32920, loss = 0.82 (314.4 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 07:34:56.052813: step 32930, loss = 0.92 (297.0 examples/sec; 0.862 sec/batch)\n",
      "2017-05-28 07:35:04.424590: step 32940, loss = 0.82 (305.8 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 07:35:13.021736: step 32950, loss = 0.78 (297.8 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 07:35:21.468067: step 32960, loss = 0.87 (303.1 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 07:35:29.635825: step 32970, loss = 0.83 (313.4 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 07:35:37.821127: step 32980, loss = 0.88 (312.8 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 07:35:46.527273: step 32990, loss = 0.87 (294.0 examples/sec; 0.871 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12686\n",
      "2017-05-28 07:36:00.573098: step 33000, loss = 0.81 (182.3 examples/sec; 1.405 sec/batch)\n",
      "2017-05-28 07:36:09.129701: step 33010, loss = 0.71 (299.2 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 07:36:17.330987: step 33020, loss = 0.80 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 07:36:25.510008: step 33030, loss = 0.59 (313.0 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 07:36:34.391259: step 33040, loss = 0.81 (288.2 examples/sec; 0.888 sec/batch)\n",
      "2017-05-28 07:36:42.507300: step 33050, loss = 0.74 (315.4 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 07:36:50.592995: step 33060, loss = 0.79 (316.6 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 07:36:59.564140: step 33070, loss = 0.82 (285.4 examples/sec; 0.897 sec/batch)\n",
      "2017-05-28 07:37:07.957071: step 33080, loss = 0.68 (305.0 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 07:37:16.388971: step 33090, loss = 0.79 (303.6 examples/sec; 0.843 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13568\n",
      "2017-05-28 07:37:28.622351: step 33100, loss = 0.80 (209.3 examples/sec; 1.223 sec/batch)\n",
      "2017-05-28 07:37:36.197763: step 33110, loss = 0.78 (337.9 examples/sec; 0.758 sec/batch)\n",
      "2017-05-28 07:37:44.638076: step 33120, loss = 0.80 (303.3 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 07:37:53.156084: step 33130, loss = 0.87 (300.5 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 07:38:01.216344: step 33140, loss = 0.73 (317.6 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 07:38:09.309655: step 33150, loss = 0.81 (316.3 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 07:38:18.171424: step 33160, loss = 0.82 (288.9 examples/sec; 0.886 sec/batch)\n",
      "2017-05-28 07:38:26.347569: step 33170, loss = 0.78 (313.1 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 07:38:34.540042: step 33180, loss = 0.83 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 07:38:43.301551: step 33190, loss = 0.86 (292.2 examples/sec; 0.876 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14838\n",
      "2017-05-28 07:38:55.701943: step 33200, loss = 0.97 (206.4 examples/sec; 1.240 sec/batch)\n",
      "2017-05-28 07:39:03.126088: step 33210, loss = 0.82 (344.8 examples/sec; 0.742 sec/batch)\n",
      "2017-05-28 07:39:11.210072: step 33220, loss = 0.85 (316.7 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 07:39:19.859051: step 33230, loss = 0.85 (296.0 examples/sec; 0.865 sec/batch)\n",
      "2017-05-28 07:39:28.165457: step 33240, loss = 0.79 (308.2 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 07:39:36.668698: step 33250, loss = 0.69 (301.1 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 07:39:45.269527: step 33260, loss = 0.82 (297.6 examples/sec; 0.860 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 07:39:53.506590: step 33270, loss = 0.75 (310.8 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 07:40:01.719750: step 33280, loss = 0.74 (311.7 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 07:40:09.803626: step 33290, loss = 0.75 (316.7 examples/sec; 0.808 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14961\n",
      "2017-05-28 07:40:22.687425: step 33300, loss = 0.76 (198.7 examples/sec; 1.288 sec/batch)\n",
      "2017-05-28 07:40:30.205913: step 33310, loss = 0.80 (340.5 examples/sec; 0.752 sec/batch)\n",
      "2017-05-28 07:40:38.954246: step 33320, loss = 0.79 (292.6 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 07:40:47.050709: step 33330, loss = 0.81 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 07:40:55.792583: step 33340, loss = 0.93 (292.8 examples/sec; 0.874 sec/batch)\n",
      "2017-05-28 07:41:04.034875: step 33350, loss = 0.68 (310.6 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 07:41:13.697169: step 33360, loss = 1.14 (264.9 examples/sec; 0.966 sec/batch)\n",
      "2017-05-28 07:41:22.984712: step 33370, loss = 0.73 (275.6 examples/sec; 0.929 sec/batch)\n",
      "2017-05-28 07:41:31.234706: step 33380, loss = 0.69 (310.3 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 07:41:39.515467: step 33390, loss = 0.71 (309.2 examples/sec; 0.828 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11967\n",
      "2017-05-28 07:41:51.998951: step 33400, loss = 0.83 (205.1 examples/sec; 1.248 sec/batch)\n",
      "2017-05-28 07:41:59.714899: step 33410, loss = 0.76 (331.8 examples/sec; 0.772 sec/batch)\n",
      "2017-05-28 07:42:08.390684: step 33420, loss = 0.72 (295.1 examples/sec; 0.868 sec/batch)\n",
      "2017-05-28 07:42:16.557821: step 33430, loss = 0.80 (313.5 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 07:42:25.309204: step 33440, loss = 0.77 (292.5 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 07:42:33.785437: step 33450, loss = 0.71 (302.0 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 07:42:41.856701: step 33460, loss = 0.98 (317.2 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 07:42:50.136968: step 33470, loss = 0.71 (309.2 examples/sec; 0.828 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 33475 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 07:42:59.026553: step 33480, loss = 0.77 (288.0 examples/sec; 0.889 sec/batch)\n",
      "2017-05-28 07:43:07.653210: step 33490, loss = 0.85 (296.8 examples/sec; 0.863 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13862\n",
      "2017-05-28 07:43:19.825175: step 33500, loss = 0.86 (210.3 examples/sec; 1.217 sec/batch)\n",
      "2017-05-28 07:43:27.794552: step 33510, loss = 0.66 (321.2 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 07:43:36.091728: step 33520, loss = 0.78 (308.5 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 07:43:44.229232: step 33530, loss = 0.86 (314.6 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 07:43:52.405471: step 33540, loss = 0.82 (313.1 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 07:44:01.007199: step 33550, loss = 0.78 (297.6 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 07:44:09.961729: step 33560, loss = 0.86 (285.9 examples/sec; 0.895 sec/batch)\n",
      "2017-05-28 07:44:18.137749: step 33570, loss = 0.69 (313.1 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 07:44:26.974682: step 33580, loss = 0.65 (289.7 examples/sec; 0.884 sec/batch)\n",
      "2017-05-28 07:44:35.144007: step 33590, loss = 0.73 (313.4 examples/sec; 0.817 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12829\n",
      "2017-05-28 07:44:48.458009: step 33600, loss = 0.90 (192.3 examples/sec; 1.331 sec/batch)\n",
      "2017-05-28 07:44:56.114818: step 33610, loss = 0.84 (334.3 examples/sec; 0.766 sec/batch)\n",
      "2017-05-28 07:45:04.336652: step 33620, loss = 0.85 (311.4 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 07:45:12.532760: step 33630, loss = 0.84 (312.3 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 07:45:21.340297: step 33640, loss = 0.73 (290.7 examples/sec; 0.881 sec/batch)\n",
      "2017-05-28 07:45:29.395828: step 33650, loss = 0.67 (317.8 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 07:45:37.663230: step 33660, loss = 0.91 (309.6 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 07:45:46.268352: step 33670, loss = 0.88 (297.5 examples/sec; 0.861 sec/batch)\n",
      "2017-05-28 07:45:54.722984: step 33680, loss = 0.68 (302.8 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 07:46:03.034025: step 33690, loss = 0.81 (308.0 examples/sec; 0.831 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14694\n",
      "2017-05-28 07:46:15.643579: step 33700, loss = 0.70 (203.0 examples/sec; 1.261 sec/batch)\n",
      "2017-05-28 07:46:23.509051: step 33710, loss = 0.85 (325.5 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 07:46:33.249201: step 33720, loss = 0.69 (262.8 examples/sec; 0.974 sec/batch)\n",
      "2017-05-28 07:46:42.595359: step 33730, loss = 0.74 (273.9 examples/sec; 0.935 sec/batch)\n",
      "2017-05-28 07:46:51.268885: step 33740, loss = 0.99 (295.2 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 07:47:00.219861: step 33750, loss = 0.82 (286.0 examples/sec; 0.895 sec/batch)\n",
      "2017-05-28 07:47:09.531242: step 33760, loss = 0.84 (274.9 examples/sec; 0.931 sec/batch)\n",
      "2017-05-28 07:47:17.961106: step 33770, loss = 0.76 (303.7 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 07:47:26.232616: step 33780, loss = 0.86 (309.5 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 07:47:34.578749: step 33790, loss = 1.04 (306.7 examples/sec; 0.835 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.09265\n",
      "2017-05-28 07:47:47.170681: step 33800, loss = 0.84 (203.3 examples/sec; 1.259 sec/batch)\n",
      "2017-05-28 07:47:54.650712: step 33810, loss = 0.78 (342.2 examples/sec; 0.748 sec/batch)\n",
      "2017-05-28 07:48:03.285740: step 33820, loss = 0.85 (296.5 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 07:48:11.383070: step 33830, loss = 0.73 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 07:48:19.523684: step 33840, loss = 0.74 (314.5 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 07:48:28.104693: step 33850, loss = 0.71 (298.3 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 07:48:36.504048: step 33860, loss = 0.81 (304.8 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 07:48:44.657742: step 33870, loss = 0.77 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 07:48:53.122374: step 33880, loss = 0.82 (302.4 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 07:49:01.818985: step 33890, loss = 0.72 (294.4 examples/sec; 0.870 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15789\n",
      "2017-05-28 07:49:13.528872: step 33900, loss = 0.78 (218.6 examples/sec; 1.171 sec/batch)\n",
      "2017-05-28 07:49:21.203618: step 33910, loss = 0.94 (333.6 examples/sec; 0.767 sec/batch)\n",
      "2017-05-28 07:49:29.614611: step 33920, loss = 0.83 (304.4 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 07:49:37.732392: step 33930, loss = 0.84 (315.4 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 07:49:45.964218: step 33940, loss = 0.93 (311.0 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 07:49:54.664093: step 33950, loss = 0.72 (294.3 examples/sec; 0.870 sec/batch)\n",
      "2017-05-28 07:50:02.844620: step 33960, loss = 0.78 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 07:50:11.497214: step 33970, loss = 0.80 (295.9 examples/sec; 0.865 sec/batch)\n",
      "2017-05-28 07:50:19.833316: step 33980, loss = 0.79 (307.1 examples/sec; 0.834 sec/batch)\n",
      "2017-05-28 07:50:28.120734: step 33990, loss = 0.72 (308.9 examples/sec; 0.829 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15467\n",
      "2017-05-28 07:50:40.134305: step 34000, loss = 0.73 (213.1 examples/sec; 1.201 sec/batch)\n",
      "2017-05-28 07:50:48.004950: step 34010, loss = 0.78 (325.3 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 07:50:56.164735: step 34020, loss = 0.76 (313.7 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 07:51:04.642269: step 34030, loss = 0.76 (302.0 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 07:51:13.201576: step 34040, loss = 0.73 (299.1 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 07:51:21.340569: step 34050, loss = 0.78 (314.5 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 07:51:29.996554: step 34060, loss = 0.80 (295.7 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 07:51:38.271107: step 34070, loss = 0.89 (309.4 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 07:51:46.911202: step 34080, loss = 0.86 (296.3 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 07:51:55.311387: step 34090, loss = 0.76 (304.8 examples/sec; 0.840 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14778\n",
      "2017-05-28 07:52:07.259127: step 34100, loss = 0.84 (214.3 examples/sec; 1.195 sec/batch)\n",
      "2017-05-28 07:52:16.114621: step 34110, loss = 0.86 (289.1 examples/sec; 0.886 sec/batch)\n",
      "2017-05-28 07:52:25.395102: step 34120, loss = 0.94 (275.8 examples/sec; 0.928 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 07:52:33.876166: step 34130, loss = 0.77 (301.8 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 07:52:42.148780: step 34140, loss = 0.79 (309.5 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 07:52:50.338381: step 34150, loss = 0.67 (312.6 examples/sec; 0.819 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 34155 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 07:52:59.303026: step 34160, loss = 0.83 (285.6 examples/sec; 0.896 sec/batch)\n",
      "2017-05-28 07:53:08.015545: step 34170, loss = 0.87 (293.8 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 07:53:16.232680: step 34180, loss = 0.81 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 07:53:24.660859: step 34190, loss = 0.76 (303.7 examples/sec; 0.843 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11487\n",
      "2017-05-28 07:53:36.955124: step 34200, loss = 0.80 (208.2 examples/sec; 1.229 sec/batch)\n",
      "2017-05-28 07:53:44.453227: step 34210, loss = 0.70 (341.4 examples/sec; 0.750 sec/batch)\n",
      "2017-05-28 07:53:52.706719: step 34220, loss = 0.75 (310.2 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 07:54:01.209769: step 34230, loss = 0.86 (301.1 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 07:54:09.853114: step 34240, loss = 0.91 (296.2 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 07:54:17.988743: step 34250, loss = 0.74 (314.7 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 07:54:26.087361: step 34260, loss = 0.78 (316.1 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 07:54:34.909321: step 34270, loss = 0.95 (290.2 examples/sec; 0.882 sec/batch)\n",
      "2017-05-28 07:54:43.054561: step 34280, loss = 0.59 (314.3 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 07:54:51.609630: step 34290, loss = 0.84 (299.2 examples/sec; 0.856 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14875\n",
      "2017-05-28 07:55:04.006802: step 34300, loss = 0.76 (206.5 examples/sec; 1.240 sec/batch)\n",
      "2017-05-28 07:55:11.903242: step 34310, loss = 0.85 (324.2 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 07:55:20.182435: step 34320, loss = 0.72 (309.2 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 07:55:28.403614: step 34330, loss = 0.80 (311.4 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 07:55:36.624333: step 34340, loss = 0.81 (311.4 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 07:55:45.081134: step 34350, loss = 0.84 (302.7 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 07:55:53.716992: step 34360, loss = 0.72 (296.4 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 07:56:01.833107: step 34370, loss = 0.71 (315.4 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 07:56:10.033702: step 34380, loss = 0.81 (312.2 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 07:56:18.182920: step 34390, loss = 0.76 (314.1 examples/sec; 0.815 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14273\n",
      "2017-05-28 07:56:31.515817: step 34400, loss = 0.74 (192.0 examples/sec; 1.333 sec/batch)\n",
      "2017-05-28 07:56:39.047603: step 34410, loss = 0.77 (339.9 examples/sec; 0.753 sec/batch)\n",
      "2017-05-28 07:56:47.301988: step 34420, loss = 0.69 (310.1 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 07:56:55.700554: step 34430, loss = 0.81 (304.8 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 07:57:04.117130: step 34440, loss = 0.82 (304.2 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 07:57:12.300100: step 34450, loss = 0.82 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 07:57:21.148470: step 34460, loss = 0.77 (289.3 examples/sec; 0.885 sec/batch)\n",
      "2017-05-28 07:57:30.729397: step 34470, loss = 0.83 (267.2 examples/sec; 0.958 sec/batch)\n",
      "2017-05-28 07:57:39.511063: step 34480, loss = 0.90 (291.5 examples/sec; 0.878 sec/batch)\n",
      "2017-05-28 07:57:47.954322: step 34490, loss = 0.83 (303.2 examples/sec; 0.844 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10487\n",
      "2017-05-28 07:58:02.026952: step 34500, loss = 0.87 (181.9 examples/sec; 1.407 sec/batch)\n",
      "2017-05-28 07:58:09.346044: step 34510, loss = 0.74 (349.8 examples/sec; 0.732 sec/batch)\n",
      "2017-05-28 07:58:17.963438: step 34520, loss = 0.87 (297.1 examples/sec; 0.862 sec/batch)\n",
      "2017-05-28 07:58:26.480483: step 34530, loss = 0.89 (300.6 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 07:58:34.738614: step 34540, loss = 0.73 (310.0 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 07:58:42.950331: step 34550, loss = 0.82 (311.7 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 07:58:51.764717: step 34560, loss = 0.82 (290.4 examples/sec; 0.881 sec/batch)\n",
      "2017-05-28 07:59:00.290630: step 34570, loss = 0.75 (300.3 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 07:59:08.563596: step 34580, loss = 0.63 (309.4 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 07:59:17.229939: step 34590, loss = 0.76 (295.4 examples/sec; 0.867 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14183\n",
      "2017-05-28 07:59:29.603947: step 34600, loss = 0.81 (206.9 examples/sec; 1.237 sec/batch)\n",
      "2017-05-28 07:59:37.008541: step 34610, loss = 0.83 (345.7 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 07:59:45.252804: step 34620, loss = 0.78 (310.5 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 07:59:54.083026: step 34630, loss = 0.87 (289.9 examples/sec; 0.883 sec/batch)\n",
      "2017-05-28 08:00:02.313838: step 34640, loss = 0.93 (311.0 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 08:00:10.468521: step 34650, loss = 0.79 (313.9 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 08:00:18.977974: step 34660, loss = 0.69 (300.8 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 08:00:27.340706: step 34670, loss = 0.67 (306.1 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 08:00:35.473344: step 34680, loss = 0.82 (314.8 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 08:00:44.284646: step 34690, loss = 0.85 (290.5 examples/sec; 0.881 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14281\n",
      "2017-05-28 08:00:57.114906: step 34700, loss = 0.88 (199.5 examples/sec; 1.283 sec/batch)\n",
      "2017-05-28 08:01:04.908740: step 34710, loss = 0.77 (328.5 examples/sec; 0.779 sec/batch)\n",
      "2017-05-28 08:01:13.072487: step 34720, loss = 0.90 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 08:01:21.274193: step 34730, loss = 0.76 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 08:01:30.048661: step 34740, loss = 0.81 (291.8 examples/sec; 0.877 sec/batch)\n",
      "2017-05-28 08:01:38.342562: step 34750, loss = 0.71 (308.7 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 08:01:46.498017: step 34760, loss = 0.84 (313.9 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 08:01:55.008414: step 34770, loss = 0.80 (300.8 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 08:02:03.402084: step 34780, loss = 0.76 (305.0 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 08:02:11.536728: step 34790, loss = 0.75 (314.7 examples/sec; 0.813 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16177\n",
      "2017-05-28 08:02:23.183520: step 34800, loss = 0.72 (219.8 examples/sec; 1.165 sec/batch)\n",
      "2017-05-28 08:02:31.936595: step 34810, loss = 0.84 (292.5 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 08:02:41.203390: step 34820, loss = 0.79 (276.3 examples/sec; 0.927 sec/batch)\n",
      "2017-05-28 08:02:49.504127: step 34830, loss = 0.82 (308.4 examples/sec; 0.830 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 34836 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 08:02:58.568898: step 34840, loss = 0.89 (282.4 examples/sec; 0.906 sec/batch)\n",
      "2017-05-28 08:03:07.327035: step 34850, loss = 0.79 (292.3 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 08:03:15.856496: step 34860, loss = 0.89 (300.1 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 08:03:24.013509: step 34870, loss = 0.69 (313.8 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 08:03:32.976528: step 34880, loss = 0.82 (285.6 examples/sec; 0.896 sec/batch)\n",
      "2017-05-28 08:03:41.228937: step 34890, loss = 0.71 (310.2 examples/sec; 0.825 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.09331\n",
      "2017-05-28 08:03:54.651792: step 34900, loss = 0.82 (190.7 examples/sec; 1.342 sec/batch)\n",
      "2017-05-28 08:04:02.188933: step 34910, loss = 0.73 (339.7 examples/sec; 0.754 sec/batch)\n",
      "2017-05-28 08:04:10.371664: step 34920, loss = 0.84 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 08:04:18.482772: step 34930, loss = 0.71 (315.6 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 08:04:27.294604: step 34940, loss = 0.91 (290.5 examples/sec; 0.881 sec/batch)\n",
      "2017-05-28 08:04:35.444881: step 34950, loss = 0.84 (314.1 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 08:04:43.968917: step 34960, loss = 0.76 (300.3 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 08:04:52.036795: step 34970, loss = 0.81 (317.3 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 08:05:00.359164: step 34980, loss = 0.84 (307.6 examples/sec; 0.832 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 08:05:08.626289: step 34990, loss = 0.69 (309.7 examples/sec; 0.827 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15519\n",
      "2017-05-28 08:05:21.214633: step 35000, loss = 0.94 (203.4 examples/sec; 1.259 sec/batch)\n",
      "2017-05-28 08:05:28.638403: step 35010, loss = 0.77 (344.8 examples/sec; 0.742 sec/batch)\n",
      "2017-05-28 08:05:37.135658: step 35020, loss = 0.88 (301.3 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 08:05:45.782637: step 35030, loss = 0.78 (296.1 examples/sec; 0.865 sec/batch)\n",
      "2017-05-28 08:05:53.907261: step 35040, loss = 0.84 (315.1 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 08:06:02.131921: step 35050, loss = 0.73 (311.3 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 08:06:10.757188: step 35060, loss = 0.85 (296.8 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 08:06:19.024244: step 35070, loss = 0.91 (309.7 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 08:06:27.168111: step 35080, loss = 0.76 (314.3 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 08:06:35.239292: step 35090, loss = 0.87 (317.2 examples/sec; 0.807 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13827\n",
      "2017-05-28 08:06:49.067708: step 35100, loss = 0.72 (185.1 examples/sec; 1.383 sec/batch)\n",
      "2017-05-28 08:06:56.482928: step 35110, loss = 0.71 (345.2 examples/sec; 0.742 sec/batch)\n",
      "2017-05-28 08:07:04.639795: step 35120, loss = 0.76 (313.8 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 08:07:13.518200: step 35130, loss = 0.74 (288.3 examples/sec; 0.888 sec/batch)\n",
      "2017-05-28 08:07:21.711417: step 35140, loss = 0.65 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 08:07:30.208848: step 35150, loss = 0.76 (301.3 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 08:07:39.565783: step 35160, loss = 0.74 (273.6 examples/sec; 0.936 sec/batch)\n",
      "2017-05-28 08:07:48.707553: step 35170, loss = 0.87 (280.0 examples/sec; 0.914 sec/batch)\n",
      "2017-05-28 08:07:57.417622: step 35180, loss = 0.89 (293.9 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 08:08:05.953611: step 35190, loss = 0.83 (299.9 examples/sec; 0.854 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10257\n",
      "2017-05-28 08:08:19.764205: step 35200, loss = 0.93 (185.4 examples/sec; 1.381 sec/batch)\n",
      "2017-05-28 08:08:27.147685: step 35210, loss = 0.73 (346.7 examples/sec; 0.738 sec/batch)\n",
      "2017-05-28 08:08:35.475701: step 35220, loss = 0.79 (307.4 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 08:08:43.803118: step 35230, loss = 0.69 (307.4 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 08:08:52.588297: step 35240, loss = 0.87 (291.4 examples/sec; 0.879 sec/batch)\n",
      "2017-05-28 08:09:00.745023: step 35250, loss = 0.69 (313.9 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 08:09:08.887436: step 35260, loss = 0.91 (314.4 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 08:09:17.775027: step 35270, loss = 0.90 (288.0 examples/sec; 0.889 sec/batch)\n",
      "2017-05-28 08:09:26.188432: step 35280, loss = 0.83 (304.3 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 08:09:34.485824: step 35290, loss = 0.91 (308.5 examples/sec; 0.830 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12936\n",
      "2017-05-28 08:09:48.310195: step 35300, loss = 0.84 (185.2 examples/sec; 1.382 sec/batch)\n",
      "2017-05-28 08:09:55.746740: step 35310, loss = 0.82 (344.2 examples/sec; 0.744 sec/batch)\n",
      "2017-05-28 08:10:04.249345: step 35320, loss = 0.82 (301.1 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 08:10:12.707529: step 35330, loss = 0.70 (302.7 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 08:10:20.905034: step 35340, loss = 0.72 (312.3 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 08:10:29.187139: step 35350, loss = 0.70 (309.1 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 08:10:38.034719: step 35360, loss = 0.91 (289.3 examples/sec; 0.885 sec/batch)\n",
      "2017-05-28 08:10:46.218038: step 35370, loss = 0.80 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 08:10:54.949988: step 35380, loss = 0.68 (293.2 examples/sec; 0.873 sec/batch)\n",
      "2017-05-28 08:11:03.128148: step 35390, loss = 0.85 (313.0 examples/sec; 0.818 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13195\n",
      "2017-05-28 08:11:16.653236: step 35400, loss = 0.81 (189.3 examples/sec; 1.353 sec/batch)\n",
      "2017-05-28 08:11:24.219048: step 35410, loss = 0.82 (338.4 examples/sec; 0.757 sec/batch)\n",
      "2017-05-28 08:11:32.315661: step 35420, loss = 0.90 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 08:11:41.155739: step 35430, loss = 0.76 (289.6 examples/sec; 0.884 sec/batch)\n",
      "2017-05-28 08:11:49.577241: step 35440, loss = 0.83 (304.0 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 08:11:57.750003: step 35450, loss = 0.75 (313.2 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 08:12:05.986812: step 35460, loss = 0.71 (310.8 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 08:12:14.448954: step 35470, loss = 0.90 (302.5 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 08:12:23.006220: step 35480, loss = 0.87 (299.2 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 08:12:31.185896: step 35490, loss = 0.76 (313.0 examples/sec; 0.818 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12908\n",
      "2017-05-28 08:12:45.222627: step 35500, loss = 0.78 (182.4 examples/sec; 1.404 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 35511 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 08:12:55.272090: step 35510, loss = 0.68 (254.7 examples/sec; 1.005 sec/batch)\n",
      "2017-05-28 08:13:02.868220: step 35520, loss = 0.86 (337.0 examples/sec; 0.760 sec/batch)\n",
      "2017-05-28 08:13:11.461108: step 35530, loss = 0.94 (297.9 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 08:13:20.024526: step 35540, loss = 0.90 (298.9 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 08:13:28.178785: step 35550, loss = 0.77 (313.9 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 08:13:36.355395: step 35560, loss = 0.81 (313.1 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 08:13:44.599493: step 35570, loss = 0.72 (310.5 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 08:13:53.289013: step 35580, loss = 0.75 (294.6 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 08:14:01.451029: step 35590, loss = 0.71 (313.6 examples/sec; 0.816 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11496\n",
      "2017-05-28 08:14:14.912951: step 35600, loss = 0.85 (190.2 examples/sec; 1.346 sec/batch)\n",
      "2017-05-28 08:14:22.532204: step 35610, loss = 0.77 (336.0 examples/sec; 0.762 sec/batch)\n",
      "2017-05-28 08:14:30.621072: step 35620, loss = 0.81 (316.5 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 08:14:38.846381: step 35630, loss = 0.75 (311.2 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 08:14:46.958143: step 35640, loss = 0.76 (315.6 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 08:14:55.837564: step 35650, loss = 0.77 (288.3 examples/sec; 0.888 sec/batch)\n",
      "2017-05-28 08:15:03.954390: step 35660, loss = 0.75 (315.4 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 08:15:12.108031: step 35670, loss = 0.95 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 08:15:20.773185: step 35680, loss = 0.71 (295.4 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 08:15:29.080650: step 35690, loss = 0.72 (308.2 examples/sec; 0.831 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12949\n",
      "2017-05-28 08:15:43.447056: step 35700, loss = 0.67 (178.2 examples/sec; 1.437 sec/batch)\n",
      "2017-05-28 08:15:50.848989: step 35710, loss = 0.72 (345.9 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 08:15:59.103738: step 35720, loss = 0.74 (310.1 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 08:16:07.642125: step 35730, loss = 0.85 (299.8 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 08:16:16.140200: step 35740, loss = 0.73 (301.2 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 08:16:24.397324: step 35750, loss = 0.68 (310.0 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 08:16:32.652843: step 35760, loss = 0.85 (310.1 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 08:16:41.322699: step 35770, loss = 0.83 (295.3 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 08:16:49.437023: step 35780, loss = 0.87 (315.5 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 08:16:58.144879: step 35790, loss = 0.82 (294.0 examples/sec; 0.871 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15008\n",
      "2017-05-28 08:17:10.396139: step 35800, loss = 0.81 (209.0 examples/sec; 1.225 sec/batch)\n",
      "2017-05-28 08:17:18.309381: step 35810, loss = 0.73 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 08:17:26.566315: step 35820, loss = 0.74 (310.0 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 08:17:34.855196: step 35830, loss = 0.87 (308.8 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 08:17:43.058619: step 35840, loss = 0.83 (312.1 examples/sec; 0.820 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 08:17:51.576581: step 35850, loss = 0.73 (300.5 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 08:18:01.551488: step 35860, loss = 0.66 (256.6 examples/sec; 0.997 sec/batch)\n",
      "2017-05-28 08:18:09.980581: step 35870, loss = 0.80 (303.7 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 08:18:18.948804: step 35880, loss = 0.76 (285.5 examples/sec; 0.897 sec/batch)\n",
      "2017-05-28 08:18:26.967388: step 35890, loss = 0.73 (319.3 examples/sec; 0.802 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11977\n",
      "2017-05-28 08:18:39.700359: step 35900, loss = 0.78 (201.1 examples/sec; 1.273 sec/batch)\n",
      "2017-05-28 08:18:47.089232: step 35910, loss = 0.72 (346.5 examples/sec; 0.739 sec/batch)\n",
      "2017-05-28 08:18:55.336465: step 35920, loss = 0.77 (310.4 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 08:19:04.218012: step 35930, loss = 0.69 (288.2 examples/sec; 0.888 sec/batch)\n",
      "2017-05-28 08:19:12.498556: step 35940, loss = 0.78 (309.2 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 08:19:20.602093: step 35950, loss = 0.76 (315.9 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 08:19:29.235149: step 35960, loss = 0.74 (296.5 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 08:19:37.541867: step 35970, loss = 0.85 (308.2 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 08:19:45.969243: step 35980, loss = 0.88 (303.8 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 08:19:54.642837: step 35990, loss = 0.84 (295.1 examples/sec; 0.867 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12655\n",
      "2017-05-28 08:20:08.467781: step 36000, loss = 0.67 (185.2 examples/sec; 1.382 sec/batch)\n",
      "2017-05-28 08:20:16.148422: step 36010, loss = 0.77 (333.3 examples/sec; 0.768 sec/batch)\n",
      "2017-05-28 08:20:24.205481: step 36020, loss = 0.81 (317.7 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 08:20:32.386376: step 36030, loss = 0.80 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 08:20:40.591244: step 36040, loss = 0.71 (312.0 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 08:20:49.266110: step 36050, loss = 0.77 (295.1 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 08:20:57.483819: step 36060, loss = 0.88 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 08:21:06.203131: step 36070, loss = 0.78 (293.6 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 08:21:14.532490: step 36080, loss = 0.75 (307.3 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 08:21:22.679243: step 36090, loss = 0.80 (314.2 examples/sec; 0.815 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13301\n",
      "2017-05-28 08:21:36.727666: step 36100, loss = 0.76 (182.2 examples/sec; 1.405 sec/batch)\n",
      "2017-05-28 08:21:44.114648: step 36110, loss = 0.84 (346.6 examples/sec; 0.739 sec/batch)\n",
      "2017-05-28 08:21:52.292224: step 36120, loss = 0.78 (313.1 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 08:22:00.882244: step 36130, loss = 0.75 (298.0 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 08:22:09.411815: step 36140, loss = 0.81 (300.1 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 08:22:17.543455: step 36150, loss = 0.71 (314.8 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 08:22:25.695743: step 36160, loss = 0.69 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 08:22:34.115967: step 36170, loss = 0.74 (304.0 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 08:22:42.778300: step 36180, loss = 0.69 (295.5 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 08:22:50.898752: step 36190, loss = 0.73 (315.3 examples/sec; 0.812 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 36195 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.12191\n",
      "2017-05-28 08:23:05.862208: step 36200, loss = 0.83 (171.1 examples/sec; 1.496 sec/batch)\n",
      "2017-05-28 08:23:13.938096: step 36210, loss = 0.87 (317.0 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 08:23:22.394570: step 36220, loss = 0.78 (302.7 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 08:23:31.097775: step 36230, loss = 0.77 (294.1 examples/sec; 0.870 sec/batch)\n",
      "2017-05-28 08:23:39.350875: step 36240, loss = 0.75 (310.2 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 08:23:47.739832: step 36250, loss = 0.72 (305.2 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 08:23:56.571608: step 36260, loss = 0.76 (289.9 examples/sec; 0.883 sec/batch)\n",
      "2017-05-28 08:24:05.150273: step 36270, loss = 0.78 (298.4 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 08:24:14.044650: step 36280, loss = 0.79 (287.8 examples/sec; 0.889 sec/batch)\n",
      "2017-05-28 08:24:22.365818: step 36290, loss = 0.93 (307.6 examples/sec; 0.832 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12933\n",
      "2017-05-28 08:24:34.409458: step 36300, loss = 0.79 (212.6 examples/sec; 1.204 sec/batch)\n",
      "2017-05-28 08:24:42.384305: step 36310, loss = 0.73 (321.0 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 08:24:50.654289: step 36320, loss = 0.74 (309.6 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 08:24:59.085750: step 36330, loss = 0.85 (303.6 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 08:25:07.691906: step 36340, loss = 0.78 (297.5 examples/sec; 0.861 sec/batch)\n",
      "2017-05-28 08:25:15.878816: step 36350, loss = 0.81 (312.7 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 08:25:24.021855: step 36360, loss = 0.87 (314.4 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 08:25:32.204184: step 36370, loss = 0.85 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 08:25:40.389676: step 36380, loss = 0.78 (312.7 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 08:25:49.342031: step 36390, loss = 0.89 (286.0 examples/sec; 0.895 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13857\n",
      "2017-05-28 08:26:02.241365: step 36400, loss = 0.76 (198.5 examples/sec; 1.290 sec/batch)\n",
      "2017-05-28 08:26:09.943352: step 36410, loss = 0.86 (332.4 examples/sec; 0.770 sec/batch)\n",
      "2017-05-28 08:26:18.167949: step 36420, loss = 0.81 (311.3 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 08:26:26.807424: step 36430, loss = 0.82 (296.3 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 08:26:35.080121: step 36440, loss = 0.91 (309.5 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 08:26:43.519094: step 36450, loss = 0.89 (303.4 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 08:26:52.018241: step 36460, loss = 0.80 (301.2 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 08:27:00.180513: step 36470, loss = 0.89 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 08:27:08.430881: step 36480, loss = 0.78 (310.3 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 08:27:17.323214: step 36490, loss = 0.80 (287.9 examples/sec; 0.889 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14016\n",
      "2017-05-28 08:27:29.948301: step 36500, loss = 0.80 (202.8 examples/sec; 1.263 sec/batch)\n",
      "2017-05-28 08:27:37.728811: step 36510, loss = 0.76 (329.0 examples/sec; 0.778 sec/batch)\n",
      "2017-05-28 08:27:45.941280: step 36520, loss = 0.76 (311.7 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 08:27:54.156966: step 36530, loss = 0.77 (311.6 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 08:28:02.302455: step 36540, loss = 0.83 (314.3 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 08:28:10.752988: step 36550, loss = 0.82 (302.9 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 08:28:20.941613: step 36560, loss = 0.76 (251.3 examples/sec; 1.019 sec/batch)\n",
      "2017-05-28 08:28:29.413483: step 36570, loss = 0.75 (302.2 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 08:28:38.054394: step 36580, loss = 0.78 (296.3 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 08:28:46.335445: step 36590, loss = 0.70 (309.1 examples/sec; 0.828 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1029\n",
      "2017-05-28 08:29:00.615538: step 36600, loss = 0.71 (179.3 examples/sec; 1.428 sec/batch)\n",
      "2017-05-28 08:29:08.035823: step 36610, loss = 0.76 (345.0 examples/sec; 0.742 sec/batch)\n",
      "2017-05-28 08:29:16.662264: step 36620, loss = 0.80 (296.8 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 08:29:24.948926: step 36630, loss = 0.73 (308.9 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 08:29:33.421563: step 36640, loss = 0.85 (302.1 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 08:29:41.664850: step 36650, loss = 0.74 (310.6 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 08:29:50.341318: step 36660, loss = 0.94 (295.1 examples/sec; 0.868 sec/batch)\n",
      "2017-05-28 08:29:58.593246: step 36670, loss = 0.85 (310.2 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 08:30:06.702626: step 36680, loss = 0.69 (315.7 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 08:30:15.433279: step 36690, loss = 0.75 (293.2 examples/sec; 0.873 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14514\n",
      "2017-05-28 08:30:27.941244: step 36700, loss = 0.73 (204.7 examples/sec; 1.251 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 08:30:35.360820: step 36710, loss = 0.80 (345.0 examples/sec; 0.742 sec/batch)\n",
      "2017-05-28 08:30:44.174564: step 36720, loss = 0.70 (290.5 examples/sec; 0.881 sec/batch)\n",
      "2017-05-28 08:30:52.302851: step 36730, loss = 0.87 (314.9 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 08:31:00.527903: step 36740, loss = 0.74 (311.2 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 08:31:09.298226: step 36750, loss = 0.64 (291.9 examples/sec; 0.877 sec/batch)\n",
      "2017-05-28 08:31:17.636395: step 36760, loss = 0.76 (307.0 examples/sec; 0.834 sec/batch)\n",
      "2017-05-28 08:31:25.715707: step 36770, loss = 0.80 (316.9 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 08:31:34.017506: step 36780, loss = 0.84 (308.4 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 08:31:42.654883: step 36790, loss = 0.74 (296.4 examples/sec; 0.864 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1346\n",
      "2017-05-28 08:31:56.081062: step 36800, loss = 0.76 (190.7 examples/sec; 1.343 sec/batch)\n",
      "2017-05-28 08:32:03.653903: step 36810, loss = 0.77 (338.1 examples/sec; 0.757 sec/batch)\n",
      "2017-05-28 08:32:11.939255: step 36820, loss = 0.71 (309.0 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 08:32:20.656318: step 36830, loss = 0.68 (293.7 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 08:32:28.809262: step 36840, loss = 0.66 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 08:32:37.116457: step 36850, loss = 0.80 (308.2 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 08:32:45.355167: step 36860, loss = 0.76 (310.7 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 08:32:54.086278: step 36870, loss = 0.74 (293.2 examples/sec; 0.873 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 36872 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 08:33:03.377209: step 36880, loss = 0.79 (275.5 examples/sec; 0.929 sec/batch)\n",
      "2017-05-28 08:33:11.537808: step 36890, loss = 0.73 (313.7 examples/sec; 0.816 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.09147\n",
      "2017-05-28 08:33:27.696983: step 36900, loss = 0.76 (158.4 examples/sec; 1.616 sec/batch)\n",
      "2017-05-28 08:33:35.115437: step 36910, loss = 0.83 (345.1 examples/sec; 0.742 sec/batch)\n",
      "2017-05-28 08:33:43.331994: step 36920, loss = 0.78 (311.6 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 08:33:52.081515: step 36930, loss = 0.80 (292.6 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 08:34:00.311927: step 36940, loss = 0.89 (311.0 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 08:34:08.596716: step 36950, loss = 1.01 (309.0 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 08:34:17.658917: step 36960, loss = 0.71 (282.5 examples/sec; 0.906 sec/batch)\n",
      "2017-05-28 08:34:25.988149: step 36970, loss = 0.76 (307.4 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 08:34:34.168497: step 36980, loss = 0.84 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 08:34:42.372536: step 36990, loss = 0.68 (312.0 examples/sec; 0.820 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12281\n",
      "2017-05-28 08:34:56.760805: step 37000, loss = 0.81 (177.9 examples/sec; 1.439 sec/batch)\n",
      "2017-05-28 08:35:04.110552: step 37010, loss = 0.72 (348.3 examples/sec; 0.735 sec/batch)\n",
      "2017-05-28 08:35:12.186484: step 37020, loss = 0.74 (317.0 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 08:35:20.645078: step 37030, loss = 0.92 (302.7 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 08:35:29.107519: step 37040, loss = 0.93 (302.5 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 08:35:37.205106: step 37050, loss = 0.78 (316.1 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 08:35:45.980925: step 37060, loss = 0.76 (291.7 examples/sec; 0.878 sec/batch)\n",
      "2017-05-28 08:35:54.225116: step 37070, loss = 0.85 (310.5 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 08:36:03.122675: step 37080, loss = 0.74 (287.7 examples/sec; 0.890 sec/batch)\n",
      "2017-05-28 08:36:11.809510: step 37090, loss = 0.73 (294.7 examples/sec; 0.869 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14629\n",
      "2017-05-28 08:36:23.997731: step 37100, loss = 0.78 (210.0 examples/sec; 1.219 sec/batch)\n",
      "2017-05-28 08:36:31.936096: step 37110, loss = 0.76 (322.5 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 08:36:40.096746: step 37120, loss = 0.84 (313.7 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 08:36:48.193165: step 37130, loss = 0.89 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 08:36:56.744049: step 37140, loss = 0.67 (299.4 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 08:37:05.149747: step 37150, loss = 0.76 (304.6 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 08:37:13.317947: step 37160, loss = 0.70 (313.4 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 08:37:22.173881: step 37170, loss = 0.76 (289.1 examples/sec; 0.886 sec/batch)\n",
      "2017-05-28 08:37:30.319617: step 37180, loss = 0.80 (314.3 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 08:37:38.533152: step 37190, loss = 0.84 (311.7 examples/sec; 0.821 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1358\n",
      "2017-05-28 08:37:52.042838: step 37200, loss = 0.75 (189.5 examples/sec; 1.351 sec/batch)\n",
      "2017-05-28 08:37:59.486413: step 37210, loss = 0.67 (343.9 examples/sec; 0.744 sec/batch)\n",
      "2017-05-28 08:38:07.637311: step 37220, loss = 0.76 (314.1 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 08:38:16.438454: step 37230, loss = 0.73 (290.9 examples/sec; 0.880 sec/batch)\n",
      "2017-05-28 08:38:24.714759: step 37240, loss = 0.90 (309.3 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 08:38:34.079617: step 37250, loss = 0.72 (273.4 examples/sec; 0.936 sec/batch)\n",
      "2017-05-28 08:38:43.158338: step 37260, loss = 0.77 (282.0 examples/sec; 0.908 sec/batch)\n",
      "2017-05-28 08:38:51.422897: step 37270, loss = 0.73 (309.8 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 08:38:59.649172: step 37280, loss = 0.77 (311.2 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 08:39:08.046985: step 37290, loss = 0.82 (304.8 examples/sec; 0.840 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10498\n",
      "2017-05-28 08:39:22.540337: step 37300, loss = 0.73 (176.6 examples/sec; 1.449 sec/batch)\n",
      "2017-05-28 08:39:29.930635: step 37310, loss = 0.79 (346.4 examples/sec; 0.739 sec/batch)\n",
      "2017-05-28 08:39:38.692464: step 37320, loss = 0.72 (292.2 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 08:39:47.572545: step 37330, loss = 0.75 (288.3 examples/sec; 0.888 sec/batch)\n",
      "2017-05-28 08:39:55.846317: step 37340, loss = 0.84 (309.4 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 08:40:04.092747: step 37350, loss = 0.82 (310.4 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 08:40:12.265306: step 37360, loss = 0.77 (313.2 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 08:40:20.410725: step 37370, loss = 0.83 (314.3 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 08:40:28.970871: step 37380, loss = 0.83 (299.1 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 08:40:37.423092: step 37390, loss = 0.88 (302.9 examples/sec; 0.845 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12206\n",
      "2017-05-28 08:40:51.663784: step 37400, loss = 0.84 (179.8 examples/sec; 1.424 sec/batch)\n",
      "2017-05-28 08:40:59.095251: step 37410, loss = 0.69 (344.5 examples/sec; 0.743 sec/batch)\n",
      "2017-05-28 08:41:07.213385: step 37420, loss = 0.86 (315.3 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 08:41:15.650841: step 37430, loss = 0.67 (303.4 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 08:41:24.385441: step 37440, loss = 0.65 (293.1 examples/sec; 0.873 sec/batch)\n",
      "2017-05-28 08:41:32.661294: step 37450, loss = 0.88 (309.3 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 08:41:40.834111: step 37460, loss = 0.70 (313.2 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 08:41:49.555414: step 37470, loss = 0.86 (293.5 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 08:41:57.878307: step 37480, loss = 0.80 (307.6 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 08:42:06.020829: step 37490, loss = 0.73 (314.4 examples/sec; 0.814 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13877\n",
      "2017-05-28 08:42:19.479374: step 37500, loss = 0.82 (190.2 examples/sec; 1.346 sec/batch)\n",
      "2017-05-28 08:42:27.231575: step 37510, loss = 0.78 (330.2 examples/sec; 0.775 sec/batch)\n",
      "2017-05-28 08:42:35.393955: step 37520, loss = 0.70 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 08:42:43.721752: step 37530, loss = 0.77 (307.4 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 08:42:52.500720: step 37540, loss = 0.70 (291.6 examples/sec; 0.878 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 37544 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 08:43:01.675975: step 37550, loss = 0.85 (279.0 examples/sec; 0.918 sec/batch)\n",
      "2017-05-28 08:43:09.795167: step 37560, loss = 0.84 (315.3 examples/sec; 0.812 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 08:43:18.549880: step 37570, loss = 0.77 (292.4 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 08:43:26.869486: step 37580, loss = 0.83 (307.7 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 08:43:35.311550: step 37590, loss = 0.79 (303.2 examples/sec; 0.844 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.10601\n",
      "2017-05-28 08:43:49.891766: step 37600, loss = 0.72 (175.6 examples/sec; 1.458 sec/batch)\n",
      "2017-05-28 08:43:57.841262: step 37610, loss = 0.73 (322.0 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 08:44:06.427915: step 37620, loss = 0.70 (298.1 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 08:44:14.568021: step 37630, loss = 0.79 (314.5 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 08:44:22.834493: step 37640, loss = 0.74 (309.7 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 08:44:31.797315: step 37650, loss = 0.89 (285.6 examples/sec; 0.896 sec/batch)\n",
      "2017-05-28 08:44:39.902912: step 37660, loss = 0.87 (315.8 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 08:44:48.248011: step 37670, loss = 0.85 (306.8 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 08:44:56.454466: step 37680, loss = 0.76 (311.9 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 08:45:05.212984: step 37690, loss = 0.86 (292.3 examples/sec; 0.876 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14345\n",
      "2017-05-28 08:45:17.346818: step 37700, loss = 0.76 (211.0 examples/sec; 1.213 sec/batch)\n",
      "2017-05-28 08:45:24.840426: step 37710, loss = 0.76 (341.6 examples/sec; 0.749 sec/batch)\n",
      "2017-05-28 08:45:33.647225: step 37720, loss = 0.74 (290.7 examples/sec; 0.881 sec/batch)\n",
      "2017-05-28 08:45:41.858879: step 37730, loss = 0.77 (311.8 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 08:45:50.003725: step 37740, loss = 0.78 (314.3 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 08:45:58.709949: step 37750, loss = 0.79 (294.0 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 08:46:07.095603: step 37760, loss = 0.66 (305.3 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 08:46:15.565420: step 37770, loss = 0.83 (302.2 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 08:46:24.141825: step 37780, loss = 0.85 (298.5 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 08:46:32.559368: step 37790, loss = 0.83 (304.1 examples/sec; 0.842 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12167\n",
      "2017-05-28 08:46:46.501100: step 37800, loss = 0.88 (183.6 examples/sec; 1.394 sec/batch)\n",
      "2017-05-28 08:46:54.014280: step 37810, loss = 0.76 (340.7 examples/sec; 0.751 sec/batch)\n",
      "2017-05-28 08:47:02.129813: step 37820, loss = 0.73 (315.4 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 08:47:10.346981: step 37830, loss = 0.70 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 08:47:19.135741: step 37840, loss = 0.79 (291.3 examples/sec; 0.879 sec/batch)\n",
      "2017-05-28 08:47:27.328951: step 37850, loss = 0.88 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 08:47:35.516154: step 37860, loss = 0.90 (312.7 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 08:47:44.201915: step 37870, loss = 0.77 (294.7 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 08:47:52.463122: step 37880, loss = 0.92 (309.9 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 08:48:00.622310: step 37890, loss = 0.79 (313.8 examples/sec; 0.816 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13596\n",
      "2017-05-28 08:48:14.531425: step 37900, loss = 0.90 (184.1 examples/sec; 1.391 sec/batch)\n",
      "2017-05-28 08:48:21.910812: step 37910, loss = 0.77 (346.9 examples/sec; 0.738 sec/batch)\n",
      "2017-05-28 08:48:30.110857: step 37920, loss = 0.74 (312.2 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 08:48:38.283390: step 37930, loss = 0.76 (313.2 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 08:48:47.365576: step 37940, loss = 0.88 (281.9 examples/sec; 0.908 sec/batch)\n",
      "2017-05-28 08:48:56.777551: step 37950, loss = 0.76 (272.0 examples/sec; 0.941 sec/batch)\n",
      "2017-05-28 08:49:04.961515: step 37960, loss = 0.75 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 08:49:13.487422: step 37970, loss = 0.86 (300.3 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 08:49:22.082621: step 37980, loss = 0.73 (297.8 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 08:49:30.291773: step 37990, loss = 0.73 (311.8 examples/sec; 0.821 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14129\n",
      "2017-05-28 08:49:42.151537: step 38000, loss = 0.76 (215.9 examples/sec; 1.186 sec/batch)\n",
      "2017-05-28 08:49:50.043305: step 38010, loss = 0.78 (324.4 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 08:49:58.851686: step 38020, loss = 0.82 (290.6 examples/sec; 0.881 sec/batch)\n",
      "2017-05-28 08:50:07.215020: step 38030, loss = 0.79 (306.1 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 08:50:15.634501: step 38040, loss = 0.88 (304.1 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 08:50:24.101993: step 38050, loss = 0.93 (302.3 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 08:50:32.677078: step 38060, loss = 0.84 (298.5 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 08:50:40.794080: step 38070, loss = 0.78 (315.4 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 08:50:48.893597: step 38080, loss = 0.94 (316.1 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 08:50:57.840381: step 38090, loss = 0.82 (286.1 examples/sec; 0.895 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13494\n",
      "2017-05-28 08:51:10.265167: step 38100, loss = 0.64 (206.0 examples/sec; 1.242 sec/batch)\n",
      "2017-05-28 08:51:18.013386: step 38110, loss = 0.74 (330.4 examples/sec; 0.775 sec/batch)\n",
      "2017-05-28 08:51:26.237203: step 38120, loss = 0.77 (311.3 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 08:51:34.547959: step 38130, loss = 0.80 (308.0 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 08:51:43.180470: step 38140, loss = 0.90 (296.6 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 08:51:51.596880: step 38150, loss = 0.82 (304.2 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 08:51:59.727861: step 38160, loss = 0.71 (314.8 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 08:52:08.232650: step 38170, loss = 0.76 (301.0 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 08:52:16.940092: step 38180, loss = 0.74 (294.0 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 08:52:25.227334: step 38190, loss = 0.86 (308.9 examples/sec; 0.829 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13609\n",
      "2017-05-28 08:52:38.285013: step 38200, loss = 0.76 (196.1 examples/sec; 1.306 sec/batch)\n",
      "2017-05-28 08:52:45.698757: step 38210, loss = 0.90 (345.3 examples/sec; 0.741 sec/batch)\n",
      "2017-05-28 08:52:53.947297: step 38220, loss = 0.82 (310.4 examples/sec; 0.825 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 38223 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 08:53:03.655127: step 38230, loss = 0.74 (263.7 examples/sec; 0.971 sec/batch)\n",
      "2017-05-28 08:53:12.015560: step 38240, loss = 0.76 (306.2 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 08:53:20.092771: step 38250, loss = 0.80 (316.9 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 08:53:28.849728: step 38260, loss = 0.69 (292.3 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 08:53:37.215632: step 38270, loss = 0.88 (306.0 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 08:53:45.487437: step 38280, loss = 0.72 (309.5 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 08:53:53.742129: step 38290, loss = 0.91 (310.1 examples/sec; 0.825 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.0999\n",
      "2017-05-28 08:54:09.200090: step 38300, loss = 0.83 (165.6 examples/sec; 1.546 sec/batch)\n",
      "2017-05-28 08:54:16.668498: step 38310, loss = 0.82 (342.8 examples/sec; 0.747 sec/batch)\n",
      "2017-05-28 08:54:25.385964: step 38320, loss = 0.69 (293.7 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 08:54:33.606996: step 38330, loss = 0.89 (311.4 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 08:54:41.809364: step 38340, loss = 0.72 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 08:54:50.407141: step 38350, loss = 0.89 (297.8 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 08:54:59.010505: step 38360, loss = 0.76 (297.6 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 08:55:07.345895: step 38370, loss = 0.88 (307.1 examples/sec; 0.834 sec/batch)\n",
      "2017-05-28 08:55:15.593074: step 38380, loss = 0.92 (310.4 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 08:55:24.081167: step 38390, loss = 0.69 (301.6 examples/sec; 0.849 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14148\n",
      "2017-05-28 08:55:36.804897: step 38400, loss = 0.79 (201.2 examples/sec; 1.272 sec/batch)\n",
      "2017-05-28 08:55:44.583036: step 38410, loss = 0.70 (329.1 examples/sec; 0.778 sec/batch)\n",
      "2017-05-28 08:55:53.168378: step 38420, loss = 0.83 (298.2 examples/sec; 0.859 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 08:56:01.387870: step 38430, loss = 0.70 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 08:56:09.525797: step 38440, loss = 0.79 (314.6 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 08:56:17.664140: step 38450, loss = 0.82 (314.6 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 08:56:26.353011: step 38460, loss = 0.86 (294.6 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 08:56:34.624602: step 38470, loss = 0.77 (309.5 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 08:56:43.376472: step 38480, loss = 0.76 (292.5 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 08:56:51.689678: step 38490, loss = 0.66 (307.9 examples/sec; 0.831 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15143\n",
      "2017-05-28 08:57:03.654068: step 38500, loss = 0.73 (214.0 examples/sec; 1.196 sec/batch)\n",
      "2017-05-28 08:57:11.032591: step 38510, loss = 0.85 (347.0 examples/sec; 0.738 sec/batch)\n",
      "2017-05-28 08:57:19.107918: step 38520, loss = 0.82 (317.0 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 08:57:27.804637: step 38530, loss = 0.78 (294.4 examples/sec; 0.870 sec/batch)\n",
      "2017-05-28 08:57:36.187097: step 38540, loss = 0.71 (305.4 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 08:57:44.600963: step 38550, loss = 0.74 (304.3 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 08:57:53.180822: step 38560, loss = 0.83 (298.4 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 08:58:01.373398: step 38570, loss = 0.80 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 08:58:09.528508: step 38580, loss = 0.73 (313.9 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 08:58:18.230697: step 38590, loss = 0.83 (294.2 examples/sec; 0.870 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15041\n",
      "2017-05-28 08:58:30.586476: step 38600, loss = 0.70 (207.2 examples/sec; 1.236 sec/batch)\n",
      "2017-05-28 08:58:38.541373: step 38610, loss = 0.75 (321.8 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 08:58:46.730357: step 38620, loss = 0.83 (312.6 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 08:58:54.923296: step 38630, loss = 0.80 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 08:59:03.688179: step 38640, loss = 0.95 (292.1 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 08:59:13.757145: step 38650, loss = 0.75 (254.2 examples/sec; 1.007 sec/batch)\n",
      "2017-05-28 08:59:22.443193: step 38660, loss = 0.80 (294.7 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 08:59:30.815987: step 38670, loss = 0.75 (305.8 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 08:59:38.983545: step 38680, loss = 0.78 (313.4 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 08:59:47.371306: step 38690, loss = 0.93 (305.2 examples/sec; 0.839 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.09789\n",
      "2017-05-28 09:00:01.665201: step 38700, loss = 0.78 (179.1 examples/sec; 1.429 sec/batch)\n",
      "2017-05-28 09:00:09.061662: step 38710, loss = 0.83 (346.1 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 09:00:17.595276: step 38720, loss = 0.82 (300.0 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 09:00:26.048037: step 38730, loss = 0.85 (302.9 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 09:00:34.251412: step 38740, loss = 0.95 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 09:00:42.476308: step 38750, loss = 0.79 (311.3 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 09:00:50.573556: step 38760, loss = 0.83 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 09:00:58.891205: step 38770, loss = 0.71 (307.8 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 09:01:07.612085: step 38780, loss = 0.72 (293.5 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 09:01:15.799934: step 38790, loss = 0.89 (312.7 examples/sec; 0.819 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14192\n",
      "2017-05-28 09:01:29.238915: step 38800, loss = 0.93 (190.5 examples/sec; 1.344 sec/batch)\n",
      "2017-05-28 09:01:36.945721: step 38810, loss = 0.86 (332.2 examples/sec; 0.771 sec/batch)\n",
      "2017-05-28 09:01:45.045540: step 38820, loss = 0.75 (316.1 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 09:01:53.739981: step 38830, loss = 0.67 (294.4 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 09:02:01.957688: step 38840, loss = 0.90 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 09:02:10.164576: step 38850, loss = 0.76 (311.9 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 09:02:18.203010: step 38860, loss = 0.86 (318.5 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 09:02:26.906429: step 38870, loss = 0.78 (294.1 examples/sec; 0.870 sec/batch)\n",
      "2017-05-28 09:02:35.198683: step 38880, loss = 0.83 (308.7 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 09:02:43.475297: step 38890, loss = 0.85 (309.3 examples/sec; 0.828 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15079\n",
      "INFO:tensorflow:Saving checkpoints for 38901 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 09:02:57.293345: step 38900, loss = 0.73 (185.3 examples/sec; 1.382 sec/batch)\n",
      "2017-05-28 09:03:04.732337: step 38910, loss = 0.83 (344.1 examples/sec; 0.744 sec/batch)\n",
      "2017-05-28 09:03:13.360846: step 38920, loss = 0.79 (296.7 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 09:03:21.769714: step 38930, loss = 0.73 (304.4 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 09:03:30.004632: step 38940, loss = 0.80 (310.9 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 09:03:38.786615: step 38950, loss = 0.83 (291.5 examples/sec; 0.878 sec/batch)\n",
      "2017-05-28 09:03:46.954916: step 38960, loss = 0.79 (313.4 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 09:03:55.159528: step 38970, loss = 0.75 (312.0 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 09:04:03.829753: step 38980, loss = 0.89 (295.3 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 09:04:11.954305: step 38990, loss = 0.78 (315.1 examples/sec; 0.812 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11329\n",
      "2017-05-28 09:04:25.955545: step 39000, loss = 0.87 (182.8 examples/sec; 1.400 sec/batch)\n",
      "2017-05-28 09:04:33.523707: step 39010, loss = 0.89 (338.3 examples/sec; 0.757 sec/batch)\n",
      "2017-05-28 09:04:42.712856: step 39020, loss = 0.84 (278.6 examples/sec; 0.919 sec/batch)\n",
      "2017-05-28 09:04:50.839332: step 39030, loss = 0.71 (315.0 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 09:04:59.024979: step 39040, loss = 0.86 (312.7 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 09:05:07.129279: step 39050, loss = 0.80 (315.9 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 09:05:15.354260: step 39060, loss = 0.72 (311.2 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 09:05:24.112154: step 39070, loss = 0.82 (292.3 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 09:05:32.713037: step 39080, loss = 0.89 (297.6 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 09:05:41.236008: step 39090, loss = 0.74 (300.4 examples/sec; 0.852 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12225\n",
      "2017-05-28 09:05:55.062176: step 39100, loss = 0.82 (185.2 examples/sec; 1.383 sec/batch)\n",
      "2017-05-28 09:06:02.404631: step 39110, loss = 0.72 (348.7 examples/sec; 0.734 sec/batch)\n",
      "2017-05-28 09:06:11.450203: step 39120, loss = 0.64 (283.0 examples/sec; 0.905 sec/batch)\n",
      "2017-05-28 09:06:20.009544: step 39130, loss = 0.70 (299.1 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 09:06:28.105842: step 39140, loss = 0.76 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 09:06:36.419326: step 39150, loss = 0.72 (307.9 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 09:06:45.053738: step 39160, loss = 0.72 (296.5 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 09:06:53.505789: step 39170, loss = 0.75 (302.9 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 09:07:01.977253: step 39180, loss = 0.72 (302.2 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 09:07:11.138461: step 39190, loss = 0.87 (279.4 examples/sec; 0.916 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11649\n",
      "2017-05-28 09:07:24.632687: step 39200, loss = 0.77 (189.7 examples/sec; 1.349 sec/batch)\n",
      "2017-05-28 09:07:32.401335: step 39210, loss = 0.88 (329.5 examples/sec; 0.777 sec/batch)\n",
      "2017-05-28 09:07:40.482442: step 39220, loss = 0.76 (316.8 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 09:07:48.589784: step 39230, loss = 0.82 (315.8 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 09:07:57.311911: step 39240, loss = 0.78 (293.5 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 09:08:05.711756: step 39250, loss = 0.80 (304.8 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 09:08:14.434503: step 39260, loss = 0.87 (293.5 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 09:08:23.405561: step 39270, loss = 0.78 (285.4 examples/sec; 0.897 sec/batch)\n",
      "2017-05-28 09:08:31.646517: step 39280, loss = 0.66 (310.6 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 09:08:39.797718: step 39290, loss = 0.79 (314.1 examples/sec; 0.815 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.13382\n",
      "2017-05-28 09:08:52.825999: step 39300, loss = 0.87 (196.5 examples/sec; 1.303 sec/batch)\n",
      "2017-05-28 09:09:00.363782: step 39310, loss = 0.73 (339.6 examples/sec; 0.754 sec/batch)\n",
      "2017-05-28 09:09:09.058619: step 39320, loss = 0.69 (294.4 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 09:09:17.291678: step 39330, loss = 0.74 (310.9 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 09:09:27.192437: step 39340, loss = 0.97 (258.6 examples/sec; 0.990 sec/batch)\n",
      "2017-05-28 09:09:35.914882: step 39350, loss = 0.78 (293.5 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 09:09:44.134174: step 39360, loss = 0.72 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 09:09:52.877479: step 39370, loss = 0.74 (292.8 examples/sec; 0.874 sec/batch)\n",
      "2017-05-28 09:10:01.579096: step 39380, loss = 0.80 (294.2 examples/sec; 0.870 sec/batch)\n",
      "2017-05-28 09:10:10.307784: step 39390, loss = 0.69 (293.3 examples/sec; 0.873 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11135\n",
      "2017-05-28 09:10:22.806878: step 39400, loss = 0.74 (204.8 examples/sec; 1.250 sec/batch)\n",
      "2017-05-28 09:10:30.145110: step 39410, loss = 0.85 (348.9 examples/sec; 0.734 sec/batch)\n",
      "2017-05-28 09:10:38.353525: step 39420, loss = 0.72 (311.9 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 09:10:47.071112: step 39430, loss = 0.85 (293.7 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 09:10:55.293704: step 39440, loss = 0.66 (311.3 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 09:11:04.273361: step 39450, loss = 0.86 (285.1 examples/sec; 0.898 sec/batch)\n",
      "2017-05-28 09:11:12.790819: step 39460, loss = 0.72 (300.6 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 09:11:20.993691: step 39470, loss = 0.93 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 09:11:29.097846: step 39480, loss = 0.81 (315.9 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 09:11:37.604439: step 39490, loss = 0.90 (300.9 examples/sec; 0.851 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15031\n",
      "2017-05-28 09:11:49.740169: step 39500, loss = 0.71 (210.9 examples/sec; 1.214 sec/batch)\n",
      "2017-05-28 09:11:57.291112: step 39510, loss = 0.89 (339.0 examples/sec; 0.755 sec/batch)\n",
      "2017-05-28 09:12:05.741802: step 39520, loss = 0.81 (302.9 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 09:12:14.382904: step 39530, loss = 0.82 (296.3 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 09:12:22.489829: step 39540, loss = 0.84 (315.8 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 09:12:30.634853: step 39550, loss = 0.77 (314.3 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 09:12:39.344105: step 39560, loss = 0.72 (293.9 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 09:12:47.542804: step 39570, loss = 0.81 (312.2 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 09:12:55.716707: step 39580, loss = 0.81 (313.2 examples/sec; 0.817 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 39582 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 09:13:04.923177: step 39590, loss = 0.70 (278.1 examples/sec; 0.921 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13058\n",
      "2017-05-28 09:13:18.190555: step 39600, loss = 0.89 (193.0 examples/sec; 1.327 sec/batch)\n",
      "2017-05-28 09:13:25.675347: step 39610, loss = 0.68 (342.0 examples/sec; 0.748 sec/batch)\n",
      "2017-05-28 09:13:34.482740: step 39620, loss = 0.77 (290.7 examples/sec; 0.881 sec/batch)\n",
      "2017-05-28 09:13:42.647001: step 39630, loss = 0.72 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 09:13:51.158582: step 39640, loss = 0.76 (300.8 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 09:13:59.560338: step 39650, loss = 0.84 (304.7 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 09:14:07.823873: step 39660, loss = 0.87 (309.8 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 09:14:16.120460: step 39670, loss = 0.76 (308.6 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 09:14:24.858978: step 39680, loss = 0.79 (293.0 examples/sec; 0.874 sec/batch)\n",
      "2017-05-28 09:14:33.823924: step 39690, loss = 0.78 (285.6 examples/sec; 0.896 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1159\n",
      "2017-05-28 09:14:47.803695: step 39700, loss = 0.70 (183.1 examples/sec; 1.398 sec/batch)\n",
      "2017-05-28 09:14:55.304659: step 39710, loss = 0.87 (341.3 examples/sec; 0.750 sec/batch)\n",
      "2017-05-28 09:15:03.640934: step 39720, loss = 0.72 (307.1 examples/sec; 0.834 sec/batch)\n",
      "2017-05-28 09:15:11.741595: step 39730, loss = 0.69 (316.0 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 09:15:20.035765: step 39740, loss = 0.67 (308.7 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 09:15:28.731098: step 39750, loss = 0.91 (294.4 examples/sec; 0.870 sec/batch)\n",
      "2017-05-28 09:15:36.933070: step 39760, loss = 0.88 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 09:15:45.617187: step 39770, loss = 0.73 (294.8 examples/sec; 0.868 sec/batch)\n",
      "2017-05-28 09:15:53.935770: step 39780, loss = 0.84 (307.7 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 09:16:02.081690: step 39790, loss = 0.72 (314.3 examples/sec; 0.815 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1604\n",
      "2017-05-28 09:16:13.981818: step 39800, loss = 0.68 (215.1 examples/sec; 1.190 sec/batch)\n",
      "2017-05-28 09:16:21.935148: step 39810, loss = 0.76 (321.9 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 09:16:30.165175: step 39820, loss = 0.86 (311.1 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 09:16:38.309333: step 39830, loss = 0.82 (314.3 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 09:16:46.925580: step 39840, loss = 0.77 (297.1 examples/sec; 0.862 sec/batch)\n",
      "2017-05-28 09:16:55.422154: step 39850, loss = 0.85 (301.3 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 09:17:03.624759: step 39860, loss = 0.85 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 09:17:12.372190: step 39870, loss = 0.87 (292.7 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 09:17:20.555143: step 39880, loss = 0.85 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 09:17:28.867220: step 39890, loss = 0.87 (308.0 examples/sec; 0.831 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13152\n",
      "2017-05-28 09:17:42.358560: step 39900, loss = 0.71 (189.8 examples/sec; 1.349 sec/batch)\n",
      "2017-05-28 09:17:49.799157: step 39910, loss = 0.78 (344.1 examples/sec; 0.744 sec/batch)\n",
      "2017-05-28 09:17:58.035152: step 39920, loss = 0.75 (310.8 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 09:18:06.287050: step 39930, loss = 0.79 (310.2 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 09:18:15.042794: step 39940, loss = 0.80 (292.4 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 09:18:23.385638: step 39950, loss = 0.78 (306.8 examples/sec; 0.834 sec/batch)\n",
      "2017-05-28 09:18:31.566162: step 39960, loss = 0.82 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 09:18:40.206904: step 39970, loss = 0.76 (296.3 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 09:18:48.623872: step 39980, loss = 0.76 (304.1 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 09:18:56.821783: step 39990, loss = 0.75 (312.3 examples/sec; 0.820 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12151\n",
      "2017-05-28 09:19:11.522993: step 40000, loss = 0.82 (174.1 examples/sec; 1.470 sec/batch)\n",
      "2017-05-28 09:19:18.917147: step 40010, loss = 0.77 (346.2 examples/sec; 0.739 sec/batch)\n",
      "2017-05-28 09:19:27.331581: step 40020, loss = 0.78 (304.2 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 09:19:35.447976: step 40030, loss = 0.76 (315.4 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 09:19:44.979573: step 40040, loss = 0.64 (268.6 examples/sec; 0.953 sec/batch)\n",
      "2017-05-28 09:19:53.951723: step 40050, loss = 0.65 (285.3 examples/sec; 0.897 sec/batch)\n",
      "2017-05-28 09:20:02.367123: step 40060, loss = 0.82 (304.2 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 09:20:10.857132: step 40070, loss = 0.82 (301.5 examples/sec; 0.849 sec/batch)\n",
      "2017-05-28 09:20:19.673912: step 40080, loss = 0.77 (290.4 examples/sec; 0.882 sec/batch)\n",
      "2017-05-28 09:20:27.826376: step 40090, loss = 0.76 (314.0 examples/sec; 0.815 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11836\n",
      "2017-05-28 09:20:40.943268: step 40100, loss = 0.79 (195.2 examples/sec; 1.312 sec/batch)\n",
      "2017-05-28 09:20:48.637546: step 40110, loss = 0.86 (332.7 examples/sec; 0.769 sec/batch)\n",
      "2017-05-28 09:20:56.781534: step 40120, loss = 0.67 (314.3 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 09:21:04.959510: step 40130, loss = 0.76 (313.0 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 09:21:13.611579: step 40140, loss = 0.81 (295.9 examples/sec; 0.865 sec/batch)\n",
      "2017-05-28 09:21:21.850667: step 40150, loss = 0.76 (310.7 examples/sec; 0.824 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 09:21:30.487774: step 40160, loss = 0.74 (296.4 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 09:21:38.999710: step 40170, loss = 0.68 (300.8 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 09:21:47.151613: step 40180, loss = 0.90 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 09:21:55.385073: step 40190, loss = 0.89 (310.9 examples/sec; 0.823 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12763\n",
      "2017-05-28 09:22:09.623044: step 40200, loss = 0.75 (179.8 examples/sec; 1.424 sec/batch)\n",
      "2017-05-28 09:22:17.170574: step 40210, loss = 0.70 (339.2 examples/sec; 0.755 sec/batch)\n",
      "2017-05-28 09:22:25.527240: step 40220, loss = 0.67 (306.3 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 09:22:34.191145: step 40230, loss = 0.73 (295.5 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 09:22:42.315891: step 40240, loss = 0.71 (315.1 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 09:22:50.457626: step 40250, loss = 0.76 (314.4 examples/sec; 0.814 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 40259 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 09:22:59.638603: step 40260, loss = 0.79 (278.8 examples/sec; 0.918 sec/batch)\n",
      "2017-05-28 09:23:07.556597: step 40270, loss = 0.74 (323.3 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 09:23:16.386519: step 40280, loss = 0.70 (289.9 examples/sec; 0.883 sec/batch)\n",
      "2017-05-28 09:23:24.632017: step 40290, loss = 0.79 (310.5 examples/sec; 0.825 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13186\n",
      "2017-05-28 09:23:37.971433: step 40300, loss = 0.74 (191.9 examples/sec; 1.334 sec/batch)\n",
      "2017-05-28 09:23:45.399483: step 40310, loss = 0.75 (344.6 examples/sec; 0.743 sec/batch)\n",
      "2017-05-28 09:23:53.539545: step 40320, loss = 0.72 (314.5 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 09:24:02.198669: step 40330, loss = 0.88 (295.6 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 09:24:10.446191: step 40340, loss = 0.65 (310.4 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 09:24:19.002459: step 40350, loss = 0.84 (299.2 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 09:24:27.585756: step 40360, loss = 0.76 (298.3 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 09:24:35.769605: step 40370, loss = 0.90 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 09:24:43.923245: step 40380, loss = 0.78 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 09:24:54.462451: step 40390, loss = 0.70 (242.9 examples/sec; 1.054 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12532\n",
      "2017-05-28 09:25:06.834897: step 40400, loss = 0.81 (206.9 examples/sec; 1.237 sec/batch)\n",
      "2017-05-28 09:25:14.507535: step 40410, loss = 0.80 (333.7 examples/sec; 0.767 sec/batch)\n",
      "2017-05-28 09:25:23.012520: step 40420, loss = 0.90 (301.0 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 09:25:31.298062: step 40430, loss = 0.88 (309.0 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 09:25:40.290076: step 40440, loss = 0.80 (284.7 examples/sec; 0.899 sec/batch)\n",
      "2017-05-28 09:25:48.455171: step 40450, loss = 0.69 (313.5 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 09:25:56.631678: step 40460, loss = 0.77 (313.1 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 09:26:04.812249: step 40470, loss = 0.74 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 09:26:13.574135: step 40480, loss = 0.82 (292.2 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 09:26:21.866864: step 40490, loss = 0.75 (308.7 examples/sec; 0.829 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15231\n",
      "2017-05-28 09:26:33.617912: step 40500, loss = 0.71 (217.9 examples/sec; 1.175 sec/batch)\n",
      "2017-05-28 09:26:41.671246: step 40510, loss = 0.79 (317.9 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 09:26:49.894739: step 40520, loss = 0.83 (311.3 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 09:26:58.091166: step 40530, loss = 0.74 (312.3 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 09:27:06.504569: step 40540, loss = 0.78 (304.3 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 09:27:15.112782: step 40550, loss = 0.86 (297.4 examples/sec; 0.861 sec/batch)\n",
      "2017-05-28 09:27:23.363143: step 40560, loss = 0.70 (310.3 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 09:27:32.127896: step 40570, loss = 0.58 (292.1 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 09:27:40.248870: step 40580, loss = 0.81 (315.2 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 09:27:48.407861: step 40590, loss = 0.66 (313.8 examples/sec; 0.816 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1338\n",
      "2017-05-28 09:28:01.816856: step 40600, loss = 0.94 (190.9 examples/sec; 1.341 sec/batch)\n",
      "2017-05-28 09:28:09.160245: step 40610, loss = 0.75 (348.6 examples/sec; 0.734 sec/batch)\n",
      "2017-05-28 09:28:17.357412: step 40620, loss = 0.77 (312.3 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 09:28:25.544390: step 40630, loss = 0.78 (312.7 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 09:28:33.625430: step 40640, loss = 0.76 (316.8 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 09:28:42.292487: step 40650, loss = 0.77 (295.4 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 09:28:50.553067: step 40660, loss = 0.78 (309.9 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 09:28:58.974401: step 40670, loss = 0.83 (304.0 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 09:29:07.578160: step 40680, loss = 0.70 (297.5 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 09:29:15.739391: step 40690, loss = 0.72 (313.7 examples/sec; 0.816 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13112\n",
      "2017-05-28 09:29:30.226307: step 40700, loss = 0.71 (176.7 examples/sec; 1.449 sec/batch)\n",
      "2017-05-28 09:29:37.629523: step 40710, loss = 0.71 (345.8 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 09:29:45.750278: step 40720, loss = 0.71 (315.2 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 09:29:54.352794: step 40730, loss = 0.84 (297.6 examples/sec; 0.860 sec/batch)\n",
      "2017-05-28 09:30:04.254396: step 40740, loss = 0.70 (258.5 examples/sec; 0.990 sec/batch)\n",
      "2017-05-28 09:30:12.685870: step 40750, loss = 0.84 (303.6 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 09:30:21.052533: step 40760, loss = 0.85 (306.0 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 09:30:29.825766: step 40770, loss = 0.74 (291.8 examples/sec; 0.877 sec/batch)\n",
      "2017-05-28 09:30:37.996648: step 40780, loss = 0.71 (313.3 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 09:30:46.400161: step 40790, loss = 0.73 (304.6 examples/sec; 0.840 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11566\n",
      "2017-05-28 09:30:59.857650: step 40800, loss = 0.78 (190.2 examples/sec; 1.346 sec/batch)\n",
      "2017-05-28 09:31:07.252247: step 40810, loss = 0.75 (346.2 examples/sec; 0.739 sec/batch)\n",
      "2017-05-28 09:31:15.360074: step 40820, loss = 0.86 (315.7 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 09:31:24.076944: step 40830, loss = 0.72 (293.7 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 09:31:32.261800: step 40840, loss = 0.81 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 09:31:40.936974: step 40850, loss = 0.84 (295.1 examples/sec; 0.868 sec/batch)\n",
      "2017-05-28 09:31:49.340281: step 40860, loss = 0.76 (304.6 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 09:31:57.550109: step 40870, loss = 0.82 (311.8 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 09:32:05.938750: step 40880, loss = 0.79 (305.2 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 09:32:14.645173: step 40890, loss = 0.80 (294.0 examples/sec; 0.871 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12904\n",
      "2017-05-28 09:32:28.429820: step 40900, loss = 0.74 (185.7 examples/sec; 1.378 sec/batch)\n",
      "2017-05-28 09:32:35.941540: step 40910, loss = 0.79 (340.8 examples/sec; 0.751 sec/batch)\n",
      "2017-05-28 09:32:44.121064: step 40920, loss = 0.71 (313.0 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 09:32:52.227453: step 40930, loss = 0.78 (315.8 examples/sec; 0.811 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 40937 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 09:33:01.202277: step 40940, loss = 0.90 (285.2 examples/sec; 0.897 sec/batch)\n",
      "2017-05-28 09:33:09.905712: step 40950, loss = 0.83 (294.1 examples/sec; 0.870 sec/batch)\n",
      "2017-05-28 09:33:18.032339: step 40960, loss = 0.71 (315.0 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 09:33:26.202892: step 40970, loss = 0.71 (313.3 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 09:33:34.883900: step 40980, loss = 0.76 (294.9 examples/sec; 0.868 sec/batch)\n",
      "2017-05-28 09:33:43.208824: step 40990, loss = 0.79 (307.5 examples/sec; 0.832 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1297\n",
      "2017-05-28 09:33:56.947124: step 41000, loss = 0.77 (186.3 examples/sec; 1.374 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 09:34:04.260415: step 41010, loss = 0.87 (350.0 examples/sec; 0.731 sec/batch)\n",
      "2017-05-28 09:34:12.465751: step 41020, loss = 0.72 (312.0 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 09:34:21.052877: step 41030, loss = 0.81 (298.1 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 09:34:29.629349: step 41040, loss = 0.73 (298.5 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 09:34:37.844458: step 41050, loss = 0.73 (311.6 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 09:34:46.011484: step 41060, loss = 0.80 (313.5 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 09:34:54.375278: step 41070, loss = 0.72 (306.1 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 09:35:02.950765: step 41080, loss = 0.73 (298.5 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 09:35:12.534675: step 41090, loss = 0.83 (267.1 examples/sec; 0.958 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12788\n",
      "2017-05-28 09:35:25.608234: step 41100, loss = 0.79 (195.8 examples/sec; 1.307 sec/batch)\n",
      "2017-05-28 09:35:33.142908: step 41110, loss = 0.65 (339.8 examples/sec; 0.753 sec/batch)\n",
      "2017-05-28 09:35:41.865832: step 41120, loss = 0.74 (293.5 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 09:35:49.914982: step 41130, loss = 0.84 (318.0 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 09:35:58.359725: step 41140, loss = 0.65 (303.1 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 09:36:07.103295: step 41150, loss = 0.81 (292.8 examples/sec; 0.874 sec/batch)\n",
      "2017-05-28 09:36:15.384315: step 41160, loss = 0.83 (309.1 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 09:36:23.623610: step 41170, loss = 0.76 (310.7 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 09:36:32.150284: step 41180, loss = 0.72 (300.2 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 09:36:40.592479: step 41190, loss = 0.76 (303.2 examples/sec; 0.844 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15117\n",
      "2017-05-28 09:36:52.477068: step 41200, loss = 0.93 (215.4 examples/sec; 1.188 sec/batch)\n",
      "2017-05-28 09:37:00.334208: step 41210, loss = 0.95 (325.8 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 09:37:08.721373: step 41220, loss = 0.69 (305.2 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 09:37:16.866705: step 41230, loss = 0.73 (314.3 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 09:37:25.246923: step 41240, loss = 0.79 (305.5 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 09:37:34.020064: step 41250, loss = 0.70 (291.8 examples/sec; 0.877 sec/batch)\n",
      "2017-05-28 09:37:42.125646: step 41260, loss = 0.79 (315.8 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 09:37:50.477240: step 41270, loss = 0.79 (306.5 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 09:37:58.667662: step 41280, loss = 0.79 (312.6 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 09:38:07.374722: step 41290, loss = 0.69 (294.0 examples/sec; 0.871 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14572\n",
      "2017-05-28 09:38:19.758239: step 41300, loss = 0.71 (206.7 examples/sec; 1.238 sec/batch)\n",
      "2017-05-28 09:38:27.322086: step 41310, loss = 0.66 (338.5 examples/sec; 0.756 sec/batch)\n",
      "2017-05-28 09:38:36.187261: step 41320, loss = 0.74 (288.8 examples/sec; 0.887 sec/batch)\n",
      "2017-05-28 09:38:44.420452: step 41330, loss = 0.83 (310.9 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 09:38:53.009706: step 41340, loss = 0.85 (298.0 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 09:39:01.367758: step 41350, loss = 0.83 (306.3 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 09:39:09.669877: step 41360, loss = 0.93 (308.4 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 09:39:18.206469: step 41370, loss = 0.82 (299.9 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 09:39:26.353253: step 41380, loss = 0.79 (314.2 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 09:39:34.581171: step 41390, loss = 0.76 (311.1 examples/sec; 0.823 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12646\n",
      "2017-05-28 09:39:48.533724: step 41400, loss = 0.77 (183.5 examples/sec; 1.395 sec/batch)\n",
      "2017-05-28 09:39:56.222531: step 41410, loss = 0.70 (333.0 examples/sec; 0.769 sec/batch)\n",
      "2017-05-28 09:40:04.366115: step 41420, loss = 0.69 (314.4 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 09:40:13.587448: step 41430, loss = 0.79 (277.6 examples/sec; 0.922 sec/batch)\n",
      "2017-05-28 09:40:22.985285: step 41440, loss = 0.73 (272.4 examples/sec; 0.940 sec/batch)\n",
      "2017-05-28 09:40:31.345324: step 41450, loss = 0.80 (306.2 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 09:40:40.038784: step 41460, loss = 0.73 (294.5 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 09:40:48.310472: step 41470, loss = 0.83 (309.5 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 09:40:56.417096: step 41480, loss = 0.82 (315.8 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 09:41:05.226124: step 41490, loss = 0.72 (290.6 examples/sec; 0.881 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12416\n",
      "2017-05-28 09:41:17.487666: step 41500, loss = 0.74 (208.8 examples/sec; 1.226 sec/batch)\n",
      "2017-05-28 09:41:25.343941: step 41510, loss = 0.71 (325.9 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 09:41:34.503857: step 41520, loss = 0.80 (279.5 examples/sec; 0.916 sec/batch)\n",
      "2017-05-28 09:41:43.856448: step 41530, loss = 0.75 (273.7 examples/sec; 0.935 sec/batch)\n",
      "2017-05-28 09:41:53.960005: step 41540, loss = 0.73 (253.4 examples/sec; 1.010 sec/batch)\n",
      "2017-05-28 09:42:03.157930: step 41550, loss = 0.75 (278.3 examples/sec; 0.920 sec/batch)\n",
      "2017-05-28 09:42:11.847273: step 41560, loss = 0.82 (294.6 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 09:42:20.517112: step 41570, loss = 0.71 (295.3 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 09:42:29.811740: step 41580, loss = 0.77 (275.4 examples/sec; 0.929 sec/batch)\n",
      "2017-05-28 09:42:38.647414: step 41590, loss = 0.82 (289.7 examples/sec; 0.884 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.08315\n",
      "2017-05-28 09:42:49.817190: step 41600, loss = 0.86 (229.2 examples/sec; 1.117 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 41611 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 09:42:59.387447: step 41610, loss = 0.84 (267.5 examples/sec; 0.957 sec/batch)\n",
      "2017-05-28 09:43:06.820510: step 41620, loss = 0.82 (344.4 examples/sec; 0.743 sec/batch)\n",
      "2017-05-28 09:43:14.949759: step 41630, loss = 0.78 (314.9 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 09:43:22.899590: step 41640, loss = 0.76 (322.0 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 09:43:31.086806: step 41650, loss = 0.87 (312.7 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 09:43:39.497197: step 41660, loss = 0.80 (304.4 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 09:43:48.183096: step 41670, loss = 0.79 (294.7 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 09:43:56.736154: step 41680, loss = 0.74 (299.3 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 09:44:04.730136: step 41690, loss = 0.68 (320.2 examples/sec; 0.799 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13254\n",
      "2017-05-28 09:44:18.110177: step 41700, loss = 0.79 (191.3 examples/sec; 1.338 sec/batch)\n",
      "2017-05-28 09:44:26.223460: step 41710, loss = 0.81 (315.5 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 09:44:34.479045: step 41720, loss = 0.75 (310.1 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 09:44:43.256408: step 41730, loss = 0.78 (291.7 examples/sec; 0.878 sec/batch)\n",
      "2017-05-28 09:44:52.116510: step 41740, loss = 0.70 (288.9 examples/sec; 0.886 sec/batch)\n",
      "2017-05-28 09:45:00.474552: step 41750, loss = 0.80 (306.3 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 09:45:08.905625: step 41760, loss = 0.94 (303.6 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 09:45:17.316406: step 41770, loss = 0.66 (304.4 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 09:45:25.697638: step 41780, loss = 0.77 (305.4 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 09:45:34.061653: step 41790, loss = 0.68 (306.1 examples/sec; 0.836 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11857\n",
      "2017-05-28 09:45:47.509783: step 41800, loss = 0.73 (190.4 examples/sec; 1.345 sec/batch)\n",
      "2017-05-28 09:45:55.317421: step 41810, loss = 0.67 (327.9 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 09:46:03.864474: step 41820, loss = 0.69 (299.5 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 09:46:12.176617: step 41830, loss = 0.81 (308.0 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 09:46:20.511476: step 41840, loss = 0.75 (307.1 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 09:46:29.602736: step 41850, loss = 0.75 (281.6 examples/sec; 0.909 sec/batch)\n",
      "2017-05-28 09:46:38.352170: step 41860, loss = 0.73 (292.6 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 09:46:46.719916: step 41870, loss = 0.73 (305.9 examples/sec; 0.837 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 09:46:55.169580: step 41880, loss = 0.78 (303.0 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 09:47:03.478199: step 41890, loss = 0.74 (308.1 examples/sec; 0.831 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13403\n",
      "2017-05-28 09:47:15.689786: step 41900, loss = 0.75 (209.6 examples/sec; 1.221 sec/batch)\n",
      "2017-05-28 09:47:23.757508: step 41910, loss = 0.75 (317.3 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 09:47:32.040275: step 41920, loss = 0.68 (309.1 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 09:47:40.570747: step 41930, loss = 0.68 (300.1 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 09:47:49.162258: step 41940, loss = 0.76 (298.0 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 09:47:57.787140: step 41950, loss = 0.80 (296.8 examples/sec; 0.862 sec/batch)\n",
      "2017-05-28 09:48:06.054990: step 41960, loss = 0.76 (309.6 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 09:48:14.825109: step 41970, loss = 0.75 (291.9 examples/sec; 0.877 sec/batch)\n",
      "2017-05-28 09:48:23.965541: step 41980, loss = 0.72 (280.1 examples/sec; 0.914 sec/batch)\n",
      "2017-05-28 09:48:32.573915: step 41990, loss = 0.79 (297.4 examples/sec; 0.861 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11493\n",
      "2017-05-28 09:48:45.381466: step 42000, loss = 0.72 (199.9 examples/sec; 1.281 sec/batch)\n",
      "2017-05-28 09:48:53.325952: step 42010, loss = 0.75 (322.2 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 09:49:01.564543: step 42020, loss = 0.73 (310.7 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 09:49:09.790330: step 42030, loss = 0.77 (311.2 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 09:49:18.857883: step 42040, loss = 0.83 (282.3 examples/sec; 0.907 sec/batch)\n",
      "2017-05-28 09:49:28.307722: step 42050, loss = 0.74 (270.9 examples/sec; 0.945 sec/batch)\n",
      "2017-05-28 09:49:36.251683: step 42060, loss = 0.79 (322.3 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 09:49:44.212332: step 42070, loss = 0.72 (321.6 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 09:49:51.992766: step 42080, loss = 0.72 (329.0 examples/sec; 0.778 sec/batch)\n",
      "2017-05-28 09:50:00.045589: step 42090, loss = 0.86 (317.9 examples/sec; 0.805 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15657\n",
      "2017-05-28 09:50:11.846926: step 42100, loss = 0.80 (216.9 examples/sec; 1.180 sec/batch)\n",
      "2017-05-28 09:50:19.248689: step 42110, loss = 0.83 (345.9 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 09:50:27.161400: step 42120, loss = 0.96 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 09:50:35.050122: step 42130, loss = 0.71 (324.5 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 09:50:42.854855: step 42140, loss = 0.78 (328.0 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 09:50:50.673502: step 42150, loss = 0.85 (327.4 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 09:50:58.567181: step 42160, loss = 0.82 (324.3 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 09:51:06.495787: step 42170, loss = 0.74 (322.9 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 09:51:14.360818: step 42180, loss = 0.72 (325.5 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 09:51:22.223610: step 42190, loss = 0.53 (325.6 examples/sec; 0.786 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.23076\n",
      "2017-05-28 09:51:33.093792: step 42200, loss = 0.89 (235.5 examples/sec; 1.087 sec/batch)\n",
      "2017-05-28 09:51:40.535528: step 42210, loss = 0.80 (344.0 examples/sec; 0.744 sec/batch)\n",
      "2017-05-28 09:51:48.839643: step 42220, loss = 0.87 (308.3 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 09:51:57.766747: step 42230, loss = 0.84 (286.8 examples/sec; 0.893 sec/batch)\n",
      "2017-05-28 09:52:05.856371: step 42240, loss = 0.78 (316.5 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 09:52:15.166055: step 42250, loss = 0.87 (275.0 examples/sec; 0.931 sec/batch)\n",
      "2017-05-28 09:52:23.836574: step 42260, loss = 0.72 (295.3 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 09:52:32.137382: step 42270, loss = 0.72 (308.4 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 09:52:40.237615: step 42280, loss = 0.75 (316.0 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 09:52:48.945143: step 42290, loss = 0.84 (294.0 examples/sec; 0.871 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14814\n",
      "INFO:tensorflow:Saving checkpoints for 42301 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 09:53:01.747908: step 42300, loss = 0.76 (200.0 examples/sec; 1.280 sec/batch)\n",
      "2017-05-28 09:53:09.380107: step 42310, loss = 0.72 (335.4 examples/sec; 0.763 sec/batch)\n",
      "2017-05-28 09:53:18.117530: step 42320, loss = 0.70 (293.0 examples/sec; 0.874 sec/batch)\n",
      "2017-05-28 09:53:26.456522: step 42330, loss = 0.70 (307.0 examples/sec; 0.834 sec/batch)\n",
      "2017-05-28 09:53:34.308547: step 42340, loss = 0.88 (326.0 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 09:53:42.731875: step 42350, loss = 0.70 (303.9 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 09:53:50.951512: step 42360, loss = 0.73 (311.4 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 09:53:59.216155: step 42370, loss = 0.95 (309.8 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 09:54:07.103407: step 42380, loss = 0.77 (324.6 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 09:54:15.015330: step 42390, loss = 0.74 (323.6 examples/sec; 0.791 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16585\n",
      "2017-05-28 09:54:25.965599: step 42400, loss = 0.85 (233.8 examples/sec; 1.095 sec/batch)\n",
      "2017-05-28 09:54:33.258811: step 42410, loss = 0.77 (351.0 examples/sec; 0.729 sec/batch)\n",
      "2017-05-28 09:54:41.040744: step 42420, loss = 0.87 (329.0 examples/sec; 0.778 sec/batch)\n",
      "2017-05-28 09:54:48.931900: step 42430, loss = 0.80 (324.4 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 09:54:56.949814: step 42440, loss = 0.85 (319.3 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 09:55:04.884006: step 42450, loss = 0.76 (322.7 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 09:55:12.705376: step 42460, loss = 0.75 (327.3 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 09:55:20.679466: step 42470, loss = 0.71 (321.0 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 09:55:28.501963: step 42480, loss = 0.75 (327.3 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 09:55:36.431390: step 42490, loss = 0.84 (322.8 examples/sec; 0.793 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22157\n",
      "2017-05-28 09:55:47.827227: step 42500, loss = 0.82 (224.6 examples/sec; 1.140 sec/batch)\n",
      "2017-05-28 09:55:55.070609: step 42510, loss = 0.77 (353.4 examples/sec; 0.724 sec/batch)\n",
      "2017-05-28 09:56:03.349470: step 42520, loss = 0.81 (309.2 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 09:56:12.505381: step 42530, loss = 0.88 (279.6 examples/sec; 0.916 sec/batch)\n",
      "2017-05-28 09:56:21.181623: step 42540, loss = 0.83 (295.1 examples/sec; 0.868 sec/batch)\n",
      "2017-05-28 09:56:29.845813: step 42550, loss = 0.77 (295.5 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 09:56:38.701346: step 42560, loss = 0.79 (289.1 examples/sec; 0.886 sec/batch)\n",
      "2017-05-28 09:56:47.359146: step 42570, loss = 0.64 (295.7 examples/sec; 0.866 sec/batch)\n",
      "2017-05-28 09:56:56.136289: step 42580, loss = 0.71 (291.7 examples/sec; 0.878 sec/batch)\n",
      "2017-05-28 09:57:04.106672: step 42590, loss = 0.74 (321.2 examples/sec; 0.797 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14092\n",
      "2017-05-28 09:57:15.479852: step 42600, loss = 0.86 (225.1 examples/sec; 1.137 sec/batch)\n",
      "2017-05-28 09:57:23.304923: step 42610, loss = 0.71 (327.2 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 09:57:32.156463: step 42620, loss = 0.77 (289.2 examples/sec; 0.885 sec/batch)\n",
      "2017-05-28 09:57:41.139961: step 42630, loss = 0.90 (285.0 examples/sec; 0.898 sec/batch)\n",
      "2017-05-28 09:57:49.381198: step 42640, loss = 0.83 (310.6 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 09:57:58.537336: step 42650, loss = 0.74 (279.6 examples/sec; 0.916 sec/batch)\n",
      "2017-05-28 09:58:06.835417: step 42660, loss = 0.89 (308.5 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 09:58:14.875499: step 42670, loss = 0.81 (318.4 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 09:58:23.798823: step 42680, loss = 0.68 (286.9 examples/sec; 0.892 sec/batch)\n",
      "2017-05-28 09:58:31.828504: step 42690, loss = 0.74 (318.8 examples/sec; 0.803 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14948\n",
      "2017-05-28 09:58:42.474978: step 42700, loss = 0.79 (240.5 examples/sec; 1.065 sec/batch)\n",
      "2017-05-28 09:58:49.935109: step 42710, loss = 0.78 (343.2 examples/sec; 0.746 sec/batch)\n",
      "2017-05-28 09:58:57.905640: step 42720, loss = 0.64 (321.2 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 09:59:06.132222: step 42730, loss = 0.75 (311.2 examples/sec; 0.823 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 09:59:14.159116: step 42740, loss = 0.91 (318.9 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 09:59:22.253122: step 42750, loss = 0.78 (316.3 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 09:59:30.100329: step 42760, loss = 0.76 (326.2 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 09:59:38.376616: step 42770, loss = 0.79 (309.3 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 09:59:46.398779: step 42780, loss = 0.78 (319.1 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 09:59:54.541545: step 42790, loss = 0.73 (314.4 examples/sec; 0.814 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19739\n",
      "2017-05-28 10:00:05.986414: step 42800, loss = 0.88 (223.7 examples/sec; 1.144 sec/batch)\n",
      "2017-05-28 10:00:13.216745: step 42810, loss = 0.86 (354.1 examples/sec; 0.723 sec/batch)\n",
      "2017-05-28 10:00:21.147509: step 42820, loss = 0.76 (322.8 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 10:00:29.106462: step 42830, loss = 0.74 (321.7 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 10:00:36.945628: step 42840, loss = 0.59 (326.6 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 10:00:45.123248: step 42850, loss = 0.60 (313.0 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 10:00:53.457505: step 42860, loss = 0.89 (307.2 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 10:01:01.298051: step 42870, loss = 0.75 (326.5 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 10:01:09.138763: step 42880, loss = 0.70 (326.5 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 10:01:17.145847: step 42890, loss = 0.75 (319.7 examples/sec; 0.801 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22324\n",
      "2017-05-28 10:01:27.737190: step 42900, loss = 0.80 (241.7 examples/sec; 1.059 sec/batch)\n",
      "2017-05-28 10:01:35.346394: step 42910, loss = 0.77 (336.4 examples/sec; 0.761 sec/batch)\n",
      "2017-05-28 10:01:43.661408: step 42920, loss = 0.91 (307.9 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 10:01:51.841775: step 42930, loss = 0.72 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 10:02:00.206495: step 42940, loss = 0.74 (306.0 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 10:02:09.779650: step 42950, loss = 0.71 (267.4 examples/sec; 0.957 sec/batch)\n",
      "2017-05-28 10:02:19.008319: step 42960, loss = 0.78 (277.4 examples/sec; 0.923 sec/batch)\n",
      "2017-05-28 10:02:27.167634: step 42970, loss = 0.91 (313.8 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 10:02:35.939635: step 42980, loss = 0.74 (291.8 examples/sec; 0.877 sec/batch)\n",
      "2017-05-28 10:02:45.138572: step 42990, loss = 0.68 (278.3 examples/sec; 0.920 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11713\n",
      "2017-05-28 10:02:57.252043: step 43000, loss = 0.73 (211.3 examples/sec; 1.211 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 43006 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 10:03:05.673714: step 43010, loss = 0.79 (304.0 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 10:03:13.847486: step 43020, loss = 0.80 (313.2 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 10:03:22.350678: step 43030, loss = 0.75 (301.1 examples/sec; 0.850 sec/batch)\n",
      "2017-05-28 10:03:31.263981: step 43040, loss = 0.66 (287.2 examples/sec; 0.891 sec/batch)\n",
      "2017-05-28 10:03:39.726978: step 43050, loss = 0.66 (302.5 examples/sec; 0.846 sec/batch)\n",
      "2017-05-28 10:03:48.173049: step 43060, loss = 0.66 (303.1 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 10:03:56.689843: step 43070, loss = 0.88 (300.6 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 10:04:04.913610: step 43080, loss = 0.84 (311.3 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 10:04:13.361167: step 43090, loss = 0.75 (303.0 examples/sec; 0.845 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13464\n",
      "2017-05-28 10:04:25.386240: step 43100, loss = 0.81 (212.9 examples/sec; 1.203 sec/batch)\n",
      "2017-05-28 10:04:32.991841: step 43110, loss = 0.81 (336.6 examples/sec; 0.761 sec/batch)\n",
      "2017-05-28 10:04:41.184511: step 43120, loss = 0.86 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 10:04:49.890039: step 43130, loss = 0.72 (294.1 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 10:04:58.023092: step 43140, loss = 0.69 (314.8 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 10:05:06.329019: step 43150, loss = 0.65 (308.2 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 10:05:14.490886: step 43160, loss = 0.78 (313.7 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 10:05:23.618030: step 43170, loss = 0.78 (280.5 examples/sec; 0.913 sec/batch)\n",
      "2017-05-28 10:05:33.434993: step 43180, loss = 0.67 (260.8 examples/sec; 0.982 sec/batch)\n",
      "2017-05-28 10:05:42.471639: step 43190, loss = 0.77 (283.3 examples/sec; 0.904 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11745\n",
      "2017-05-28 10:05:54.874473: step 43200, loss = 0.66 (206.4 examples/sec; 1.240 sec/batch)\n",
      "2017-05-28 10:06:03.190838: step 43210, loss = 0.77 (307.8 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 10:06:11.770524: step 43220, loss = 0.79 (298.4 examples/sec; 0.858 sec/batch)\n",
      "2017-05-28 10:06:20.592673: step 43230, loss = 0.81 (290.2 examples/sec; 0.882 sec/batch)\n",
      "2017-05-28 10:06:30.067050: step 43240, loss = 0.83 (270.2 examples/sec; 0.947 sec/batch)\n",
      "2017-05-28 10:06:38.736477: step 43250, loss = 0.75 (295.3 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 10:06:47.380885: step 43260, loss = 0.77 (296.1 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 10:06:55.625600: step 43270, loss = 0.93 (310.5 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 10:07:03.858077: step 43280, loss = 0.77 (311.0 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 10:07:12.060100: step 43290, loss = 0.76 (312.1 examples/sec; 0.820 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13376\n",
      "2017-05-28 10:07:23.080657: step 43300, loss = 0.69 (232.3 examples/sec; 1.102 sec/batch)\n",
      "2017-05-28 10:07:30.481414: step 43310, loss = 0.81 (345.8 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 10:07:38.847253: step 43320, loss = 0.82 (306.0 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 10:07:47.028577: step 43330, loss = 0.68 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 10:07:55.501643: step 43340, loss = 0.68 (302.1 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 10:08:03.656468: step 43350, loss = 0.73 (313.9 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 10:08:11.699009: step 43360, loss = 0.69 (318.3 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 10:08:19.566566: step 43370, loss = 0.73 (325.4 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 10:08:27.953134: step 43380, loss = 0.78 (305.3 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 10:08:36.058338: step 43390, loss = 0.73 (315.8 examples/sec; 0.811 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17642\n",
      "2017-05-28 10:08:48.079164: step 43400, loss = 0.77 (213.0 examples/sec; 1.202 sec/batch)\n",
      "2017-05-28 10:08:55.671825: step 43410, loss = 0.69 (337.2 examples/sec; 0.759 sec/batch)\n",
      "2017-05-28 10:09:04.314532: step 43420, loss = 0.77 (296.2 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 10:09:13.038610: step 43430, loss = 0.69 (293.4 examples/sec; 0.872 sec/batch)\n",
      "2017-05-28 10:09:20.961527: step 43440, loss = 0.69 (323.1 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 10:09:28.946548: step 43450, loss = 0.68 (320.6 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 10:09:37.297667: step 43460, loss = 0.73 (306.5 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 10:09:45.344409: step 43470, loss = 0.67 (318.1 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 10:09:53.535097: step 43480, loss = 0.85 (312.6 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 10:10:02.491853: step 43490, loss = 0.70 (285.8 examples/sec; 0.896 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15959\n",
      "2017-05-28 10:10:14.316817: step 43500, loss = 0.79 (216.5 examples/sec; 1.182 sec/batch)\n",
      "2017-05-28 10:10:22.933966: step 43510, loss = 0.67 (297.1 examples/sec; 0.862 sec/batch)\n",
      "2017-05-28 10:10:31.298718: step 43520, loss = 0.67 (306.0 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 10:10:39.805952: step 43530, loss = 0.76 (300.9 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 10:10:48.168455: step 43540, loss = 0.77 (306.1 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 10:10:56.531634: step 43550, loss = 0.85 (306.1 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 10:11:04.446447: step 43560, loss = 0.84 (323.4 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 10:11:13.211103: step 43570, loss = 0.74 (292.1 examples/sec; 0.876 sec/batch)\n",
      "2017-05-28 10:11:22.802264: step 43580, loss = 0.77 (266.9 examples/sec; 0.959 sec/batch)\n",
      "2017-05-28 10:11:31.435014: step 43590, loss = 0.80 (296.5 examples/sec; 0.863 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 10:11:42.115428: step 43600, loss = 0.79 (239.7 examples/sec; 1.068 sec/batch)\n",
      "2017-05-28 10:11:49.591792: step 43610, loss = 0.78 (342.4 examples/sec; 0.748 sec/batch)\n",
      "2017-05-28 10:11:57.480234: step 43620, loss = 0.77 (324.5 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 10:12:05.382011: step 43630, loss = 0.79 (324.0 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 10:12:14.086468: step 43640, loss = 0.82 (294.1 examples/sec; 0.870 sec/batch)\n",
      "2017-05-28 10:12:22.318828: step 43650, loss = 0.79 (311.0 examples/sec; 0.823 sec/batch)\n",
      "2017-05-28 10:12:30.113867: step 43660, loss = 0.68 (328.4 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 10:12:38.297453: step 43670, loss = 0.80 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 10:12:46.226477: step 43680, loss = 0.72 (322.9 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 10:12:54.094241: step 43690, loss = 0.80 (325.4 examples/sec; 0.787 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 43700 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.17687\n",
      "2017-05-28 10:13:07.089347: step 43700, loss = 0.85 (197.0 examples/sec; 1.300 sec/batch)\n",
      "2017-05-28 10:13:14.641304: step 43710, loss = 0.75 (339.0 examples/sec; 0.755 sec/batch)\n",
      "2017-05-28 10:13:22.631536: step 43720, loss = 0.67 (320.4 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 10:13:30.553944: step 43730, loss = 0.72 (323.1 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 10:13:38.440438: step 43740, loss = 0.74 (324.6 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 10:13:46.392897: step 43750, loss = 0.76 (321.9 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 10:13:54.252178: step 43760, loss = 0.81 (325.7 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 10:14:02.035008: step 43770, loss = 0.75 (328.9 examples/sec; 0.778 sec/batch)\n",
      "2017-05-28 10:14:09.918246: step 43780, loss = 0.87 (324.7 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 10:14:17.826091: step 43790, loss = 0.79 (323.7 examples/sec; 0.791 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20912\n",
      "2017-05-28 10:14:29.793146: step 43800, loss = 0.90 (213.9 examples/sec; 1.197 sec/batch)\n",
      "2017-05-28 10:14:37.061024: step 43810, loss = 0.69 (352.2 examples/sec; 0.727 sec/batch)\n",
      "2017-05-28 10:14:44.957194: step 43820, loss = 0.77 (324.2 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 10:14:52.821256: step 43830, loss = 0.72 (325.5 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 10:15:00.682527: step 43840, loss = 0.87 (325.6 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 10:15:08.563674: step 43850, loss = 0.62 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 10:15:16.404808: step 43860, loss = 0.74 (326.5 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 10:15:24.292039: step 43870, loss = 0.75 (324.6 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 10:15:32.170100: step 43880, loss = 0.74 (325.0 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 10:15:40.023067: step 43890, loss = 0.77 (326.0 examples/sec; 0.785 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.23043\n",
      "2017-05-28 10:15:51.065955: step 43900, loss = 0.72 (231.8 examples/sec; 1.104 sec/batch)\n",
      "2017-05-28 10:15:58.575627: step 43910, loss = 0.78 (340.9 examples/sec; 0.751 sec/batch)\n",
      "2017-05-28 10:16:08.044588: step 43920, loss = 0.81 (270.4 examples/sec; 0.947 sec/batch)\n",
      "2017-05-28 10:16:17.178972: step 43930, loss = 0.75 (280.3 examples/sec; 0.913 sec/batch)\n",
      "2017-05-28 10:16:25.573274: step 43940, loss = 0.78 (305.0 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 10:16:33.861594: step 43950, loss = 0.80 (308.9 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 10:16:42.014229: step 43960, loss = 0.72 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 10:16:50.722742: step 43970, loss = 0.83 (294.0 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 10:16:59.109001: step 43980, loss = 0.86 (305.3 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 10:17:07.340332: step 43990, loss = 0.82 (311.0 examples/sec; 0.823 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14586\n",
      "2017-05-28 10:17:18.333705: step 44000, loss = 0.82 (232.9 examples/sec; 1.099 sec/batch)\n",
      "2017-05-28 10:17:27.007451: step 44010, loss = 0.76 (295.1 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 10:17:35.598968: step 44020, loss = 0.69 (298.0 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 10:17:43.552989: step 44030, loss = 0.67 (321.8 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 10:17:51.954798: step 44040, loss = 0.74 (304.7 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 10:18:01.361403: step 44050, loss = 0.80 (272.1 examples/sec; 0.941 sec/batch)\n",
      "2017-05-28 10:18:10.509661: step 44060, loss = 0.84 (279.8 examples/sec; 0.915 sec/batch)\n",
      "2017-05-28 10:18:19.180264: step 44070, loss = 0.80 (295.3 examples/sec; 0.867 sec/batch)\n",
      "2017-05-28 10:18:27.123998: step 44080, loss = 0.80 (322.3 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 10:18:35.013928: step 44090, loss = 0.78 (324.5 examples/sec; 0.789 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14208\n",
      "2017-05-28 10:18:45.899304: step 44100, loss = 0.78 (235.3 examples/sec; 1.088 sec/batch)\n",
      "2017-05-28 10:18:54.202168: step 44110, loss = 0.74 (308.2 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 10:19:02.416947: step 44120, loss = 0.75 (311.6 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 10:19:10.390604: step 44130, loss = 0.85 (321.1 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 10:19:18.383240: step 44140, loss = 0.80 (320.3 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 10:19:26.311687: step 44150, loss = 0.81 (322.9 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 10:19:34.387302: step 44160, loss = 0.79 (317.0 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 10:19:42.492265: step 44170, loss = 0.73 (315.9 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 10:19:51.062429: step 44180, loss = 0.62 (298.7 examples/sec; 0.857 sec/batch)\n",
      "2017-05-28 10:19:59.009015: step 44190, loss = 0.84 (322.2 examples/sec; 0.795 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18048\n",
      "2017-05-28 10:20:10.608006: step 44200, loss = 0.68 (220.7 examples/sec; 1.160 sec/batch)\n",
      "2017-05-28 10:20:18.229184: step 44210, loss = 0.77 (335.9 examples/sec; 0.762 sec/batch)\n",
      "2017-05-28 10:20:26.773407: step 44220, loss = 0.85 (299.6 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 10:20:35.521061: step 44230, loss = 0.76 (292.6 examples/sec; 0.875 sec/batch)\n",
      "2017-05-28 10:20:44.648657: step 44240, loss = 0.87 (280.5 examples/sec; 0.913 sec/batch)\n",
      "2017-05-28 10:20:54.344177: step 44250, loss = 0.91 (264.0 examples/sec; 0.970 sec/batch)\n",
      "2017-05-28 10:21:02.639128: step 44260, loss = 0.81 (308.6 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 10:21:11.277175: step 44270, loss = 0.81 (296.4 examples/sec; 0.864 sec/batch)\n",
      "2017-05-28 10:21:20.584970: step 44280, loss = 0.80 (275.0 examples/sec; 0.931 sec/batch)\n",
      "2017-05-28 10:21:30.601048: step 44290, loss = 0.79 (255.6 examples/sec; 1.002 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.08026\n",
      "2017-05-28 10:21:43.174323: step 44300, loss = 0.72 (203.6 examples/sec; 1.257 sec/batch)\n",
      "2017-05-28 10:21:51.546478: step 44310, loss = 0.79 (305.8 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 10:22:00.879153: step 44320, loss = 0.75 (274.3 examples/sec; 0.933 sec/batch)\n",
      "2017-05-28 10:22:09.717777: step 44330, loss = 0.66 (289.6 examples/sec; 0.884 sec/batch)\n",
      "2017-05-28 10:22:18.665300: step 44340, loss = 0.89 (286.1 examples/sec; 0.895 sec/batch)\n",
      "2017-05-28 10:22:27.397479: step 44350, loss = 0.70 (293.2 examples/sec; 0.873 sec/batch)\n",
      "2017-05-28 10:22:35.951252: step 44360, loss = 0.71 (299.3 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 10:22:43.809868: step 44370, loss = 0.64 (325.8 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 10:22:51.704947: step 44380, loss = 0.83 (324.3 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 10:22:59.579485: step 44390, loss = 0.84 (325.1 examples/sec; 0.787 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 44393 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.11832\n",
      "2017-05-28 10:23:12.598437: step 44400, loss = 0.80 (196.6 examples/sec; 1.302 sec/batch)\n",
      "2017-05-28 10:23:19.962022: step 44410, loss = 0.69 (347.7 examples/sec; 0.736 sec/batch)\n",
      "2017-05-28 10:23:27.881819: step 44420, loss = 0.79 (323.2 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 10:23:35.759518: step 44430, loss = 0.71 (325.0 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 10:23:43.615060: step 44440, loss = 0.84 (325.9 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 10:23:51.546872: step 44450, loss = 0.81 (322.8 examples/sec; 0.793 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 10:23:59.454277: step 44460, loss = 0.80 (323.7 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 10:24:07.421566: step 44470, loss = 0.74 (321.3 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 10:24:15.580275: step 44480, loss = 0.79 (313.8 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 10:24:24.075238: step 44490, loss = 0.83 (301.4 examples/sec; 0.849 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18724\n",
      "2017-05-28 10:24:36.827956: step 44500, loss = 0.70 (200.7 examples/sec; 1.275 sec/batch)\n",
      "2017-05-28 10:24:44.611381: step 44510, loss = 0.76 (328.9 examples/sec; 0.778 sec/batch)\n",
      "2017-05-28 10:24:52.717347: step 44520, loss = 0.80 (315.8 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 10:25:01.002288: step 44530, loss = 0.67 (309.0 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 10:25:09.111798: step 44540, loss = 0.79 (315.7 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 10:25:17.221218: step 44550, loss = 0.83 (315.7 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 10:25:25.070704: step 44560, loss = 0.73 (326.1 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 10:25:33.031833: step 44570, loss = 0.83 (321.6 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 10:25:40.830439: step 44580, loss = 0.75 (328.3 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 10:25:49.044516: step 44590, loss = 0.79 (311.7 examples/sec; 0.821 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19779\n",
      "2017-05-28 10:26:00.310417: step 44600, loss = 0.78 (227.2 examples/sec; 1.127 sec/batch)\n",
      "2017-05-28 10:26:08.067579: step 44610, loss = 0.77 (330.0 examples/sec; 0.776 sec/batch)\n",
      "2017-05-28 10:26:16.311412: step 44620, loss = 0.77 (310.5 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 10:26:24.184943: step 44630, loss = 0.71 (325.1 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 10:26:32.428288: step 44640, loss = 0.73 (310.6 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 10:26:41.553193: step 44650, loss = 0.69 (280.6 examples/sec; 0.912 sec/batch)\n",
      "2017-05-28 10:26:49.804040: step 44660, loss = 0.78 (310.3 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 10:26:58.130880: step 44670, loss = 0.77 (307.4 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 10:27:06.056253: step 44680, loss = 0.77 (323.0 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 10:27:14.262112: step 44690, loss = 0.74 (312.0 examples/sec; 0.821 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17051\n",
      "2017-05-28 10:27:25.743598: step 44700, loss = 0.71 (223.0 examples/sec; 1.148 sec/batch)\n",
      "2017-05-28 10:27:32.978373: step 44710, loss = 0.81 (353.8 examples/sec; 0.723 sec/batch)\n",
      "2017-05-28 10:27:40.779678: step 44720, loss = 0.82 (328.2 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 10:27:48.671709: step 44730, loss = 0.70 (324.4 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 10:27:56.531001: step 44740, loss = 0.76 (325.7 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 10:28:04.371635: step 44750, loss = 0.80 (326.5 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 10:28:12.282842: step 44760, loss = 0.82 (323.6 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 10:28:20.630262: step 44770, loss = 0.90 (306.7 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 10:28:28.597087: step 44780, loss = 0.74 (321.3 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 10:28:36.438238: step 44790, loss = 0.73 (326.5 examples/sec; 0.784 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22674\n",
      "2017-05-28 10:28:47.260479: step 44800, loss = 0.79 (236.5 examples/sec; 1.082 sec/batch)\n",
      "2017-05-28 10:28:54.506077: step 44810, loss = 0.76 (353.3 examples/sec; 0.725 sec/batch)\n",
      "2017-05-28 10:29:02.768140: step 44820, loss = 0.72 (309.9 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 10:29:10.871453: step 44830, loss = 0.79 (315.9 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 10:29:18.727569: step 44840, loss = 0.76 (325.9 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 10:29:26.610815: step 44850, loss = 0.74 (324.7 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 10:29:34.552559: step 44860, loss = 0.81 (322.3 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 10:29:42.587649: step 44870, loss = 0.84 (318.6 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 10:29:50.675966: step 44880, loss = 0.72 (316.5 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 10:29:58.512771: step 44890, loss = 0.78 (326.7 examples/sec; 0.784 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21448\n",
      "2017-05-28 10:30:09.599698: step 44900, loss = 0.80 (230.9 examples/sec; 1.109 sec/batch)\n",
      "2017-05-28 10:30:16.943338: step 44910, loss = 0.70 (348.6 examples/sec; 0.734 sec/batch)\n",
      "2017-05-28 10:30:24.751065: step 44920, loss = 0.85 (327.9 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 10:30:32.543346: step 44930, loss = 0.87 (328.5 examples/sec; 0.779 sec/batch)\n",
      "2017-05-28 10:30:40.376120: step 44940, loss = 0.81 (326.8 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 10:30:48.241989: step 44950, loss = 0.61 (325.5 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 10:30:56.542892: step 44960, loss = 0.66 (308.4 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 10:31:04.473718: step 44970, loss = 0.73 (322.8 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 10:31:12.350787: step 44980, loss = 0.68 (325.0 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 10:31:20.298512: step 44990, loss = 0.85 (322.1 examples/sec; 0.795 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.2305\n",
      "2017-05-28 10:31:30.867930: step 45000, loss = 0.70 (242.2 examples/sec; 1.057 sec/batch)\n",
      "2017-05-28 10:31:38.189833: step 45010, loss = 0.67 (349.6 examples/sec; 0.732 sec/batch)\n",
      "2017-05-28 10:31:46.020328: step 45020, loss = 0.86 (326.9 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 10:31:53.839997: step 45030, loss = 0.82 (327.4 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 10:32:01.603766: step 45040, loss = 0.80 (329.7 examples/sec; 0.776 sec/batch)\n",
      "2017-05-28 10:32:09.840146: step 45050, loss = 0.74 (310.8 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 10:32:17.912827: step 45060, loss = 0.60 (317.1 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 10:32:25.859031: step 45070, loss = 0.76 (322.2 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 10:32:33.835124: step 45080, loss = 0.72 (321.0 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 10:32:41.635827: step 45090, loss = 0.83 (328.2 examples/sec; 0.780 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21761\n",
      "2017-05-28 10:32:52.995852: step 45100, loss = 0.71 (225.4 examples/sec; 1.136 sec/batch)\n",
      "2017-05-28 10:33:00.384419: step 45110, loss = 0.69 (346.5 examples/sec; 0.739 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 45112 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 10:33:09.036770: step 45120, loss = 0.82 (295.9 examples/sec; 0.865 sec/batch)\n",
      "2017-05-28 10:33:17.003309: step 45130, loss = 0.69 (321.3 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 10:33:24.915363: step 45140, loss = 0.72 (323.6 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 10:33:32.956655: step 45150, loss = 0.78 (318.4 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 10:33:40.834878: step 45160, loss = 0.71 (324.9 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 10:33:48.905079: step 45170, loss = 0.80 (317.2 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 10:33:56.726600: step 45180, loss = 1.00 (327.3 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 10:34:04.585293: step 45190, loss = 0.74 (325.8 examples/sec; 0.786 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21227\n",
      "2017-05-28 10:34:15.485388: step 45200, loss = 0.82 (234.9 examples/sec; 1.090 sec/batch)\n",
      "2017-05-28 10:34:23.054970: step 45210, loss = 0.77 (338.2 examples/sec; 0.757 sec/batch)\n",
      "2017-05-28 10:34:31.108663: step 45220, loss = 0.79 (317.9 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 10:34:39.056697: step 45230, loss = 0.77 (322.1 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 10:34:47.101697: step 45240, loss = 0.74 (318.2 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 10:34:54.953443: step 45250, loss = 0.72 (326.0 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 10:35:02.894346: step 45260, loss = 0.81 (322.4 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 10:35:10.747546: step 45270, loss = 0.68 (326.0 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 10:35:18.633527: step 45280, loss = 0.85 (324.6 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 10:35:26.933631: step 45290, loss = 0.75 (308.4 examples/sec; 0.830 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21662\n",
      "2017-05-28 10:35:37.681679: step 45300, loss = 0.80 (238.2 examples/sec; 1.075 sec/batch)\n",
      "2017-05-28 10:35:44.921549: step 45310, loss = 0.75 (353.6 examples/sec; 0.724 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 10:35:53.105182: step 45320, loss = 0.70 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 10:36:00.922893: step 45330, loss = 0.76 (327.5 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 10:36:08.831716: step 45340, loss = 0.80 (323.7 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 10:36:16.707419: step 45350, loss = 0.82 (325.1 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 10:36:24.517756: step 45360, loss = 0.80 (327.8 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 10:36:32.408562: step 45370, loss = 0.91 (324.4 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 10:36:40.599225: step 45380, loss = 0.72 (312.6 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 10:36:48.544533: step 45390, loss = 0.73 (322.2 examples/sec; 0.795 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22828\n",
      "2017-05-28 10:36:59.095895: step 45400, loss = 0.74 (242.6 examples/sec; 1.055 sec/batch)\n",
      "2017-05-28 10:37:06.375671: step 45410, loss = 0.75 (351.7 examples/sec; 0.728 sec/batch)\n",
      "2017-05-28 10:37:14.200390: step 45420, loss = 0.65 (327.2 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 10:37:22.059224: step 45430, loss = 0.79 (325.7 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 10:37:29.897556: step 45440, loss = 0.75 (326.6 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 10:37:38.169384: step 45450, loss = 0.75 (309.5 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 10:37:46.233720: step 45460, loss = 0.74 (317.4 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 10:37:54.241834: step 45470, loss = 0.74 (319.7 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 10:38:02.119531: step 45480, loss = 0.70 (325.0 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 10:38:09.970749: step 45490, loss = 0.68 (326.1 examples/sec; 0.785 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22317\n",
      "2017-05-28 10:38:20.851894: step 45500, loss = 0.82 (235.3 examples/sec; 1.088 sec/batch)\n",
      "2017-05-28 10:38:28.180423: step 45510, loss = 0.63 (349.3 examples/sec; 0.733 sec/batch)\n",
      "2017-05-28 10:38:35.993074: step 45520, loss = 0.71 (327.7 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 10:38:44.020794: step 45530, loss = 0.78 (318.9 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 10:38:51.880769: step 45540, loss = 0.77 (325.7 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 10:38:59.812655: step 45550, loss = 0.89 (322.7 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 10:39:08.150738: step 45560, loss = 0.89 (307.0 examples/sec; 0.834 sec/batch)\n",
      "2017-05-28 10:39:16.078032: step 45570, loss = 0.83 (322.9 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 10:39:24.202293: step 45580, loss = 0.93 (315.1 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 10:39:32.185327: step 45590, loss = 0.72 (320.7 examples/sec; 0.798 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20069\n",
      "2017-05-28 10:39:44.136025: step 45600, loss = 0.79 (214.2 examples/sec; 1.195 sec/batch)\n",
      "2017-05-28 10:39:51.331312: step 45610, loss = 0.71 (355.8 examples/sec; 0.720 sec/batch)\n",
      "2017-05-28 10:39:59.154891: step 45620, loss = 0.69 (327.2 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 10:40:07.079324: step 45630, loss = 0.87 (323.1 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 10:40:14.936221: step 45640, loss = 0.85 (325.8 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 10:40:22.766891: step 45650, loss = 0.89 (326.9 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 10:40:30.649473: step 45660, loss = 0.88 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 10:40:38.565454: step 45670, loss = 0.80 (323.4 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 10:40:46.393626: step 45680, loss = 0.73 (327.0 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 10:40:54.652692: step 45690, loss = 0.62 (310.0 examples/sec; 0.826 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.23179\n",
      "2017-05-28 10:41:05.319272: step 45700, loss = 0.78 (240.0 examples/sec; 1.067 sec/batch)\n",
      "2017-05-28 10:41:12.743018: step 45710, loss = 0.71 (344.8 examples/sec; 0.742 sec/batch)\n",
      "2017-05-28 10:41:20.567520: step 45720, loss = 0.69 (327.2 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 10:41:28.468802: step 45730, loss = 0.73 (324.0 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 10:41:36.391135: step 45740, loss = 0.80 (323.1 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 10:41:44.259543: step 45750, loss = 0.84 (325.4 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 10:41:52.245292: step 45760, loss = 0.92 (320.6 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 10:42:00.262662: step 45770, loss = 0.78 (319.3 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 10:42:08.510489: step 45780, loss = 0.79 (310.4 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 10:42:16.299812: step 45790, loss = 0.85 (328.7 examples/sec; 0.779 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21225\n",
      "2017-05-28 10:42:27.813546: step 45800, loss = 0.74 (222.3 examples/sec; 1.151 sec/batch)\n",
      "2017-05-28 10:42:35.152180: step 45810, loss = 0.85 (348.8 examples/sec; 0.734 sec/batch)\n",
      "2017-05-28 10:42:43.513984: step 45820, loss = 0.83 (306.2 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 10:42:51.504941: step 45830, loss = 0.82 (320.4 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 10:42:59.384666: step 45840, loss = 0.66 (324.9 examples/sec; 0.788 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 45844 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 10:43:08.261857: step 45850, loss = 0.88 (288.4 examples/sec; 0.888 sec/batch)\n",
      "2017-05-28 10:43:16.140798: step 45860, loss = 0.62 (324.9 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 10:43:24.062875: step 45870, loss = 0.83 (323.1 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 10:43:31.993947: step 45880, loss = 0.76 (322.8 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 10:43:39.862849: step 45890, loss = 0.69 (325.3 examples/sec; 0.787 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20574\n",
      "2017-05-28 10:43:50.747300: step 45900, loss = 0.78 (235.2 examples/sec; 1.088 sec/batch)\n",
      "2017-05-28 10:43:57.992547: step 45910, loss = 0.68 (353.3 examples/sec; 0.725 sec/batch)\n",
      "2017-05-28 10:44:05.905424: step 45920, loss = 0.90 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 10:44:14.107663: step 45930, loss = 0.72 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 10:44:22.256571: step 45940, loss = 0.83 (314.2 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 10:44:30.234795: step 45950, loss = 0.80 (320.9 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 10:44:38.161595: step 45960, loss = 0.80 (323.0 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 10:44:46.045504: step 45970, loss = 0.78 (324.7 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 10:44:53.894765: step 45980, loss = 0.77 (326.1 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 10:45:01.747589: step 45990, loss = 0.69 (326.0 examples/sec; 0.785 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20191\n",
      "2017-05-28 10:45:13.950169: step 46000, loss = 0.76 (209.8 examples/sec; 1.220 sec/batch)\n",
      "2017-05-28 10:45:21.409290: step 46010, loss = 0.78 (343.2 examples/sec; 0.746 sec/batch)\n",
      "2017-05-28 10:45:29.314626: step 46020, loss = 0.79 (323.8 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 10:45:37.209724: step 46030, loss = 0.81 (324.3 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 10:45:45.117657: step 46040, loss = 0.82 (323.7 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 10:45:52.981728: step 46050, loss = 0.72 (325.5 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 10:46:00.964207: step 46060, loss = 0.77 (320.7 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 10:46:09.391971: step 46070, loss = 0.91 (303.8 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 10:46:17.349726: step 46080, loss = 0.70 (321.7 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 10:46:25.224065: step 46090, loss = 0.78 (325.1 examples/sec; 0.787 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21264\n",
      "2017-05-28 10:46:36.412254: step 46100, loss = 0.85 (228.8 examples/sec; 1.119 sec/batch)\n",
      "2017-05-28 10:46:43.724038: step 46110, loss = 0.76 (350.1 examples/sec; 0.731 sec/batch)\n",
      "2017-05-28 10:46:51.578767: step 46120, loss = 0.86 (325.9 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 10:46:59.741766: step 46130, loss = 0.81 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 10:47:07.838291: step 46140, loss = 0.84 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 10:47:15.693111: step 46150, loss = 0.79 (325.9 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 10:47:23.503828: step 46160, loss = 0.71 (327.8 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 10:47:31.351379: step 46170, loss = 0.66 (326.2 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 10:47:39.310217: step 46180, loss = 0.71 (321.7 examples/sec; 0.796 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 10:47:47.125145: step 46190, loss = 0.73 (327.6 examples/sec; 0.781 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.23281\n",
      "2017-05-28 10:47:57.528738: step 46200, loss = 0.88 (246.1 examples/sec; 1.040 sec/batch)\n",
      "2017-05-28 10:48:05.091909: step 46210, loss = 0.75 (338.5 examples/sec; 0.756 sec/batch)\n",
      "2017-05-28 10:48:13.338686: step 46220, loss = 0.68 (310.4 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 10:48:21.260245: step 46230, loss = 0.83 (323.2 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 10:48:29.147448: step 46240, loss = 0.81 (324.6 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 10:48:37.107192: step 46250, loss = 0.81 (321.6 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 10:48:45.614380: step 46260, loss = 0.67 (300.9 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 10:48:53.619862: step 46270, loss = 0.85 (319.8 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 10:49:01.592081: step 46280, loss = 0.73 (321.1 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 10:49:09.625422: step 46290, loss = 0.78 (318.7 examples/sec; 0.803 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20836\n",
      "2017-05-28 10:49:20.287686: step 46300, loss = 0.71 (240.1 examples/sec; 1.066 sec/batch)\n",
      "2017-05-28 10:49:27.611627: step 46310, loss = 0.70 (349.5 examples/sec; 0.732 sec/batch)\n",
      "2017-05-28 10:49:35.576228: step 46320, loss = 0.74 (321.4 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 10:49:43.968632: step 46330, loss = 0.83 (305.0 examples/sec; 0.839 sec/batch)\n",
      "2017-05-28 10:49:52.058326: step 46340, loss = 0.75 (316.5 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 10:49:59.948871: step 46350, loss = 0.78 (324.4 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 10:50:07.833705: step 46360, loss = 0.67 (324.7 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 10:50:15.760145: step 46370, loss = 0.78 (323.0 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 10:50:23.619711: step 46380, loss = 0.78 (325.7 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 10:50:31.462601: step 46390, loss = 0.70 (326.4 examples/sec; 0.784 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22342\n",
      "2017-05-28 10:50:42.025324: step 46400, loss = 0.80 (242.4 examples/sec; 1.056 sec/batch)\n",
      "2017-05-28 10:50:49.427631: step 46410, loss = 0.75 (345.8 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 10:50:57.569365: step 46420, loss = 0.75 (314.4 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 10:51:05.733765: step 46430, loss = 0.71 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 10:51:13.537014: step 46440, loss = 0.71 (328.1 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 10:51:21.422682: step 46450, loss = 0.72 (324.6 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 10:51:29.336389: step 46460, loss = 0.71 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 10:51:37.250017: step 46470, loss = 0.81 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 10:51:45.096452: step 46480, loss = 0.61 (326.3 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 10:51:53.029006: step 46490, loss = 0.74 (322.7 examples/sec; 0.793 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22232\n",
      "2017-05-28 10:52:03.834702: step 46500, loss = 0.81 (236.9 examples/sec; 1.081 sec/batch)\n",
      "2017-05-28 10:52:11.187850: step 46510, loss = 0.79 (348.2 examples/sec; 0.735 sec/batch)\n",
      "2017-05-28 10:52:19.383796: step 46520, loss = 0.75 (312.3 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 10:52:27.252489: step 46530, loss = 0.73 (325.3 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 10:52:35.221802: step 46540, loss = 0.90 (321.2 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 10:52:43.078484: step 46550, loss = 0.70 (325.8 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 10:52:50.961045: step 46560, loss = 0.80 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 10:52:58.804924: step 46570, loss = 0.78 (326.4 examples/sec; 0.784 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 46575 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 10:53:07.424747: step 46580, loss = 0.71 (297.0 examples/sec; 0.862 sec/batch)\n",
      "2017-05-28 10:53:15.873735: step 46590, loss = 0.80 (303.0 examples/sec; 0.845 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21305\n",
      "2017-05-28 10:53:26.270312: step 46600, loss = 0.73 (246.2 examples/sec; 1.040 sec/batch)\n",
      "2017-05-28 10:53:33.701869: step 46610, loss = 0.69 (344.5 examples/sec; 0.743 sec/batch)\n",
      "2017-05-28 10:53:41.494330: step 46620, loss = 0.83 (328.5 examples/sec; 0.779 sec/batch)\n",
      "2017-05-28 10:53:49.300933: step 46630, loss = 0.65 (327.9 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 10:53:57.287967: step 46640, loss = 0.82 (320.5 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 10:54:05.119392: step 46650, loss = 0.74 (326.9 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 10:54:13.000302: step 46660, loss = 0.77 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 10:54:20.999499: step 46670, loss = 0.68 (320.0 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 10:54:28.775882: step 46680, loss = 0.78 (329.2 examples/sec; 0.778 sec/batch)\n",
      "2017-05-28 10:54:36.588723: step 46690, loss = 0.73 (327.7 examples/sec; 0.781 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21986\n",
      "2017-05-28 10:54:48.250713: step 46700, loss = 0.67 (219.5 examples/sec; 1.166 sec/batch)\n",
      "2017-05-28 10:54:55.857474: step 46710, loss = 0.77 (336.5 examples/sec; 0.761 sec/batch)\n",
      "2017-05-28 10:55:03.691751: step 46720, loss = 0.82 (326.8 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 10:55:11.580315: step 46730, loss = 0.69 (324.5 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 10:55:19.617939: step 46740, loss = 0.77 (318.5 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 10:55:27.419429: step 46750, loss = 0.79 (328.1 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 10:55:35.459412: step 46760, loss = 0.68 (318.4 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 10:55:43.835353: step 46770, loss = 0.82 (305.6 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 10:55:51.772986: step 46780, loss = 0.65 (322.5 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 10:55:59.614667: step 46790, loss = 0.65 (326.5 examples/sec; 0.784 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21818\n",
      "2017-05-28 10:56:10.338804: step 46800, loss = 0.69 (238.7 examples/sec; 1.072 sec/batch)\n",
      "2017-05-28 10:56:18.055617: step 46810, loss = 0.67 (331.7 examples/sec; 0.772 sec/batch)\n",
      "2017-05-28 10:56:25.875560: step 46820, loss = 0.72 (327.4 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 10:56:33.958916: step 46830, loss = 0.75 (316.7 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 10:56:41.737039: step 46840, loss = 0.82 (329.1 examples/sec; 0.778 sec/batch)\n",
      "2017-05-28 10:56:49.625034: step 46850, loss = 0.98 (324.5 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 10:56:57.984507: step 46860, loss = 0.74 (306.2 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 10:57:05.919817: step 46870, loss = 0.72 (322.6 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 10:57:13.760770: step 46880, loss = 0.68 (326.5 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 10:57:21.844440: step 46890, loss = 0.77 (316.7 examples/sec; 0.808 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19659\n",
      "2017-05-28 10:57:33.911225: step 46900, loss = 0.70 (212.2 examples/sec; 1.207 sec/batch)\n",
      "2017-05-28 10:57:41.372474: step 46910, loss = 0.78 (343.1 examples/sec; 0.746 sec/batch)\n",
      "2017-05-28 10:57:49.221040: step 46920, loss = 0.68 (326.2 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 10:57:57.079587: step 46930, loss = 0.63 (325.8 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 10:58:05.044875: step 46940, loss = 0.80 (321.4 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 10:58:12.903333: step 46950, loss = 0.76 (325.8 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 10:58:20.814560: step 46960, loss = 0.87 (323.6 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 10:58:28.643351: step 46970, loss = 0.74 (327.0 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 10:58:36.915912: step 46980, loss = 0.80 (309.5 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 10:58:44.772965: step 46990, loss = 0.81 (325.8 examples/sec; 0.786 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22541\n",
      "2017-05-28 10:58:55.513530: step 47000, loss = 0.84 (238.3 examples/sec; 1.074 sec/batch)\n",
      "2017-05-28 10:59:02.785973: step 47010, loss = 0.87 (352.0 examples/sec; 0.727 sec/batch)\n",
      "2017-05-28 10:59:10.667186: step 47020, loss = 0.78 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 10:59:18.652990: step 47030, loss = 0.78 (320.6 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 10:59:26.601909: step 47040, loss = 0.75 (322.1 examples/sec; 0.795 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 10:59:34.470891: step 47050, loss = 0.74 (325.3 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 10:59:42.617166: step 47060, loss = 0.81 (314.3 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 10:59:50.930115: step 47070, loss = 0.83 (308.0 examples/sec; 0.831 sec/batch)\n",
      "2017-05-28 10:59:58.861313: step 47080, loss = 0.71 (322.8 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 11:00:06.740669: step 47090, loss = 0.73 (324.9 examples/sec; 0.788 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19972\n",
      "2017-05-28 11:00:18.868467: step 47100, loss = 0.74 (211.1 examples/sec; 1.213 sec/batch)\n",
      "2017-05-28 11:00:26.064756: step 47110, loss = 0.70 (355.7 examples/sec; 0.720 sec/batch)\n",
      "2017-05-28 11:00:33.846894: step 47120, loss = 0.70 (329.0 examples/sec; 0.778 sec/batch)\n",
      "2017-05-28 11:00:41.943779: step 47130, loss = 0.86 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 11:00:49.817911: step 47140, loss = 0.65 (325.1 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 11:00:57.710829: step 47150, loss = 0.76 (324.3 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 11:01:05.751740: step 47160, loss = 0.75 (318.4 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 11:01:13.705031: step 47170, loss = 0.70 (321.9 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 11:01:21.609202: step 47180, loss = 0.83 (323.9 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 11:01:29.472673: step 47190, loss = 0.78 (325.6 examples/sec; 0.786 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21634\n",
      "2017-05-28 11:01:41.083141: step 47200, loss = 0.66 (220.5 examples/sec; 1.161 sec/batch)\n",
      "2017-05-28 11:01:48.316961: step 47210, loss = 0.67 (353.9 examples/sec; 0.723 sec/batch)\n",
      "2017-05-28 11:01:56.156685: step 47220, loss = 0.92 (326.5 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 11:02:04.070458: step 47230, loss = 0.78 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 11:02:12.332401: step 47240, loss = 0.86 (309.9 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 11:02:20.366045: step 47250, loss = 0.77 (318.7 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 11:02:28.244295: step 47260, loss = 0.77 (324.9 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 11:02:36.201496: step 47270, loss = 0.86 (321.7 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 11:02:44.002129: step 47280, loss = 0.77 (328.2 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 11:02:51.844228: step 47290, loss = 0.71 (326.4 examples/sec; 0.784 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22671\n",
      "INFO:tensorflow:Saving checkpoints for 47301 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 11:03:03.743373: step 47300, loss = 0.65 (215.1 examples/sec; 1.190 sec/batch)\n",
      "2017-05-28 11:03:10.947030: step 47310, loss = 0.77 (355.4 examples/sec; 0.720 sec/batch)\n",
      "2017-05-28 11:03:18.995889: step 47320, loss = 0.73 (318.1 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 11:03:27.033149: step 47330, loss = 0.88 (318.5 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 11:03:34.914585: step 47340, loss = 0.79 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 11:03:43.265172: step 47350, loss = 0.68 (306.6 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 11:03:51.129457: step 47360, loss = 0.66 (325.5 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 11:03:59.007746: step 47370, loss = 0.69 (324.9 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 11:04:06.923701: step 47380, loss = 0.76 (323.4 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 11:04:15.120578: step 47390, loss = 0.77 (312.3 examples/sec; 0.820 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20072\n",
      "2017-05-28 11:04:25.883003: step 47400, loss = 0.73 (237.9 examples/sec; 1.076 sec/batch)\n",
      "2017-05-28 11:04:33.207277: step 47410, loss = 0.67 (349.5 examples/sec; 0.732 sec/batch)\n",
      "2017-05-28 11:04:41.048875: step 47420, loss = 0.75 (326.5 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 11:04:48.964303: step 47430, loss = 0.83 (323.4 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 11:04:57.033502: step 47440, loss = 0.69 (317.3 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 11:05:05.304700: step 47450, loss = 0.84 (309.5 examples/sec; 0.827 sec/batch)\n",
      "2017-05-28 11:05:13.241748: step 47460, loss = 0.76 (322.5 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 11:05:21.117888: step 47470, loss = 0.85 (325.0 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 11:05:28.874505: step 47480, loss = 0.72 (330.0 examples/sec; 0.776 sec/batch)\n",
      "2017-05-28 11:05:36.789154: step 47490, loss = 0.71 (323.5 examples/sec; 0.791 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22411\n",
      "2017-05-28 11:05:47.576333: step 47500, loss = 0.66 (237.3 examples/sec; 1.079 sec/batch)\n",
      "2017-05-28 11:05:54.915189: step 47510, loss = 0.69 (348.8 examples/sec; 0.734 sec/batch)\n",
      "2017-05-28 11:06:02.700156: step 47520, loss = 0.81 (328.8 examples/sec; 0.778 sec/batch)\n",
      "2017-05-28 11:06:10.766493: step 47530, loss = 0.74 (317.4 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 11:06:18.737528: step 47540, loss = 0.83 (321.2 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 11:06:26.551371: step 47550, loss = 0.71 (327.6 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 11:06:34.491741: step 47560, loss = 0.75 (322.4 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 11:06:42.941402: step 47570, loss = 0.75 (303.0 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 11:06:50.854305: step 47580, loss = 0.73 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 11:06:58.664403: step 47590, loss = 0.81 (327.8 examples/sec; 0.781 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20328\n",
      "2017-05-28 11:07:10.680681: step 47600, loss = 0.81 (213.0 examples/sec; 1.202 sec/batch)\n",
      "2017-05-28 11:07:17.989038: step 47610, loss = 0.78 (350.3 examples/sec; 0.731 sec/batch)\n",
      "2017-05-28 11:07:25.809911: step 47620, loss = 0.79 (327.3 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 11:07:33.762272: step 47630, loss = 0.72 (321.9 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 11:07:42.039500: step 47640, loss = 0.73 (309.3 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 11:07:50.192616: step 47650, loss = 0.82 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 11:07:58.100078: step 47660, loss = 0.79 (323.7 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 11:08:05.927340: step 47670, loss = 0.82 (327.1 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 11:08:13.879547: step 47680, loss = 0.80 (321.9 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 11:08:21.749004: step 47690, loss = 0.81 (325.3 examples/sec; 0.787 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20865\n",
      "2017-05-28 11:08:33.418482: step 47700, loss = 0.83 (219.4 examples/sec; 1.167 sec/batch)\n",
      "2017-05-28 11:08:40.993802: step 47710, loss = 0.64 (337.9 examples/sec; 0.758 sec/batch)\n",
      "2017-05-28 11:08:48.928604: step 47720, loss = 0.87 (322.6 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 11:08:56.743478: step 47730, loss = 0.70 (327.6 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 11:09:04.626274: step 47740, loss = 0.75 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 11:09:12.978923: step 47750, loss = 0.79 (306.5 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 11:09:20.963365: step 47760, loss = 0.72 (320.6 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 11:09:28.666435: step 47770, loss = 0.73 (332.3 examples/sec; 0.770 sec/batch)\n",
      "2017-05-28 11:09:36.675294: step 47780, loss = 0.84 (319.6 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 11:09:44.544426: step 47790, loss = 0.78 (325.3 examples/sec; 0.787 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22157\n",
      "2017-05-28 11:09:55.281081: step 47800, loss = 0.84 (238.4 examples/sec; 1.074 sec/batch)\n",
      "2017-05-28 11:10:02.656128: step 47810, loss = 0.84 (347.1 examples/sec; 0.738 sec/batch)\n",
      "2017-05-28 11:10:10.498703: step 47820, loss = 0.72 (326.4 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 11:10:18.446931: step 47830, loss = 0.76 (322.1 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 11:10:26.344242: step 47840, loss = 0.79 (324.2 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 11:10:34.709757: step 47850, loss = 0.75 (306.0 examples/sec; 0.837 sec/batch)\n",
      "2017-05-28 11:10:42.580633: step 47860, loss = 0.85 (325.2 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 11:10:50.578093: step 47870, loss = 0.68 (320.1 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 11:10:58.557131: step 47880, loss = 0.72 (320.8 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 11:11:06.416152: step 47890, loss = 0.71 (325.7 examples/sec; 0.786 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22141\n",
      "2017-05-28 11:11:17.153755: step 47900, loss = 0.84 (238.4 examples/sec; 1.074 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 11:11:24.901722: step 47910, loss = 0.73 (330.4 examples/sec; 0.775 sec/batch)\n",
      "2017-05-28 11:11:32.955781: step 47920, loss = 0.83 (317.9 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 11:11:40.848321: step 47930, loss = 0.78 (324.4 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 11:11:48.732893: step 47940, loss = 0.66 (324.7 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 11:11:56.550442: step 47950, loss = 0.73 (327.5 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 11:12:04.316904: step 47960, loss = 0.74 (329.6 examples/sec; 0.777 sec/batch)\n",
      "2017-05-28 11:12:12.127568: step 47970, loss = 0.64 (327.8 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 11:12:20.074442: step 47980, loss = 0.59 (322.1 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 11:12:28.478721: step 47990, loss = 0.67 (304.6 examples/sec; 0.840 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21235\n",
      "2017-05-28 11:12:39.638866: step 48000, loss = 0.74 (229.4 examples/sec; 1.116 sec/batch)\n",
      "2017-05-28 11:12:46.898305: step 48010, loss = 0.90 (352.6 examples/sec; 0.726 sec/batch)\n",
      "2017-05-28 11:12:54.872751: step 48020, loss = 0.73 (321.0 examples/sec; 0.797 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 48031 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 11:13:04.111394: step 48030, loss = 0.63 (277.1 examples/sec; 0.924 sec/batch)\n",
      "2017-05-28 11:13:11.411703: step 48040, loss = 0.75 (350.7 examples/sec; 0.730 sec/batch)\n",
      "2017-05-28 11:13:19.347197: step 48050, loss = 0.74 (322.6 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 11:13:27.749083: step 48060, loss = 0.69 (304.7 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 11:13:35.595036: step 48070, loss = 0.82 (326.3 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 11:13:43.405619: step 48080, loss = 0.62 (327.8 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 11:13:51.369481: step 48090, loss = 0.69 (321.5 examples/sec; 0.796 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.2126\n",
      "2017-05-28 11:14:02.102090: step 48100, loss = 0.96 (238.5 examples/sec; 1.073 sec/batch)\n",
      "2017-05-28 11:14:09.775627: step 48110, loss = 0.79 (333.6 examples/sec; 0.767 sec/batch)\n",
      "2017-05-28 11:14:17.785846: step 48120, loss = 0.72 (319.6 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 11:14:25.673708: step 48130, loss = 0.74 (324.5 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 11:14:33.486079: step 48140, loss = 0.68 (327.7 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 11:14:41.289319: step 48150, loss = 0.86 (328.1 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 11:14:49.196410: step 48160, loss = 0.82 (323.8 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 11:14:57.183199: step 48170, loss = 0.71 (320.5 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 11:15:05.050137: step 48180, loss = 0.74 (325.4 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 11:15:12.942080: step 48190, loss = 0.81 (324.4 examples/sec; 0.789 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20133\n",
      "2017-05-28 11:15:25.347874: step 48200, loss = 0.79 (206.4 examples/sec; 1.241 sec/batch)\n",
      "2017-05-28 11:15:32.695016: step 48210, loss = 0.77 (348.4 examples/sec; 0.735 sec/batch)\n",
      "2017-05-28 11:15:40.614046: step 48220, loss = 0.76 (323.3 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 11:15:48.448173: step 48230, loss = 0.72 (326.8 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 11:15:56.359103: step 48240, loss = 0.65 (323.6 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 11:16:04.254091: step 48250, loss = 0.70 (324.3 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 11:16:12.618802: step 48260, loss = 0.68 (306.0 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 11:16:20.413372: step 48270, loss = 0.75 (328.4 examples/sec; 0.779 sec/batch)\n",
      "2017-05-28 11:16:28.305733: step 48280, loss = 0.73 (324.4 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 11:16:36.209162: step 48290, loss = 0.81 (323.9 examples/sec; 0.790 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22409\n",
      "2017-05-28 11:16:47.036544: step 48300, loss = 0.78 (236.4 examples/sec; 1.083 sec/batch)\n",
      "2017-05-28 11:16:54.415817: step 48310, loss = 0.81 (346.9 examples/sec; 0.738 sec/batch)\n",
      "2017-05-28 11:17:02.202645: step 48320, loss = 0.78 (328.8 examples/sec; 0.779 sec/batch)\n",
      "2017-05-28 11:17:10.529633: step 48330, loss = 0.61 (307.4 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 11:17:18.526329: step 48340, loss = 0.73 (320.1 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 11:17:26.427628: step 48350, loss = 0.74 (324.0 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 11:17:34.252427: step 48360, loss = 0.73 (327.2 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 11:17:42.113272: step 48370, loss = 0.75 (325.7 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 11:17:50.117442: step 48380, loss = 0.88 (319.8 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 11:17:58.428547: step 48390, loss = 0.74 (308.0 examples/sec; 0.831 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20649\n",
      "2017-05-28 11:18:09.926242: step 48400, loss = 0.88 (222.7 examples/sec; 1.150 sec/batch)\n",
      "2017-05-28 11:18:17.359577: step 48410, loss = 0.71 (344.4 examples/sec; 0.743 sec/batch)\n",
      "2017-05-28 11:18:25.268579: step 48420, loss = 0.73 (323.7 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 11:18:33.131236: step 48430, loss = 0.83 (325.6 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 11:18:40.964376: step 48440, loss = 0.79 (326.8 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 11:18:48.891659: step 48450, loss = 0.74 (322.9 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 11:18:57.298798: step 48460, loss = 0.91 (304.5 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 11:19:05.314873: step 48470, loss = 0.77 (319.4 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 11:19:13.293175: step 48480, loss = 0.59 (320.9 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 11:19:21.227247: step 48490, loss = 0.76 (322.7 examples/sec; 0.793 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22021\n",
      "2017-05-28 11:19:31.874430: step 48500, loss = 0.70 (240.4 examples/sec; 1.065 sec/batch)\n",
      "2017-05-28 11:19:39.246255: step 48510, loss = 0.76 (347.3 examples/sec; 0.737 sec/batch)\n",
      "2017-05-28 11:19:47.401615: step 48520, loss = 0.69 (313.9 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 11:19:55.579855: step 48530, loss = 0.91 (313.0 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 11:20:03.521488: step 48540, loss = 0.81 (322.4 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 11:20:11.340035: step 48550, loss = 0.68 (327.4 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 11:20:19.166900: step 48560, loss = 0.79 (327.1 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 11:20:27.094894: step 48570, loss = 0.82 (322.9 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 11:20:34.945220: step 48580, loss = 0.77 (326.1 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 11:20:42.770451: step 48590, loss = 0.77 (327.1 examples/sec; 0.783 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21356\n",
      "2017-05-28 11:20:54.293991: step 48600, loss = 0.73 (222.2 examples/sec; 1.152 sec/batch)\n",
      "2017-05-28 11:21:01.760666: step 48610, loss = 0.71 (342.8 examples/sec; 0.747 sec/batch)\n",
      "2017-05-28 11:21:09.580245: step 48620, loss = 0.82 (327.4 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 11:21:17.370895: step 48630, loss = 0.76 (328.6 examples/sec; 0.779 sec/batch)\n",
      "2017-05-28 11:21:25.210855: step 48640, loss = 0.76 (326.5 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 11:21:33.293037: step 48650, loss = 0.64 (316.7 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 11:21:41.147666: step 48660, loss = 0.79 (325.9 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 11:21:48.994812: step 48670, loss = 0.80 (326.2 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 11:21:56.834968: step 48680, loss = 0.84 (326.5 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 11:22:04.829257: step 48690, loss = 0.74 (320.2 examples/sec; 0.799 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20186\n",
      "2017-05-28 11:22:17.483156: step 48700, loss = 0.73 (202.3 examples/sec; 1.265 sec/batch)\n",
      "2017-05-28 11:22:24.892024: step 48710, loss = 0.76 (345.5 examples/sec; 0.741 sec/batch)\n",
      "2017-05-28 11:22:32.743628: step 48720, loss = 0.70 (326.0 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 11:22:40.860645: step 48730, loss = 0.73 (315.4 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 11:22:48.718813: step 48740, loss = 0.78 (325.8 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 11:22:56.573470: step 48750, loss = 0.77 (325.9 examples/sec; 0.785 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 48759 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 11:23:05.972049: step 48760, loss = 0.80 (272.4 examples/sec; 0.940 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 11:23:13.640605: step 48770, loss = 0.83 (333.8 examples/sec; 0.767 sec/batch)\n",
      "2017-05-28 11:23:21.662499: step 48780, loss = 0.63 (319.1 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 11:23:29.511150: step 48790, loss = 0.72 (326.2 examples/sec; 0.785 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21094\n",
      "2017-05-28 11:23:40.061049: step 48800, loss = 0.70 (242.7 examples/sec; 1.055 sec/batch)\n",
      "2017-05-28 11:23:47.293658: step 48810, loss = 0.82 (354.0 examples/sec; 0.723 sec/batch)\n",
      "2017-05-28 11:23:55.032742: step 48820, loss = 0.79 (330.8 examples/sec; 0.774 sec/batch)\n",
      "2017-05-28 11:24:03.129450: step 48830, loss = 0.73 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 11:24:10.946323: step 48840, loss = 0.69 (327.5 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 11:24:18.813474: step 48850, loss = 0.85 (325.4 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 11:24:26.685332: step 48860, loss = 0.76 (325.2 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 11:24:34.628913: step 48870, loss = 0.71 (322.3 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 11:24:42.985865: step 48880, loss = 0.70 (306.3 examples/sec; 0.836 sec/batch)\n",
      "2017-05-28 11:24:51.022370: step 48890, loss = 0.70 (318.5 examples/sec; 0.804 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22619\n",
      "2017-05-28 11:25:01.618769: step 48900, loss = 0.77 (241.6 examples/sec; 1.060 sec/batch)\n",
      "2017-05-28 11:25:09.024243: step 48910, loss = 0.73 (345.7 examples/sec; 0.741 sec/batch)\n",
      "2017-05-28 11:25:16.874173: step 48920, loss = 0.61 (326.1 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 11:25:24.744203: step 48930, loss = 0.80 (325.3 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 11:25:32.568644: step 48940, loss = 0.72 (327.2 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 11:25:40.441999: step 48950, loss = 0.86 (325.1 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 11:25:48.724892: step 48960, loss = 0.71 (309.1 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 11:25:56.487629: step 48970, loss = 0.74 (329.8 examples/sec; 0.776 sec/batch)\n",
      "2017-05-28 11:26:04.598536: step 48980, loss = 0.72 (315.6 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 11:26:12.593446: step 48990, loss = 0.80 (320.2 examples/sec; 0.799 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22263\n",
      "2017-05-28 11:26:23.406069: step 49000, loss = 0.84 (236.8 examples/sec; 1.081 sec/batch)\n",
      "2017-05-28 11:26:30.641369: step 49010, loss = 0.70 (353.8 examples/sec; 0.724 sec/batch)\n",
      "2017-05-28 11:26:38.511731: step 49020, loss = 0.76 (325.3 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 11:26:46.419945: step 49030, loss = 0.78 (323.7 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 11:26:54.288311: step 49040, loss = 0.78 (325.4 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 11:27:02.175699: step 49050, loss = 0.72 (324.6 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 11:27:10.028732: step 49060, loss = 0.69 (326.0 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 11:27:18.105969: step 49070, loss = 0.68 (316.9 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 11:27:26.323076: step 49080, loss = 0.71 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 11:27:34.241205: step 49090, loss = 0.65 (323.3 examples/sec; 0.792 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21812\n",
      "2017-05-28 11:27:45.502828: step 49100, loss = 0.76 (227.3 examples/sec; 1.126 sec/batch)\n",
      "2017-05-28 11:27:52.832995: step 49110, loss = 0.74 (349.2 examples/sec; 0.733 sec/batch)\n",
      "2017-05-28 11:28:00.783284: step 49120, loss = 0.67 (322.0 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 11:28:08.599906: step 49130, loss = 0.66 (327.5 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 11:28:16.976457: step 49140, loss = 0.75 (305.6 examples/sec; 0.838 sec/batch)\n",
      "2017-05-28 11:28:25.040236: step 49150, loss = 0.72 (317.5 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 11:28:32.914607: step 49160, loss = 0.83 (325.1 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 11:28:40.921005: step 49170, loss = 0.94 (319.7 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 11:28:48.929311: step 49180, loss = 0.67 (319.7 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 11:28:56.873279: step 49190, loss = 0.66 (322.3 examples/sec; 0.794 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21659\n",
      "2017-05-28 11:29:07.698727: step 49200, loss = 0.70 (236.5 examples/sec; 1.083 sec/batch)\n",
      "2017-05-28 11:29:15.504375: step 49210, loss = 0.80 (328.0 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 11:29:23.404654: step 49220, loss = 0.72 (324.0 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 11:29:31.284991: step 49230, loss = 0.72 (324.9 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 11:29:39.091599: step 49240, loss = 0.68 (327.9 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 11:29:47.023690: step 49250, loss = 0.77 (322.7 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 11:29:54.885693: step 49260, loss = 0.59 (325.6 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 11:30:03.167138: step 49270, loss = 0.69 (309.1 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 11:30:11.336159: step 49280, loss = 0.75 (313.4 examples/sec; 0.817 sec/batch)\n",
      "2017-05-28 11:30:19.321487: step 49290, loss = 0.79 (320.6 examples/sec; 0.799 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19607\n",
      "2017-05-28 11:30:31.307030: step 49300, loss = 0.90 (213.6 examples/sec; 1.199 sec/batch)\n",
      "2017-05-28 11:30:38.586201: step 49310, loss = 0.65 (351.7 examples/sec; 0.728 sec/batch)\n",
      "2017-05-28 11:30:46.681073: step 49320, loss = 0.76 (316.2 examples/sec; 0.809 sec/batch)\n",
      "2017-05-28 11:30:54.514034: step 49330, loss = 0.83 (326.8 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 11:31:02.493344: step 49340, loss = 0.70 (320.8 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 11:31:10.401127: step 49350, loss = 0.65 (323.7 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 11:31:18.313604: step 49360, loss = 0.74 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 11:31:26.267144: step 49370, loss = 0.76 (321.9 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 11:31:34.689991: step 49380, loss = 0.81 (303.9 examples/sec; 0.842 sec/batch)\n",
      "2017-05-28 11:31:42.626473: step 49390, loss = 0.73 (322.6 examples/sec; 0.794 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22043\n",
      "2017-05-28 11:31:53.242432: step 49400, loss = 0.77 (241.1 examples/sec; 1.062 sec/batch)\n",
      "2017-05-28 11:32:00.609698: step 49410, loss = 0.76 (347.5 examples/sec; 0.737 sec/batch)\n",
      "2017-05-28 11:32:08.832115: step 49420, loss = 0.81 (311.3 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 11:32:16.915655: step 49430, loss = 0.77 (316.7 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 11:32:24.850792: step 49440, loss = 0.78 (322.6 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 11:32:32.767142: step 49450, loss = 0.79 (323.4 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 11:32:40.572709: step 49460, loss = 0.74 (328.0 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 11:32:48.480570: step 49470, loss = 0.72 (323.7 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 11:32:56.420861: step 49480, loss = 0.68 (322.4 examples/sec; 0.794 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 49490 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 11:33:05.554549: step 49490, loss = 0.72 (280.3 examples/sec; 0.913 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21379\n",
      "2017-05-28 11:33:15.628424: step 49500, loss = 0.79 (254.1 examples/sec; 1.007 sec/batch)\n",
      "2017-05-28 11:33:23.253186: step 49510, loss = 0.64 (335.7 examples/sec; 0.762 sec/batch)\n",
      "2017-05-28 11:33:31.504378: step 49520, loss = 0.72 (310.3 examples/sec; 0.825 sec/batch)\n",
      "2017-05-28 11:33:39.426751: step 49530, loss = 0.70 (323.1 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 11:33:47.264032: step 49540, loss = 0.78 (326.6 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 11:33:55.119394: step 49550, loss = 0.81 (325.9 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 11:34:03.053504: step 49560, loss = 0.80 (322.7 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 11:34:12.174440: step 49570, loss = 0.81 (280.7 examples/sec; 0.912 sec/batch)\n",
      "2017-05-28 11:34:20.695680: step 49580, loss = 0.69 (300.4 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 11:34:28.703462: step 49590, loss = 0.89 (319.7 examples/sec; 0.801 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1921\n",
      "2017-05-28 11:34:39.514761: step 49600, loss = 0.83 (236.8 examples/sec; 1.081 sec/batch)\n",
      "2017-05-28 11:34:47.167384: step 49610, loss = 0.80 (334.5 examples/sec; 0.765 sec/batch)\n",
      "2017-05-28 11:34:55.152568: step 49620, loss = 0.79 (320.6 examples/sec; 0.799 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 11:35:02.853001: step 49630, loss = 0.70 (332.4 examples/sec; 0.770 sec/batch)\n",
      "2017-05-28 11:35:10.862978: step 49640, loss = 0.68 (319.6 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 11:35:18.862852: step 49650, loss = 0.57 (320.0 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 11:35:26.757702: step 49660, loss = 0.80 (324.3 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 11:35:34.595039: step 49670, loss = 0.79 (326.6 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 11:35:42.429196: step 49680, loss = 0.70 (326.8 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 11:35:50.391067: step 49690, loss = 0.71 (321.5 examples/sec; 0.796 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19385\n",
      "2017-05-28 11:36:03.279076: step 49700, loss = 0.81 (198.6 examples/sec; 1.289 sec/batch)\n",
      "2017-05-28 11:36:10.613796: step 49710, loss = 0.69 (349.0 examples/sec; 0.733 sec/batch)\n",
      "2017-05-28 11:36:18.542672: step 49720, loss = 0.76 (322.9 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 11:36:26.597454: step 49730, loss = 0.61 (317.8 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 11:36:34.483292: step 49740, loss = 0.76 (324.6 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 11:36:42.339585: step 49750, loss = 0.64 (325.9 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 11:36:50.389894: step 49760, loss = 0.75 (318.0 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 11:36:58.284669: step 49770, loss = 0.82 (324.3 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 11:37:06.124951: step 49780, loss = 0.72 (326.5 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 11:37:14.056001: step 49790, loss = 0.62 (322.8 examples/sec; 0.793 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22171\n",
      "2017-05-28 11:37:25.132347: step 49800, loss = 0.77 (231.1 examples/sec; 1.108 sec/batch)\n",
      "2017-05-28 11:37:32.795879: step 49810, loss = 0.76 (334.0 examples/sec; 0.766 sec/batch)\n",
      "2017-05-28 11:37:40.608076: step 49820, loss = 0.75 (327.7 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 11:37:48.473901: step 49830, loss = 0.73 (325.5 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 11:37:56.609046: step 49840, loss = 0.76 (314.7 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 11:38:04.793529: step 49850, loss = 0.68 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-28 11:38:12.608427: step 49860, loss = 0.65 (327.6 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 11:38:20.503442: step 49870, loss = 0.73 (324.3 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 11:38:28.490764: step 49880, loss = 0.64 (320.5 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 11:38:36.363156: step 49890, loss = 0.78 (325.2 examples/sec; 0.787 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20398\n",
      "2017-05-28 11:38:48.191791: step 49900, loss = 0.72 (216.4 examples/sec; 1.183 sec/batch)\n",
      "2017-05-28 11:38:55.372101: step 49910, loss = 0.67 (356.5 examples/sec; 0.718 sec/batch)\n",
      "2017-05-28 11:39:03.490478: step 49920, loss = 0.66 (315.3 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 11:39:11.436160: step 49930, loss = 0.65 (322.2 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 11:39:19.343275: step 49940, loss = 0.71 (323.8 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 11:39:27.351460: step 49950, loss = 0.68 (319.7 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 11:39:35.668031: step 49960, loss = 0.73 (307.8 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 11:39:43.830131: step 49970, loss = 0.71 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 11:39:51.762074: step 49980, loss = 0.80 (322.7 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 11:39:59.732026: step 49990, loss = 0.82 (321.2 examples/sec; 0.797 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19825\n",
      "2017-05-28 11:40:11.646164: step 50000, loss = 0.77 (214.9 examples/sec; 1.191 sec/batch)\n",
      "2017-05-28 11:40:19.190475: step 50010, loss = 0.76 (339.3 examples/sec; 0.754 sec/batch)\n",
      "2017-05-28 11:40:27.086127: step 50020, loss = 0.92 (324.2 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 11:40:35.143670: step 50030, loss = 0.80 (317.7 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 11:40:42.949468: step 50040, loss = 0.67 (328.0 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 11:40:50.854977: step 50050, loss = 0.81 (323.8 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 11:40:59.154601: step 50060, loss = 0.70 (308.4 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 11:41:07.274466: step 50070, loss = 0.78 (315.3 examples/sec; 0.812 sec/batch)\n",
      "2017-05-28 11:41:15.130758: step 50080, loss = 0.74 (325.9 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 11:41:23.020129: step 50090, loss = 0.72 (324.5 examples/sec; 0.789 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21643\n",
      "2017-05-28 11:41:33.850100: step 50100, loss = 0.79 (236.4 examples/sec; 1.083 sec/batch)\n",
      "2017-05-28 11:41:41.475332: step 50110, loss = 0.83 (335.7 examples/sec; 0.763 sec/batch)\n",
      "2017-05-28 11:41:49.677729: step 50120, loss = 0.78 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-28 11:41:57.544870: step 50130, loss = 0.82 (325.4 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 11:42:05.400660: step 50140, loss = 0.77 (325.9 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 11:42:13.299307: step 50150, loss = 0.77 (324.1 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 11:42:21.150173: step 50160, loss = 0.89 (326.1 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 11:42:29.031620: step 50170, loss = 0.74 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 11:42:37.069741: step 50180, loss = 0.70 (318.5 examples/sec; 0.804 sec/batch)\n",
      "2017-05-28 11:42:45.000796: step 50190, loss = 0.68 (322.8 examples/sec; 0.793 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20432\n",
      "2017-05-28 11:42:56.889877: step 50200, loss = 0.70 (215.3 examples/sec; 1.189 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 50210 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 11:43:05.599654: step 50210, loss = 0.74 (293.9 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 11:43:13.104215: step 50220, loss = 0.69 (341.1 examples/sec; 0.750 sec/batch)\n",
      "2017-05-28 11:43:21.131566: step 50230, loss = 0.70 (318.9 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 11:43:28.932575: step 50240, loss = 0.66 (328.2 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 11:43:36.899112: step 50250, loss = 0.66 (321.3 examples/sec; 0.797 sec/batch)\n",
      "2017-05-28 11:43:45.123660: step 50260, loss = 0.78 (311.3 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 11:43:53.224588: step 50270, loss = 0.83 (316.0 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 11:44:01.060225: step 50280, loss = 0.71 (326.7 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 11:44:08.975358: step 50290, loss = 0.76 (323.4 examples/sec; 0.792 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20122\n",
      "2017-05-28 11:44:20.136171: step 50300, loss = 0.70 (229.4 examples/sec; 1.116 sec/batch)\n",
      "2017-05-28 11:44:27.431084: step 50310, loss = 0.68 (350.9 examples/sec; 0.729 sec/batch)\n",
      "2017-05-28 11:44:35.367820: step 50320, loss = 0.80 (322.6 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 11:44:43.297591: step 50330, loss = 0.93 (322.8 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 11:44:51.224704: step 50340, loss = 0.81 (322.9 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 11:44:59.204015: step 50350, loss = 0.69 (320.8 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 11:45:07.155385: step 50360, loss = 0.73 (322.0 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 11:45:15.566305: step 50370, loss = 0.73 (304.4 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 11:45:23.559057: step 50380, loss = 0.76 (320.3 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 11:45:31.879174: step 50390, loss = 0.74 (307.7 examples/sec; 0.832 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20465\n",
      "2017-05-28 11:45:43.144443: step 50400, loss = 0.71 (227.2 examples/sec; 1.127 sec/batch)\n",
      "2017-05-28 11:45:50.520892: step 50410, loss = 0.66 (347.1 examples/sec; 0.738 sec/batch)\n",
      "2017-05-28 11:45:58.602486: step 50420, loss = 0.91 (316.8 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 11:46:06.947725: step 50430, loss = 0.58 (306.8 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 11:46:14.823027: step 50440, loss = 0.84 (325.1 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 11:46:22.764897: step 50450, loss = 0.76 (322.3 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 11:46:30.556900: step 50460, loss = 0.68 (328.5 examples/sec; 0.779 sec/batch)\n",
      "2017-05-28 11:46:38.500265: step 50470, loss = 0.73 (322.3 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 11:46:46.433066: step 50480, loss = 0.76 (322.7 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 11:46:54.721517: step 50490, loss = 0.80 (308.9 examples/sec; 0.829 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.21647\n",
      "2017-05-28 11:47:05.350599: step 50500, loss = 0.67 (240.8 examples/sec; 1.063 sec/batch)\n",
      "2017-05-28 11:47:12.752853: step 50510, loss = 0.65 (345.8 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 11:47:20.577289: step 50520, loss = 0.71 (327.2 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 11:47:28.784201: step 50530, loss = 0.83 (311.9 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 11:47:36.935283: step 50540, loss = 0.70 (314.1 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 11:47:44.859165: step 50550, loss = 0.72 (323.1 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 11:47:52.809817: step 50560, loss = 0.77 (322.0 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 11:48:00.662230: step 50570, loss = 0.64 (326.0 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 11:48:08.516362: step 50580, loss = 0.77 (325.9 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 11:48:16.401187: step 50590, loss = 0.69 (324.7 examples/sec; 0.788 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20635\n",
      "2017-05-28 11:48:28.248081: step 50600, loss = 0.83 (216.1 examples/sec; 1.185 sec/batch)\n",
      "2017-05-28 11:48:35.650049: step 50610, loss = 0.78 (345.9 examples/sec; 0.740 sec/batch)\n",
      "2017-05-28 11:48:43.544435: step 50620, loss = 0.72 (324.3 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 11:48:51.489049: step 50630, loss = 0.80 (322.2 examples/sec; 0.794 sec/batch)\n",
      "2017-05-28 11:48:59.349470: step 50640, loss = 0.70 (325.7 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 11:49:07.837967: step 50650, loss = 0.77 (301.6 examples/sec; 0.849 sec/batch)\n",
      "2017-05-28 11:49:15.793331: step 50660, loss = 0.74 (321.8 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 11:49:23.812471: step 50670, loss = 0.87 (319.2 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 11:49:31.614141: step 50680, loss = 0.88 (328.1 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 11:49:39.489836: step 50690, loss = 0.85 (325.1 examples/sec; 0.788 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22064\n",
      "2017-05-28 11:49:50.169750: step 50700, loss = 0.72 (239.7 examples/sec; 1.068 sec/batch)\n",
      "2017-05-28 11:49:58.064903: step 50710, loss = 0.74 (324.2 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 11:50:06.145689: step 50720, loss = 0.80 (316.8 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 11:50:14.144958: step 50730, loss = 0.75 (320.0 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 11:50:22.177741: step 50740, loss = 0.70 (318.7 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 11:50:30.234054: step 50750, loss = 0.75 (317.8 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 11:50:38.575807: step 50760, loss = 0.74 (306.9 examples/sec; 0.834 sec/batch)\n",
      "2017-05-28 11:50:47.569132: step 50770, loss = 0.80 (284.7 examples/sec; 0.899 sec/batch)\n",
      "2017-05-28 11:50:56.121075: step 50780, loss = 0.78 (299.3 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 11:51:05.796806: step 50790, loss = 0.84 (264.6 examples/sec; 0.968 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14598\n",
      "2017-05-28 11:51:17.430884: step 50800, loss = 0.84 (220.0 examples/sec; 1.163 sec/batch)\n",
      "2017-05-28 11:51:25.163398: step 50810, loss = 0.75 (331.1 examples/sec; 0.773 sec/batch)\n",
      "2017-05-28 11:51:33.509691: step 50820, loss = 0.66 (306.7 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 11:51:42.103145: step 50830, loss = 0.83 (297.9 examples/sec; 0.859 sec/batch)\n",
      "2017-05-28 11:51:50.023842: step 50840, loss = 0.62 (323.2 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 11:51:58.560156: step 50850, loss = 0.72 (299.9 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 11:52:07.125213: step 50860, loss = 0.62 (298.9 examples/sec; 0.857 sec/batch)\n",
      "2017-05-28 11:52:15.133315: step 50870, loss = 0.83 (319.7 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 11:52:24.070695: step 50880, loss = 0.75 (286.4 examples/sec; 0.894 sec/batch)\n",
      "2017-05-28 11:52:34.072319: step 50890, loss = 0.75 (256.0 examples/sec; 1.000 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13084\n",
      "2017-05-28 11:52:45.866536: step 50900, loss = 0.77 (217.1 examples/sec; 1.179 sec/batch)\n",
      "2017-05-28 11:52:53.537722: step 50910, loss = 0.76 (333.7 examples/sec; 0.767 sec/batch)\n",
      "2017-05-28 11:53:01.860697: step 50920, loss = 0.67 (307.6 examples/sec; 0.832 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 50923 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 11:53:11.204953: step 50930, loss = 0.72 (274.0 examples/sec; 0.934 sec/batch)\n",
      "2017-05-28 11:53:19.649110: step 50940, loss = 0.76 (303.2 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 11:53:28.102158: step 50950, loss = 0.71 (302.8 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 11:53:36.733610: step 50960, loss = 0.76 (296.6 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 11:53:45.890513: step 50970, loss = 0.70 (279.6 examples/sec; 0.916 sec/batch)\n",
      "2017-05-28 11:53:54.870933: step 50980, loss = 0.70 (285.1 examples/sec; 0.898 sec/batch)\n",
      "2017-05-28 11:54:03.602773: step 50990, loss = 0.78 (293.2 examples/sec; 0.873 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13093\n",
      "2017-05-28 11:54:14.288267: step 51000, loss = 0.72 (239.6 examples/sec; 1.069 sec/batch)\n",
      "2017-05-28 11:54:22.859699: step 51010, loss = 0.75 (298.7 examples/sec; 0.857 sec/batch)\n",
      "2017-05-28 11:54:31.416121: step 51020, loss = 0.74 (299.2 examples/sec; 0.856 sec/batch)\n",
      "2017-05-28 11:54:39.829530: step 51030, loss = 0.81 (304.3 examples/sec; 0.841 sec/batch)\n",
      "2017-05-28 11:54:48.480638: step 51040, loss = 0.86 (295.9 examples/sec; 0.865 sec/batch)\n",
      "2017-05-28 11:54:57.382283: step 51050, loss = 0.76 (287.6 examples/sec; 0.890 sec/batch)\n",
      "2017-05-28 11:55:05.597108: step 51060, loss = 0.89 (311.6 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 11:55:13.600920: step 51070, loss = 0.71 (319.8 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 11:55:22.343182: step 51080, loss = 0.66 (292.8 examples/sec; 0.874 sec/batch)\n",
      "2017-05-28 11:55:31.068478: step 51090, loss = 0.70 (293.4 examples/sec; 0.873 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13136\n",
      "2017-05-28 11:55:42.675489: step 51100, loss = 0.82 (220.6 examples/sec; 1.161 sec/batch)\n",
      "2017-05-28 11:55:50.759142: step 51110, loss = 0.73 (316.7 examples/sec; 0.808 sec/batch)\n",
      "2017-05-28 11:55:59.078994: step 51120, loss = 0.66 (307.7 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 11:56:07.476506: step 51130, loss = 0.79 (304.9 examples/sec; 0.840 sec/batch)\n",
      "2017-05-28 11:56:16.281811: step 51140, loss = 0.84 (290.7 examples/sec; 0.881 sec/batch)\n",
      "2017-05-28 11:56:26.121505: step 51150, loss = 0.98 (260.2 examples/sec; 0.984 sec/batch)\n",
      "2017-05-28 11:56:34.450199: step 51160, loss = 0.66 (307.4 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 11:56:43.229377: step 51170, loss = 0.78 (291.6 examples/sec; 0.878 sec/batch)\n",
      "2017-05-28 11:56:51.861114: step 51180, loss = 0.73 (296.6 examples/sec; 0.863 sec/batch)\n",
      "2017-05-28 11:56:59.756824: step 51190, loss = 0.70 (324.2 examples/sec; 0.790 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1057\n",
      "2017-05-28 11:57:13.113848: step 51200, loss = 0.77 (191.7 examples/sec; 1.336 sec/batch)\n",
      "2017-05-28 11:57:20.343271: step 51210, loss = 0.79 (354.1 examples/sec; 0.723 sec/batch)\n",
      "2017-05-28 11:57:28.291404: step 51220, loss = 0.81 (322.1 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 11:57:37.084998: step 51230, loss = 0.72 (291.1 examples/sec; 0.879 sec/batch)\n",
      "2017-05-28 11:57:45.959061: step 51240, loss = 0.86 (288.5 examples/sec; 0.887 sec/batch)\n",
      "2017-05-28 11:57:54.301719: step 51250, loss = 0.72 (306.9 examples/sec; 0.834 sec/batch)\n",
      "2017-05-28 11:58:02.604431: step 51260, loss = 0.76 (308.3 examples/sec; 0.830 sec/batch)\n",
      "2017-05-28 11:58:10.636320: step 51270, loss = 0.65 (318.7 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 11:58:18.743810: step 51280, loss = 0.71 (315.8 examples/sec; 0.811 sec/batch)\n",
      "2017-05-28 11:58:26.584328: step 51290, loss = 0.79 (326.5 examples/sec; 0.784 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1838\n",
      "2017-05-28 11:58:37.589389: step 51300, loss = 0.83 (232.6 examples/sec; 1.101 sec/batch)\n",
      "2017-05-28 11:58:45.001899: step 51310, loss = 0.74 (345.4 examples/sec; 0.741 sec/batch)\n",
      "2017-05-28 11:58:52.796553: step 51320, loss = 0.72 (328.4 examples/sec; 0.779 sec/batch)\n",
      "2017-05-28 11:59:00.690321: step 51330, loss = 0.77 (324.3 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 11:59:08.592400: step 51340, loss = 0.67 (324.0 examples/sec; 0.790 sec/batch)\n",
      "2017-05-28 11:59:16.411623: step 51350, loss = 0.83 (327.4 examples/sec; 0.782 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 11:59:24.952356: step 51360, loss = 0.61 (299.7 examples/sec; 0.854 sec/batch)\n",
      "2017-05-28 11:59:32.970232: step 51370, loss = 0.79 (319.3 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 11:59:40.995737: step 51380, loss = 0.75 (319.0 examples/sec; 0.803 sec/batch)\n",
      "2017-05-28 11:59:48.826454: step 51390, loss = 0.78 (326.9 examples/sec; 0.783 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21846\n",
      "2017-05-28 11:59:59.658503: step 51400, loss = 0.76 (236.3 examples/sec; 1.083 sec/batch)\n",
      "2017-05-28 12:00:08.128410: step 51410, loss = 0.79 (302.2 examples/sec; 0.847 sec/batch)\n",
      "2017-05-28 12:00:16.925865: step 51420, loss = 0.71 (291.0 examples/sec; 0.880 sec/batch)\n",
      "2017-05-28 12:00:25.116147: step 51430, loss = 0.82 (312.6 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 12:00:33.805595: step 51440, loss = 0.74 (294.6 examples/sec; 0.869 sec/batch)\n",
      "2017-05-28 12:00:42.333602: step 51450, loss = 0.77 (300.2 examples/sec; 0.853 sec/batch)\n",
      "2017-05-28 12:00:50.883411: step 51460, loss = 0.71 (299.4 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 12:00:59.722584: step 51470, loss = 0.84 (289.6 examples/sec; 0.884 sec/batch)\n",
      "2017-05-28 12:01:08.229527: step 51480, loss = 0.83 (300.9 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 12:01:17.375576: step 51490, loss = 0.72 (279.9 examples/sec; 0.915 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.1211\n",
      "2017-05-28 12:01:28.856119: step 51500, loss = 0.70 (223.0 examples/sec; 1.148 sec/batch)\n",
      "2017-05-28 12:01:37.663028: step 51510, loss = 0.77 (290.7 examples/sec; 0.881 sec/batch)\n",
      "2017-05-28 12:01:47.028902: step 51520, loss = 0.78 (273.3 examples/sec; 0.937 sec/batch)\n",
      "2017-05-28 12:01:55.090475: step 51530, loss = 0.66 (317.6 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 12:02:03.384335: step 51540, loss = 0.72 (308.7 examples/sec; 0.829 sec/batch)\n",
      "2017-05-28 12:02:11.937705: step 51550, loss = 0.71 (299.3 examples/sec; 0.855 sec/batch)\n",
      "2017-05-28 12:02:20.095320: step 51560, loss = 0.93 (313.8 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 12:02:28.304045: step 51570, loss = 0.82 (311.9 examples/sec; 0.821 sec/batch)\n",
      "2017-05-28 12:02:36.350723: step 51580, loss = 0.74 (318.1 examples/sec; 0.805 sec/batch)\n",
      "2017-05-28 12:02:44.426184: step 51590, loss = 0.77 (317.0 examples/sec; 0.808 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12103\n",
      "2017-05-28 12:02:58.062063: step 51600, loss = 0.69 (187.7 examples/sec; 1.364 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 51609 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 12:03:06.580805: step 51610, loss = 0.59 (300.5 examples/sec; 0.852 sec/batch)\n",
      "2017-05-28 12:03:14.529437: step 51620, loss = 0.76 (322.1 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 12:03:23.007830: step 51630, loss = 0.89 (301.9 examples/sec; 0.848 sec/batch)\n",
      "2017-05-28 12:03:31.334928: step 51640, loss = 0.80 (307.4 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 12:03:39.579562: step 51650, loss = 0.71 (310.5 examples/sec; 0.824 sec/batch)\n",
      "2017-05-28 12:03:47.722879: step 51660, loss = 0.78 (314.4 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 12:03:56.780591: step 51670, loss = 0.79 (282.6 examples/sec; 0.906 sec/batch)\n",
      "2017-05-28 12:04:05.849519: step 51680, loss = 0.78 (282.3 examples/sec; 0.907 sec/batch)\n",
      "2017-05-28 12:04:15.024950: step 51690, loss = 0.84 (279.0 examples/sec; 0.918 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12379\n",
      "2017-05-28 12:04:27.045352: step 51700, loss = 0.80 (213.0 examples/sec; 1.202 sec/batch)\n",
      "2017-05-28 12:04:35.934280: step 51710, loss = 0.68 (288.0 examples/sec; 0.889 sec/batch)\n",
      "2017-05-28 12:04:45.079345: step 51720, loss = 0.77 (279.9 examples/sec; 0.915 sec/batch)\n",
      "2017-05-28 12:04:54.197082: step 51730, loss = 0.64 (280.8 examples/sec; 0.912 sec/batch)\n",
      "2017-05-28 12:05:03.097712: step 51740, loss = 0.66 (287.6 examples/sec; 0.890 sec/batch)\n",
      "2017-05-28 12:05:11.527689: step 51750, loss = 0.68 (303.7 examples/sec; 0.843 sec/batch)\n",
      "2017-05-28 12:05:20.237283: step 51760, loss = 0.74 (293.9 examples/sec; 0.871 sec/batch)\n",
      "2017-05-28 12:05:28.235759: step 51770, loss = 0.71 (320.1 examples/sec; 0.800 sec/batch)\n",
      "2017-05-28 12:05:36.251499: step 51780, loss = 0.93 (319.4 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 12:05:45.237981: step 51790, loss = 0.74 (284.9 examples/sec; 0.899 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.11671\n",
      "2017-05-28 12:05:56.593642: step 51800, loss = 0.69 (225.4 examples/sec; 1.136 sec/batch)\n",
      "2017-05-28 12:06:03.949247: step 51810, loss = 0.73 (348.0 examples/sec; 0.736 sec/batch)\n",
      "2017-05-28 12:06:11.965046: step 51820, loss = 0.62 (319.4 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 12:06:20.784937: step 51830, loss = 0.65 (290.3 examples/sec; 0.882 sec/batch)\n",
      "2017-05-28 12:06:29.906237: step 51840, loss = 0.64 (280.7 examples/sec; 0.912 sec/batch)\n",
      "2017-05-28 12:06:37.981158: step 51850, loss = 0.72 (317.0 examples/sec; 0.807 sec/batch)\n",
      "2017-05-28 12:06:46.122327: step 51860, loss = 0.78 (314.5 examples/sec; 0.814 sec/batch)\n",
      "2017-05-28 12:06:54.637150: step 51870, loss = 0.69 (300.7 examples/sec; 0.851 sec/batch)\n",
      "2017-05-28 12:07:04.181841: step 51880, loss = 0.75 (268.2 examples/sec; 0.954 sec/batch)\n",
      "2017-05-28 12:07:12.644472: step 51890, loss = 0.73 (302.5 examples/sec; 0.846 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15587\n",
      "2017-05-28 12:07:23.110769: step 51900, loss = 0.76 (244.6 examples/sec; 1.047 sec/batch)\n",
      "2017-05-28 12:07:30.648698: step 51910, loss = 0.63 (339.6 examples/sec; 0.754 sec/batch)\n",
      "2017-05-28 12:07:38.498580: step 51920, loss = 0.76 (326.1 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 12:07:46.310292: step 51930, loss = 0.75 (327.7 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 12:07:54.098580: step 51940, loss = 0.66 (328.7 examples/sec; 0.779 sec/batch)\n",
      "2017-05-28 12:08:02.287688: step 51950, loss = 0.69 (312.6 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 12:08:10.420198: step 51960, loss = 0.68 (314.8 examples/sec; 0.813 sec/batch)\n",
      "2017-05-28 12:08:18.161447: step 51970, loss = 0.81 (330.7 examples/sec; 0.774 sec/batch)\n",
      "2017-05-28 12:08:26.075989: step 51980, loss = 0.74 (323.5 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 12:08:33.996437: step 51990, loss = 0.66 (323.2 examples/sec; 0.792 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22146\n",
      "2017-05-28 12:08:44.979633: step 52000, loss = 0.77 (233.1 examples/sec; 1.098 sec/batch)\n",
      "2017-05-28 12:08:52.315610: step 52010, loss = 0.65 (349.0 examples/sec; 0.734 sec/batch)\n",
      "2017-05-28 12:09:00.225287: step 52020, loss = 0.75 (323.7 examples/sec; 0.791 sec/batch)\n",
      "2017-05-28 12:09:08.371515: step 52030, loss = 0.70 (314.3 examples/sec; 0.815 sec/batch)\n",
      "2017-05-28 12:09:16.217929: step 52040, loss = 0.77 (326.3 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 12:09:24.053359: step 52050, loss = 0.70 (326.7 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 12:09:31.896344: step 52060, loss = 0.81 (326.4 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 12:09:40.155132: step 52070, loss = 0.82 (310.0 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 12:09:48.139856: step 52080, loss = 0.64 (320.6 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 12:09:56.013785: step 52090, loss = 0.74 (325.1 examples/sec; 0.787 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22543\n",
      "2017-05-28 12:10:06.581111: step 52100, loss = 0.71 (242.3 examples/sec; 1.057 sec/batch)\n",
      "2017-05-28 12:10:13.882702: step 52110, loss = 0.68 (350.6 examples/sec; 0.730 sec/batch)\n",
      "2017-05-28 12:10:21.717343: step 52120, loss = 0.82 (326.8 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 12:10:30.156822: step 52130, loss = 0.84 (303.3 examples/sec; 0.844 sec/batch)\n",
      "2017-05-28 12:10:38.371955: step 52140, loss = 0.84 (311.6 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 12:10:46.238390: step 52150, loss = 0.70 (325.4 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 12:10:54.067562: step 52160, loss = 0.86 (327.0 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 12:11:01.905300: step 52170, loss = 0.67 (326.6 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 12:11:09.773658: step 52180, loss = 0.88 (325.4 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 12:11:17.635458: step 52190, loss = 0.72 (325.6 examples/sec; 0.786 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.2072\n",
      "2017-05-28 12:11:29.421908: step 52200, loss = 0.75 (217.2 examples/sec; 1.179 sec/batch)\n",
      "2017-05-28 12:11:36.829931: step 52210, loss = 0.77 (345.6 examples/sec; 0.741 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-28 12:11:44.661695: step 52220, loss = 0.81 (326.9 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 12:11:52.531873: step 52230, loss = 0.78 (325.3 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 12:12:00.448200: step 52240, loss = 0.65 (323.4 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 12:12:08.728597: step 52250, loss = 0.73 (309.2 examples/sec; 0.828 sec/batch)\n",
      "2017-05-28 12:12:16.786182: step 52260, loss = 0.72 (317.7 examples/sec; 0.806 sec/batch)\n",
      "2017-05-28 12:12:24.676065: step 52270, loss = 0.84 (324.5 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 12:12:32.600707: step 52280, loss = 0.83 (323.0 examples/sec; 0.792 sec/batch)\n",
      "2017-05-28 12:12:40.579884: step 52290, loss = 0.65 (320.8 examples/sec; 0.798 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21774\n",
      "2017-05-28 12:12:51.537486: step 52300, loss = 0.75 (233.6 examples/sec; 1.096 sec/batch)\n",
      "2017-05-28 12:12:59.189604: step 52310, loss = 0.69 (334.5 examples/sec; 0.765 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 52317 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 12:13:08.116113: step 52320, loss = 0.73 (286.8 examples/sec; 0.893 sec/batch)\n",
      "2017-05-28 12:13:15.998946: step 52330, loss = 0.69 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 12:13:24.008844: step 52340, loss = 0.77 (319.6 examples/sec; 0.801 sec/batch)\n",
      "2017-05-28 12:13:32.272126: step 52350, loss = 0.78 (309.8 examples/sec; 0.826 sec/batch)\n",
      "2017-05-28 12:13:40.145640: step 52360, loss = 0.70 (325.1 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 12:13:47.952139: step 52370, loss = 0.71 (327.9 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 12:13:56.144267: step 52380, loss = 0.76 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-28 12:14:04.122757: step 52390, loss = 0.75 (320.9 examples/sec; 0.798 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19562\n",
      "2017-05-28 12:14:15.178864: step 52400, loss = 0.69 (231.5 examples/sec; 1.106 sec/batch)\n",
      "2017-05-28 12:14:22.554072: step 52410, loss = 0.86 (347.1 examples/sec; 0.738 sec/batch)\n",
      "2017-05-28 12:14:30.407595: step 52420, loss = 0.68 (326.0 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 12:14:38.256316: step 52430, loss = 0.65 (326.2 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 12:14:46.119176: step 52440, loss = 0.70 (325.6 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 12:14:53.953151: step 52450, loss = 0.83 (326.8 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 12:15:01.790864: step 52460, loss = 0.68 (326.6 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 12:15:09.677229: step 52470, loss = 0.69 (324.6 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 12:15:18.001402: step 52480, loss = 0.84 (307.5 examples/sec; 0.832 sec/batch)\n",
      "2017-05-28 12:15:25.835172: step 52490, loss = 0.73 (326.8 examples/sec; 0.783 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22681\n",
      "2017-05-28 12:15:36.687118: step 52500, loss = 0.78 (235.9 examples/sec; 1.085 sec/batch)\n",
      "2017-05-28 12:15:44.077465: step 52510, loss = 0.78 (346.4 examples/sec; 0.739 sec/batch)\n",
      "2017-05-28 12:15:52.176748: step 52520, loss = 0.69 (316.1 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 12:16:00.529615: step 52530, loss = 0.73 (306.5 examples/sec; 0.835 sec/batch)\n",
      "2017-05-28 12:16:08.384975: step 52540, loss = 0.66 (325.9 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 12:16:16.213977: step 52550, loss = 0.80 (327.0 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 12:16:24.175765: step 52560, loss = 0.69 (321.5 examples/sec; 0.796 sec/batch)\n",
      "2017-05-28 12:16:31.980979: step 52570, loss = 0.71 (328.0 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 12:16:39.907836: step 52580, loss = 0.77 (323.0 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 12:16:48.172309: step 52590, loss = 0.70 (309.8 examples/sec; 0.826 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22073\n",
      "2017-05-28 12:16:58.605071: step 52600, loss = 0.75 (245.4 examples/sec; 1.043 sec/batch)\n",
      "2017-05-28 12:17:05.903280: step 52610, loss = 0.74 (350.8 examples/sec; 0.730 sec/batch)\n",
      "2017-05-28 12:17:13.708937: step 52620, loss = 0.76 (328.0 examples/sec; 0.781 sec/batch)\n",
      "2017-05-28 12:17:21.563129: step 52630, loss = 0.75 (325.9 examples/sec; 0.785 sec/batch)\n",
      "2017-05-28 12:17:29.395998: step 52640, loss = 0.67 (326.8 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 12:17:37.183972: step 52650, loss = 0.71 (328.7 examples/sec; 0.779 sec/batch)\n",
      "2017-05-28 12:17:45.283040: step 52660, loss = 0.71 (316.1 examples/sec; 0.810 sec/batch)\n",
      "2017-05-28 12:17:53.145649: step 52670, loss = 0.79 (325.6 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 12:18:01.098540: step 52680, loss = 0.84 (321.9 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 12:18:08.978881: step 52690, loss = 0.87 (324.9 examples/sec; 0.788 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21725\n",
      "2017-05-28 12:18:20.757982: step 52700, loss = 0.86 (217.3 examples/sec; 1.178 sec/batch)\n",
      "2017-05-28 12:18:28.063398: step 52710, loss = 0.75 (350.4 examples/sec; 0.731 sec/batch)\n",
      "2017-05-28 12:18:35.944821: step 52720, loss = 0.61 (324.8 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 12:18:43.837015: step 52730, loss = 0.83 (324.4 examples/sec; 0.789 sec/batch)\n",
      "2017-05-28 12:18:51.822762: step 52740, loss = 0.70 (320.6 examples/sec; 0.799 sec/batch)\n",
      "2017-05-28 12:19:00.269966: step 52750, loss = 0.85 (303.1 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 12:19:08.718547: step 52760, loss = 0.77 (303.0 examples/sec; 0.845 sec/batch)\n",
      "2017-05-28 12:19:17.044876: step 52770, loss = 0.73 (307.5 examples/sec; 0.833 sec/batch)\n",
      "2017-05-28 12:19:25.022161: step 52780, loss = 0.76 (320.9 examples/sec; 0.798 sec/batch)\n",
      "2017-05-28 12:19:33.291318: step 52790, loss = 0.60 (309.6 examples/sec; 0.827 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19111\n",
      "2017-05-28 12:19:44.717440: step 52800, loss = 0.82 (224.0 examples/sec; 1.143 sec/batch)\n",
      "2017-05-28 12:19:52.303556: step 52810, loss = 0.81 (337.5 examples/sec; 0.759 sec/batch)\n",
      "2017-05-28 12:20:00.178639: step 52820, loss = 0.77 (325.1 examples/sec; 0.788 sec/batch)\n",
      "2017-05-28 12:20:08.107204: step 52830, loss = 0.78 (322.9 examples/sec; 0.793 sec/batch)\n",
      "2017-05-28 12:20:15.911663: step 52840, loss = 0.75 (328.0 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 12:20:23.685160: step 52850, loss = 0.72 (329.3 examples/sec; 0.777 sec/batch)\n",
      "2017-05-28 12:20:31.704647: step 52860, loss = 0.68 (319.2 examples/sec; 0.802 sec/batch)\n",
      "2017-05-28 12:20:39.547992: step 52870, loss = 0.65 (326.4 examples/sec; 0.784 sec/batch)\n",
      "2017-05-28 12:20:47.379606: step 52880, loss = 0.80 (326.9 examples/sec; 0.783 sec/batch)\n",
      "2017-05-28 12:20:55.241012: step 52890, loss = 0.75 (325.6 examples/sec; 0.786 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.2096\n",
      "2017-05-28 12:21:07.385255: step 52900, loss = 0.76 (210.8 examples/sec; 1.214 sec/batch)\n",
      "2017-05-28 12:21:14.603810: step 52910, loss = 0.92 (354.6 examples/sec; 0.722 sec/batch)\n",
      "2017-05-28 12:21:22.554989: step 52920, loss = 0.77 (322.0 examples/sec; 0.795 sec/batch)\n",
      "2017-05-28 12:21:30.413682: step 52930, loss = 0.81 (325.8 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 12:21:38.629120: step 52940, loss = 0.83 (311.6 examples/sec; 0.822 sec/batch)\n",
      "2017-05-28 12:21:46.789798: step 52950, loss = 0.77 (313.7 examples/sec; 0.816 sec/batch)\n",
      "2017-05-28 12:21:54.658327: step 52960, loss = 0.87 (325.3 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 12:22:02.531331: step 52970, loss = 0.68 (325.2 examples/sec; 0.787 sec/batch)\n",
      "2017-05-28 12:22:10.388533: step 52980, loss = 0.62 (325.8 examples/sec; 0.786 sec/batch)\n",
      "2017-05-28 12:22:18.410424: step 52990, loss = 0.76 (319.1 examples/sec; 0.802 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20612\n",
      "2017-05-28 12:22:30.299519: step 53000, loss = 0.74 (215.3 examples/sec; 1.189 sec/batch)\n",
      "2017-05-28 12:22:37.818198: step 53010, loss = 0.74 (340.5 examples/sec; 0.752 sec/batch)\n",
      "2017-05-28 12:22:45.642329: step 53020, loss = 0.74 (327.2 examples/sec; 0.782 sec/batch)\n",
      "2017-05-28 12:22:53.437772: step 53030, loss = 0.67 (328.4 examples/sec; 0.780 sec/batch)\n",
      "2017-05-28 12:23:01.305903: step 53040, loss = 0.77 (325.4 examples/sec; 0.787 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 53045 into /home/ipython/cnn-cifar10/tb_log/res2/train/model.ckpt.\n",
      "2017-05-28 12:23:10.626427: step 53050, loss = 0.82 (274.7 examples/sec; 0.932 sec/batch)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9047975394a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mArguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcifar10_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ipython/cnn-cifar10/cifar10/cifar10_train.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m             log_device_placement=Arguments.log_device_placement)) as mon_sess:\n\u001b[1;32m    100\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    482\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    818\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    821\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    928\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "Arguments.set_model_folder(\"res2\")\n",
    "print(Arguments.train_dir)\n",
    "\n",
    "cifar10_train.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
